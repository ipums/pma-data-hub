[
  {
    "path": "posts/2023-02-15-abor-reg/",
    "title": "Comparing Measures of Abortion Incidence with a Shiny Dashboard",
    "description": "New abortion data from PMA includes women who reported doing something to remove a pregnancy, or to regulate a late period because of a suspected pregnancy.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      },
      {
        "name": "Devon Kristiansen",
        "url": "https://www.linkedin.com/in/devonkristiansen"
      }
    ],
    "date": "2023-02-15",
    "categories": [
      "Data Analysis",
      "Abortion",
      "shiny",
      "dplyr"
    ],
    "contents": "\n\nContents\nSetup\nAnalytic Dataset\nSummary statistics\nIncidence by education\nOther groups\n\nShiny Dashboard\n\nWhen we announced the release of new longitudinal data from PMA this month, we mentioned two surveys from Côte d’Ivoire and Nigeria that include a special focus on women’s experiences seeking and accessing abortion services.\nBoth surveys are follow-up interviews with a subset of women who participated in a nationally representative, cross-sectional survey conducted in 2018. These are women who responded “yes” in 2018 to one of these questions:\nHave you ever done something to remove a pregnancy when you were pregnant or worried you were pregnant?\nHave you ever done something to regulate your period when you were worried you were pregnant?\nWhy do PMA surveys include multiple ways of asking about abortion? The answer, explained by Bell and Fissell (2021, pg. 507), is that conventional measures of abortion incidence are prone to substantial underreporting if they fail to account for procedures undertaken when a woman’s pregnancy status is ambiguous:\n\nFor example, most surveys studying induced abortion unambiguously ask women about actions they may have taken to end a pregnancy, but such questions leave no room to account for women’s actions that consciously or unconsciously attempt to regulate fertility in the period of time that we are characterizing as ambiguous, neither pregnant nor nonpregnant. Nor can we say that there is a simple third state of “maybe pregnant”; both ethnographic and historical data suggest that complex mixtures of perception and denial, a wide range of models of the reproductive body, and myriad other factors create rich and complex ambiguity rather than merely a simple third state.\n\n\nBell and Fissell (2021) in Population and Development Review 47(2)\nElsewhere, Bell et al. (2020a; 2020b) discuss methods for estimating abortion incidence with both of these 2018 PMA samples. They demonstrate how to estimate incidence with:\nAffirmative responses only to the pregnancy removal question\nAffirmative responses to either question\nAn average of both of the above measures.1\nIn this post, we’ll share code you can use to reproduce the abortion incidence shown in both of these publications.\nBecause readers may wish to compare the authors’ final averaged measure against the incidence derived from either or both of the source questions, this is a particularly good opportunity to leverage an interactive dashboard built with the shiny package for R.\nIn this case, we’ll want to allow the user to switch between samples, incidence measures, and several disaggregation variables representing each woman’s:\nage\neducation\nhousehold wealth\nmarital status\narea of residence (urban / rural)\nSetup\nThroughout this ongoing series on PMA abortion data, we’ll be showcasing the same longitudinal (wide format) extract downloaded from IPUMS PMA. For this post, we’ll focus only on responses from the 2018 baseline surveys in both Côte d’Ivoire and Nigeria - over the next few weeks, we’ll also investigate abortion data collected each woman’s closest confidantes, and on her responses to the abortion follow-up survey conducted in 2019-2020.\nTo follow along, you’ll need to select a longitudinal (wide format) with Female Respondents only - these are women who completed the 2018 baseline survey (even if they were not included in the 2019-2020 follow-up). You’ll also need the following variables:\nCOUNTRY - country of residence\nFQWEIGHT - sampling weight for 2018 survey\nEAID - sample cluster (enumeration area)\nSTRATA - sample strata\nINTFQCMC - CMC for date of 2018 interview\nAGE - age\nURBAN - area of residence (urban / rural)\nEDUCATTGEN - education\nWEALTHQ - household wealth\nMARSTAT - marital status\nABORYR - year of last aborted pregnancy\nREGYR - year of regulated period\nIn our extract, these variables will each appear twice: those ending with _1 come from the 2018 baseline surveys, with those ending with _2 come from the 2019-2020 follow-ups. Today’s analysis will focus only on the former.\nAfter your extract has been downloaded and saved to a data folder in your working directory, attach the following packages and load your extract as an object named pma.\n\n\nlibrary(tidyverse)\nlibrary(ipumsr)\nlibrary(srvyr)\n\npma <- read_ipums_micro(\n  ddi = \"data/pma_00192.xml\",\n  data = \"data/pma_00192.dat.gz\"\n)\n\n\n\n\n\nNext, drop any women who are not part of the de facto population - in these samples, women outside of this population have a sampling weight of 0 in FQWEIGHT_1.\n\n\npma <- pma %>% filter(FQWEIGHT_1 != 0)\n\n\nAnalytic Dataset\nNow, we’ll build an analytic dataset dat derived from the variables shown above. Most importantly, we’ll need to consider how Bell et al. report abortion incidence: they show an estimated annual abortion count per 1,000 women in each country.\nThe variables ABORYR and REGYR report the calendar year for each woman’s most recent pregnancy termination and period regulation, but PMA does not collect the precise month in which each event might have occurred.\nBecause of this limitation, we’ll include any procedure undertaken throughout all of the 2017 calendar year and any month before each woman’s 2018 interview. Create these four variables:\nabor indicating whether the woman’s most recent pregnancy termination occurred after January 1, 2017\nreg indicating whether the woman’s most recent period regulation occurred after January 1, 2017\nany indicating whether the woman’s most recent pregnancy termination or period regulation occurred after January 1, 2017\navg the mean value of abor and any (reported by Bell et al.)\nyrs - the number of months between January 1, 2017 and the date of a woman’s interview divided by 12 (e.g. 1.5 represents 18 months)\n\n2018 interviews Nigeria were conducted between March and June; those for Côte d’Ivoire were conducted between July and August.\n\n\ndat <- pma %>% \n  mutate(\n    .keep = \"none\",\n    reg = REGYR_1 %in% 2017:2018,\n    abor = ABORYR_1 %in% 2017:2018,\n    any = reg | abor,\n    avg = pick(abor, any) %>% rowMeans,\n    yrs = (INTFQCMC_1 - 1405)/12, # Jan 2017 as CMC = 1405\n  )\n\n\ntransmute was superseded in favor of mutate(.keep = \"none\") in the latest major version of dplyr (version 1.0.0). We use this to drop any variables from pma that aren’t created directly by mutate.\nNext, we’ll consider how to disaggregate abortion incidence measures in groups defined by those variables mentioned above. It will be helpful to create a few meaningful categories for each variable, and then transform the result into a factor (this will control the ordering of categories along the x-axis in our final plots). We’ll also create a variable all to show the overall abortion incidence for all women of reproductive age in each country.\n\n\ndat <- pma %>% \n  mutate(\n    .keep = \"none\",\n    age = AGE_1 %>% \n      case_match(\n        15:19 ~ \"15-19\",\n        20:24 ~ \"20-24\",\n        25:29 ~ \"25-29\",\n        30:34 ~ \"30-34\",\n        35:39 ~ \"35-39\",\n        40:49 ~ \"40+\",\n      ) %>% \n      fct_relevel(\"15-19\",\"20-24\",\"25-29\",\"30-34\",\"35-39\"),\n    urban = URBAN %>% as_factor(),\n    edu = EDUCATTGEN_1 %>% \n      case_match(\n        1 ~ \"Never\",\n        2 ~ \"Primary\",\n        3 ~ \"Secondary\",\n        4 ~ \"Higher\"\n      ) %>% \n      fct_relevel(\"Never\", \"Primary\", \"Secondary\"),\n    wealth = WEALTHQ_1 %>% \n      as_factor() %>% \n      str_remove(\" quintile\") %>% \n      fct_relevel(\"Lowest\", \"Lower\", \"Middle\", \"Higher\"),\n    marstat = MARSTAT_1 %>% \n      case_match(\n        10 ~ \"Never Married\",\n        21:22 ~ \"Partnered\",\n        31:32 ~ \"Separated / Widowed\"\n      ) %>% \n      fct_relevel(\"Never Married\", \"Partnered\"),\n    all = \"All\" \n  ) %>% \n  bind_cols(dat)\n\n\ncase_match was introduced in the latest major version of dplyr (version 1.0.0). Designed as a replacement for recode, it allows you to use case_when syntax to remap values (read more here).\nfct_relevel is a sort-of clumsy way to create a factor from each case_match and to organize its levels. Look for a more efficient solution in the upcoming version of forcats!\nFinally, we’ll tweak the remaining technical variables for improved readability.\n\n\ndat <- pma %>% \n  mutate(\n    .keep = \"none\",\n    country = COUNTRY %>% as_factor, \n    weight = FQWEIGHT_1 %>% zap_labels,\n    eaid = EAID_1 %>% zap_labels,\n    strata = STRATA_1 %>% zap_labels,\n  ) %>% \n  bind_cols(dat)\n\n\n\n\n\nSummary statistics\n\n\n\nYour analytic dataset should now look something like this:\n\n\ndat \n\n# A tibble: 13,844 × 15\n   country  weight  eaid strata   yrs age   urban edu   wealth marstat all   reg   abor  any     avg\n   <fct>     <dbl> <dbl>  <int> <dbl> <fct> <fct> <fct> <fct>  <fct>   <chr> <lgl> <lgl> <lgl> <dbl>\n 1 Cote d'…  0.574 11543  38401  1.5  30-34 Urban Seco… Higher Partne… All   FALSE FALSE FALSE   0  \n 2 Cote d'…  1.26  11498  38401  1.5  15-19 Urban Never Highe… Never … All   FALSE FALSE FALSE   0  \n 3 Cote d'…  0.766 11148  38402  1.5  20-24 Rural Prim… Middle Partne… All   FALSE FALSE FALSE   0  \n 4 Cote d'…  0.983 11142  38401  1.5  15-19 Urban Seco… Higher Never … All   FALSE FALSE FALSE   0  \n 5 Cote d'…  1.45  11279  38401  1.5  30-34 Urban Seco… Highe… Never … All   FALSE FALSE FALSE   0  \n 6 Cote d'…  0.653 11989  38401  1.5  40+   Urban Never Middle Separa… All   FALSE FALSE FALSE   0  \n 7 Cote d'…  1.15  11040  38402  1.58 40+   Rural Prim… Middle Separa… All   FALSE FALSE FALSE   0  \n 8 Cote d'…  0.627 11331  38401  1.58 15-19 Urban Prim… Highe… Never … All   FALSE FALSE FALSE   0  \n 9 Cote d'…  0.875 11898  38401  1.5  20-24 Urban High… Higher Never … All   TRUE  FALSE TRUE    0.5\n10 Cote d'…  0.983 11142  38401  1.5  25-29 Urban Never Highe… Partne… All   FALSE FALSE FALSE   0  \n# … with 13,834 more rows\n\nIf so, you’re ready to calculate incidence measures for each of the derived variables reg, abor, any, and avg. Because our data extract includes two completely independent samples (one per country), we’ll need to think about three iterative steps:\nWe’ll cycle once through the data collected from each country\nWithin the data for each country, we’ll cycle through each of our disaggregation variables\nFor each of those variables, we’ll calculate one estimate (and a 95% confidence interval) for each of our four abortion incidence measures\nBefore we show how to write code that performs each of these steps in sequence, let’s start with a simple example.\nIncidence by education\nSuppose we only wanted to estimate incidence via pregnancy termination (leaving aside period regulation) for women sorted by educational attainment in Nigeria.\nBell and Fissell (2021, pg 520) point to differences in education as a possible source of error in measures of incidence like those derived from our variable abor (termination only).\n\n…if more educated women are more likely to interpret a missed menses as a possible pregnancy and to seek out pregnancy confirmation, researchers may be more likely to capture their behaviors with traditional questions regarding induced abortion/ending a pregnancy. Conversely, if less-educated women are less likely to view their experience in these terms, we may disproportionally underestimate their post-coital behaviors to attempt to regulate fertility. This difference could result in invalid estimates of these behaviors among different subpopulations.\n\nLet’s check! We’ll first define information about the Nigeria survey design and then group_by our education variable edu (dropping any missing values only afterward to preserve the correct degrees of freedom from our full sample).2\n\n\ndat %>% \n  filter(country == \"Nigeria\") %>% \n  as_survey_design(weight = weight, id = eaid, strata = strata, nest = TRUE) %>% \n  filter(!is.na(edu)) %>%\n  group_by(edu) %>% \n  summarise(1000 * survey_mean(abor /yrs, vartype = \"ci\", proportion = TRUE))\n\n# A tibble: 4 × 4\n  edu        coef `_low` `_upp`\n  <fct>     <dbl>  <dbl>  <dbl>\n1 Never      6.32   3.19   12.5\n2 Primary   15.2   10.1    22.6\n3 Secondary 24.2   19.3    30.4\n4 Higher    24.8   16.1    38.0\n\nIf we only use abor, we estimate that about 6 in 1,000 women with no formal education will report an abortion within one year. Conversely, 24 in 1,000 women with secondary education or higher education report an abortion within one year: the proportions for these groups are nearly quadrupled compared with women with no formal education! This disparity seems to support Bell and Fissell’s argument, but we’ll want to generate estimates from our other abortion measures for further context.\nHere, we’ll use across to iterate over each of our measures - including avg, corresponding with the results reported in Bell et al. (2020b).\n\n\ndat %>% \n  filter(country == \"Nigeria\") %>% \n  reframe(across(\n    c(reg, abor, any, avg), \n    ~pick(everything()) %>% \n      as_survey_design(weight = weight, id = eaid, strata = strata, nest = TRUE) %>% \n      group_by(edu) %>% \n      summarise(1000 * survey_mean(.x / yrs, vartype = \"ci\", proportion = TRUE))\n  )) %>% \n  pivot_longer(where(is.list), names_to = \"measure\")\n\n# A tibble: 16 × 2\n   measure value$edu $coef $`_low` $`_upp`\n   <chr>   <fct>     <dbl>   <dbl>   <dbl>\n 1 reg     Never      8.88    4.66    16.9\n 2 abor    Never      6.32    3.19    12.5\n 3 any     Never     13.6     8.17    22.5\n 4 avg     Never      9.95    5.94    16.6\n 5 reg     Primary   21.3    14.0     32.2\n 6 abor    Primary   15.2    10.1     22.6\n 7 any     Primary   33.8    24.8     46.0\n 8 avg     Primary   24.5    18.0     33.3\n 9 reg     Secondary 29.2    20.6     41.3\n10 abor    Secondary 24.2    19.3     30.4\n11 any     Secondary 48.7    38.5     61.4\n12 avg     Secondary 36.5    29.5     44.9\n13 reg     Higher    33.1    23.2     47.1\n14 abor    Higher    24.8    16.1     38.0\n15 any     Higher    56.5    43.2     73.6\n16 avg     Higher    40.7    30.5     54.1\n\ncur_data was deprecated in favor of pick in the latest major version of dplyr (version 1.0.0). We use this to reference all other variables as we iterate through through each of our abortion measures.\nAlso: note our use of reframe - generally this replaces summarise for operations resulting in multiple rows. For now, you must still use summarise for functions following as_survey_design.\nNotice here that the number of women with no formal education reporting an abortion roughly doubles (from 6 in 1,000 to nearly 14) if we define incidence with any (either pregnancy termination or period regulation). The measure avg puts our estimate directly between abor and any at about 10 in 1,000 women.\nOther groups\nAs a reader, wouldn’t it be nice to be able to cycle through multiple samples and disaggregation measures? Next, we’ll build an summary table that we can incorporate into an application that will do exactly that!\nBuilding on the previous example, we’ll now iterate through each of the disaggregation measures we’ve discussed. We’ll wrap everything within one larger iteration completed with group_by for each country.\n\n\n\n\n\ndat <- dat %>% \n  group_by(country) %>% \n  reframe(across(\n    c(urban, edu, wealth, marstat, age, all), \n    ~pick(everything()) %>% \n      rename(group = .x) %>% \n      filter(!is.na(group)) %>% \n      reframe(across(\n        c(reg, abor, any, avg), \n        ~pick(everything()) %>% \n          as_survey_design(weight = weight, id = eaid, strata = strata, nest = TRUE) %>% \n          group_by(group) %>% \n          summarise(1000 * survey_mean(.x / yrs, vartype = \"ci\", proportion = TRUE)) \n      )) %>% \n      pivot_longer(where(is.list), names_to = \"measure\") %>% \n      unnest(value) %>% \n      list()\n  )) \n\ndat \n\n# A tibble: 2 × 7\n  country       urban    edu      wealth   marstat  age      all     \n  <fct>         <list>   <list>   <list>   <list>   <list>   <list>  \n1 Nigeria       <tibble> <tibble> <tibble> <tibble> <tibble> <tibble>\n2 Cote d'Ivoire <tibble> <tibble> <tibble> <tibble> <tibble> <tibble>\n\nWe’ll reference each of these lists by country within our shiny app. For example, here are the urban results for each country.\n\n\ndat %>% \n  select(country, urban) %>% \n  unnest(urban)\n\n# A tibble: 16 × 6\n   country       measure group  coef `_low` `_upp`\n   <fct>         <chr>   <fct> <dbl>  <dbl>  <dbl>\n 1 Nigeria       reg     Rural  14.7   8.99   23.9\n 2 Nigeria       abor    Rural  12.7   9.42   17.0\n 3 Nigeria       any     Rural  24.9  17.7    34.8\n 4 Nigeria       avg     Rural  18.8  13.8    25.4\n 5 Nigeria       reg     Urban  33.2  23.6    46.3\n 6 Nigeria       abor    Urban  25.2  18.7    33.8\n 7 Nigeria       any     Urban  54.6  43.0    69.1\n 8 Nigeria       avg     Urban  39.9  31.6    50.2\n 9 Cote d'Ivoire reg     Rural  23.3  12.0    44.9\n10 Cote d'Ivoire abor    Rural  15.5   7.88   30.4\n11 Cote d'Ivoire any     Rural  38.9  20.7    71.9\n12 Cote d'Ivoire avg     Rural  27.2  14.5    50.5\n13 Cote d'Ivoire reg     Urban  19.6  12.7    30.0\n14 Cote d'Ivoire abor    Urban  21.6  13.6    34.1\n15 Cote d'Ivoire any     Urban  37.1  26.0    52.7\n16 Cote d'Ivoire avg     Urban  29.4  20.1    42.7\n\n\n\n\nShiny Dashboard\nDashboards like this one can be run locally in RStudio, or you can publish them on a server like shinyapps.io. Ours is built as a Quarto document with the following header:\n---\ntitle: \"ESTIMATED ONE-YEAR ABORTION INCIDENCE\"\nformat: \n  html:\n    page-layout: custom\n    css: 'css/pma.css'\nserver: shiny\n---\ncss/pma.css is responsible for incorporating the IPUMS fonts you see throughout this blog. Feel free to omit that line, or include your own css document.\nThe rest of the document consists of four named chunks:\ncontext: setup - load your data and packages here\npanel: sidebar - home to all user inputs\npanel: fill - home to plots generated from user inputs\ncontext: server - all back-end computation performed by R\nIn summary, we use ggplot2 to build a dot-whisker plot for selected abortion estimates for a user-provided country and disaggregation measure. As an extra flourish, the choiceNames argument in checkboxGroupInput uses color-coded text to save space where you would normally see a legend.\n\n\n```{r, context=\"setup\"}\n\nlibrary(shiny)\nlibrary(tidyverse)\ndat <- read_rds(\"www/dat.rds\") \n\n```\n\n\n\n\n\n```{r, panel=\"sidebar\"}\n\nselectInput(\n  inputId = \"country\", \n  label = \"Country:\", \n  choices = unique(dat$country)\n)\n\nselectInput(\n  inputId = 'group', \n  label = 'Group by:', \n  choices = list(Age = \"age\", `Urban / Rural` = \"urban\", Education = \"edu\", \n       Wealth = \"wealth\", `Marital Status` = \"marstat\"),\n)\n\ncheckboxGroupInput(\n  inputId = \"measure\",\n  label=\"Abortion Measure:\",\n  choiceNames = list(\n    HTML(\"<span style='color: #00263A;'>Period Regulation Only<\/span>\"),\n    HTML(\"<span style='color: #98579B;'>Termination Only<\/span>\"),\n    HTML(\"<span style='color: #B56576;'>Termination or Regulation<\/span>\"),\n    HTML(\"<span style='color: #EAAC8B;'>Average of Measures<\/span>\")\n  ),\n  choiceValues = list(\"reg\", \"abor\", \"any\", \"avg\"),\n  selected =  list(\"reg\", \"abor\", \"any\", \"avg\")\n)\n\n```\n\n\nYour inputID in these inputs can be anything: it’s what we use to reference user choices in the server context below.\nselectInput creates a dropdown menu with options provided by choices. If you want to change choice labels from the values in your dataset, you can provide them via list names as we do in the group dropdown.\ncheckboxGroupInput creates a group of check-boxes. Adding color is more complicated than providing list names, so we write HTML code for each option in choiceNames.\n\n\n\n```{r, context=\"server\"}\n\nselectedData <- reactive({\n  dat %>% \n    filter(country == input$country) %>% \n    unnest(any_of(input$group)) %>% \n    filter(measure %in% input$measure)\n})\n\noutput$plot <- renderPlot(width = 700, height = 400, expr = {\n  selectedData() %>%\n    ggplot(aes(x = group, y = coef, color = measure)) + \n    geom_point(position = position_dodge(width = 0.3)) + \n    geom_errorbar(\n      aes(ymin = `_low`, ymax = `_upp`), \n      width = 0, \n      position = position_dodge(width = 0.3)\n    ) + \n    theme_minimal()  %+replace% theme(\n      panel.grid.major.x = element_blank(),\n      legend.position = \"none\"\n    ) + \n    labs(x = NULL,color = NULL, y = \"Number of abortions per 1,000 women\") + \n    scale_y_continuous(limits = c(0, 110)) + \n    scale_color_manual(values = c(\n      \"reg\" = \"#00263A\",\n      \"abor\" = \"#98579B\",\n      \"any\" = \"#B56576\",\n      \"avg\" = \"#EAAC8B\"\n    )) \n})\n\n```\n\n\nselectedData is a reactive function that reacts to user input referenced by each inputID created in our sidebar.\nThe object output$plot stores a new ggplot created in reaction to these inputs.\n\n\n\n```{r, panel=\"fill\"}\n\nplotOutput('plot')\n\n```\n\n\nThat’s it! Simply hit “Run Document” to test your application in RStudio. For information about deploying it for use by others, check out this article.\nHere’s our finished app:\n\n\n\n\n\n\n\nBell, Suzanne O, and Mary E Fissell. 2021. “A Little Bit Pregnant? Productive Ambiguity and Fertility Research.” Population and Development Review 47 (2): 505–26. https://onlinelibrary.wiley.com/doi/10.1111/padr.12403.\n\n\nBell, Suzanne O, Elizabeth Omoluabi, Funmilola OlaOlorun, Mridula Shankar, and Caroline Moreau. 2020. “Inequities in the Incidence and Safety of Abortion in Nigeria.” BMJ Global Health 5 (1): e001814. http://dx.doi.org/10.1136/bmjgh-2019-001814.\n\n\nBell, Suzanne O, Grace Sheehy, Andoh Kouakou Hyacinthe, Georges Guiella, and Caroline Moreau. 2020. “Induced Abortion Incidence and Safety in côte d’ivoire.” PloS One 15 (5): e0232364. http://dx.doi.org/10.1371/journal.pone.0232364.\n\n\n“We averaged the two point estimates\nbecause we believe the pregnancy removal data fails to capture some abortions (that women may not view as abortions or are not willing to admit are abortions) while the period regulation data likely include some experiences that we would not consider to be abortions.” (Bell et al. 2020a, pg 5)↩︎\nNote: in Nigeria, the same EAID codes are recycled in multiple sample STRATA. You must use nest = TRUE to ensure that these EAs are treated as separate sampling locations!↩︎\n",
    "preview": "posts/2023-02-15-abor-reg/images/featured.png",
    "last_modified": "2023-03-02T10:53:09-05:00",
    "input_file": {},
    "preview_width": 2144,
    "preview_height": 1004
  },
  {
    "path": "posts/2023-01-31-abor-discovery/",
    "title": "New longitudinal data",
    "description": "Follow-up surveys focused on abortion, maternal and newborn health surveys collected during the COVID-19 pandemic, and updates to the ongoing Family Planning panel study",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      },
      {
        "name": "Devon Kristiansen",
        "url": "https://www.linkedin.com/in/devonkristiansen"
      }
    ],
    "date": "2023-02-01",
    "categories": [
      "Data Discovery",
      "New Data",
      "Maternal and Newborn Health",
      "Abortion",
      "Longitudinal"
    ],
    "contents": "\n\nContents\nAbortion Data\nMaternal and Newborn Health\nNew Family Planning Panel Data\n\nHere at IPUMS PMA, we’re kicking off 2023 with a huge release of newly harmonized family planning data! This release spans multiple units of analysis and represents surveys conducted in several countries, so we’ll provide a quick tour of the major topics in this post. We’ll then cover each of those topics in detail throughout multiple blog series in the first half of the year, beginning with our upcoming series on PMA abortion data.\nAs always, we’ve also provided full release notes over on our website, where you’ll also find information about a few improvements to data in previously released samples.\nAbortion Data\nThree of the surveys included in this release are primarily focused on women’s experiences seeking and accessing abortion services. Each is a follow-up to a cross sectional survey conducted with the same women in 2018 in the following countries:\nCountry\nBaseline Survey\nFollow-Up\nFollow-Up Eligibility\nCôte d’Ivoire\n2018\n2019\nAny woman who had  “removed a pregnancy” or  “regulated her period”\nNigeria\n2018\n2020\nAny woman who had  “removed a pregnancy” or  “regulated her period”\nEthiopia\n2018\n2020\nAll previously interviewed women\nIn the 2018 Côte d’Ivoire and Nigeria samples, women were asked whether they had “ever done something to remove a pregnancy” or “done something to regulate your period” when pregnant or worried that they were pregnant. Those who answered “Yes” to either question were invited to participate in the follow-up surveys included in this release. All women in the 2018 Ethiopia sample were invited to participate in the follow-up, regardless of their answer to these questions.\nThis distinction is particularly notable: while PMA User Notes for the Côte d’Ivoire and Nigeria use the shorthand title “Follow-up (Abortion) Surveys”, women participating in the survey do not necessarily describe their experiences as abortion. In our upcoming series, we’ll examine how experiences differ for women who reported “removing a pregnancy” compared with those who reported “regulating their period”.\nWe’ll also explore how researchers might approach the longitudinal structure of these surveys. Like the PMA panel surveys1 we covered here in Spring 2022, IPUMS PMA has made these data available in both wide format (one woman per row) and long format (separate rows for cross sectional and follow-up surveys) so that you can select the data that best meet your needs.\nThese follow-up surveys focus on several topics related to the woman’s own abortion experiences, often described in separate questions for pregnancy removal and period regulation:\nThe timing and circumstances surrounding pregnancy removal, including whether the woman was using contraception beforehand\nProviders and methods used for pregnancy removal and period regulation\nWhether the woman experienced problems related to pregnancy removal or period regulation, including whether and where she sought treatment\nWhether the woman was able to use her preferred method and provider\nThe overall quality of care she received\nWhether she adopted a family planning method or discussed one with a provider afterward\nWhether other people were involved in the decision to remove her pregnancy or regulate her period\nHer general views on abortion, including specific circumstances in which she thinks abortion should be legal or acceptable, and whether she believes certain methods are “period regulation” or “pregnancy removal”\nAdditionally, each woman is asked to reflect on abortion in her community. These questions cover topics like:\nHer knowledge about the pregnancy removal and period regulation experiences of other women, including up to three close confidantes\nCommon methods used by women in her community\nWatch for upcoming posts showcasing these social network questions as well: we’ll learn how some researchers use the network scale-up method to estimate incidence ratios for pregnancy removal and period regulation procedures in hidden populations.\nMaternal and Newborn Health\nMaternal and Newborn Health (MNH) surveys are a unique product from PMA Ethiopia: they represent panel data following women who were pregnant at the time of a baseline survey, and who participated in regular follow-up surveys following childbirth. Prior to this release, IPUMS PMA had published data from a single cohort of women interviewed at baseline in 2016; this release includes data from a new cohort interviewed at baseline in 2019.\nCountry\nBaseline  Survey\nFollow-Up Schedule\nFollow-Up Eligibility\nEthiopia\n2016\n7 days  6 weeks  6 months\nPregnant at baseline\nEthiopia\n2019\n6 weeks  6 months  1 year\nPregnant or < 9 weeks postpartum at baseline\nBecause 2019 baseline surveys were collected just months before the emergence of COVID-19, researchers at PMA Ethiopia were able to quickly modify follow-up surveys to include questions about the pandemic’s impact on mothers and the newborn children in the panel. These revised questionnaires address whether pandemic restrictions impacted women’s ability to receive postnatal care or vaccinations, changed the planned location of delivery, or otherwise impacted their pregnancy. The new variables SURVEYVERSION_6W and SURVEYVERSION_6M indicate whether panel members received a questionnaire that was modified to address COVID-19.\nYou’ll notice that, compared with other PMA Family Planning surveys, MNH surveys have a unique data stricture: MNH data from the 2019 cohort includes records for household members and the women who are part of the panel. IPUMS has adjusted the data format such that each non-household member record represents one infant (both live and stillbirth), or a panel member woman if the pregnancy ended in miscarriage or abortion. There are multiple cases of twins, in which case the attributes of the mother and the household are attached on each infant’s record. Therefore, in each file, mothers of twins are represented twice. There are also a small number of cases of households with more than one pregnant woman. These households will also be represented more than once.\nBecause of the unique structure of MNH data, you’ll find them under a separate unit of analysis in the IPUMS PMA data extract system.\n\n\n\nNew Family Planning Panel Data\nFinally, the third component of this release includes an update to the ongoing PMA panel study we’ve been covering for the last year on this blog. IPUMS PMA has now released the final Phase 1 (baseline) survey in this study: a nationally representative sample from Niger.\n\n\n\n\n\n\nNow Available from IPUMS PMA\n\n\n\nSample\n\n\nPhase 1 Data Collection*\n\nPhase 1\n\n\nPhase 2\n\n\nPhase 3\n\n\nBurkina Faso\n\n\nDec 2019 - Mar 2020\n\n\nx\n\n\nx\n\n\n\n\nCote d’Ivoire\n\n\nSep 2020 - Dec 2020\n\n\nx\n\n\n\n\n\n\nDRC - Kinshasa\n\n\nDec 2019 - Feb 2020\n\n\nx\n\n\nx\n\n\n\n\nDRC - Kongo Central\n\n\nDec 2019 - Feb 2020\n\n\nx\n\n\nx\n\n\n\n\nIndia - Rajasthan\n\n\nAug 2020 - Oct 2020\n\n\nx\n\n\n\n\n\n\nKenya\n\n\nNov 2019 - Dec 2019\n\n\nx\n\n\nx\n\n\n\n\nNiger\n\n\nDec 2020 - April 2021\n\n\nx\n\n\n\n\n\n\nNigeria - Kano\n\n\nDec 2019 - Jan 2020\n\n\nx\n\n\nx\n\n\n\n\nNigeria - Lagos\n\n\nDec 2019 - Jan 2020\n\n\nx\n\n\nx\n\n\n\n\nUganda\n\n\nSep 2020 - Oct 2020\n\n\nx\n\n\n\n\n\n\n* Each data collection phase is spaced one year apart\n\n\n\nAll of these samples are now available in Cross-sectional format, while those with two or more available phases are also available in Longitudinal format. Check back here over the coming months for updates on Phase 2 and Phase 3 samples!\n\nPMA abortion follow-up surveys are not part of the PMA panel study, which covers a broader range of family planning topics. The PMA panel study includes three interviews with women of reproductive age, each conducted one year apart. For more information, check out our blog series or our PDF guide published earlier this year.↩︎\n",
    "preview": "posts/2023-01-31-abor-discovery/../../images/new_data.png",
    "last_modified": "2023-02-01T12:03:14-05:00",
    "input_file": {},
    "preview_width": 2555,
    "preview_height": 1437
  },
  {
    "path": "posts/2023-01-19-survey-survival/",
    "title": "Survival Analysis with Survey Weights",
    "description": "The survey package for R makes it easy to incorpate weights and other elements of survey design into survival analysis.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2023-01-25",
    "categories": [
      "Data Analysis",
      "Survival Analysis",
      "Weights",
      "Cluster Sampling",
      "Contraceptive Calendar",
      "survey",
      "survival",
      "srvyr"
    ],
    "contents": "\n\nContents\nData\nSetup\nUnweighted Estimates\nSurvey Design\nData with Multiple Samples\n\n\n\n\nSeveral months ago, we introduced the PMA Contraceptive Calendar as a monthly recollection of contraceptive use and pregnancy status reported by women in each phase of the ongoing PMA panel study. These data are an especially useful tool for researchers interested in survival analysis, which can be used to estimate the expected amount of time to a particular family planning event (measured in months).\nIn that introduction, we demonstrated how to estimate time to adoption of a family planning method for women who initially were not using one. Because we focused most of our attention on data preparation and visualization techniques with the survival package for R, we set aside some issues related to PMA survey weights and its clustered sample design. In short: survival is probably the best known way to conduct this kind of survival analysis in R, but it does not include the tools we need to incorporate information about the PMA survey design.1\nIn our case, survival functions included in the survey package offer an easy way to use PMA weights and identifiers for each cluster and sample stratum.\nData\nLet’s pick up with the contraceptive calendar dataset we created in our earlier post, except that we’ll now include all of the variables necessary to describe PMA survey design:\nID - Unique identifier for each woman (our data includes de facto panel members only)\nPOP - Population of study. Our extract contains six independent samples drawn from different populations; we’ll demonstrate how to use survey design information for one sample first, and then repeat for all samples.\nPANELWEIGHT - An inverse probability weight for panel membership, adjusted for loss to follow-up at Phase 22\nEAID - Unique identifier for each sample cluster\nSTRATA - Unique identifier for each sample stratum, from which clusters are drawn\nCALSTART - The date of the woman’s Phase 1 interview (CMC format). This corresponds with the first month in our survival analysis.\nCALSTOP - The date of the woman’s Phase 2 interview (CMC format). This corresponds with the last month in our survival analysis.\nCALCMC - The date of each month, formatted here as one month per row (CMC format). Most women report about 12 months between CALSTART and CALSTOP, depending on the actual spacing of Phase 1 and Phase 2 interviews. Some women do not have completed Phase 2 calendars, so we only have data from the month in CALSTART.3\nAdditionally, we’ve included a two variables describing 1) each woman’s family planning intentions at Phase 1 and 2) her monthly family planning status reported on the Phase 2 Contraceptive Calendar.\nFPPLANYR indicates whether the woman indicated at Phase 1 that she was not currently using a method, but planned to adopt one by Phase 2 (one year later). All cases are either TRUE (non-user with plans to adopt) or FALSE (e.g. Phase 1 users, or Phase 1 non-users with no such plans). Derived from FPPLANWHEN and FPPLANVAL.\nFPSTATUS indicates the woman’s recalled family planning status for each month between Phase 1 and her Phase 2 interview (approximately 12 months later).\nSince we’re working with a dataset created in a previous session, we’ll load it with read_rds from the tidyverse. We’ll also load survey (along with its tidy-helper srvyr). The survival package is listed as a dependency for survey, so it is attched automatically.\n\n\nlibrary(tidyverse)\nlibrary(survey)\nlibrary(srvyr)\ndat <- read_rds(\"data/dat.rds\")\n\n\n\n# A tibble: 208,098 × 10\n# Groups:   ID [17,725]\n      ID POP          PANELWEIGHT      EAID STRATA CALSTART CALSTOP CALCMC FPPLANYR FPSTATUS\n   <int> <chr>              <dbl>     <dbl>  <int>    <dbl>   <dbl>  <dbl> <lgl>    <chr>   \n 1     1 Burkina Faso        2.50 854111005  85402     1442    1453   1453 TRUE     3       \n 2     1 Burkina Faso        2.50 854111005  85402     1442    1453   1452 TRUE     3       \n 3     1 Burkina Faso        2.50 854111005  85402     1442    1453   1451 TRUE     3       \n 4     1 Burkina Faso        2.50 854111005  85402     1442    1453   1450 TRUE     3       \n 5     1 Burkina Faso        2.50 854111005  85402     1442    1453   1449 TRUE     3       \n 6     1 Burkina Faso        2.50 854111005  85402     1442    1453   1448 TRUE     3       \n 7     1 Burkina Faso        2.50 854111005  85402     1442    1453   1447 TRUE     0       \n 8     1 Burkina Faso        2.50 854111005  85402     1442    1453   1446 TRUE     0       \n 9     1 Burkina Faso        2.50 854111005  85402     1442    1453   1445 TRUE     0       \n10     1 Burkina Faso        2.50 854111005  85402     1442    1453   1444 TRUE     0       \n11     1 Burkina Faso        2.50 854111005  85402     1442    1453   1443 TRUE     0       \n12     1 Burkina Faso        2.50 854111005  85402     1442    1453   1442 TRUE     0       \n13     2 Burkina Faso        2.61 854111004  85402     1441    1452   1452 FALSE    5       \n14     2 Burkina Faso        2.61 854111004  85402     1441    1452   1451 FALSE    5       \n15     2 Burkina Faso        2.61 854111004  85402     1441    1452   1450 FALSE    5       \n# … with 208,083 more rows\n\nSetup\nThe numeric codes shown above in FPSTATUS refer to specific family planning methods used in a particular month, with the following exceptions:\nP Pregnant\nB Birth\nT Termination of pregnancy\n0 No pregnancy and no family planning method used\nWe’ll build a binary indicator for USE of any method, as indicated by any value except for these codes. (For the moment, our data contain placeholder NA values for women with incomplete Phase 2 calendars).\n\n\ndat <- dat %>% \n  rowwise() %>% \n  mutate(USE = !any(FPSTATUS == c(\"0\", \"P\", \"B\", \"T\")))\n\n\nOur analysis will compare time to adoption for Phase 1 non-users like the woman at the top of our dataset (ID == 1). FPPLANYR shows that she reported plans to adopt a method within 12 months after the Phase 1 interview, and the Phase 2 calendar data in FPSTATUS shows that she did so just 6 months later. We should hypothesize that women with plans probably adopt a method sooner, on average, compared with women who had no plans.\n\n\ndat \n\n# A tibble: 208,098 × 11\n# Rowwise:  ID\n      ID POP          PANELWEIGHT      EAID STRATA CALSTART CALSTOP CALCMC FPPLANYR FPSTATUS USE  \n   <int> <chr>              <dbl>     <dbl>  <int>    <dbl>   <dbl>  <dbl> <lgl>    <chr>    <lgl>\n 1     1 Burkina Faso        2.50 854111005  85402     1442    1453   1453 TRUE     3        TRUE \n 2     1 Burkina Faso        2.50 854111005  85402     1442    1453   1452 TRUE     3        TRUE \n 3     1 Burkina Faso        2.50 854111005  85402     1442    1453   1451 TRUE     3        TRUE \n 4     1 Burkina Faso        2.50 854111005  85402     1442    1453   1450 TRUE     3        TRUE \n 5     1 Burkina Faso        2.50 854111005  85402     1442    1453   1449 TRUE     3        TRUE \n 6     1 Burkina Faso        2.50 854111005  85402     1442    1453   1448 TRUE     3        TRUE \n 7     1 Burkina Faso        2.50 854111005  85402     1442    1453   1447 TRUE     0        FALSE\n 8     1 Burkina Faso        2.50 854111005  85402     1442    1453   1446 TRUE     0        FALSE\n 9     1 Burkina Faso        2.50 854111005  85402     1442    1453   1445 TRUE     0        FALSE\n10     1 Burkina Faso        2.50 854111005  85402     1442    1453   1444 TRUE     0        FALSE\n11     1 Burkina Faso        2.50 854111005  85402     1442    1453   1443 TRUE     0        FALSE\n12     1 Burkina Faso        2.50 854111005  85402     1442    1453   1442 TRUE     0        FALSE\n13     2 Burkina Faso        2.61 854111004  85402     1441    1452   1452 FALSE    5        TRUE \n14     2 Burkina Faso        2.61 854111004  85402     1441    1452   1451 FALSE    5        TRUE \n15     2 Burkina Faso        2.61 854111004  85402     1441    1452   1450 FALSE    5        TRUE \n# … with 208,083 more rows\n\nGiven our research interest, you might consider subsetting the dataset to exclude women who were already using a method at the time of the Phase 1 interview. In fact, we’ll want to keep track of these women so that we can calculate the correct degrees of freedom from each original sample size. For now, we’ll mark each of those cases as “User”, dividing the remaining cases into “Plan” and “No Plan” in a new variable called INTENT.\n\n\ndat <- dat %>% \n  group_by(ID) %>% \n  mutate(\n    INTENT = case_when(\n      any(USE & CALCMC == CALSTART) ~ \"User\",\n      any(!USE & FPPLANYR & CALCMC == CALSTART) ~ \"Plan\",\n      any(!USE & !FPPLANYR & CALCMC == CALSTART) ~ \"No Plan\",\n    )\n  )\n\n\n\nLastly, whether who intend to use the survival package or its counterpart functions in the survey package, you’ll want to filter down to use one row per person: this should be the first month of USE or the last reported month in CALCMC, whichever comes first.\nWith only one row per person remaining we’ll 1) create MONTH to count the number of months after the Phase 1 interview, and 2) remove any extra variables that won’t be necessary in our analysis.\n\n\nWomen who were not yet using a method by the last calendar month are said to be right-censored. If they adopted a method at all, that month occurs after the analysis period.\n\n\ndat <- dat %>% \n  group_by(ID) %>% \n  mutate(\n    USEMO = case_when(USE ~ CALCMC),\n    KEEP = ifelse(any(USE), min(USEMO, na.rm = TRUE), max(CALCMC))\n  ) %>% \n  filter(KEEP == CALCMC) %>% \n  mutate(.before = USE, MONTH = CALCMC - CALSTART) %>% \n  select(-c(starts_with(\"CAL\"), starts_with(\"FP\"), USEMO, KEEP)) %>% \n  ungroup()\n\ndat \n\n# A tibble: 17,725 × 8\n      ID POP          PANELWEIGHT      EAID STRATA MONTH USE   INTENT \n   <int> <chr>              <dbl>     <dbl>  <int> <dbl> <lgl> <chr>  \n 1     1 Burkina Faso       2.50  854111005  85402     6 TRUE  Plan   \n 2     2 Burkina Faso       2.61  854111004  85402     3 TRUE  No Plan\n 3     3 Burkina Faso       3.21  854161007  85402    12 FALSE No Plan\n 4     4 Burkina Faso       0.538 854141008  85401    11 FALSE No Plan\n 5     5 Burkina Faso       0.358 854191022  85402     0 FALSE Plan   \n 6     6 Burkina Faso       3.20  854141002  85402    12 FALSE No Plan\n 7     7 Burkina Faso       0.404 854131034  85401    11 FALSE No Plan\n 8     8 Burkina Faso       0.314 854191036  85402    11 FALSE No Plan\n 9     9 Burkina Faso       0.337 854121003  85401     0 TRUE  User   \n10    10 Burkina Faso       2.55  854231003  85402     0 FALSE No Plan\n11    11 Burkina Faso       0.221 854111006  85401     9 TRUE  No Plan\n12    12 Burkina Faso       0.478 854191025  85402     0 TRUE  User   \n13    13 Burkina Faso       0.412 854191026  85402     0 TRUE  User   \n14    14 Burkina Faso       0.404 854191013  85402     0 TRUE  User   \n15    15 Burkina Faso       0.395 854131021  85401     0 TRUE  User   \n# … with 17,710 more rows\n\nUnweighted Estimates\nLet’s review the procedure highlighted in our previous post, where we used no survey design information at all. To estimate a survival model for one population, we’ll filter dat to include only women from one sample; we’ll use Kenya as an example.\nThe function Surv indicates whether the observation in the last MONTH for each woman was adopted USE of a method, or that her ultimate adoption is right-censored (if at happened at all). Surv is part of a model formula provided to the function survfit; in this case, we’re modeling USE with each woman’s original INTENT at Phase 1.\n\n\nke_survival <- dat %>% \n  filter(POP == \"Kenya\") %>% \n  survfit(Surv(MONTH, USE) ~ INTENT, data = .)\n\nke_survival \n\nCall: survfit(formula = Surv(MONTH, USE) ~ INTENT, data = .)\n\n                  n events median 0.95LCL 0.95UCL\nINTENT=No Plan 2997    419     NA      NA      NA\nINTENT=Plan     676    328     10       9      11\nINTENT=User    3266   3266      0      NA      NA\n\nThe output returned as ke_survival is an object in the survfit class defined by the survival package. We’ll get more information from this object if we pass it to tidy from the broom package.\n\n\nbroom::tidy(ke_survival) %>% print(n = Inf)\n\n# A tibble: 29 × 9\n    time n.risk n.event n.censor estimate std.error conf.high conf.low strata        \n   <dbl>  <dbl>   <dbl>    <dbl>    <dbl>     <dbl>     <dbl>    <dbl> <chr>         \n 1     0   2997       0      269    1       0           1        1     INTENT=No Plan\n 2     1   2728      53        0    0.981   0.00269     0.986    0.975 INTENT=No Plan\n 3     2   2675      41        0    0.966   0.00362     0.972    0.959 INTENT=No Plan\n 4     3   2634      24        0    0.957   0.00407     0.964    0.949 INTENT=No Plan\n 5     4   2610      40        0    0.942   0.00475     0.951    0.933 INTENT=No Plan\n 6     5   2570      26        0    0.933   0.00515     0.942    0.923 INTENT=No Plan\n 7     6   2544      36        0    0.919   0.00567     0.930    0.909 INTENT=No Plan\n 8     7   2508      34        0    0.907   0.00613     0.918    0.896 INTENT=No Plan\n 9     8   2474      36        0    0.894   0.00660     0.905    0.882 INTENT=No Plan\n10     9   2438      37        0    0.880   0.00707     0.892    0.868 INTENT=No Plan\n11    10   2401      40        0    0.865   0.00755     0.878    0.853 INTENT=No Plan\n12    11   2361      28      782    0.855   0.00788     0.869    0.842 INTENT=No Plan\n13    12   1551      24     1336    0.842   0.00850     0.856    0.828 INTENT=No Plan\n14    13    191       0      191    0.842   0.00850     0.856    0.828 INTENT=No Plan\n15     0    676       0       90    1       0           1        1     INTENT=Plan   \n16     1    586      28        0    0.952   0.00925     0.970    0.935 INTENT=Plan   \n17     2    558      33        0    0.896   0.0141      0.921    0.872 INTENT=Plan   \n18     3    525      45        0    0.819   0.0194      0.851    0.789 INTENT=Plan   \n19     4    480      34        0    0.761   0.0231      0.796    0.727 INTENT=Plan   \n20     5    446      35        0    0.701   0.0270      0.739    0.665 INTENT=Plan   \n21     6    411      28        0    0.654   0.0301      0.693    0.616 INTENT=Plan   \n22     7    383      35        0    0.594   0.0342      0.635    0.555 INTENT=Plan   \n23     8    348      20        0    0.560   0.0366      0.601    0.521 INTENT=Plan   \n24     9    328      23        0    0.520   0.0397      0.563    0.482 INTENT=Plan   \n25    10    305      24        0    0.480   0.0430      0.522    0.441 INTENT=Plan   \n26    11    281      15       66    0.454   0.0453      0.496    0.415 INTENT=Plan   \n27    12    200       7      159    0.438   0.0473      0.481    0.399 INTENT=Plan   \n28    13     34       1       33    0.425   0.0559      0.474    0.381 INTENT=Plan   \n29     0   3266    3266        0    0     Inf          NA       NA     INTENT=User   \n\nNotice that tidy creates an object in the tibble class with several helpful columns:\nThe most important column here is estimate: this represents the estimated probability of “surviving” continuous non-use of a method for each month in time.\nstd.error shows the standard error for each estimate on the log scale, and is used to report a 95% confidence interval (by default) in conf.high and conf.low.\nstrata shows that the months reported in time are divided by the three groups of women defined in INTENT.\nn.risk shows the original group size at month 0, and those remaining for every month afterward.\nThe number of women who adopted a method in each month are reported in n.event, while those who reported no further months (right-censored cases) are reported in n.censor.\n\nDon’t be fooled by the tidy column name strata - this refers to the subgroups defined by each woman’s INTENT at Phase 1. It does not refer to PMA sample strata in the variable STRATA.\nIn the last row, strata shows the results for 3,266 women who were already using a method at month 0 (when Phase 1 interviews were conducted). The survival probability for these women is 0 because they “survived” no months of non-use.\nLet’s create a quick step-wise Time to Event plot for the two groups with data after month 0.\n\n\nShow ggplot theme\n\n# Define `theme_pma` for maps\nlibrary(showtext)\nsysfonts::font_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext::showtext_auto()\n\ntheme_pma <- function(){\n  legned_title =  \"Planned to Adopt Any Method within 12 Months\" %>% \n    str_wrap(16)\n  list(\n    theme_minimal() %+replace% \n      theme(\n        text = element_text(family = \"cabrito\", size = 13),\n        plot.title = element_text(\n          size = 18, \n          color = pma_blue, \n          hjust = 0, \n          margin = margin(b = 10)\n        ),\n        panel.spacing = unit(1, \"lines\"),\n        legend.position = \"right\"\n      ),\n    scale_y_continuous(labels = scales::percent, limits = c(0, 1)),\n    scale_x_continuous(limits = c(0,15)), \n    scale_fill_manual(\n      aesthetics = c(\"color\", \"fill\"),\n      values = c(\n        \"Plan\" = pma_pink, \n        \"No Plan\" = pma_blue\n      ),\n      labels = c(\n        \"Plan\" = \"Yes\", \n        \"No Plan\" = \"No\"\n      )\n    ), \n    labs(\n      x = \"Months After Baseline\", \n      y = \"Probability of Continued Non-use\",\n      fill = legned_title,\n      color = legned_title\n    )\n  )\n}\n\n\n\n\nke_survival %>% \n  broom::tidy() %>% \n  mutate(estimate = 1 - estimate, strata = strata %>% str_remove(\"INTENT=\")) %>% \n  filter(strata != \"User\") %>% \n  ggplot(aes(x = time, y = estimate, color = strata)) +\n  geom_step() + \n  theme_pma() + \n  labs(title = \"Predicted time to FP Adoption for Phase 1 Non-users in Kenya\")\n\n\n\nNo surprises here: women who planned to adopt a method at Phase 1 are expected to adopt one sooner than women with no such plans. Notice, however, that we didn’t bother to plot confidence intervals for each line: that’s because we’ll first want to incorporate information about the PMA sampling procedure with help from the survey package.\nSurvey Design\nWe can use a similar workflow with survey, but it’s important to remember that the output of survfit shown above was an object of a particular class called survfit - because survival is such a popular package, the developers of broom wrote specific methods for tidy-ing objects from this class.\nsurvey uses the survival function Surv, but has its own modeling function svykm. Its output is not familiar to broom, so we’ll have to create our own tidy output from scratch.\nBefore we add survey design information, let’s ensure that we’re able to reproduce the above results with svykm. This time, we’ll pass dummy survey design information to as_survey_design via a test-variable w: we’ll use this to weight every case equally with the value 1.\n\n\nke_survey <- dat %>%\n  filter(POP == \"Kenya\") %>%\n  mutate(w = 1) %>%\n  as_survey_design(weight = w) %>%\n  svykm(Surv(MONTH, USE) ~ INTENT, design = .)\n\nke_survey\n\nWeighted survival curves:\nsvykm(formula = Surv(MONTH, USE) ~ INTENT, design = .)\nNo Plan : Q1 = Inf  median = Inf  Q3 = Inf \nPlan : Q1 = 5  median = 10  Q3 = Inf \nUser : Q1 = 0  median = 0  Q3 = 0 \n\nNotice how this output looks different from ke_survival? If we try, broom will be unable to tidy it.\n\n\nbroom::tidy(ke_survey)\n\nError: No tidy method for objects of class svykmlist\n\nYou can think about ke_survey as a kind of special list, with one element per group in INTENT. Each of those elements also has a list-like structure with vectors representing time (months), surv (survival probability), and standard error (if specified). For example, you can use list-syntax to check that the monthly estimates in ke_survey match those in ke_survival for women who planned to adopt a method:\n\n\nke_survey$Plan$surv %>% round(3)\n\n [1] 1.000 1.000 0.952 0.896 0.819 0.761 0.701 0.654 0.594 0.560 0.520 0.480 0.454 0.438 0.425\n\nWe’ll want to compile all of these lists in a tibble, which we’ll demonstrate with the new recommended workflow for map with purrr version 1.0.0. (We now use list_rbind in place of map_dfr, which has been superseded).\n\n\nke_survey %>% \n  imap(~c(.x) %>% as_tibble() %>% mutate(strata = .y)) %>% \n  list_rbind() \n\n# A tibble: 32 × 3\n    time  surv strata \n   <dbl> <dbl> <chr>  \n 1     0 1     No Plan\n 2     0 1     No Plan\n 3     1 0.981 No Plan\n 4     2 0.966 No Plan\n 5     3 0.957 No Plan\n 6     4 0.942 No Plan\n 7     5 0.933 No Plan\n 8     6 0.919 No Plan\n 9     7 0.907 No Plan\n10     8 0.894 No Plan\n11     9 0.880 No Plan\n12    10 0.865 No Plan\n13    11 0.855 No Plan\n14    12 0.842 No Plan\n15    13 0.842 No Plan\n# … with 17 more rows\n\nWe’ll ultimately want cluster-robust standard error estimates for each month, so this output isn’t very useful on its own. Instead, we’ll specify se = TRUE in svykm. Just make sure to drop women who were originally using a method at Phase 1: the estimated standard error for these cases is infinite in month 0, and R will likely stall if you don’t exclude them from svykm! We’ll do this after our call to as_survey_design in order to preserve the correct sample size.\n\n\nke_survey <- dat %>% \n  filter(POP == \"Kenya\") %>% \n  mutate(w = 1) %>% \n  as_survey_design(weight = w) %>% \n  filter(INTENT != \"User\") %>% # remove baseline users \n  svykm(Surv(MONTH, USE) ~ INTENT, design = ., se = TRUE) %>% # add se = TRUE\n  imap(~c(.x) %>% as_tibble() %>% mutate(strata = .y)) %>% \n  list_rbind() \n\nke_survey\n\n# A tibble: 747 × 4\n    time  surv      varlog strata \n   <dbl> <dbl>       <dbl> <chr>  \n 1     1 1.00  0.000000134 No Plan\n 2     1 0.999 0.000000269 No Plan\n 3     1 0.999 0.000000403 No Plan\n 4     1 0.999 0.000000537 No Plan\n 5     1 0.998 0.000000671 No Plan\n 6     1 0.998 0.000000805 No Plan\n 7     1 0.997 0.000000938 No Plan\n 8     1 0.997 0.00000107  No Plan\n 9     1 0.997 0.00000121  No Plan\n10     1 0.996 0.00000134  No Plan\n11     1 0.996 0.00000147  No Plan\n12     1 0.996 0.00000161  No Plan\n13     1 0.995 0.00000174  No Plan\n14     1 0.995 0.00000187  No Plan\n15     1 0.995 0.00000200  No Plan\n# … with 732 more rows\n\nThe new column varlog represents the log-scale variance, which is the square of our desired standard error. The confidence intervals shown above can be reproduced if we use p = 0.05 in qnorm and exponentiate the results.\n\nWe also use summarise here to obtain just one estimate per month. When you use se = TRUE, svykm generates one row for each case that experienced the event.\n\n\nke_survey <- ke_survey %>% \n  group_by(strata, time) %>% \n  summarise(\n    n.event = n(),\n    estimate = min(surv),\n    std.error = sqrt(varlog) %>% min(),\n    conf.high = exp(log(estimate) - std.error * qnorm(0.05/2)),\n    conf.low = exp(log(estimate) + std.error * qnorm(0.05/2))\n  )\n\nke_survey\n\n# A tibble: 25 × 7\n# Groups:   strata [2]\n   strata   time n.event estimate std.error conf.high conf.low\n   <chr>   <dbl>   <int>    <dbl>     <dbl>     <dbl>    <dbl>\n 1 No Plan     1      53    0.981  0.000367     0.981    0.980\n 2 No Plan     2      41    0.966  0.00267      0.971    0.961\n 3 No Plan     3      24    0.957  0.00357      0.964    0.950\n 4 No Plan     4      40    0.943  0.00403      0.950    0.935\n 5 No Plan     5      26    0.933  0.00469      0.942    0.925\n 6 No Plan     6      36    0.920  0.00509      0.929    0.911\n 7 No Plan     7      34    0.908  0.00560      0.918    0.898\n 8 No Plan     8      36    0.894  0.00606      0.905    0.884\n 9 No Plan     9      37    0.881  0.00652      0.892    0.870\n10 No Plan    10      40    0.866  0.00698      0.878    0.855\n11 No Plan    11      28    0.856  0.00745      0.869    0.844\n12 No Plan    12      24    0.843  0.00779      0.856    0.830\n13 Plan        1      28    0.953  0.00171      0.957    0.950\n14 Plan        2      33    0.899  0.00899      0.915    0.883\n15 Plan        3      45    0.825  0.0135       0.847    0.803\n# … with 10 more rows\n\nThis is close to the output from ke_survival, except that you’ll notice we have no rows for months were all cases are censored (e.g. month 0). This leaves us with no column analogous to n.risk. We’ll create it from dat and then left_join the results from ke_survey. If you’d like to have a column for censored cases in n.censor, it can be made by subtracting n.event from the count of women in each month (n). Lastly, we’ll carry the same std.error and confidence interval downward for all new rows where only censored cases are listed.\n\n\nke_survey <- dat %>% \n  filter(POP == \"Kenya\") %>% \n  group_by(INTENT) %>% \n  count(MONTH) %>% \n  mutate(n.risk = if_else(MONTH == 0, sum(n), lag(sum(n) - n))) %>% \n  rename(strata = INTENT, time = MONTH) %>% \n  left_join(ke_survey) %>% \n  mutate(\n    n.event = n.event %>% replace_na(0), \n    n.censor = n - n.event,\n    across(\n      c(estimate, std.error, starts_with(\"conf\")),\n      ~case_when(\n        time == 0 ~ as.double(cur_column() != \"std.error\"),\n        !is.na(.x) ~ .x,\n        is.na(.x) ~ lag(.x)\n      )\n    )\n  )\n\nke_survey\n\n# A tibble: 29 × 10\n# Groups:   strata [3]\n   strata   time     n n.risk n.event estimate std.error conf.high conf.low n.censor\n   <chr>   <dbl> <int>  <int>   <int>    <dbl>     <dbl>     <dbl>    <dbl>    <int>\n 1 No Plan     0   269   2997       0    1      0            1        1          269\n 2 No Plan     1    53   2728      53    0.981  0.000367     0.981    0.980        0\n 3 No Plan     2    41   2944      41    0.966  0.00267      0.971    0.961        0\n 4 No Plan     3    24   2956      24    0.957  0.00357      0.964    0.950        0\n 5 No Plan     4    40   2973      40    0.943  0.00403      0.950    0.935        0\n 6 No Plan     5    26   2957      26    0.933  0.00469      0.942    0.925        0\n 7 No Plan     6    36   2971      36    0.920  0.00509      0.929    0.911        0\n 8 No Plan     7    34   2961      34    0.908  0.00560      0.918    0.898        0\n 9 No Plan     8    36   2963      36    0.894  0.00606      0.905    0.884        0\n10 No Plan     9    37   2961      37    0.881  0.00652      0.892    0.870        0\n11 No Plan    10    40   2960      40    0.866  0.00698      0.878    0.855        0\n12 No Plan    11   810   2957      28    0.856  0.00745      0.869    0.844      782\n13 No Plan    12  1360   2187      24    0.843  0.00779      0.856    0.830     1336\n14 No Plan    13   191   1637       0    0.843  0.00779      0.856    0.830      191\n15 Plan        0    90    676       0    1      0            1        1           90\n# … with 14 more rows\n\nNow that we know how to obtain identical results from survival and survey, we’ll rebuild our table with the actual survey weights, cluster IDs, and stratum IDs in as_survey_design.\n\n\n# Fit the survival model with information from `as_survey_design`\n ke_survey <- dat %>% \n  filter(POP == \"Kenya\") %>% \n  as_survey_design(weight = PANELWEIGHT, id = EAID, strata = STRATA) %>% \n  filter(INTENT != \"User\") %>% \n  svykm(Surv(MONTH, USE) ~ INTENT, design = ., se = TRUE) \n\n# Create tidy output from the `svykm` object\nke_survey <- ke_survey %>% \n  imap(~c(.x) %>% as_tibble() %>% mutate(strata = .y)) %>% \n  list_rbind() %>% \n  group_by(strata, time) %>% \n  summarise(\n    n.event = n(),\n    estimate = min(surv),\n    std.error = sqrt(varlog) %>% min(),\n    conf.high = exp(log(estimate) - std.error * qnorm(0.05/2)),\n    conf.low = exp(log(estimate) + std.error * qnorm(0.05/2))\n  )\n\n# Complete tidy output with information about censored cases in each month\nke_survey <- dat %>% \n  filter(POP == \"Kenya\") %>% \n  group_by(INTENT) %>% \n  count(MONTH) %>% \n  mutate(n.risk = if_else(MONTH == 0, sum(n), lag(sum(n) - n))) %>% \n  rename(strata = INTENT, time = MONTH) %>% \n  left_join(ke_survey) %>% \n  mutate(\n    n.event = n.event %>% replace_na(0), \n    n.censor = n - n.event,\n    across(\n      c(estimate, std.error, starts_with(\"conf\")),\n      ~case_when(\n        time == 0 ~ as.double(cur_column() != \"std.error\"),\n        !is.na(.x) ~ .x,\n        is.na(.x) ~ lag(.x)\n      )\n    )\n  )\n\nke_survey\n\n# A tibble: 29 × 10\n# Groups:   strata [3]\n   strata   time     n n.risk n.event estimate std.error conf.high conf.low n.censor\n   <chr>   <dbl> <int>  <int>   <int>    <dbl>     <dbl>     <dbl>    <dbl>    <int>\n 1 No Plan     0   269   2997       0    1      0            1        1          269\n 2 No Plan     1    53   2728      53    0.981  0.000201     0.982    0.981        0\n 3 No Plan     2    41   2944      41    0.965  0.00279      0.971    0.960        0\n 4 No Plan     3    24   2956      24    0.958  0.00418      0.966    0.950        0\n 5 No Plan     4    40   2973      40    0.942  0.00487      0.951    0.933        0\n 6 No Plan     5    26   2957      26    0.934  0.00556      0.944    0.924        0\n 7 No Plan     6    36   2971      36    0.920  0.00583      0.931    0.910        0\n 8 No Plan     7    34   2961      34    0.907  0.00689      0.920    0.895        0\n 9 No Plan     8    36   2963      36    0.898  0.00767      0.911    0.884        0\n10 No Plan     9    37   2961      37    0.883  0.00808      0.897    0.869        0\n11 No Plan    10    40   2960      40    0.869  0.00886      0.884    0.854        0\n12 No Plan    11   810   2957      28    0.860  0.00982      0.876    0.843      782\n13 No Plan    12  1360   2187      24    0.845  0.0103       0.862    0.828     1336\n14 No Plan    13   191   1637       0    0.845  0.0103       0.862    0.828      191\n15 Plan        0    90    676       0    1      0            1        1           90\n# … with 14 more rows\n\nFinally, we’ll plot these new weighted estimates, this time also adding their associated cluster-robust confidence intervals with geom_rect.\n\n\nke_survey %>% \n  filter(strata != \"User\") %>% \n  group_by(strata) %>% \n  mutate(\n    across(c(estimate, starts_with(\"conf\")), ~1 - .x),\n    xmax = if_else(time == max(time), time, time + 1)\n  ) %>% \n  ggplot(aes(x = time, y = estimate, fill = strata)) +\n  geom_step(linewidth = 0.25) + \n  geom_rect(\n    aes(xmin = time, xmax = xmax, ymin = conf.low, ymax = conf.high),\n    alpha = 0.2, color = 0\n  ) + \n  theme_pma() + \n  labs(\n    title = \"Predicted time to FP Adoption for Phase 1 Non-users in Kenya\",\n    subtitle = \"Weighted estimates (95% CI)\"\n  )\n\n\n\nData with Multiple Samples\nSo far, we’ve only generated survival curves for one of the samples in our original data extract. Now we’ll show how to iterate through each of the samples, and then compbine their results in a faceted plot.\nThe tricky thing here is that we need to be careful to avoid combining sample sizes in the formula survey uses to calculate degrees of freedom. Remember our point above about not subsetting the Kenya sample to exclude Phase 1 users prior to defining its survey design? By contrast, you should subset your data extract before defining survey design if your extract contains multiple samples.\nFortunately, this procedure is made very simple with two functions from dplyr: we’ll use group_by followed by group_modify.\nIn group_by, we’ll subset dat by the variable POP so that everything in group_modify applies only to the members of each group.\nThen, in group_modify, we’ll signal an anonymous function with ~{}, inside of which .x references only the data within each group. Hence .x replaces all of the code where we’d written dat %>% filter(POP == \"Kenya\") above. We also replace the name ke_survey with a more general name output.\n\n\ndat_surv <- dat %>% \n  group_by(POP) %>% \n  group_modify(~{\n    # Fit the survival model with information from `as_survey_design`\n    output <- .x %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID, strata = STRATA) %>% \n      filter(INTENT != \"User\") %>% \n      svykm(Surv(MONTH, USE) ~ INTENT, design = ., se = TRUE) \n    \n    # Create tidy output from the `svykm` object\n    output <- output %>% \n      imap(~c(.x) %>% as_tibble() %>% mutate(strata = .y)) %>% \n      list_rbind() %>% \n      group_by(strata, time) %>% \n      summarise(\n        n.event = n(),\n        estimate = min(surv),\n        std.error = sqrt(varlog) %>% min(),\n        conf.high = exp(log(estimate) - std.error * qnorm(0.05/2)),\n        conf.low = exp(log(estimate) + std.error * qnorm(0.05/2))\n      )\n    \n    # Complete tidy output with information about censored cases in each month\n    output <- .x %>%\n      group_by(INTENT) %>% \n      count(MONTH) %>% \n      mutate(n.risk = if_else(MONTH == 0, sum(n), lag(sum(n) - n))) %>% \n      rename(strata = INTENT, time = MONTH) %>% \n      left_join(output) %>% \n      mutate(\n        n.event = n.event %>% replace_na(0), \n        n.censor = n - n.event,\n        across(\n          c(estimate, std.error, starts_with(\"conf\")),\n          ~case_when(\n            time == 0 ~ as.double(cur_column() != \"std.error\"),\n            !is.na(.x) ~ .x,\n            is.na(.x) ~ lag(.x)\n          )\n        )\n      )\n  }) %>% \n  ungroup()\n\ndat_surv\n\n# A tibble: 175 × 11\n   POP          strata   time     n n.risk n.event estimate std.error conf.high conf.low n.censor\n   <chr>        <chr>   <dbl> <int>  <int>   <int>    <dbl>     <dbl>     <dbl>    <dbl>    <int>\n 1 Burkina Faso No Plan     0   348   2686       0    1      0            1        1          348\n 2 Burkina Faso No Plan     1    30   2338      30    0.990  0.000334     0.990    0.989        0\n 3 Burkina Faso No Plan     2    20   2656      20    0.984  0.00304      0.990    0.979        0\n 4 Burkina Faso No Plan     3    16   2666      16    0.977  0.00424      0.985    0.969        0\n 5 Burkina Faso No Plan     4    22   2670      22    0.967  0.00500      0.976    0.957        0\n 6 Burkina Faso No Plan     5    16   2664      16    0.958  0.00617      0.970    0.947        0\n 7 Burkina Faso No Plan     6    18   2670      18    0.952  0.00666      0.964    0.940        0\n 8 Burkina Faso No Plan     7    22   2668      22    0.943  0.00751      0.957    0.929        0\n 9 Burkina Faso No Plan     8    17   2664      17    0.937  0.00783      0.952    0.923        0\n10 Burkina Faso No Plan     9    32   2669      32    0.927  0.00820      0.942    0.912        0\n11 Burkina Faso No Plan    10   152   2654      39    0.911  0.00936      0.928    0.895      113\n12 Burkina Faso No Plan    11  1100   2534      29    0.902  0.0103       0.920    0.884     1071\n13 Burkina Faso No Plan    12   783   1586       7    0.894  0.0116       0.915    0.874      776\n14 Burkina Faso No Plan    13    84   1903       3    0.879  0.0131       0.902    0.857       81\n15 Burkina Faso No Plan    14    26   2602       0    0.879  0.0131       0.902    0.857       26\n# … with 160 more rows\n\nThe resulting tibble dat_surv includes the POP variable we used to define each group. That’s helpful, because we’ll now want to use add facet_wrap(~POP) to our previous ggplot2 code, thereby creating one panel from each sample.\n\n\ndat_surv %>% \n  filter(strata != \"User\") %>% \n  group_by(POP, strata) %>% \n  mutate(\n    across(c(estimate, starts_with(\"conf\")), ~1 - .x),\n    xmax = if_else(time == max(time), time, time + 1)\n  ) %>% \n  ggplot(aes(x = time, y = estimate, fill = strata)) +\n  geom_step(linewidth = 0.25) + \n  geom_rect(\n    aes(xmin = time, xmax = xmax, ymin = conf.low, ymax = conf.high),\n    alpha = 0.2, color = 0\n  ) + \n  theme_pma() + \n  labs(\n    title = \"Predicted time to FP Adoption for Phase 1 Non-users\",\n    subtitle = \"Weighted estimates (95% CI)\"\n  ) + \n  facet_wrap(~POP) # one panel per sample \n\n\n\n\nCertain functions like survival::survfit function do accept a weight argument, but these are intended for frequency weights representing duplicate observations. Our discussion concerns survey weights representing each woman’s sampling probability. You can use the weight arguments in the survival package to obtain weighted point-estimates, but the standard error estimation will be incorrect. See discussion here.↩︎\nPANELWEIGHT should be used in analyses of all questions on the female questionnaire for women who were interviewed in both Phase 1 and Phase 2 survey rounds. See our weighting guide for details.↩︎\nWe discuss reasons for missing data in our previous Contraceptive Calendar post. The data we feature here have been modified to include women who maintained the same family planning status throughout the duration of the calendar period.↩︎\n",
    "preview": "posts/2023-01-19-survey-survival/survey-survival_files/figure-html5/unnamed-chunk-21-1.png",
    "last_modified": "2023-01-31T10:28:46-05:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 1152
  },
  {
    "path": "posts/2022-12-09-data-dictionary/",
    "title": "Building an IPUMS PMA Codebook",
    "description": "You can automatically generate documentation with the metadata included in your data extract, or supplement with additional details scraped from the IPUMS PMA website.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-12-09",
    "categories": [
      "Data Manipulation",
      "Data Dictionary",
      "Codebook",
      "Metadata",
      "Web Scraping",
      "pagedown",
      "rvest",
      "ipumsr"
    ],
    "contents": "\n\nContents\nData Dictionary\nCodebook\nScraping Additional Metadata\n\n\n\n\nHave you ever wondered why IPUMS encourages R users to download data in the Fixed-width text (.dat) data format? After all, most analysts are probably more familiar with the Comma delimited (.csv) format, and you might already know some handy functions like read_csv that can help identify variable classes when you load .csv data into R.\nIn fact, IPUMS does make .csv data available at checkout. You can find it listed at the bottom of the Data Format menu here:\n\n\n\nOne big problem with using read_csv to import such a file is that the resulting dataset contains no helpful attributes to tell the analyst more about the data they’re working with!\nAnother issue is that read_csv makes a guess about the appropriate variable class for each column - and particularly when one of your columns contains a lot of blank strings, it can guess wrong. Here, we’ve downloaded a .csv file containing the variables ABORDECOTHSP and ABORCFOTHSP, which contain open string responses describing a woman’s abortion experience only if she 1) reported having an abortion, and 2) exhausted a number of response options listed on the questionnaire.\nIf you check the documentation for read_csv, you’ll see that read_csv makes guesses about column type based only on the first 1000 rows by default. In our dataset, the first 1000 rows for ABORDECOTHSP and ABORCFOTHSP are blank, so read_csv guesses that they might be logical, rather than character variables.\n\n\nlibrary(tidyverse)\ncsv <- read_csv(\"data/pma_00181.csv.gz\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\nRows: 96481 Columns: 95\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): PERSONID, FQINSTID\ndbl (91): SAMPLE, COUNTRY, YEAR, ROUND, ELIGIBLE, EAID, CONSENTFQ, CONSENTHQ...\nlgl  (2): ABORDECOTHSP, ABORCFOTHSP\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nThis is a big problem! To see why, let’s count the responses in ABORDECOTHSP:\n\n\ncsv %>% count(ABORDECOTHSP)\n\n# A tibble: 1 × 2\n  ABORDECOTHSP     n\n  <lgl>        <int>\n1 NA           96481\n\nYou should expect to see several responses listed here, but instead only NA values are found. This is because logical values should only be TRUE, FALSE, or NA - when R encounters any other value, it transforms them into NA by coercion. If you’re not careful with read_csv, it is easy to accidentally distort or remove data by coercion.\nMeanwhile, if we examine a variable like COUNTRY, we’ll find only numeric codes with no value labels attached:\n\n\ncsv %>% count(COUNTRY)\n\n# A tibble: 8 × 2\n  COUNTRY     n\n    <dbl> <int>\n1       1 13385\n2       2  8927\n3       3  7546\n4       6 11379\n5       7 18926\n6       9 16489\n7      10 12780\n8      11  7049\n\nYou can certainly find the labels for each value on the IPUMS PMA website, but it would be much more convenient to have these and other attributes loaded into R.\nData Dictionary\nNow let’s import the same data as a fixed width (.dat) file together with metadata provided by an accompanying .xml file. As recommended, we’ll use the function read_ipums_micro to load these two files into R.\n\n\nlibrary(ipumsr)\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00180.xml\",\n  data = \"data/pma_00180.dat.gz\"\n)\n\n\nThe .xml file contains all the information R needs to correctly identify the class for each variable. Note that ABORDECOTHSP now contains the string responses we expected to see (reported in the language spoken by the respondent):\n\n\ndat %>% count(ABORDECOTHSP)\n\n# A tibble: 5 × 2\n  ABORDECOTHSP           n\n  <chr>              <int>\n1 \"\"                 96477\n2 \"Ami de son copin\"     1\n3 \"Ex petit ami\"         1\n4 \"tuteur\"               1\n5 \"Une Camarade\"         1\n\nMoreover, value labels for COUNTRY are printed to the console:\n\n\ndat %>% count(COUNTRY)\n\n# A tibble: 8 × 2\n  COUNTRY                             n\n  <int+lbl>                       <int>\n1  1 [Burkina Faso]               13385\n2  2 [Congo, Democratic Republic]  8927\n3  3 [Ethiopia]                    7546\n4  6 [India]                      11379\n5  7 [Kenya]                      18926\n6  9 [Nigeria]                    16489\n7 10 [Uganda]                     12780\n8 11 [Cote d'Ivoire]               7049\n\nIn fact, value labels are only one of several attributes associated with each variable in an IPUMS dataset. The .xml file also provides 1) a brief label for each variable, and 2) the detailed variable description shown on the DESCRIPTION tab on our website. For instance, here is the DESCRIPTION tab for the variable PREGENDEV:\n\n\n\n\nYou can access all of the .xml metadata for PREGENDEV with the functions ipums_val_labels, ipums_var_label, and ipums_var_desc, or you can combine them into a tabular data dictionary with the function ipums_var_info. Let’s call this table dd.\n\n\ndd <- dat %>% ipums_var_info()\ndd\n\n# A tibble: 95 × 4\n   var_name   var_label                                         var_d…¹ val_la…²\n   <chr>      <chr>                                             <chr>   <list>  \n 1 SAMPLE     PMA sample number                                 \"SAMPL… <tibble>\n 2 COUNTRY    PMA country                                       \"COUNT… <tibble>\n 3 YEAR       Year                                              \"YEAR … <tibble>\n 4 ROUND      PMA survey round in this country                  \"ROUND… <tibble>\n 5 PERSONID   Unique person ID number                           \"PERSO… <tibble>\n 6 ELIGIBLE   Eligible female respondent                        \"ELIGI… <tibble>\n 7 EAID       Enumeration area                                  \"EAID … <tibble>\n 8 CONSENTFQ  Female respondent provided consent to be intervi… \"CONSE… <tibble>\n 9 FQINSTID   Unique ID for female questionnaire                \"FQINS… <tibble>\n10 CONSENTHQ  Household respondent provided consent to be inte… \"CONSE… <tibble>\n11 FQWEIGHT   Female weight                                     \"FQWEI… <tibble>\n12 STRATA     Strata                                            \"STRAT… <tibble>\n13 PREGENDEV  Ever had a pregnancy that miscarried, aborted, o… \"PREGE… <tibble>\n14 PREGEND    Had pregnancy that ended in last 3 yrs            \"PREGE… <tibble>\n15 ABORYRSAGO Number of years ago pregnancy ended               \"ABORY… <tibble>\n16 PREGENDYR  Year last pregnancy was terminated                \"For w… <tibble>\n17 PREGENDMO  Month last pregnancy was terminated               \"For w… <tibble>\n18 ABORWHERE  Where abortion was performed                      \"ABORW… <tibble>\n19 ABOREV     Ever aborted pregnancy                            \"ABORE… <tibble>\n20 ABORMON    Month of last aborted pregnancy                   \"ABORM… <tibble>\n# … with 75 more rows, and abbreviated variable names ¹​var_desc, ²​val_labels\n\nJust a quick note on terminology here: the terms data dictionary and codebook are often used interchangeably. Personally, I think of a data dictionary as a tabular or machine-readable tool describing the contents of a dataset (usually for the purpose of improving user experience with statistical software); a codebook is usually - well, book-like. Analysts often create a codebook containing metadata and summary statistics for each variable in a survey dataset.\nYou might want access to a data dictionary like dd if you wanted to quickly identify all of the variables in a data extract that contain a search term like “abort”.\n\n\ndd %>% \n  filter(var_label %>% str_detect(\"abort\")) %>% \n  pull(var_name)\n\n [1] \"PREGENDEV\"        \"ABORWHERE\"        \"ABOREV\"           \"ABORMON\"         \n [5] \"ABORYR\"           \"ABOROTHER\"        \"ABORNUM\"          \"ABOR1STYR\"       \n [9] \"ABORMULT\"         \"ABORONLYMETH\"     \"ABORFIRSTMETH\"    \"ABORLASTMETH\"    \n[13] \"ABORCARE\"         \"ABORFIRSTMEDLOC\"  \"ABORLASTMEDLOC\"   \"ABORFIRSTSURGLOC\"\n[17] \"ABORLASTSURGLOC\"  \"ABORYPARENTS\"     \"ABORDISCFRND1\"    \"ABORDISCFRND2\"   \n[21] \"ABORDISCFRND3\"    \"ABORDISCNONE\"    \n\nYou can also search the detailed variable description for each variable the same way:\n\n\ndd %>% \n  filter(var_desc %>% str_detect(\"abort\")) %>% \n  pull(var_name)\n\n [1] \"PREGENDEV\"        \"PREGEND\"          \"PREGENDYR\"        \"PREGENDMO\"       \n [5] \"ABORWHERE\"        \"ABOREV\"           \"ABORMON\"          \"ABORYR\"          \n [9] \"ABORINSCHOOL\"     \"ABOROTHER\"        \"ABORNUM\"          \"ABOR1STYR\"       \n[13] \"ABORMULT\"         \"ABORONLYMETH\"     \"ABORFIRSTMETH\"    \"ABORLASTMETH\"    \n[17] \"ABORCARE\"         \"ABORFIRSTMEDLOC\"  \"ABORLASTMEDLOC\"   \"ABORFIRSTSURGLOC\"\n[21] \"ABORLASTSURGLOC\"  \"ABORYFETUSHLTH\"   \"ABORYSOCIAL\"      \"ABORYHEALTH\"     \n[25] \"ABORYMATURE\"      \"ABORYMEANS\"       \"ABORYPARENTS\"     \"ABORYRAPE\"       \n[29] \"ABORYREADY\"       \"ABORYHUS\"         \"ABORYSCHOOL\"      \"ABORYSINGLE\"     \n[33] \"ABORYLIMIT\"       \"ABORYWORRIED\"     \"ABORYOTH\"         \"ABORDISCFRND1\"   \n[37] \"ABORDISCFRND2\"    \"ABORDISCFRND3\"    \"ABORDISCNONE\"     \"ABORCFBRO\"       \n[41] \"ABORCFDAD\"        \"ABORCFRND1\"       \"ABORCFRND2\"       \"ABORCFMOM\"       \n[45] \"ABORCFRNDOTH\"     \"ABORCFRELOTH\"     \"ABORCFPART\"       \"ABORCFSIS\"       \n[49] \"ABORCFFRND\"       \"ABORCFOTH\"       \n\nCodebook\nAnother reason you might want access to a data dictionary is that - combined with tools like pagedown or bookdown- it can help generate a detailed codebook with just a few lines of code.\n\nHere, we’ll build a quick codebook with pagedown, so we’ll need to create an RMarkdown file called codebook.Rmd with the following YAML header pointing to a helper CSS file in our working directory. We’ll specify that we want the output to be paginated for HTML (although we’ll ultimately tell R to turn that output into a PDF with chrome_print), and we’ll give a custom title to our Table Contents page.\n---\noutput:\n  pagedown::html_paged: \n    toc: true\n    self_contained: false\ntoc-title: 'IPUMS PMA Codebook: <br>Pregnancy Termination Variables'\ncss:  'custom.css'\n---\n\n\n\n\n\n© RStudio, Inc. (MIT)\n\n\nThe first few lines of code in this Rmarkdown file should load your dataset and create a data dictionary called dd as shown above. Additionally, we’ll drop the first 12 variables that are preselected for every IPUMS PMA data extract.\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\nlibrary(gtsummary)\nlibrary(gt)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00180.xml\",\n  data = \"data/pma_00180.dat.gz\"\n)\n\ndd <- dat %>% ipums_var_info() %>% slice(-c(1:12))\n\n\n\nBesides the information already contained in dd, we might want to add a table showing the frequency of each response for every labelled variable (excluding mainly ID variables like EAID and FQINSTID). We’ll use gtsummary to create a frequency table for every such variable, and we’ll attach the results in a column called tbl in our data dictionary.\n\n\ndd$tbl <- dd$var_name %>% \n  map(\n    ~if(dat[[.x]] %>% is.labelled){\n      dat %>%\n        select(!!.x) %>%\n        mutate(across(where(is.labelled), ~.x %>% as_factor %>% fct_drop)) %>%\n        tbl_summary() %>%\n        modify_footnote(update = list(stat_0 ~ NA)) %>%\n        bold_labels() %>%\n        as_gt() %>%\n        tab_options(\n          column_labels.hidden = TRUE,\n          table.font.names = \"cabrito_sans_norm_regular\",\n          table.width = pct(100),\n          table.font.size = \".8em\"\n        )\n    }\n  )\n\n\n\n\n\n\n\n© Daniel D. Sjoberg et al. (MIT)\n\n\n\nCheck out this post for an in-depth tutorial on gtsummary tables.\nNext we’ll use pwalk to iterate over each of the rows in dd: the walk family of functions works just like the iterative function map, except that the results are not returned in a list. Instead, we’ll call cat to capture the text results within each iteration.\nWhat about the p in pwalk? This stands for “parallel” in the sense that an arbitrary number of inputs can be processed in parallel. In our case, we want to return text from the columns var_name and var_desc, and then return either HTML code representing our gtsummary table or an explanation like Table omitted for space constraints.\nThis is achieved with a custom function with unnamed arguments represented by the ellipsis ... - this carries all of the columns in each row of dd into a list we call text. Hence, text$var_name returns SAMPLE in the first iteration, while text$var_desc returns its variable description and text$tbl returns its gtsummary table. The second iteration returns text for COUNTRY, and so-on.\n\n\ndd %>% \n  pwalk(function(...){\n    text <- list(...)\n    text$var_name %>% \n      paste(\"#\", ., \"{.unnumbered} \\n\\n\") %>% \n      paste(text$var_desc, \"\\n\\n\") %>% \n      cat()\n    if(is.null(text$tbl)){\n      cat(\"*Table omitted for space constraints*\\n\\n\")\n    } else {\n      text$tbl %>% as_raw_html() %>% cat()\n    }\n  })\n\n\n\nMake sure to use the option results='asis' in this chunk to capture the output of cat as plain text.\nOnce you’ve saved this RMarkdown file, type the following function directly into the R console to generate a PDF.\n\n\npagedown::chrome_print(\"codebook.Rmd\",\"codebook.pdf\")\n\n\nThe result looks like this:\n\n\n\n\nScraping Additional Metadata\nThis codebook is a great start, but you’ll find even more metadata available on the IPUMS PMA website. For example, the AVAILABILITY tab for PREGENDEV tells us that this variable is only available for certain samples:\n\n\n\n\nAlthough this information is not included in the .xml file we used to produce dd, we can easily scrape it from the website with help from the rvest package. First, locate the URL for the variable you want to scrape:\n\n\npma_url <- \"https://pma.ipums.org/pma-action/variables/PREGENDEV\"\n\n\n\nNext, we’ll load rvest and use a few of its basic functions to load the AVAILABILITY text into R. Each tab on the IPUMS PMA website is represented by CSS tag that also appears at the end of URL when you click on the tab. For example, clicking on the AVAILABILITY tab add the suffix #availability_section to the URL shown in pma_url.\nSimply use read_html to read the full HTML for pma_url, then pipe the HTML to html_elements to select “#availability_section” and html_text2 to return the text located there.\n\n\n\n\n\n© RStudio, Inc. (MIT)\n\n\n\n\nlibrary(rvest)\n\npma_text <- pma_url %>% \n  read_html() %>% \n  html_elements(\"#availability_section\") %>% \n  html_text2()\n\npma_text\n\n[1] \"Availability\\nIndia: 2017, 2020\\nUganda: 2020\"\n\nThis text includes special characters indicating line-breaks. Again, you can preview the formatted text with cat.\n\n\ncat(pma_text)\n\nAvailability\nIndia: 2017, 2020\nUganda: 2020\n\nAll of the tabs you’ll find on the IPUMS PMA site can be accessed this way, except for the CODES and QUESTIONNAIRE TEXT tabs. While the CODES tab is redundant with information already accessible in our dataset, there may be instances where you want to access the original text of the questionnaire. If you use the same approach to scrape it, you’ll get no results:\n\n\npma_url %>% \n  read_html() %>% \n  html_elements(\"#questionnaire_text_section\") %>% \n  html_text2() \n\n[1] \"\"\n\nThis is because Javascript is required to display text on both of these tabs. Fortunately, IPUMS also has a hidden static HTML page (which you can find by right-clicking on the QUESTIONNAIRE TEXT tab and clicking “inspect” on most browsers). You can use the following modified URL to scrape questionnaire text if needed:\n\n\npma_enum_text <- pma_url %>% \n  paste0(\"/ajax_enum_text\") %>% \n  read_html() %>% \n  html_elements(\".docSectionSample\") %>% \n  map_df(\n    ~c(\n      SAMPLE = .x %>% html_element(\".td1\") %>% html_text2(),\n      TEXT = .x %>% html_element(\".enum_section_text\") %>% html_text2()\n    )\n  )\n\npma_enum_text\n\n# A tibble: 3 × 2\n  SAMPLE      TEXT                                                              \n  <chr>       <chr>                                                             \n1 India 2017a \"1. Have you ever had a pregnancy that miscarried, was aborted, o…\n2 India 2020  \"207. Have you ever had a pregnancy that miscarried, was aborted,…\n3 Uganda 2020 \"207. Have you ever had a pregnancy that miscarried, was aborted,…\n\nSo what if we want to add text from each tab to our codebook? We’ll just need to iterate over each tab for every variable, and then add the results to dd.\n\n\ndd <- dd %>% \n  rowwise() %>% \n  mutate(\n    url = paste0(\"https://pma.ipums.org/pma-action/variables/\", var_name),\n    comp = url %>% \n      read_html() %>% \n      html_elements(\"#comparability_section\") %>% \n      html_text2(),\n    avail = url %>% \n      read_html() %>% \n      html_elements(\"#availability_section\") %>% \n      html_text2(),\n    universe = url %>% \n      read_html() %>% \n      html_elements(\"#universe_section\") %>% \n      html_text2(),\n    qtext = url %>% \n      paste0(\"/ajax_enum_text\") %>% \n      read_html() %>% \n      html_elements(\".docSectionSample\") %>% \n      map_df(\n        ~c(\n          SAMPLE = .x %>% html_element(\".td1\") %>% html_text2(),\n          TEXT = .x %>% html_element(\".enum_section_text\") %>% html_text2()\n        )\n      ) %>% \n      list()\n  ) %>% \n  ungroup()\n\n\n\n\n\n\n\n\nWe’ll then need to modify the final chunk in codebook.Rmd to add the text from each of these new columns. Our data extract contains 17 different samples, so we’ll choose not to show the questionnaire text we’ve scraped in each case - you could easily add it, though, if it’s important to compare small variations in the question administred in each survey.\n\n\n# Create headings for each metadata section \ndd <- dd %>% \n  mutate(\n    var_name = var_name %>% \n      paste(\"#\", ., \"{.unnumbered}\"),\n    comp = comp %>% \n      str_replace(\"Comparability\", \"#### Comparability {.unnumbered}\\n\"),\n    avail = avail %>% \n      str_replace_all(\"\\n\", \"\\n - \") %>% \n      str_replace(\"Availability\", \"#### Availability {.unnumbered}\\n\"),\n    universe = universe %>% \n      str_replace_all(\"\\n\", \"\\n - \") %>% \n      str_replace(\"Universe\", \"#### Universe {.unnumbered}\\n\")\n  )\n\n# Add one new `cat` for each new metadata section\ndd %>% \n  ungroup() %>% \n  pwalk(function(...){\n    text <- list(...)\n    text$var_name %>% cat(\"\\n\\n\")\n    text$var_desc %>% cat(\"\\n\\n\")\n    text$comp %>% cat(\"\\n\\n\")\n    text$avail %>% cat(\"\\n\\n\")\n    text$universe %>% cat(\"\\n\\n\")\n    cat(\"#### Results {.unnumbered} \\n\\n\")\n    if(is.null(text$tbl)){\n      cat(\"*Table omitted for space constraints*\\n\\n\")\n    } else {\n      text$tbl %>% as_raw_html() %>% cat()\n    }\n  })\n\n\nAnd here’s the final result - a fully automated codebook containing nearly all of the metadata available for each variable in the Pregnancy Termination group on the IPUMS PMA website!\n\n\n\n\n\n\n\n\n\n\n",
    "preview": "posts/2022-12-09-data-dictionary/images/featured.png",
    "last_modified": "2022-12-22T12:27:34-05:00",
    "input_file": {},
    "preview_width": 1077,
    "preview_height": 616
  },
  {
    "path": "posts/2022-11-28-icfp/",
    "title": "ICFP Workshop: Reasons for Unmet Need",
    "description": "IPUMS PMA hosted a coding workshop at the International Conference on Family Planning in Pattaya City, Thailand this month. Slides for both R and Stata users are available here!",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-11-28",
    "categories": [
      "Unmet Need",
      "Stata",
      "R",
      "Data Analysis",
      "Slides",
      "Quarto"
    ],
    "contents": "\nThis month, IPUMS PMA staff were excited to join researchers and advocates from around the world at the International Conference on Family Planning in Pattaya City, Thailand. Several faculty, graduate students, and post-doctoral researchers were on hand to discuss ongoing research projects featuring PMA data, and IPUMS PMA staff also hosted a pre-conference coding workshop showcasing PMA data addressing unmet need for family planning.\nSlides from the workshop are available to guide both R and Stata users, and Stata slides have been translated in French (we hope to release a French translation of the R slides soon, as well). You can also find these and other workshop materials on the IPUMS Global Health GitHub page.\n\nThese RevealJS slides were built in R with Quarto.\nStata Users\nEnglish version\n\nBrowser not supported! Visit https://ipums-global-health.github.io/icfp22/stata_slides.html for slides.\n\nFrench version\n\nBrowser not supported! Visit https://ipums-global-health.github.io/icfp22/stata_slides.html for slides.\n\nR Users\n\nBrowser not supported! Visit https://ipums-global-health.github.io/icfp22/r_slides.html for slides.\n\n\n\n\n",
    "preview": "posts/2022-11-28-icfp/images/featured.png",
    "last_modified": "2022-12-22T12:58:38-05:00",
    "input_file": {},
    "preview_width": 1440,
    "preview_height": 820
  },
  {
    "path": "posts/2022-11-18-phase2-pdf/",
    "title": "Longitudinal Analysis Guide",
    "description": "Attention Stata users! Our blog series covering the first two phases of PMA panel data is now available in PDF format, with separate versions featuring examples in both R and Stata.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-11-18",
    "categories": [
      "Panel Data",
      "Stata",
      "R",
      "PDF",
      "Data Analysis"
    ],
    "contents": "\nThanks to contributions from our friends at Biostat Global Consulting, IPUMS PMA is pleased to announce that we’ve released a PDF version of our blog series on PMA panel data adapted for Stata users. We’ve also reformatted the original R examples for readers who prefer a PDF.\nYou can find both versions of the PMA Longitudinal Analysis Guide below, or on our GitHub Page. If you’d like, you can also download a .do file containing all of the code featured in the Stata version (additional helper files are available here). R users can download an R Markdown file containing the full PDF text with embedded, executable R code.\nGuide for Stata Users\n\n\nGuide for R Users\n\n\nHow We Built This\nIf you visit our GitHub Page, you’ll notice two R Markdown files: one for the R version of this guide, and - perhaps surprisingly - one for the Stata version! Although we weren’t quite able to elegantly execute Stata code with R Markdown, building both documents with the same toolkit allowed us to create “twin” versions with a single set of layout options. Additionally, we were able to use hidden inline R functions in both documents that, for example, automatically style hyperlinks for IPUMS variables in R (UPPERCASE) and Stata (lowercase). Check out our utilities script on GitHub if you’d like to peek under the hood at these inline tools.\nHuge thanks to the authors of pagedown, an R package that uses the Page.js JavaScript library to paginate HTML content for PDF printing. If you’re someone who has already put a lot of thought into CSS for an website or blog, and you’re wondering if there’s an easy way to port your style guide to a book (without LaTeX) - this is it!\n\n\n\n",
    "preview": "posts/2022-11-18-phase2-pdf/images/pdf.png",
    "last_modified": "2022-11-18T12:47:15-05:00",
    "input_file": {},
    "preview_width": 1312,
    "preview_height": 924
  },
  {
    "path": "posts/2022-10-07-implant-removal/",
    "title": "Barriers to Implant Removal",
    "description": "For women who tried and were unable to have their implant removed in the past year, were the main obstacles related to provider willingness, access to services, or something else?",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-10-07",
    "categories": [
      "Data Analysis",
      "Data Visualization",
      "Measurement",
      "Implants",
      "LARCs"
    ],
    "contents": "\n\nContents\nData Availability\nRemoval Prevalence\nEstimation\nGraphics\n\nReasons for Failed Removal\nVariable Labels\nData Cleaning\nEstimation\nGraphics\n\n\n\n\n\nSubdermal implants - together with IUDs - are part of a group of\nfamily planning methods known as long-acting reversible\ncontraceptives (LARCs). Because they are highly effective,\nincreasingly affordable, and relatively easy to provide, use of implants\nhas grown\nvery rapidly in nearly all of the countries surveyed by PMA since\n2014. However, researchers have cautioned that some implant users in\nthese countries experience difficulty seeking implant removal\nservices from their healthcare provider. Senderowicz and Kolenda (2022),\nfor example, show that focus group participants in one FP2020 country\nstruggled to convince providers to remove their implant prior to its\nlabelled duration; women’s expressed desire to discontinue the method\nwere not considered legitimate in comparison with other factors:\n\n\n\n\nSource: Senderowicz and Kolenda (2022)\nIn response to these concerns, recent PMA surveys have asked current\nimplant users 1) whether they have tried to get their implant removed in\nthe past year, and 2) if so, why they were unable to get their implant\nremoved. Let’s take a look at the results they have collected to\ndate.\nData Availability\nThe structure of these two questions has evolved somewhat since they\nwere first posed to sampled women in Burkina Faso, Ethiopia, and Kenya\nbetween 2015 and 2016. Initially, current implant users in Ethiopia and\nKenya were asked whether they had ever tried to have their\nimplant removed (FPIMPREMOVETRY),\nand users in all three countries could only select one reason\nwhy they were unable to have it removed at that time (FPIMPRMVYNOT).\nAfter 2016, the questionnaire in each country was changed to ask only\nabout implant removal in the last year (FPIMPREMOVEYR),\nand the Burkina Faso and Kenya questionnaires allowed women to select\nmore than one reason why they were unable to have it removed\n(Ethiopia continued to allow selection of only one reason). Each of the\n11 reasons included in this multiple-response question is available as a\nbinary variable named with the prefix FPIMPRMVY (listed in\nquestionnaire order):\nFPIMPRMVYCLOSED\n- Facility not open\nFPIMPRMVYUNAVAIL\n- Qualified provider not available\nFPIMPRMVYUNSUCC\n- Provider attempted but could not remove the implant\nFPIMPRMVYREFUSE\n- Provider refused\nFPIMPRMVYCOST\n- Cost of removal services\nFPIMPRMVYTRAVEL\n- Travel cost\nFPIMPRMVYCOUNS\n- Provider counseled against removal\nFPIMPRMVYRETURN\n- Told to return another day\nFPIMPRMVYELSEWH\n- Referred elsewhwere\nFPIMPRMVYOTH\n- Other\nFPIMPRMVYDK\n- Don’t know\nThese questions were added to samples collected from the DRC,\nNigeria, and Uganda beginning in 2020; however, no information is\navailable about reasons for non-removal in the Uganda sample, where\nneither of the 3 qualifying women selected a reason. In Nigeria, only 4\nwomen qualified and provided a reason across both samples from Lagos and\nKano; in the DRC, there were only 4 in Kongo Central and 11 in\nKinshasa.\nData availability is summarised in the table below. Women could offer\nmultiple reasons for an implant removal attempted in the last year\nunless otherwise noted.\nCountry\nSample Years\nNotes\nBurkina Faso\n2016b-2021\nSelect one reason (2016b)\nDRC\n2020\n\nEthiopia\n2016-2019\nSelect one reason (2016-2019); Ever tried\n(2016)\nKenya\n2015b-2020\nSelect one reason (2015-2016); Reasons unavailable (2017);\nEver tried (2015b)\nNigeria\n2020\n\nUganda\n2020\nReasons unavailable\nRemoval Prevalence\nWith these caveats in mind, we’ll start by combining\nFPIMPREMOVETRY with FPIMPREMOVEYR to estimate\nthe prevalence of attempted implant removal among current implant users\nin each population.\nWe’ve downloaded an extract from IPUMS PMA containing all of the\nvariables and samples listed above (female respondents only), and we’ll\nload it into R along with several analysis packages as follows:\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\nlibrary(srvyr)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00175.xml\",\n  data = \"data/pma_00175.dat.gz\"\n)\n\n\n\n\n\n\nBefore we jump into our analysis, we’ll make three minor adjustments\nto this data extract. First, we’ll drop cases where PMA has assigned a\nweight of zero in FQWEIGHT.1 Second, we’ll create a variable\ncalled POP to label the population represented by each\nsample.2. Finally, we’ll make two minor\nmodifications to STRATA\nso that it can be used for samples with data where it is missing, or\nwhere there are strata with data from only one sample cluster (EAID).3\n\n\ndat <- dat %>% \n  filter(FQWEIGHT > 0) %>% \n  mutate(\n    POP = case_when(\n      !is.na(GEOCD) ~ paste(\"DRC -\", GEOCD %>% as_factor, YEAR),\n      !is.na(GEONG) ~ paste(\"Nigeria -\", GEONG %>% as_factor, YEAR),\n      TRUE ~ paste(COUNTRY %>% as_factor, YEAR)\n    ),\n    STRATARC = case_when(\n      !is.na(GEOCD) ~ as.numeric(GEOCD),\n      as_factor(COUNTRY) %in% c(\"Ethiopia\", \"Uganda\") ~ as.numeric(URBAN), \n      TRUE ~ as.numeric(STRATA)\n    )\n  ) \n\n\n\nEstimation\nNow, we can easily calculate the estimated proportion of implant\nusers in each population who tried to have their implant removed in the\nlast year (or ever as noted in some early samples). We start by\ncombining the information in FPIMPREMOVETRY with\nFPIMPREMOVEYR in a variable we’ll call\ntried.\nNotice that FPIMPREMOVETRY and\nFPIMPREMOVEYR use composite coding to\nindicate both 1) whether implant removal was attempted, and 2) whether\nremoval was sought by a health professional (in available samples).\nHowever, FPIMPREMOVETRY uses codes 21 and 22 to indicate\n“yes”, while FPIMPREMOVEYR uses codes 10, 11, and 12. The\ncode 98 is used for non-response, while 99 is used for women who were\nnot currently implant users; we’ll recode these values with\nNA.\n\n\ndat <- dat %>% \n  mutate(\n    tried = case_when(\n      FPIMPREMOVETRY < 90 ~ FPIMPREMOVETRY %in% 20:30,\n      FPIMPREMOVEYR < 90 ~ FPIMPREMOVEYR %in% 10:20\n    )\n  ) \n\n# review recoding\ndat %>% count(tried, FPIMPREMOVETRY, FPIMPREMOVEYR)\n\n\n# A tibble: 10 × 4\n   tried FPIMPREMOVETRY                         FPIMPREMOVEYR                              n\n   <lgl> <int+lbl>                              <int+lbl>                              <int>\n 1 FALSE 10 [No]                                NA                                       894\n 2 FALSE NA                                      0 [No]                                10037\n 3 TRUE  21 [Yes, by a health professional]     NA                                        57\n 4 TRUE  22 [Yes, by a non-health professional] NA                                         1\n 5 TRUE  NA                                     10 [Yes]                                 342\n 6 TRUE  NA                                     11 [Yes, health care professional]        69\n 7 TRUE  NA                                     12 [Yes, not health care professional]     1\n 8 NA    99 [NIU (not in universe)]             NA                                     11451\n 9 NA    NA                                     98 [No response or missing]                6\n10 NA    NA                                     99 [NIU (not in universe)]             83301\n\nIn tried, we’ve created a logical\nbinary variable. For users who might only be interested in the\npoint-estimate for each population (ignoring confidence interval\nestimation), you can now take a weighted.mean of\ntried weighted by FQWEIGHT.\nWe’ll also include n to show the number of responding\nimplant users in each sample.\n\n\ndat %>% \n  group_by(POP) %>% \n  summarise(\n    tried_prop = weighted.mean(tried, FQWEIGHT, na.rm= TRUE),\n    n = sum(!is.na(tried))\n  )\n\n\n# A tibble: 20 × 3\n   POP                      tried_prop     n\n   <chr>                         <dbl> <int>\n 1 Burkina Faso 2016           0.0710    320\n 2 Burkina Faso 2017           0.0453    421\n 3 Burkina Faso 2018           0.0342    365\n 4 Burkina Faso 2019           0.0340    818\n 5 Burkina Faso 2021           0.0462    777\n 6 DRC - Kinshasa 2020         0.103     150\n 7 DRC - Kongo Central 2020    0.0244    196\n 8 Ethiopia 2016               0.0722    462\n 9 Ethiopia 2017               0.0388    444\n10 Ethiopia 2018               0.0366    488\n11 Ethiopia 2019               0.0554    675\n12 Kenya 2015                  0.0411    490\n13 Kenya 2016                  0.0525    713\n14 Kenya 2017                  0.0925    798\n15 Kenya 2018                  0.0333    823\n16 Kenya 2019                  0.0199   1531\n17 Kenya 2020                  0.0262   1471\n18 Nigeria - Kano 2020         0.0116     31\n19 Nigeria - Lagos 2020        0.0472     64\n20 Uganda 2020                 0.00894   364\n\nTo obtain a 95% confidence interval for each estimate, we’ll need to\nuse tools from the srvyr package.\nFirst, we group the data by POP to ensure that the correct\ndegrees of freedom are used from each sample. Then, we summarise\neach group using FQWEIGHT and sample-specific clusters and\nstrata. Finally, survey_mean\ngives us an asymmetric confidence interval (adjusted for proportions\nnear 0% or 100%).\nWe’ll want to graph these results, so we’ll save the output as\ntried_tbl.\n\n\ntried_tbl <- dat %>%\n  group_by(POP) %>% \n  summarise(\n    cur_data() %>% \n      as_survey_design(weight = FQWEIGHT, id = EAID, strata = STRATARC) %>%\n      summarise(\n        tried_prop = survey_mean(tried, proportion = TRUE, vartype = \"ci\"),\n        n = sum(!is.na(tried))\n      )\n  )\n\ntried_tbl\n\n\n# A tibble: 20 × 5\n   POP                      tried_prop tried_prop_low tried_prop_upp     n\n   <chr>                         <dbl>          <dbl>          <dbl> <int>\n 1 Burkina Faso 2016           0.0710         0.0380          0.129    320\n 2 Burkina Faso 2017           0.0453         0.0276          0.0735   421\n 3 Burkina Faso 2018           0.0342         0.0175          0.0658   365\n 4 Burkina Faso 2019           0.0340         0.0205          0.0560   818\n 5 Burkina Faso 2021           0.0462         0.0306          0.0691   777\n 6 DRC - Kinshasa 2020         0.103          0.0596          0.172    150\n 7 DRC - Kongo Central 2020    0.0244         0.00778         0.0738   196\n 8 Ethiopia 2016               0.0722         0.0475          0.108    462\n 9 Ethiopia 2017               0.0388         0.0221          0.0671   444\n10 Ethiopia 2018               0.0366         0.0203          0.0653   488\n11 Ethiopia 2019               0.0554         0.0360          0.0844   675\n12 Kenya 2015                  0.0411         0.0243          0.0687   490\n13 Kenya 2016                  0.0525         0.0292          0.0926   713\n14 Kenya 2017                  0.0925         0.0695          0.122    798\n15 Kenya 2018                  0.0333         0.0187          0.0586   823\n16 Kenya 2019                  0.0199         0.0130          0.0304  1531\n17 Kenya 2020                  0.0262         0.0175          0.0389  1471\n18 Nigeria - Kano 2020         0.0116         0.00126         0.0988    31\n19 Nigeria - Lagos 2020        0.0472         0.0134          0.153     64\n20 Uganda 2020                 0.00894        0.00196         0.0399   364\n\nGraphics\nLet’s plot these results as a bar chart with error bars for each\nconfidence interval. We’ll organize the bar for each sample in rows,\nwhere the length of each bar on the x-axis is mapped to\ntried_prop. The length of each error bar will be mapped to\ntried_prop_low and tried_prop_upp. Because the\nEthiopia 2016 and Kenya 2015 samples actually ask whether the woman\never tried to have her implant removed, we’ll add a\n* symbol to each of those POP labels, along\nwith a caption at the bottom.\n\n\ntried_tbl %>% \n  mutate(\n    POP = if_else(\n      POP %in% c(\"Ethiopia 2016\", \"Kenya 2015\"),\n      paste0(POP, \"*\"),\n      POP\n    ),\n    POP = paste0(POP, \"\\nN = \", n)\n  ) %>% \n  ggplot(aes(x = tried_prop, y = POP, \n             xmin = tried_prop_low, xmax = tried_prop_upp)) + \n  geom_bar(stat = \"identity\", fill = \"#00263A\", alpha = 0.7) +\n  geom_errorbar(width = 0.2, alpha = 0.4) +\n  scale_x_continuous(labels = scales::label_percent()) + \n  labs(\n    title = paste(\"IN THE PAST 12 MONTHS, HAVE YOU TRIED TO HAVE YOUR CURRENT\",\n                  \"IMPLANT REMOVED?\") %>% \n      str_wrap(50),\n    subtitle = paste(\"Weighted percentages (95% CI) from sampled women age\",\n                     \"15-49 who were currently using an implant (N)\"),\n    caption = paste(\"* Includes women who have EVER tried to have their\",\n                    \"current implant removed\"),\n    y = NULL, \n    x = NULL\n  ) + \n  theme_minimal() +\n  theme(\n    text = element_text(family=\"cabrito\"),\n    panel.grid.major.y = element_blank(),\n    plot.title = element_text(size = 22, color = \"#00263A\",\n                              hjust = 0, margin = margin(b = 5)),\n    plot.subtitle = element_text(size = 12, hjust = 0, \n                                 margin = margin(b = 10)),\n    legend.position = \"none\"\n  ) \n\n\n\n\nLooking at these results, a few things stand out: first, there\ndoesn’t appear to be (at least to my eye) a clear pattern in the way\nthis issue has developed over time or across countries. While the number\nof sampled implant users has grown over time (reflecting its increased\npopularity), the share of current users who have tried to have their\nimplant removed is almost always within a fairly regular confidence\ninterval. Second, we rarely expect that more than 10% of current implant\nusers have attempted removal, and most outlying populations probably\ndon’t exceed about 15% of current users; the mean value across sampled\npopulations is probably closer to 5%.\nAnother important thing to consider here is the effect of survival\nbias. Remember: these data only include women who are current\nimplant users, so they exclude women who actually did have\ntheir implant removed successfully within the past year. If we were able\nto identify all of the women who used implants in the past year, the\nproportion who attempted removal would be higher, but it would include\nwomen who experienced no difficulty doing so.\nReasons for Failed Removal\nTurning our attention to reasons for failed removal, we’ll again have\nto contend with two sets of variables: in one set, women could only\nselect one reason in FPIMPRMVYNOT; in the other set, women\ncould select any number of reasons in other variables named with the\nprefix FPIMPRMVY.\nWe’ll be modifying the latter set with responses from\nFPIMPRMVYNOT, so it might be useful to set our IPUMS\nvariable labels aside for now. We’ll return to them\nafter data manipulation so that we can use them directly on our\ngraph.\nVariable Labels\nTip: you can use ipums_var_info\nto get a tidy data dictionary for any IPUMS extract! This includes\ncolumns for the variable label, a full-text variable description, and a\ntable of value labels.\n\n\nreason_labels <- dat %>% \n  select(starts_with(\"FPIMPRMVY\")) %>% \n  ipums_var_info()\n\nreason_labels\n\n\n# A tibble: 12 × 4\n   var_name         var_label                                                 var_desc      val_la…¹\n   <chr>            <chr>                                                     <chr>         <list>  \n 1 FPIMPRMVYNOT     Reason not able to have implant removed                   \"For women w… <tibble>\n 2 FPIMPRMVYCOST    Why implant not removed: Service cost                     \"For women w… <tibble>\n 3 FPIMPRMVYCOUNS   Why implant not removed: Provider counseled against       \"For women w… <tibble>\n 4 FPIMPRMVYDK      Why implant not removed: Don't know                       \"For women w… <tibble>\n 5 FPIMPRMVYCLOSED  Why implant not removed: Facility closed                  \"For women w… <tibble>\n 6 FPIMPRMVYOTH     Why implant not removed: Other                            \"For women w… <tibble>\n 7 FPIMPRMVYREFUSE  Why implant not removed: Provider refused                 \"For women w… <tibble>\n 8 FPIMPRMVYELSEWH  Why implant not removed: Referred elsewhere               \"For women w… <tibble>\n 9 FPIMPRMVYRETURN  Why implant not removed: Told to return another day       \"For women w… <tibble>\n10 FPIMPRMVYTRAVEL  Why implant not removed: Travel cost                      \"For women w… <tibble>\n11 FPIMPRMVYUNAVAIL Why implant not removed: Qualified provider not available \"For women w… <tibble>\n12 FPIMPRMVYUNSUCC  Why implant not removed: Failed attempt by provider       \"For women w… <tibble>\n# … with abbreviated variable name ¹​val_labels\n\nWe’ll remove the repeated text “Why implant not removed:”, along with\nthe other columns we won’t be using here.\n\n\nreason_labels <- reason_labels %>% \n  mutate(var_label = var_label %>% str_remove(\"Why implant not removed: \")) %>% \n  select(var_name, var_label)\n\nreason_labels\n\n\n# A tibble: 12 × 2\n   var_name         var_label                              \n   <chr>            <chr>                                  \n 1 FPIMPRMVYNOT     Reason not able to have implant removed\n 2 FPIMPRMVYCOST    Service cost                           \n 3 FPIMPRMVYCOUNS   Provider counseled against             \n 4 FPIMPRMVYDK      Don't know                             \n 5 FPIMPRMVYCLOSED  Facility closed                        \n 6 FPIMPRMVYOTH     Other                                  \n 7 FPIMPRMVYREFUSE  Provider refused                       \n 8 FPIMPRMVYELSEWH  Referred elsewhere                     \n 9 FPIMPRMVYRETURN  Told to return another day             \n10 FPIMPRMVYTRAVEL  Travel cost                            \n11 FPIMPRMVYUNAVAIL Qualified provider not available       \n12 FPIMPRMVYUNSUCC  Failed attempt by provider             \n\nData Cleaning\nWe’ll again transform each of our multiple-response variables into a\nlogical binary variable, where NA\nrepresents women who were either not currently an implant user or had\nnot tried to remove it in the last year (these cases are marked “NIU”\nfor “Not in universe”). This should impact all of the variables with the\nprefix FPIMPRMVY except FPIMPRMVYNOT (the\nvariable used for samples accepting only one reason per woman).\n\n\ndat <- dat %>% \n  mutate(\n    across(\n      starts_with(\"FPIMPRMVY\") & !FPIMPRMVYNOT,\n      ~case_when(tried ~ .x == 1) \n    )\n  )\n\n\n\nNext, we’ll make a helper variable to indicate whether we should\nupdate each of these variables with appropriate values from\nFPIMPRMVYNOT. This is the case only if a woman\ntried to remove her implant and FPIMPRMVYNOT\nis not missing (NA) for her sample.\n\n\ndat <- dat %>% mutate(update = tried & !is.na(FPIMPRMVYNOT))\n\n\n\nFinally, we’ll update each of the multiple-response\nvariables with each of the appropriate values from\nFPIMPRMVYNOT as needed, leaving it unchanged otherwise.\n\n\ndat <- dat %>% \n  mutate(\n    FPIMPRMVYCLOSED = update %>% if_else(FPIMPRMVYNOT == 1, FPIMPRMVYCLOSED),\n    FPIMPRMVYUNAVAIL = update %>% if_else(FPIMPRMVYNOT == 2, FPIMPRMVYUNAVAIL),\n    FPIMPRMVYUNSUCC = update %>% if_else(FPIMPRMVYNOT == 3, FPIMPRMVYUNSUCC),\n    FPIMPRMVYREFUSE = update %>% if_else(FPIMPRMVYNOT == 4, FPIMPRMVYREFUSE),\n    FPIMPRMVYCOST = update %>% if_else(FPIMPRMVYNOT == 5, FPIMPRMVYCOST),\n    FPIMPRMVYTRAVEL = update %>% if_else(FPIMPRMVYNOT == 6, FPIMPRMVYTRAVEL),\n    FPIMPRMVYCOUNS = update %>% if_else(FPIMPRMVYNOT == 7, FPIMPRMVYCOUNS),\n    FPIMPRMVYRETURN = update %>% if_else(FPIMPRMVYNOT == 8, FPIMPRMVYRETURN),\n    FPIMPRMVYELSEWH = update %>% if_else(FPIMPRMVYNOT == 9, FPIMPRMVYELSEWH),\n    FPIMPRMVYOTH = update %>% if_else(FPIMPRMVYNOT == 10, FPIMPRMVYOTH),\n    FPIMPRMVYDK = update %>% if_else(FPIMPRMVYNOT == 97, FPIMPRMVYDK),\n  ) \n\n\n\nEstimation\nBefore we can estimate the proportion of failed removal cases caused\nby each reason, we’ll need to address a few more data availability\nissues. For starters, we mentioned above that the Kenya 2017 and Uganda\n2020 samples contain no data on any of the reasons, so we’ll drop them\nfrom our dataset right away.\n\n\nreasons <- dat %>% filter(POP != \"Kenya 2017\", POP != \"Uganda 2020\")\n\n\n\nAnother issue is that some samples include very few implant\nusers who attempted to remove it in the last year. Following our data\ncleaning procedure above, you’ll see the total number of qualifying\ncases if you count the number of non-NA values for any one of the\nFPIMPRMVY variables we’ve modified. For example, we’ll use\nFPIMPRMVYCOUNS:\n\n\npop_cases <- reasons %>% \n  filter(!is.na(FPIMPRMVYCOUNS)) %>% \n  count(POP)\n\npop_cases\n\n\n# A tibble: 18 × 2\n   POP                          n\n   <chr>                    <int>\n 1 Burkina Faso 2016           20\n 2 Burkina Faso 2017           18\n 3 Burkina Faso 2018           12\n 4 Burkina Faso 2019           26\n 5 Burkina Faso 2021           35\n 6 DRC - Kinshasa 2020         11\n 7 DRC - Kongo Central 2020     4\n 8 Ethiopia 2016               35\n 9 Ethiopia 2017               16\n10 Ethiopia 2018               21\n11 Ethiopia 2019               37\n12 Kenya 2015                  23\n13 Kenya 2016                  34\n14 Kenya 2018                  22\n15 Kenya 2019                  34\n16 Kenya 2020                  42\n17 Nigeria - Kano 2020          1\n18 Nigeria - Lagos 2020         3\n\nIn some cases, fewer than five women reported trying to remove their\nimplant in the past year. We’ll omit these samples from our final\nanalysis, where the proportion selecting any one reason is not likely to\nbe very meaningful.\n\n\npop_cases <- pop_cases %>% filter(n > 5)\nreasons <- reasons %>% filter(POP %in% pop_cases$POP)\n\n\n\nFinally, there are also several samples where certain reasons were\nnot included in the questionnaire: the Kenya 2018-2019 samples do not\ninclude “failed attempt by provider”, while the Kenya 2018-2020, Burkina\nFaso 2019-2021, and DRC 2020 samples include no option for “don’t know”.\nThese samples include only NA values for the variables\nrepresenting each of those reasons.\nIf you attempt to estimate the standard error for proportion\ncontaining only NA values, the srvyr package\ngenerates an error like this one:\n\n\nreasons %>% \n  filter(POP == \"Kenya 2020\") %>% \n  as_survey_design(weight = FQWEIGHT, id = EAID, strata = STRATARC) %>% \n  summarise(\n    survey_mean(FPIMPRMVYDK, proportion = TRUE, vartype = \"ci\")\n  )\n\n\nError in `dplyr::summarise()`:\n! Problem while computing `..1 = survey_mean(FPIMPRMVYDK, proportion = TRUE, vartype =\n  \"ci\")`.\nCaused by error in `family$linkfun()`:\n! Argument mu must be a nonempty numeric vector\n\nFortunately, you can avoid this error by setting\nproportion = FALSE in only those cases. This will return\nNA for the estimated proportion and confidence\ninterval.\n\n\nreasons %>% \n  filter(POP == \"Kenya 2020\") %>% \n  as_survey_design(weight = FQWEIGHT, id = EAID, strata = STRATARC) %>% \n  summarise(\n    survey_mean(FPIMPRMVYDK, proportion = !all(is.na(FPIMPRMVYDK)), vartype = \"ci\")\n  )\n\n\n# A tibble: 1 × 3\n   coef `_low` `_upp`\n  <dbl>  <dbl>  <dbl>\n1    NA     NA     NA\n\nWe’ll use across to\nsummarise\neach reason this way, and then we’ll use pivot_longer\nto store the results from each reason in a separate row.\n\n\nreasons_tbl <- reasons %>% \n  group_by(POP) %>%\n  summarise(\n    cur_data() %>%\n      as_survey_design(weight = FQWEIGHT, id = EAID, strata = STRATARC) %>% \n      summarise(across(\n        starts_with(\"FPIMPRMVY\") & !FPIMPRMVYNOT,\n        ~survey_mean(\n          .x,\n          proportion = !all(is.na(.x)),\n          vartype = \"ci\"\n        ) %>% list()\n      )) \n  ) %>% \n  pivot_longer(where(is.list), names_to = \"var_name\") %>% \n  unnest(value)\n  \nreasons_tbl\n\n\n# A tibble: 165 × 5\n   POP               var_name             coef   `_low`   `_upp`\n   <chr>             <chr>               <dbl>    <dbl>    <dbl>\n 1 Burkina Faso 2016 FPIMPRMVYCOST    1.16e- 1 2.57e- 2 3.97e- 1\n 2 Burkina Faso 2016 FPIMPRMVYCOUNS   2.28e- 1 6.88e- 2 5.42e- 1\n 3 Burkina Faso 2016 FPIMPRMVYDK      1.50e- 1 4.03e- 2 4.27e- 1\n 4 Burkina Faso 2016 FPIMPRMVYCLOSED  1.93e- 2 2.52e- 3 1.33e- 1\n 5 Burkina Faso 2016 FPIMPRMVYOTH     5.52e- 2 1.56e- 2 1.77e- 1\n 6 Burkina Faso 2016 FPIMPRMVYREFUSE  1.14e- 1 3.32e- 2 3.23e- 1\n 7 Burkina Faso 2016 FPIMPRMVYELSEWH  6.56e- 2 8.28e- 3 3.72e- 1\n 8 Burkina Faso 2016 FPIMPRMVYRETURN  7.19e-12 3.90e-12 1.32e-11\n 9 Burkina Faso 2016 FPIMPRMVYTRAVEL  7.19e-12 3.90e-12 1.32e-11\n10 Burkina Faso 2016 FPIMPRMVYUNAVAIL 1.87e- 1 4.53e- 2 5.26e- 1\n11 Burkina Faso 2016 FPIMPRMVYUNSUCC  6.50e- 2 9.47e- 3 3.36e- 1\n12 Burkina Faso 2017 FPIMPRMVYCOST    2.61e- 1 9.96e- 2 5.29e- 1\n13 Burkina Faso 2017 FPIMPRMVYCOUNS   9.16e- 2 1.70e- 2 3.70e- 1\n14 Burkina Faso 2017 FPIMPRMVYDK      1.90e- 2 2.43e- 3 1.33e- 1\n15 Burkina Faso 2017 FPIMPRMVYCLOSED  7.07e-12 4.10e-12 1.22e-11\n16 Burkina Faso 2017 FPIMPRMVYOTH     6.46e- 2 8.29e- 3 3.64e- 1\n17 Burkina Faso 2017 FPIMPRMVYREFUSE  1.68e- 1 5.01e- 2 4.38e- 1\n18 Burkina Faso 2017 FPIMPRMVYELSEWH  1.12e- 1 2.03e- 2 4.35e- 1\n19 Burkina Faso 2017 FPIMPRMVYRETURN  9.65e- 2 1.72e- 2 3.95e- 1\n20 Burkina Faso 2017 FPIMPRMVYTRAVEL  7.66e- 2 9.92e- 3 4.07e- 1\n# … with 145 more rows\n\nTo finish the table, we’ll now attach the number of\npop_cases and the appropriate reason_labels we\nsaved above.\n\n\nreasons_tbl <- reasons_tbl %>% \n  left_join(pop_cases, by = \"POP\") %>% \n  left_join(reason_labels, by = \"var_name\")\n\nreasons_tbl\n\n\n# A tibble: 165 × 7\n   POP               var_name             coef   `_low`   `_upp`     n var_label                    \n   <chr>             <chr>               <dbl>    <dbl>    <dbl> <int> <chr>                        \n 1 Burkina Faso 2016 FPIMPRMVYCOST    1.16e- 1 2.57e- 2 3.97e- 1    20 Service cost                 \n 2 Burkina Faso 2016 FPIMPRMVYCOUNS   2.28e- 1 6.88e- 2 5.42e- 1    20 Provider counseled against   \n 3 Burkina Faso 2016 FPIMPRMVYDK      1.50e- 1 4.03e- 2 4.27e- 1    20 Don't know                   \n 4 Burkina Faso 2016 FPIMPRMVYCLOSED  1.93e- 2 2.52e- 3 1.33e- 1    20 Facility closed              \n 5 Burkina Faso 2016 FPIMPRMVYOTH     5.52e- 2 1.56e- 2 1.77e- 1    20 Other                        \n 6 Burkina Faso 2016 FPIMPRMVYREFUSE  1.14e- 1 3.32e- 2 3.23e- 1    20 Provider refused             \n 7 Burkina Faso 2016 FPIMPRMVYELSEWH  6.56e- 2 8.28e- 3 3.72e- 1    20 Referred elsewhere           \n 8 Burkina Faso 2016 FPIMPRMVYRETURN  7.19e-12 3.90e-12 1.32e-11    20 Told to return another day   \n 9 Burkina Faso 2016 FPIMPRMVYTRAVEL  7.19e-12 3.90e-12 1.32e-11    20 Travel cost                  \n10 Burkina Faso 2016 FPIMPRMVYUNAVAIL 1.87e- 1 4.53e- 2 5.26e- 1    20 Qualified provider not avail…\n11 Burkina Faso 2016 FPIMPRMVYUNSUCC  6.50e- 2 9.47e- 3 3.36e- 1    20 Failed attempt by provider   \n12 Burkina Faso 2017 FPIMPRMVYCOST    2.61e- 1 9.96e- 2 5.29e- 1    18 Service cost                 \n13 Burkina Faso 2017 FPIMPRMVYCOUNS   9.16e- 2 1.70e- 2 3.70e- 1    18 Provider counseled against   \n14 Burkina Faso 2017 FPIMPRMVYDK      1.90e- 2 2.43e- 3 1.33e- 1    18 Don't know                   \n15 Burkina Faso 2017 FPIMPRMVYCLOSED  7.07e-12 4.10e-12 1.22e-11    18 Facility closed              \n16 Burkina Faso 2017 FPIMPRMVYOTH     6.46e- 2 8.29e- 3 3.64e- 1    18 Other                        \n17 Burkina Faso 2017 FPIMPRMVYREFUSE  1.68e- 1 5.01e- 2 4.38e- 1    18 Provider refused             \n18 Burkina Faso 2017 FPIMPRMVYELSEWH  1.12e- 1 2.03e- 2 4.35e- 1    18 Referred elsewhere           \n19 Burkina Faso 2017 FPIMPRMVYRETURN  9.65e- 2 1.72e- 2 3.95e- 1    18 Told to return another day   \n20 Burkina Faso 2017 FPIMPRMVYTRAVEL  7.66e- 2 9.92e- 3 4.07e- 1    18 Travel cost                  \n# … with 145 more rows\n\nGraphics\nBecause we’re working with a larger number of samples and reasons for\nfailed removal, we’ll build a concise heatmap showing\nthe proportion associated with each response. We’ll arrange the reasons\non our x-axis in the order of their average proportion across samples.\nThen, we’ll map a color gradient and text label to the proportion in\neach cell (switching font color from white to black if the proportion\nexceeds 0.35).\n\n\nreasons_tbl %>% \n  mutate(\n    var_label = var_label %>% fct_reorder(coef, mean, na.rm = T) %>% fct_rev(),\n    final = paste0(POP, paste0(\"\\nN = \", n)),\n    coef_pct = if_else(is.na(coef), \"NA\", scales::percent(coef, 1))\n  ) %>%  \n  ggplot(aes(x = var_label, y = final, fill = coef)) + \n  geom_tile() + \n  geom_text(aes(label = coef_pct, color = coef > 0.35)) +\n  theme_minimal() +  \n  theme(\n    text = element_text(family=\"cabrito\"),\n    panel.grid = element_blank(),\n    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1, \n                               margin = margin(t = 5)),\n    plot.title = element_text(size = 22, color = \"#00263A\",\n                              hjust = 0, margin = margin(b = 5)),\n    plot.subtitle = element_text(size = 12, hjust = 0, margin = margin(b = 10)),\n    legend.position = \"none\"\n  ) + \n   scale_fill_gradient(\n    na.value = \"transparent\",\n    low =  \"#00263A05\",\n    high = \"#00263A\"\n  ) + \n  scale_color_manual(values = c(\"black\", \"white\")) + \n  labs(\n    title = \"WHY WERE YOU NOT ABLE TO HAVE YOUR IMPLANT REMOVED?\",\n    subtitle = paste(\n      \"Weighted percentages for women age 15-49 who were currently using an\",\n      \"implant and attempted to have it \\nremoved within the last 12 months (N)\"\n    ),\n    y = NULL, \n    x = NULL\n  )\n\n\n\n\nAgain, we should keep in-mind that the overall number of women who\nwere unable to remove their current implant is quite low across samples\n(as shown by N). However, among those who did experience\ndifficulty, the most popular reasons include provider counseling,\ndelays, and refusals (together with “Other” reasons). Issues related to\naccess - costs, provider availability, facility closure, etc. - are less\ncommonly listed as barriers to removal.\n\n\n\nSenderowicz, Leigh, and Al Kolenda. 2022. “‘She Told Me No,\nThat You Cannot Change’: Understanding Provider Refusal to Remove\nContraceptive Implants.” SSM - Qualitative Research in\nHealth 2: 100154. https://www.sciencedirect.com/science/article/pii/S2667321522001160.\n\n\nUsually, PMA assigns zero weight to\nwomen who are not members of the de facto population. Removal\nof these cases is not technically necessary, because they drop out\nautomatically when weights are applied; doing so simply prevents\nsrvyr from issuing a warning message.↩︎\nAll of the samples included in our\nanalysis are nationally representative, except for subnationally\nrepresentative samples from the DRC and Nigeria. We’ll label these\nsamples with their respective regions.↩︎\nEach of the DRC samples uses a single\nstratum, so STRATA is NA (blank) in the\noriginal data; we’ll replace these blank values with a numeric code\nrepresenting the two represented regions (GEOCD).\nThe Ethiopia and Uganda samples are stratified by urban and rural areas\nwith in each region, resulting in 27 strata for Ethiopia and 92 strata\nfor Uganda; many of these strata contain data from only one sample\ncluster, but each stratum must contain at least two clusters in\norder to correctly calculate standard error under a stratified cluster\nsample design. R generates an error if we use STRATA as\nprovided, so we’ll oversimplify the original design by dividing Ethiopia\nand Uganda samples into just two urban and rural strata.↩︎\n",
    "preview": "posts/2022-10-07-implant-removal/implant-removal_files/figure-html5/unnamed-chunk-21-1.png",
    "last_modified": "2022-10-11T10:16:46-04:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1728
  },
  {
    "path": "posts/2022-09-15-leaflet-eda/",
    "title": "Data Exploration with Leaflet",
    "description": "Using interactive maps for exploratory data analysis with PMA GPS data",
    "author": [
      {
        "name": "Finn Roberts",
        "url": "https://www.linkedin.com/in/finn-roberts-b04b98148/"
      }
    ],
    "date": "2022-09-15",
    "categories": [
      "Leaflet",
      "Data Analysis",
      "Data Visualization",
      "Spatial",
      "Mapping"
    ],
    "contents": "\n\nContents\nSetup\nIntroduction to Leaflet\nBasemaps\nAdding Spatial Features\n\nRoad\nNetwork Metrics\nObtaining\nData\nRoad Distance\nMapping EAs\nGrid Layer\n\nRoad Density\nLayer Toggle\n\n\nPopup Tables\n\nSeveral recent posts have introduced techniques for integrating\nspatial data sources with PMA survey data. We’ve explored precipitation\npatterns in Burkina Faso using terra, considered the evolution of conflict areas in\nUganda from 2019-2020, and created multi-country faceted maps using cowplot.\nIn each of these cases, we’ve relied on the familiar ggplot2 and ggspatial packages\nas our cartographic workhorses. ggplot2 can be a powerful\ntool when making maps, and its standardized syntax for both spatial and\nnon-spatial data visualization is appealing, but in practice it is best\nfor producing static maps.\nIn many — probably most — cases, a static map is all that we need to\ndisplay the spatial patterns present in our data, but there are\nsituations in which it can be beneficial to be able to interact with the\nmap directly. Interactivity is often thought of as a\nfeature to be employed in a final visualization product, but it can be\nextremely useful during data exploration, as well.\nBy allowing the reader to click to receive specific information about\ncertain spatial features, zoom and pan to see both macro- and\nmicro-level patterns, toggle between different metrics, and more,\ninteractive maps can make it easier to:\nFamiliarize oneself with a new spatial data source\nConduct quality assurance to ensure that spatial computations are\nbehaving as might be expected\nVisualize variables that show a broad range of spatial variation.\n(For example, some areas may have a high density of features, while\nother areas have no features at all.)\nGenerate new hypotheses or research questions based on initial\nexploration of the spatial distribution of a variable\nCompare different operational definitions of a spatial variable of\ninterest\n\nIn this post, we’ll use the leaflet package to explore\nthe spatial distribution of two competing metrics for urbanism using PMA panel data from Kenya.\nIPUMS PMA has a variable indicating whether an enumeration area is urban\nor rural (URBAN),\nbut the definition of this variable is not well-standardized across\ncountries, so an external data source may provide a more reliable\nindication of urbanism.\nThe leaflet package provides an R interface with the leaflet.js JavaScript library. While\nnot all of the functionality available in the JavaScript version is\navailable in R, the package makes it surprisingly easy to quickly\nassemble professional-quality interactive maps for data exploration and\npresentation.\n\n\n\n\n\n© Vladimir Agafonkin (BSD 2-Clause)\n\n\nleaflet R package\n© RStudio, Inc. (GPL-3)\nSetup\nTo showcase the advantages of interactive maps, we’ll use the\nvariable PANELBIRTH,\nwhich indicates whether a woman gave birth in the year between Phase 1\nand Phase 2 of the Kenya panel study. As you might imagine, PMA surveys\nalready contain a number of key predictors for childbirth. We’ll feature\nonly a few variables representing each woman’s\nAGE\n- age,\nMARSTAT\n- marital status, and\nWEALTHQ\n- household wealth quintile\nAs we’ll see, an interactive map allows the user to zoom-in on each\nPMA sample cluster - known as an enumeration area (EA) - and dynamically\nrender a summary table for the average age, marital status, and wealth\nof reproductive age women in that specific location.\nMapping also allows us to examine the relationship between PMA\nvariables and data from external sources. We mentioned above that IPUMS\nPMA includes the variable URBAN, which indicates whether\neach country’s statistical bureau classifies a woman’s EA as “urban” or\n“rural”. Because this definition varies by country, PMA researchers like\nZhang (2022) sometimes\nuse road network density as a standardized proxy for urbanism. To\ndemonstrate, we’ll obtain road network data from Geofabrik and plot local road\ndensity together with PMA summary data for each EA.\nTo get started, we’ll load the following packages in R. (If you\nhaven’t installed all of these yet, you can do so with install.packages\nfirst.)\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\nlibrary(srvyr)\nlibrary(leaflet)\nlibrary(sf)\nlibrary(terra)\nlibrary(spatstat)\nlibrary(gtsummary)\n\n\n\nNext, we’ll obtain a long-format longitudinal\nextract with members of the Kenya panel study (Female Respondents\nonly). To keep things simple, we’ll filter to\ninclude only records from the Phase 2 interview.1\n\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00149.xml\",\n  data = \"data/pma_00149.dat.gz\"\n)\n\ndat <- dat %>% filter(YEAR == 2020 & RESULTFQ == 1)\n\n\n\n\nWe’ve mentioned previously on this blog that researchers must apply with\nPMA to access the GPS coordinates for each EA. These GPS data come\nin the form of a CSV file of displaced centroid points\nin latitude/longitude format. The PMA documentation goes into more detail\nabout this displacement methodology. For our purposes, it is enough to\nkeep in mind that the point locations in our GPS data are\napproximate: they represent the center of each sample\ncluster, but this center is randomly displaced up to 10 kilometers in\norder to further protect participant confidentiality.\nThe GPS data come in CSV format, which we’ll load into R with read_csv.\nWe’ll then use the sf\npackage to convert the imported data into an sf spatial\nobject, which will use the coordinate reference system\nWGS 84.2 We can pass EPSG code 4326 to st_set_crs\nto indicate that our coordinates are relative to the WGS 84 system.\n\n\nThis post will assume some familiarity with the sf package\nand simple features objects in general. If you need a\nrefresher, there are previous posts here and here that have\ndiscussed these topics in more depth.\n\n\nea_coords <- read_csv(\"data/ea/gps_kenya.csv\") %>%\n  st_as_sf(coords = c(\"GPSLONG\", \"GPSLAT\")) %>%\n  st_set_crs(\"epsg:4326\") %>% \n  select(EAID, geometry)\n\n\n\nNow that we have our PMA data and EA coordinates prepared, we can\nstart working with leaflet itself.\nIntroduction to Leaflet\nFor those familiar with ggplot2, the conceptual\nframework when building a leaflet map should be fairly\nfamiliar. In both cases, we’ll construct our final visual product in a\nseries of layers, which will be superimposed to form the final\noutput.\nAccordingly, when we initialize a leaflet map with its\neponymous function, leaflet, we see\nonly a blank gray canvas, just like we might expect with\nggplot2:\n\n\nleaflet()\n\n\n\n\nAs with ggplot, the leaflet function allows\nyou to attach data and set several other map-wide parameters.\nAt its core, though, calling leaflet is enough to get a\nmap going.\nBasemaps\nMost web basemaps rely on a set of square tiles that can be stitched\ntogether to form an entire map. This improves processing since only the\nnew tiles in the region being viewed need to be downloaded as the user\npans or zooms. leaflet has several built-in basemaps, which\ncan be added with addProviderTiles.\nAvailable map providers can be accessed using providers.\n\nTo see a visual catalog of provider tiles, click here.\nFor our maps, we’ll use the Positron tiles from Carto. These understated basemap tiles are\nwell-suited for emphasizing our data, which we will overlay later.\n\n\nleaflet() %>%\n  addProviderTiles(providers$CartoDB.PositronNoLabels)\n\n\n\n\nWe can set some initial parameters using the options\nargument in addProviderTiles. This argument itself takes a\nfunction, providerTileOptions,\nwhose arguments correspond to several of the options available for\nstandard JavaScript leaflet maps. Here, we set the minimum\nand maximum zoom range for the map. We then use the setView\nfunction to initialize the map over our area of interest with an\nappropriate zoom level.\n\n\nbasemap <- leaflet() %>%\n  addProviderTiles(\n    provider = providers$CartoDB.PositronNoLabels,\n    options = providerTileOptions(minZoom = 6, maxZoom = 12),\n  ) %>%\n  setView(lat = -0.06, lng = 37.48, zoom = 7)\n\nbasemap\n\n\n\n\nAdding Spatial Features\nEven though our basemap shows up-to-date borders from OpenStreetMap, it would\nbe nice to emphasize Kenya’s administrative regions to draw the viewer’s\nattention to our area of interest. We load a shapefile of Kenya’s\nadministrative borders for use in our maps:\n\n\nborders_sub <- st_read(\"data/ke_boundaries/ke_boundaries.shp\")\n\n\n\n\n\n\nTo get a border for the entire country, we can dissolve the internal\nadministrative region borders to the external border with st_union:\n\n\nborders_cntry <- borders_sub %>% st_union() %>% st_sf()\n\n\n\n\n\n\nJust like with ggplot2, leaflet has a\nvariety of similar layer types,\neach of which is specific to the types of spatial features being mapped.\nFor instance, data of point locations call for the use of\naddCircles or addCircleMarkers, whereas data\nof polygon areas would require addPolygons.\nEach of these functions anticipates a map object as its\nfirst argument. This makes leaflet maps respond well to the\npipe syntax you may be familiar with from data manipulation in the\ntidyverse, since each of these functions also\nreturns a map object. The only difference is that\ninstead of piping data through each step in the processing pipeline,\nwe’re piping our map.\nSo, to add both our borders and our EA coordinates to the map, we\nsimply have to pipe our basemap into a call to addPolygons\nwhere we specify that the data associated with this map layer come from\nour borders_sub object. Then we can pipe this output\ndirectly into a call to addCircleMarkers, adding the EA\npoints to the map. The other function arguments, like\nfillColor, opacity, and so on, control the\naesthetics of these layers.\n\n\nbasemap %>%\n  addPolygons(\n    data = borders_sub,\n    fill = NA,\n    opacity = 0.8,\n    weight = 2,\n    color = \"#9D9D9D\"\n  ) %>%\n  addCircleMarkers(\n    data = ea_coords,\n    radius = 4,\n    fillColor = \"#575757\",\n    fillOpacity = 0.8,\n    color = \"#1D1D1D\",\n    opacity = 0,\n    weight = 1.5\n  )\n\n\n\n\nAs we can see, all of the EAs fall into a few specific administrative\nregions, reflecting the regions that were included in the 2019 survey.\nAnd one of the advantages of the interactive map is already becoming\napparent: while the western portions of the map are too dense with EAs\nto adequately see their distribution, we can easily zoom\nin to get a better sense of their layout. In our case, we\nexpect this clustered distribution of EAs, but with less-familiar data\nsources, these types of observations might lead to important questions\nabout the quality and collection mechanism of the data being used.\nRoad Network Metrics\nNow that we’ve mapped the centroid of each EA, we’re ready to begin\nwork on a road network measure that classifies each EA as either “urban”\nor “rural”. Because leaflet allows readers to\ntoggle between layers in real-time, we’ll consider two\nmetrics in turn:\ndistance from the EA centroid to the nearest road\nroad density near the EA centroid\nResearchers may disagree about which metric works best as a proxy for\nurbanism in this context, but the interactive features built into our\nmap could allow readers to compare potentially several measures at once.\nThe tools shown here could also showcase layers for landcover,\npopulation density, light pollution, and much more.\nObtaining Data\nFirst, we need to obtain data on the Kenyan road network. We will use\nOpenStreetMap, which\nis a publicly available, crowdsourced geospatial database covering the\nentire globe. There are several ways to access OpenStreetMap data. We’ve\ndownloaded road network data for Kenya from Geofabrik, which distributes\nOpenStreetMap data in manageable region-specific chunks.\nTo access the data we are using for this post, click here to go to\nthe download page for Kenya and download the “kenya-latest-free.shp.zip”\nfile.\n\n\n\nThis file will include several different ESRI shapefiles; we are\nusing “gis_osm_roads_free_1.shp”. To improve processing for this brief\ndemo, we restrict our focus to the 6 principal road categories used in\nthe OpenStreetMap classification\nscheme, which greatly thins out the number of features present in\nthe road network shapefile.\n\n\nke_roads <- st_read(\"data/kenya-latest-free.shp/gis_osm_roads_free_1.shp\") %>%\n  filter(fclass %in% c(\"motorway\", \"trunk\", \"primary\", \"secondary\", \n                       \"tertiary\", \"unclassified\"))\n\n\n\nBefore we continue, we need to project the road network to a CRS that\nis better suited for working with spatial distance calculations.\nLatitude/longitude data are insufficient for this purpose because the\ndistance between degrees of latitude or longitude varies at different\npoints on the Earth’s surface.\nWhile the most accurate method of calculating distances between\npoints is the geodesic distance, which takes into\naccount the three-dimensional nature of the Earth’s surface, this method\nis often more computationally intensive than alternatives. Since we’re\nfocusing on visualization rather than rigorous analysis in this post,\nwe’ll opt to calculate simpler Euclidean distances,\nrequiring that we convert our data to a Cartesian (X/Y) coordinate\nsystem.\nOne of the most common projected reference systems is the\nUniversal Transverse Mercator (UTM). The UTM is a\ncommon map projection system that divides the Earth into 60 projection\nzones. Each zone runs in a north/south band. While map projects\ninherently introduce distortion, the narrow bands used by the UTM help\nto reduce these inaccuracies provided that the area under consideration\nroughly fits into one of these bands. Fortunately, Kenya is almost\nentirely contained within UTM Zone 37N, which has the EPSG code 20137.\nWe can use st_transform\nto project the road data into this new CRS. You’ll notice that our data\nare now represented in meters, rather than in degrees:\n\n\nke_roads <- st_transform(ke_roads, \"epsg:20137\")\n\nke_roads %>% select(geometry)\n\n\nSimple feature collection with 129131 features and 0 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: -67446.75 ymin: -523095.5 xmax: 841462.4 ymax: 584378.8\nProjected CRS: Adindan / UTM zone 37N\nFirst 10 features:\n                         geometry\n1  LINESTRING (267847.7 -14892...\n2  LINESTRING (252816.8 -14401...\n3  LINESTRING (255587 -142503,...\n4  LINESTRING (256616.2 -14258...\n5  LINESTRING (256247.1 -14283...\n6  LINESTRING (255393.3 -14348...\n7  LINESTRING (257017.9 -14252...\n8  LINESTRING (256227.3 -14286...\n9  LINESTRING (255454.1 -14376...\n10 LINESTRING (253121.6 -14399...\n\nRoad Distance\nNow that the road network data are prepared, we can use\nsf to calculate the distances of each EA centroid to its\nnearest road.\nFirst, we’ll have to project ea_coords into UTM 37N\ncoordinates to match the CRS of our road data:\n\n\nea_coords <- st_transform(ea_coords, \"epsg:20137\")\n\n\n\nNow we can use st_nearest_feature\nto identify the index of the nearest feature in ke_roads\nfor each EA centroid. Because st_nearest_feature returns\nthe row index of the nearest road in ke_roads, we can\nsubset the ke_roads data to extract only those features\nthat are closest to at least one of the EA centroids.\n\n\nea_nearest_rds <- ke_roads[st_nearest_feature(ea_coords, ke_roads), ]\n\n\n\nFinally, we use st_distance\nto calculate the distance from each of the EA centroids to its nearest\nroad. This produces a point layer of EA centroids where each EA has a\ncalculated distance stored in the DIST variable.\n\n\nea_dist <- ea_coords %>%\n  mutate(\n    DIST = ea_coords %>% \n      st_distance(ea_nearest_rds, by_element = TRUE) %>% \n      as.numeric / 1000  # Get units in km.\n  )\n\n\n\nNow we have the data we need to visualize the distribution of road\ndistances across the EAs.\nMapping EAs\nTo start, we’ll demonstrate how to assign a color gradient to the EA\ncircle markers shown in grey on our map above. This time, we’ll use\ncolor to represent the DIST variable we created in\nea_dist. With leaflet, we’ll have to create a\npalette function that specifies which values should be mapped to which\ncolors on the scale. You can use one of several built-in palette\ngenerators to facilitate the creation of different types of color\npalettes:\ncolorNumeric: Map continuous values to colors\ncolorBin: Map continuous values to colors, but group\nthem into binned categories by value\ncolorQuantile: Map continuous values to colors, but\ngroup them into binned categories by quantile\ncolorFactor: Map discrete values to colors\nEach of these functions takes a palette argument, which\ntakes a vector of colors or the name of an available palette (e.g. a\npalette provided by RColorBrewer\nor viridis), and a\ndomain argument, which indicates the domain of all data\nvalues that should be mapped to the interpolated colors in the provided\npalette.\nIn our case, we use the colorspace package\nto create a vector of colors from its “Blue-Yellow” palette, and we\nprovide the entire range of distance values calculated in the previous\nstep as the domain.\n\n\npal <- colorBin(\n  colorspace::sequential_hcl(10, \"Blue-Yellow\", rev = TRUE),\n  domain = ea_dist$DIST\n)\n\n\n\nThis pal variable is actually a\nfunction — one that maps data values to color values.\nSo, to use the palette for the fill color of our grid cells, we pass the\ndata values of the cells (DIST) into our pal\nusing the ~ syntax to indicate that the\nfillColor is a function of our data, not a\nstatic value.\nSince we’re adding colors, we’ll also create a legend with addLegend\nusing the pal function we made above.\nWe’ll also return ea_dist to its original WGS 84\nprojection, overriding the default Web Mercator projection used in\nleaflet by default.3\n\n\nbasemap %>%\n  addPolygons(\n    data = borders_sub,\n    fill = NA,\n    opacity = 0.8,\n    weight = 2,\n    color = \"#9D9D9D\"\n  ) %>%\n  addCircleMarkers(\n    data = st_transform(ea_dist, \"epsg:4326\"),\n    radius = 6,\n    fillColor = ~pal(DIST),\n    fillOpacity = 0.8,\n    color = \"#6F6F6F\",\n    weight = 1.5\n  ) %>%\n  addLegend(\n    title = \"Distance to Nearest Road (km)\",\n    position = \"bottomright\",\n    pal = pal,\n    values = ea_dist$DIST\n  )\n\n\n\n\nAt first glance, it doesn’t look like there is much variability in\nroad distance across our enumeration areas. Most of the areas appear to\nbe within a single kilometer of their nearest road. However, because our\nEAs are not evenly distributed across the country, we’re lacking in some\ncontext. That is, we have no indication of how far someone would need to\ntravel to the nearest road in areas of the country where there aren’t\nany EAs in this survey, and this could be giving us a distorted view of\nhow outlying the high-distance EAs really are.\nGrid Layer\n\nTo solve this problem, we’ll create a new layer on our map that shows\nthe distance to the nearest road on a grid spanning the\ncomplete land area for Kenya. That is: rather than coloring the circle\nmarkers for each EA, we’ll situate grey circle markers on a layer\nshowing the spatial variance of road distances throughout the country.\nThis grid will be comprised of hexagonal cells built with st_make_grid,\nand fitted to the national border in borders_cntry with st_filter:\n\n\nhex_grid <- borders_cntry %>% \n  st_make_grid(cellsize = 0.1, what = \"polygons\", square = FALSE) %>%\n  st_sf() %>% \n  st_filter(borders_cntry)\n\n\n\n\nHexagonal grids have several appealing properties when compared\nsquare grids, both for analysis and visualization.\nOne cartographically-important example: they are less likely to bias the\neye toward seeing spurious vertical or horizontal patterns.\nLet’s take a look at the grid we’ve created so far:\n\n\nbasemap %>%\n  addPolygons(\n    data = hex_grid,\n    fill = NA,\n    opacity = 0.8,\n    weight = 2,\n    color = \"#9D9D9D\"\n  )\n\n\n\n\nNext, we’ll proceed as we did earlier, except that we’ll find the\ndistance to the nearest road from the centroid of each hexagonal\ncell rather than the centroid of each EA. To find each centroid,\nwe’ll use st_centroid.\n\n\nhex_grid <- hex_grid %>% st_transform(\"epsg:20137\")\n\nhex_ctrs <- st_centroid(hex_grid)\n\nhex_nearest_rds <- ke_roads[st_nearest_feature(hex_ctrs, ke_roads), ]\n\nhex_grid <- hex_grid %>%\n  mutate(\n    DIST = hex_ctrs %>% \n      st_distance(hex_nearest_rds, by_element = TRUE) %>% \n      as.numeric / 1000 # Get units in km.\n  )\n\n\n\nWe’ll need to update the domain in our palette function,\nsince it currently only captures the range of distances for our EAs,\nwhich will be a subset of the total range of distances across the new\ngrid layer.\n\n\npal <- colorBin(\n  colorspace::sequential_hcl(10, \"Blue-Yellow\", rev = TRUE),\n  domain = hex_grid$DIST\n)\n\n\n\nWe’ll now use pal to color each of the grid cells, and\nthen we’ll add layers for sub-national borders and EA circle markers as\nwe did before. Lastly, we’ll update addLegend to span the\nrange of values in our new grid layer.\n\n\nbasemap %>%\n  addPolygons(\n    data = hex_grid %>% st_transform(\"epsg:4326\"),\n    fillColor = ~pal(DIST),\n    color = \"#fefefe\",\n    fillOpacity = 0.5,\n    weight = 1,\n    group = \"Road Distance\"\n  ) %>%\n  addPolygons(\n    data = borders_sub,\n    fill = NA,\n    opacity = 0.8,\n    weight = 2,\n    color = \"#9D9D9D\"\n  ) %>%\n  addCircleMarkers(\n    data = ea_coords %>% st_transform(\"epsg:4326\"),\n    radius = 4,\n    fillColor = \"#575757\",\n    fillOpacity = 0.8,\n    color = \"#1D1D1D\",\n    opacity = 0,\n    weight = 1.5\n  ) %>%\n  addLegend(\n    title = \"Distance to Nearest Road (km)\",\n    position = \"bottomright\",\n    pal = pal,\n    values = hex_grid$DIST\n  ) \n\n\n\n\nThis country-wide map shows us what we suspected earlier: while the\nmost remote EAs were only about 3 kilometers from the nearest road, the\nentire range of road distances spans all the way to roughly 40\nkilometers in some places. In fact, all of the EAs would fall\ninto the lowest binned color class using the full range of distance\nvalues!\nOf course, this may not be a true cause for concern. Areas of high\ndistance might also have few inhabitants, making those regions someone\nless representative of the bulk of the population. Similarly, depending\non the research questions of interest, it may well be the case that the\ndifference between a 500m distance and 1km distance is conceptually\nmeaningful, even though it composes only a tiny fraction of the overall\nrange of possible road distances.\nHowever, it might also be the case that the distance from the nearest\nroad simply isn’t a very useful measure of urbanism. Even though we\naren’t using residential roads or other minor road classes recorded in\nthe OpenStreetMap data, a sufficiently comprehensive road network\ndatabase would probably suggest that most EAs are very close to\nsome type of road.\nInstead of road distance, it might make more sense to calculate road\ndensity. Even EAs that are fairly close to some road may not be in an\narea that has a dense network of roads.\nRoad Density\nTo calculate the road density from our ke_roads data,\nwe’ll use the spatstat package, which\nprovides a collection of point pattern analysis tools. First, we’ll\nconvert our ke_roads object to a psp\nobject. This is a class that spatstat uses to represent\nline segment data.\nWe can then use the density.psp\nfunction to calculate the density of our road network and convert to a\nmore familiar SpatRaster\nobject from the terra package.\nIn a true analysis, it would be worth spending time to identify an\nappropriate value for the standard deviation parameter\nsigma and the pixel resolution eps, but the\nfollowing should do for our purposes:\n\n\nke_roads_dens <- ke_roads %>% \n  st_geometry() %>% \n  as.psp() %>% \n  density.psp(sigma = 5000, eps = 2000) %>% \n  rast()\n\ncrs(ke_roads_dens) <- \"epsg:20137\"\n\n\n\n\n\n\n\nWe could go ahead and map our raster object directly. However, for\nbetter visual comparison with our previous gridded map, we’ll convert\nthe raster to a hexagonal grid, so we use extract to get the\nmean density values within each hexagon.\n\n\nhex_grid <- hex_grid %>%\n  mutate(\n    DENS = ke_roads_dens %>% \n      extract(vect(hex_grid), fun = \"mean\", na.rm = TRUE) %>% \n      .$`lyr.1`\n  )\n\n\n\n\nleaflet does support raster mapping with addRasterImage,\nbut its functionality is slightly more limited than functions for\nmapping vector data, and performance can suffer for medium-sized raster\nfiles or larger.\nOur Road Density map will closely resemble our previous Road Distance\nmap, so we’ll want to be sure to create a distinctive color palette for\neach to help readers tell the two metrics apart. This time, we’ll use a\nred / orange palette.\n\n\n pal <- colorNumeric(\n    colorspace::sequential_hcl(10, \"OrRd\", rev = TRUE), # substitute \"OrRd\"\n    domain = hex_grid$DENS # substitute \"DENS\"\n  )\n\n\n\nWe can use the same code for our new Road Density map, except that\nwe’ll need to make several substitutions for the new variable\nDENS and for our legend (which we’ll now show at the\nbottom-left).\n\n\nbasemap %>%\n  addPolygons(\n    data = hex_grid %>% st_transform(\"epsg:4326\"),\n    fillColor = ~pal(DENS), # substitute \"DENS\"\n    color = \"#fefefe\",\n    fillOpacity = 0.5,\n    weight = 1,\n    group = \"Road Density\" # substitute \"Road Density\"\n  ) %>%\n  addPolygons(\n    data = borders_sub,\n    fill = NA,\n    opacity = 0.8,\n    weight = 2,\n    color = \"#9D9D9D\"\n  ) %>%\n  addCircleMarkers(\n    data = ea_coords %>% st_transform(\"epsg:4326\"),\n    radius = 4,\n    fillColor = \"#575757\",\n    fillOpacity = 0.8,\n    color = \"#1D1D1D\",\n    opacity = 0,\n    weight = 1.5\n  ) %>%\n  addLegend(\n    title = \"Desnity of road network\", # new legend title  \n    position = \"bottomleft\", # new legend position \n    pal = pal,\n    values = hex_grid$DENS # substitute \"DENS\"\n  ) \n\n\n\n\nCompared with our previous map, we see that there appears to be more\nvariation in road density across our EAs, a potential sign that this\nmetric may capture a wider spectrum of urbanism. Of course, this is a\nrelatively simple density calculation, and a more sophisticated approach\nmight take into account the different types of roads present in the\nnetwork and adjust for the fact that the road density will inherently\ndecrease along coastlines, and so on.\nOf course, we want to avoid asking our reader to compare maps by\nscrolling upward and downward on this page! To make this comparison\neasier to see, we’ll now demonstrate how to combine the two metrics on a\nsingle map that allows the reader to switch between metrics of\ninterest.\nLayer Toggle\nIn our combined map, we’ll have 2 grid layers - each showing a\ndifferent road network metric. We’ll introduce a toggle at the top-right\ncorner of our map allowing the user to choose between Road Distance and\nRoad Density.\nRemember: in addition to both of the grid layers, we’re also mapping\nlayers for sub-national borders and the location of each EA. With so\nmany layers in-play, we’ll want to control the order in which each one\nis plotted on top of the next. To do so, we’ll use addMapPane to\ncreate a name and zIndex for each layer: a\nzIndex value should typically fall between 400 (the default\noverlay pane) and 500 (the default shadow pane). Let’s update\nbasemap to include the following “map panes”:\nHex for the hexagonal grid layers,\nBorders for the sub-national borders\nEAs for the EA centroid locations\n\n\nbasemap <- basemap %>% \n  addMapPane(\"Hex\", zIndex = 430) %>%\n  addMapPane(\"Borders\", zIndex = 450) %>%\n  addMapPane(\"EAs\", zIndex = 500)\n\n\n\nNext, we’ll start building the layers that will comprise our new map,\nwhich we’ll call toggle_map. First, we’ll recycle code from\nthe sections above to plot the Borders and\nEAs. The options argument allows us to assign\na “map pane” for each.\n\n\ntoggle_map <- basemap %>% \n  addPolygons(\n    data = borders_sub,\n    fill = NA,\n    opacity = 0.8,\n    weight = 2,\n    color = \"#9D9D9D\",\n    options = pathOptions(pane = \"Borders\") # <-------------- New part!\n  ) %>%\n  addCircleMarkers(\n    data = ea_coords %>% st_transform(\"epsg:4326\"),\n    radius = 4,\n    fillColor = \"#575757\",\n    fillOpacity = 0.8,\n    color = \"#1D1D1D\",\n    opacity = 0,\n    weight = 1.5,\n    options = pathOptions(pane = \"EAs\") # <-------------- New part!\n  )\n\n\n\nNext, we’d like to use addPolygons and\naddLegend twice each: once for the Road Distance layer, and\nonce again for the Road Density layer. However, we need to update our\ncolor palette function pal with different colors for each\nmetric. In this case, it might make sense to write a custom function\nthat runs addPolygons and addLegend with\nchanges provided by user input.\nThis function, which we’ll call add_hex_grid, takes a\nunique var (either “DIST” or “DENS”),\nlegend_title, and legend_position for each\ngrid layer. We’ll also create one group name for each\nlayer, which will allow us to toggle between layers with addLayersControl.\n\nUnfortunately, R’s leaflet doesn’t fully support toggling\nof legends, so we have to space them out around the map if there are\nmore than one.\n\n\nadd_hex_grid <- function(map, data, var, palette, group, \n                         legend_title, legend_position) {\n  \n  data <- st_transform(data, \"epsg:4326\")\n  \n  pal <- colorNumeric(\n    colorspace::sequential_hcl(10, palette, rev = TRUE),\n    domain = data[[var]]\n  )\n  \n  map %>%\n    addPolygons(\n      data = data,\n      fillColor = ~pal(data[[var]]),\n      color = \"#fefefe\",\n      fillOpacity = 0.7,\n      weight = 1,\n      group = group,\n      options = pathOptions(pane = \"Hex\")\n    ) %>%\n    addLegend(\n      title = legend_title,\n      position = legend_position,\n      pal = pal,\n      values = data[[var]]\n    )\n}\n\n\n\nNow, we’ll use add_hex_grid once for each grid layer,\nfollowed by addLayersControl to toggle between them.\n\n\ntoggle_map %>% \n  add_hex_grid(\n    data = hex_grid,\n    palette = \"Blue-Yellow\",\n    var = \"DIST\",\n    legend_title = \"Distance to nearest road (km)\",\n    legend_position = \"bottomright\",\n    group = \"Road Distance\"\n  ) %>%\n  add_hex_grid(\n    data = hex_grid,\n    palette = \"OrRd\",\n    var = \"DENS\",\n    legend_title = \"Density of road network\",\n    legend_position = \"bottomleft\",\n    group = \"Road Density\"\n  ) %>% \n  addLayersControl(\n    baseGroups = c(\"Road Distance\", \"Road Density\"),\n    options = layersControlOptions(collapsed = FALSE)\n  )\n\n\n\n",
    "preview": "posts/2022-09-15-leaflet-eda/images/preview.png",
    "last_modified": "2022-10-11T10:16:08-04:00",
    "input_file": {},
    "preview_width": 2296,
    "preview_height": 1540
  },
  {
    "path": "posts/2022-08-15-method-mix-trends/",
    "title": "Trends in Modern Contraceptive Method Mix",
    "description": "Which methods are have gained popularity among modern method users since 2014?",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-08-25",
    "categories": [
      "Modern Method Mix",
      "Indicators",
      "Measurement",
      "Data Analysis",
      "Data Visualization"
    ],
    "contents": "\n\nContents\nSetup\nMost Effective Method\nRecoding\n\nModern Method Users\nMissing values\n\nModern Method Mix\nData Visualization\nDisaggregation\n\n\n\n\nModern Contraceptive Method Mix is a core indicator in the FP2030 Measurement\nFramework representing the distribution of modern method\nusers by method. Researchers use this distribution to\nunderstand which family planning methods are preferred and accessible in\na particular place.\n\nWhile there is no “right” method mix or “ideal” method, there is\ngeneral agreement that providing access to a wide variety of methods is\nboth a component of quality of care as well as an important principle of\nrights-based family planning.\n\n— FP2030\nCore Indicators\n\nModern Method Mix can change year-to-year in response to the\nintroduction of new methods in-country, access restrictions\n(e.g. stockouts), increased need for specific methods (e.g. those that\nprotect against sexually transmitted infections), and shifting user\npreferences.1 Cross-sectional PMA surveys are\nfielded approximately once per year, allowing researchers to monitor\nthese changes at annual intervals. Typically, you’ll find “Trends in\nModern Contraceptive Mix” updated in the PMA Survey\nResults Summary published for each new sample.\n\n\n\nSource:\nBurkina\nFaso Phase 2\nCross-sectional Survey Results Summary\nIn this post, we’ll show how you can make a graphic similar to this\none in R using a single data extract downloaded from IPUMS PMA. We’ll be focusing on Modern\nMethod Mix, but we recommend using IPUMS data any time you want to\ninvestigate how indicators change over time or how they compare across\npopulations. That’s because the IPUMS PMA data extract system is\ndesigned both to allow researchers to combine data from multiple samples\nand to flag important comparability issues between those samples.\nSetup\nYou can compare trends in Modern Method Mix for any number of PMA\nsamples with a single data extract from IPUMS PMA. Here, we’ll\nillustrate using data from two countries, Burkina Faso and Kenya, where\ncross-sectional data have been collected continuously between 2014 and\n2021.\nCountry\nSample Year\nData Collection Period\nBurkina Faso\n2014\nNov 2014 - Jan 2015\n\n2015\nApr 2015 - June 2015\n\n2016a\nMar 2016 - Apr 2016\n\n2016b\nNov 2016 - Feb 2017\n\n2017\nNov 2017 - Jan 2018\n\n2018\nDec 2018 - Jan 2019\n\n2020\nDec 2019 - Feb 2020\n\n2021\nDec 2020 - Mar 2021\nKenya\n2014a\nMay 2014 - Aug 2014\n\n2014b\nNov 2014 - Dec 2014\n\n2015a\nJun 2015 - Jul 2015\n\n2015b\nNov 2015 - Dec 2015\n\n2016\nNov 2016 - Dec 2016\n\n2017\nNov 2017 - Dec 2017\n\n2018\nNov 2018 - Jan 2019\n\n2019\nNov 2019 - Dec 2019\n\n2020\nNov 2020 - Dec 2020\nThis extract includes cross-sectional samples for\nBurkina Faso and Kenya.\nFor information on panel data collected in 2019-2020,\nsee our longitudinal\nguide.\nOur extract will contain all of these cross-sectional samples,\nfiltered to include only Female\nRespondents. It will also contain the following variables:\nSAMPLE\nCOUNTRY\nYEAR\nINTFQMON\nINTFQYEAR\nFQWEIGHT\nEAID\nSTRATA\nRESIDENT\nLASTDOBCMC\nTIMEMENSTRUATE\nTIMEMENSTRUATEVAL\nMCP\nFPCURRUSE\nFPCURREFFMETH\nFPCURREFFMETHRC\nFPEFFECTIVEYR\nFPCURRINJTYPE\nFP1STMETHOD\nMARSTAT\nAGE\nWe’ll load the extract and a few key packages into R like so:\n\n\n# Load packages \nlibrary(ipumsr)\nlibrary(tidyverse)\nlibrary(srvyr)\nlibrary(ggalluvial)\n\n# Load data extract \ndat <- read_ipums_micro(\n  ddi = \"data/pma_00165.xml\",\n  data = \"data/pma_00165.dat.gz\"\n)\n\n\n\nAdditionally, we’ll modify a few variables to improve\nreadability:\nA Century\nMonth Code (CMC) we call INTFQCMC will be created for\neach individual woman’s interview date2\nWe’ll store the median interview date for each sample in\nINTFQMED\nAll key categorical variables will be recoded with as_factor\n\n\ndat <- dat %>% \n  group_by(SAMPLE) %>% \n  mutate(\n    INTFQCMC = 12*(INTFQYEAR - 1900) + INTFQMON,\n    INTFQMED = median(INTFQCMC), \n    across(\n      c(COUNTRY, INTFQMON, TIMEMENSTRUATE, MCP, FPCURRUSE, FPCURREFFMETH,\n        FPCURREFFMETHRC, FPEFFECTIVEYR, FPCURRINJTYPE, FP1STMETHOD, MARSTAT),\n      as_factor\n    )\n  ) %>% \n  ungroup()\n\n\n\nMost Effective Method\nPMA surveys ask each woman to report all family planning\nmethods she or her partner are currently using to delay or avoid getting\npregnant. The question looks something like this one, where the\nrespondent is prompted to select all options that apply:\nWhich method or methods are you using?\n\nPROBE: Anything else?\n\nSelect all methods mentioned. \nSCROLL TO THE BOTTOM to see all choices.\n\n  [] Female sterilization\n  [] Male sterilization\n  [] Implant\n  [] IUD\n  [] Injectables\n  [] Pill\n  [] Emergency Contraception\n  [] Male condom\n  [] Female condom\n  [] Diaphragm\n  [] Foam/Jelly\n  [] Standard Days/Cycle beads\n  [] LAM\n  [] Rhythm method\n  [] Withdrawal\n  [] Other traditional method\n  [] No response\nSource:\nBurkina\nFaso Phase 2 Questionnaire\nMethod list may vary by sample!\nBecause a woman can report more than one method, PMA ranks the\neffectiveness of each method and uses only her most effective\nmethod to calculate Modern Method Mix. This ensures that sum of\nall methods included in Modern Method Mix is 100%.\nEvery PMA sample includes a variable FPCURREFFMETH\nthat indicates the most effective method reported by the respondent on\nthis question. However, it’s important to note that the list of methods\nmay vary between samples.\nFortunately, IPUMS makes it easy to identify whether each method is\navailable for the researcher’s samples of interest. On the\nFPCURREFFMETH codes\ntab, we see the availability of every method in each sample from\nBurkina Faso and Kenya.\n\n\n\nCertain methods like N-tablet, Washing, or “Other Modern” were\nincluded in none of our samples. Others, like Diaphragm and Foam, appear\nintermittently: these methods may have been listed on the questionnaire,\nbut appear unavailable if no women selected the associated response\noption (or if they were only selected in combination with a more\neffective method).\nFPCURREFFMETH uses composite coding, where general\ncategories like Injectables (code 120) are used if a particular\nquestionnaire did not distinguish between specific sub-categories like\n3-month, monthly, or Sayana Press (codes 121, 122, and 123). In Burkina\nFaso and Kenya samples, women were not asked to specify injectable type\non this question; however, later samples included the following\nsupplementary question (accompanied by a visual aid):\nWas the injection administered via syringe or small needle?\n\nShow the image to the respondent.\n\n  [] Syringe\n  [] Small needle (Sayana Press)\n  [] No response\nResponses to this question are recorded in the variable FPCURRINJTYPE.\nThe IPUMS system shows that it was added to Burkina Faso samples\nbeginning in 2016, and that it was added to Kenya samples beginning in\n2018:\n\n\n\nRecoding\nWhen the supplementary question associated with\nFPCURRINJTYPE was added, PMA released a recoded version of\nmost effective method that you’ll find in FPCURREFFMETHRC\n(the suffix RC indicates “recoded”). This variable makes\nfour adjustments to the original variable FPCURREFFMETH\n(see description\ntab):\nWomen who report Sayana Press in FPCURRINJTYPE are\ndifferentiated from those using 3-month injectables. (Sayana Press users\nare identified as “Injectable (SC)” in the graphic at the top of this\npost.)\nWomen who report using the lactational amenorrhea method (LAM) in\nFPCURREFFMETH are coded “other traditional” in\nFPCURREFFMETHRC if they fail to meet the criteria for\neffective use of LAM. Specifically, LAM users must be less than six\nmonths post-partum (see LASTDOBCMC)\nand amenorrheic / not currently menstruating (see TIMEMENSTRUATE\nand TIMEMENSTRUATEVAL).\nWomen who did not report current use of a contraceptive method\n(coded “NIU (not in universe)” in FPCURREFFMETH) are coded\n“emergency contraception” in FPCURREFFMETHRC if they\nreported using an emergency method at all in the last 12 months (see FPEFFECTIVEYR,\nor FPECUSYR\nfor later samples).\nWomen who did not report using Female Sterilization as a current\nmethod in FPCURREFFMETH are coded “female sterilization” if\nthey indicated elsewhere that they had been sterilized (see FP1STMETHOD).\nPMA uses FPCURREFFMETHRC in its calculation of Modern\nMethod Mix, but FPCURREFFMETHRC was not retroactively added\nto older samples. We’ll demonstrate how to recode\nFPCURREFFMETH manually for samples where\nFPCURREFFMETHRC is not available.\nNotably, we won’t be able to identify users of Sayana Press for\nsamples prior to the introduction of FPCURRINJTYPE (this\nexplains the apparent growth from 0% in June 2015 to 5% in May 2016 in\nthe Burkina Faso graphic at the top of this post).\nInstead, we’ll begin with the adjustment made for LAM users who are\nnot post-partum amenorrheic (PPA). Unfortunately, PMA does not include a\nvariable indicating whether women are PPA, so we’ll need to make our own\nvariable called PPA.\n\n\n# `TIMEMENSTRUATE` gives a unit, while `TIMEMENSTRUATEVAL` gives a value\n# We use these variables to calculate months since last period: `MENSTR_MOS`\ndat <- dat %>% \n  mutate(\n    MENSTR_MOS = case_when(\n      TIMEMENSTRUATE == \"Days\" ~ TIMEMENSTRUATEVAL / 30,\n      TIMEMENSTRUATE == \"Weeks\" ~ TIMEMENSTRUATEVAL / 4,\n      TIMEMENSTRUATE == \"Months\" ~ TIMEMENSTRUATEVAL %>% as.double,\n      TIMEMENSTRUATE == \"Years\" ~ TIMEMENSTRUATEVAL * 12\n    ) \n  )\n\n# `INTFQCMC` gives the month of the interview, while\n# `LASTDOBCMC` gives the month of most recent birth (or 9999 for no prior birth) \n# The difference is the number of months since last birth: `BIRTH_MOS`\ndat <- dat %>% \n  mutate(\n    BIRTH_MOS = case_when(\n      LASTDOBCMC < 9000 ~ INTFQCMC - LASTDOBCMC\n    ) \n  )\n\n# `TIMEMENSTRUATE` can also be \"Before last birth\" \n# If so, or if MENSTR_MOS > BIRTH_MOS, women who gave birth < 6 months are PPA\n# All others are not PPA (or NA if most recent period cannot be determined)\ndat <- dat %>% \n  mutate(\n    PPA = case_when(\n      BIRTH_MOS < 6 & TIMEMENSTRUATE == \"Before last birth\" ~ TRUE,\n      BIRTH_MOS < 6 & MENSTR_MOS > BIRTH_MOS ~ TRUE,\n      BIRTH_MOS >= 6 | LASTDOBCMC > 9000 ~ FALSE\n    )\n  ) \n\n\n\nWe use our PPA variable together with\nFP1STMETHOD and FPEFFECTIVEYR to manually\nbuild FPCURREFFMETHRC for early samples where it is not\navailable. Otherwise, we use the version of FPCURREFFMETHRC\nprovided by PMA for later samples.\n\n\ndat <- dat %>% \n  mutate(\n    FPCURREFFMETHRC = case_when(\n      !is.na(`FPCURREFFMETHRC`) ~ FPCURREFFMETHRC %>% as_factor %>% as.character,\n      FP1STMETHOD == \"Female sterilization\" ~ \"Female Sterilization\",\n      FPCURRUSE != \"Yes\" & FPEFFECTIVEYR == \"Emergency Contraception\" ~ \"Emergency Contraception\",\n      FPCURREFFMETH == \"Lactational amenorrhea method (LAM)\" & !PPA ~ \"Other traditional\",\n      TRUE ~ FPCURREFFMETH %>% as_factor %>% as.character\n    )\n  )\n\n\n\nYou can review the changes made to FPCURREFFMETH in\nFPCURREFFMETHRC like so:\n\n\ndat %>% \n  filter(FPCURREFFMETH != FPCURREFFMETHRC) %>% \n  count(FPCURREFFMETH, FPCURREFFMETHRC)\n\n\n# A tibble: 7 × 3\n  FPCURREFFMETH                       FPCURREFFMETHRC                n\n  <fct>                               <chr>                      <int>\n1 IUD                                 Female Sterilization           1\n2 Injectables (3 months)              Female Sterilization           1\n3 Injectables (3 months)              Injectables (Sayana Press)   895\n4 Female condom                       Female Sterilization           1\n5 Lactational amenorrhea method (LAM) Other traditional            108\n6 NIU (not in universe)               Emergency Contraception      314\n7 NIU (not in universe)               Female Sterilization           7\n\nModern Method Users\n\nWhen we calculate Modern Method Mix, we’ll determine the share of\nwomen who use each method as a proportion of women age 15-49 who use any\nmodern method. Every PMA sample includes a variable MCP indicating\nwhether the woman is currently using a modern method (any method except\nRhythm, Withdrawal, or Other Traditional).\nMCP also uses the woman’s most effective current\nmethod if she indicates that she is using more than one method.\nFortunately, MCP uses the same recoding logic shown for\nFPCURREFFMETHRC above: it adjusts for non-PPA use of LAM,\nEmergency Contraception within the past year, and prior sterilization\n(see description\ntab for details). Because MCP is available for every\nPMA sample, we need to make no additional changes here.\n\nModern Method Mix is a proportion among women age 15-49 who\nuse modern methods.\nNote that this is different from the prevalence of\nindividual methods, which would reflect the proportion among\nall women age 15-49.\nMissing values\nMCP includes the values “Yes”, “No”, and “No response or\nmissing”. If you compare MCP with\nFPCURREFFMETH, you’ll see that there are several cases\nwhere MCP is “missing” even though the woman reported use\nof a method:\n\n\ndat %>% \n  filter(MCP == \"No response or missing\") %>% \n  count(MCP, FPCURREFFMETH)\n\n\n# A tibble: 14 × 3\n   MCP                    FPCURREFFMETH                           n\n   <fct>                  <fct>                               <int>\n 1 No response or missing Female Sterilization                    3\n 2 No response or missing Implants                              149\n 3 No response or missing IUD                                    20\n 4 No response or missing Injectables (3 months)                 93\n 5 No response or missing Pill                                   36\n 6 No response or missing Emergency Contraception                 7\n 7 No response or missing Male condom                            48\n 8 No response or missing Female condom                           2\n 9 No response or missing Standard Days/Cycle Beads Method        5\n10 No response or missing Lactational amenorrhea method (LAM)     2\n11 No response or missing Rhythm                                 25\n12 No response or missing Withdrawal                              4\n13 No response or missing Other traditional                       1\n14 No response or missing NIU (not in universe)                 805\n\nHow can this be? A strong majority of these cases are women who were\nnot members of the de facto population of women who slept in\nthe household during the night before the household screening interview\n(see RESIDENT).\nAs a result, they are not considered part of the analytic sample, and\nthey are assigned a weight of 0 in FQWEIGHT:\nthese cases drop out in weighted population inference (or we can drop\nthem ourselves to suppress a warning message).\n\n\ndat %>% \n  filter(MCP == \"No response or missing\") %>% \n  count(FQWEIGHT == 0)\n\n\n# A tibble: 2 × 2\n  `FQWEIGHT == 0`     n\n  <lgl>           <int>\n1 FALSE              35\n2 TRUE             1165\n\nThe remaining 35 cases are women who were missing data on one or more\nof the variables used in recoding for MCP. We’ll keep them\nin our data in order to calculate the correct degrees of freedom for\neach sample.\nModern Method Mix\nFinally, we’re ready to use FPCURREFFMETHRC and\nMCP to calculate Modern Method Mix. PMA uses a stratified\ncluster-sample design, so we’ll use the variables EAID\nand STRATA\ntogether with FQWEIGHT as survey design information.\nBecause our data extract contains multiple samples, we’ll need to use\ngroup_by\nto iterate through each independent sample (identified by our labeling\nvariables COUNTRY and INTFQMED). To make this\neasier, we’ll use two nested summarise\nfunctions:\nThe outer summarise\nfunction allows us to specify survey\ndesign information for each independent sample (referenced\niteratively as cur_data)\nThe inner summarise\nfunction estimates the proportion of women for each combination of\nMCP and FPCURREFFMETHRC in each\npopulation\n\n\ndat %>% \n  filter(FQWEIGHT > 0) %>% \n  group_by(COUNTRY, INTFQMED) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weights = FQWEIGHT, ids = EAID, strata = STRATA) %>% \n      group_by(MCP = as_factor(MCP), FPCURREFFMETHRC) %>% \n      summarise(survey_mean(prop = TRUE, prop_method = \"logit\", vartype = \"ci\"))\n  ) \n\n\n# A tibble: 288 × 7\n# Groups:   COUNTRY, INTFQMED [17]\n   COUNTRY      INTFQMED MCP   FPCURREFFMETHRC                      coef    `_low`  `_upp`\n   <fct>           <dbl> <fct> <chr>                               <dbl>     <dbl>   <dbl>\n 1 Burkina Faso     1379 No    NIU (not in universe)            0.999    0.996     1.00   \n 2 Burkina Faso     1379 No    Other traditional                0.000203 0.0000272 0.00151\n 3 Burkina Faso     1379 No    Rhythm                           0.000672 0.0000903 0.00497\n 4 Burkina Faso     1379 Yes   Diaphragm                        0.00102  0.000134  0.00765\n 5 Burkina Faso     1379 Yes   Emergency Contraception          0.00163  0.000220  0.0120 \n 6 Burkina Faso     1379 Yes   Female Sterilization             0.00416  0.00128   0.0135 \n 7 Burkina Faso     1379 Yes   Implants                         0.436    0.358     0.518  \n 8 Burkina Faso     1379 Yes   Injectables (3 months)           0.363    0.287     0.446  \n 9 Burkina Faso     1379 Yes   IUD                              0.0194   0.00836   0.0445 \n10 Burkina Faso     1379 Yes   Male condom                      0.0349   0.0157    0.0758 \n11 Burkina Faso     1379 Yes   Pill                             0.134    0.0986    0.181  \n12 Burkina Faso     1379 Yes   Standard Days/Cycle Beads Method 0.00544  0.00204   0.0144 \n13 Burkina Faso     1385 No    NIU (not in universe)            0.989    0.982     0.993  \n14 Burkina Faso     1385 No    No response or missing           0.000221 0.0000294 0.00166\n15 Burkina Faso     1385 No    Other traditional                0.00121  0.000306  0.00478\n16 Burkina Faso     1385 No    Rhythm                           0.00848  0.00514   0.0139 \n17 Burkina Faso     1385 No    Withdrawal                       0.00157  0.000502  0.00493\n18 Burkina Faso     1385 Yes   Emergency Contraception          0.00463  0.00172   0.0124 \n19 Burkina Faso     1385 Yes   Female condom                    0.00287  0.000652  0.0126 \n20 Burkina Faso     1385 Yes   Female Sterilization             0.00373  0.00123   0.0113 \n# … with 268 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\nHere, coef sums to 100% for each level of\nMCP, while the columns _low and\n_upp report a 95% confidence interval for each estimate.\nBecause we’re only concerned with Modern Method Mix, we can disregard\nany rows where MCP != \"Yes\".\nData Visualization\nTo match the PMA graphic shown at the top of this post, we’ll make a\nfew minor modifications to our summary table. First, we’ll combine a few\nof the lesser-used modern methods under “Other Modern Method”:\nMale Sterilization\nFemale Sterilization\nFemale Condom\nFoam\nStandard Days / Cycle Beads\nDiaphragm\nLAM3\nYou can use fct_collapse\nto combine several factors levels into a new level like “other”.\nConveniently, you can also use it to relabel levels as shown here for\nImplant, Injectable (IM), Injectable (SC), and Emergency\ncontraception:\n\n\ndat <- dat %>% \n  mutate(\n    FPCURREFFMETHRC = FPCURREFFMETHRC %>% \n      fct_collapse(\n        \"Other modern methods\" = c(\n          \"Male Sterilization\", \"Female Sterilization\", \"Female condom\",\n          \"Foam\", \"Standard Days/Cycle Beads Method\", \"Diaphragm\",\n          \"Lactational amenorrhea method (LAM)\"\n        ),\n        \"Implant\" = \"Implants\",\n        \"Injectable (IM)\" = \"Injectables (3 months)\",\n        \"Injectable (SC)\" = \"Injectables (Sayana Press)\",\n        \"Emergency contraception\" = \"Emergency Contraception\",\n      ) \n  ) \n\n\n\nWe’ll now save the revised summary table as a data frame called\nmix_tbl. We’ll also remove any of the rows that aren’t\nnecessary to calculate Modern Method Mix (where MCP is “No”\nand “No response or missing”).\n\n\nmix_tbl <- dat %>% \n  filter(FQWEIGHT > 0) %>% \n  group_by(COUNTRY, INTFQMED) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weights = FQWEIGHT, ids = EAID, strata = STRATA) %>% \n      group_by(MCP = as_factor(MCP), FPCURREFFMETHRC) %>% \n      summarise(survey_mean(prop = TRUE, prop_method = \"logit\", vartype = \"ci\"))\n  ) %>% \n  filter(MCP == \"Yes\")\n\nmix_tbl\n\n\n# A tibble: 131 × 7\n# Groups:   COUNTRY, INTFQMED [17]\n   COUNTRY      INTFQMED MCP   FPCURREFFMETHRC            coef   `_low` `_upp`\n   <fct>           <dbl> <fct> <fct>                     <dbl>    <dbl>  <dbl>\n 1 Burkina Faso     1379 Yes   Other modern methods    0.0106  0.00517  0.0217\n 2 Burkina Faso     1379 Yes   Emergency contraception 0.00163 0.000220 0.0120\n 3 Burkina Faso     1379 Yes   Implant                 0.436   0.358    0.518 \n 4 Burkina Faso     1379 Yes   Injectable (IM)         0.363   0.287    0.446 \n 5 Burkina Faso     1379 Yes   IUD                     0.0194  0.00836  0.0445\n 6 Burkina Faso     1379 Yes   Male condom             0.0349  0.0157   0.0758\n 7 Burkina Faso     1379 Yes   Pill                    0.134   0.0986   0.181 \n 8 Burkina Faso     1385 Yes   Other modern methods    0.0138  0.00680  0.0278\n 9 Burkina Faso     1385 Yes   Emergency contraception 0.00463 0.00172  0.0124\n10 Burkina Faso     1385 Yes   Implant                 0.367   0.272    0.473 \n11 Burkina Faso     1385 Yes   Injectable (IM)         0.333   0.226    0.459 \n12 Burkina Faso     1385 Yes   IUD                     0.0383  0.0194   0.0742\n13 Burkina Faso     1385 Yes   Male condom             0.114   0.0744   0.169 \n14 Burkina Faso     1385 Yes   Pill                    0.130   0.0947   0.177 \n15 Burkina Faso     1395 Yes   Other modern methods    0.00325 0.000656 0.0159\n16 Burkina Faso     1395 Yes   Emergency contraception 0.00502 0.00215  0.0117\n17 Burkina Faso     1395 Yes   Implant                 0.444   0.382    0.508 \n18 Burkina Faso     1395 Yes   Injectable (IM)         0.261   0.194    0.341 \n19 Burkina Faso     1395 Yes   Injectable (SC)         0.0477  0.0297   0.0756\n20 Burkina Faso     1395 Yes   IUD                     0.0203  0.0120   0.0342\n# … with 111 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\nWith these revisions in place, we’re now ready to make our plot.\nWe’ve showcased the excellent ggalluvial package\nin earlier posts,\nso we won’t dig into the details too deeply here. In short: we use geom_stratum\nto build stacked bars for each sample, and we use geom_flow\nto show change over time. The argument decreasing = FALSE\nensures that the methods are arranged in order of popularity for each\nsample.\nA basic alluvial plot can be made like so:\n\n\nmix_plot <- mix_tbl %>% \n  ggplot(aes(\n    x = INTFQMED, \n    y = coef,\n    fill = FPCURREFFMETHRC,\n    stratum = FPCURREFFMETHRC,\n    alluvium = FPCURREFFMETHRC\n  )) + \n  facet_wrap(vars(COUNTRY), ncol = 1) + \n  geom_flow(decreasing = FALSE) + \n  geom_stratum(size = 0, width = 2, decreasing = FALSE)\n\nmix_plot\n\n\n\n\nAs always, we’ll apply our own custom theme and labels to clean-up\nthe final result. If you intend to make multiple plots with the same\ntheme, we recommend saving it as a function; we’ll call ours\ntheme_pma.\n\n\n# Fonts \nlibrary(showtext)\nsysfonts::font_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext_auto()\n\n# Fonts for geom_text\nupdate_geom_defaults(\"text\", list(family = \"cabrito\", size = 4))\n\n# Theme \ntheme_pma <- function(){\n  components <- list(\n    # Edit `theme_minimal`\n    theme_minimal() %+replace% theme(\n      text = element_text(family = \"cabrito\", size = 12),\n      plot.title = element_text(size = 26, color = \"#00263A\",\n                                hjust = 0, margin = margin(b = 5)),\n      plot.subtitle = element_text(hjust = 0, margin = margin(b = 0), size = 18),\n      plot.caption = element_text(hjust = 1, size = 10, margin = margin(t = 15)),\n      plot.caption.position = \"plot\",\n      strip.background = element_blank(),\n      strip.text.x = element_text(size = 14, hjust = 1),\n      strip.text.y = element_text(size = 14, angle = 0),\n      panel.spacing = unit(1, \"lines\"),\n      legend.position = \"bottom\",\n      legend.title = element_blank()\n    ) ,\n    \n    # Add breaks by percent to y-axis, dates to x-axis\n    scale_y_continuous(labels = scales::label_percent()),\n    scale_x_continuous(\n      breaks = map(2014:2021, ~c(12*(.x - 1900) + 1, 12*(.x - 1900) + 7)) %>%\n        unlist(),\n      labels = map(2014:2021, ~c(paste(\"Jan\", .x), paste(\"Jul\", .x))) %>%\n        unlist() %>% \n        str_wrap(3)\n    ),\n    \n    # Custom colors copied from the PMA graphic\n    scale_fill_manual(values = c(\n      \"Implant\" = \"#C3B7D5\",\n      \"Injectable (IM)\" = \"#B7749A\", \n      \"Injectable (SC)\" = \"#F6BFD8\", \n      \"Pill\" = \"#171E48\", \n      \"Male condom\" = \"#11687E\", \n      \"IUD\" = \"#541E59\", \n      \"Emergency contraception\" = \"#5B6160\", \n      \"Other modern methods\" = \"#5BBBC9\"\n    )),\n    \n    # Switch text labels from white to black for Implant & Injectable (SC)\n    scale_color_manual(values = c(\"white\", \"black\")),\n    \n    # Add text labels for each method (if > 3%)\n    stat_stratum(\n      geom = \"text\",\n      aes(\n        label = if_else(\n          coef > 0.03,\n          scales::percent(coef, 1, suffix = NULL),\n          \"\"\n        ),\n        color = FPCURREFFMETHRC %in% c(\"Implant\", \"Injectable (SC)\")\n      ),\n      size = 4,\n      show.legend = FALSE,\n      decreasing = FALSE\n    ),\n    \n    # Customize labels \n    labs(\n      x = NULL, y = NULL,\n      title = \"Trends in Modern Method Mix\",\n      subtitle = paste(\n        \"Percent distribution of all women age 15-49 using modern\",\n        \"contraceptive methods by method and year\"\n      ),\n      caption = paste(\n        '\"Other modern methods\" includes male and female sterilization,',\n        'the female condom, contraceptive foam or jelly, the standard days',\n        'method/cycle beads, and diaphragm.') %>% \n        str_wrap(85) %>% \n        paste0('\\n\\nValues < 3% not labelled.')\n    ) \n  )\n}\n\n\n\nYou can apply your theme to mix_plot like so:\n\n\nmix_plot + theme_pma()\n\n\n\n\nDisaggregation\nFinally, you’ll also notice that PMA reports Modern Method Mix\ndisaggregated by marital status MARSTAT.\nYou may also see Modern Method Mix disaggregated by age AGE,\neducation EDUCATTGEN,\nor parity BIRTHEVENT.\nIt’s easy to update our code for mix_tbl with these or\nother variables, but it’s important to note that there may be zero\nobservations available for certain methods in some subgroups. In this\ncase, survey_mean\nwill be unable to estimate the standard error for each proportion, and\nyou’ll receive a warning message like this one:\n\nWarning: glm.fit: algorithm did not converge\n\nIf you’re simply constructing a graphic like the one we made above,\nyou can skip standard error estimation altogether by setting\nvartype = NULL. Here, we demonstrate using a recoded\nversion of MARSTAT.\n\n\nmar_tbl <- dat %>% \n  mutate(\n    MARSTAT = case_when(\n      MARSTAT == \"Currently married\" ~ \"Married / Partnered\",\n      MARSTAT == \"Currently living with partner\" ~ \"Married / Partnered\",\n      TRUE ~ \"Not Married / Partnered\"\n    ),\n    MARSTAT = as_factor(MARSTAT)\n  ) %>% \n  filter(FQWEIGHT > 0) %>% \n  group_by(COUNTRY, INTFQMED) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weights = FQWEIGHT, ids = EAID, strata = STRATA) %>% \n      group_by(\n        MARSTAT, # Add `MARSTAT`\n        MCP = as_factor(MCP), \n        FPCURREFFMETHRC\n      ) %>% \n      summarise(survey_mean(vartype = NULL))\n  ) %>% \n  filter(MCP == \"Yes\")\n\nmar_tbl\n\n\n# A tibble: 255 × 6\n# Groups:   COUNTRY, INTFQMED [17]\n   COUNTRY      INTFQMED MARSTAT                 MCP   FPCURREFFMETHRC            coef\n   <fct>           <dbl> <fct>                   <fct> <fct>                     <dbl>\n 1 Burkina Faso     1379 Not Married / Partnered Yes   Other modern methods    0.0258 \n 2 Burkina Faso     1379 Not Married / Partnered Yes   Emergency contraception 0.0191 \n 3 Burkina Faso     1379 Not Married / Partnered Yes   Implant                 0.262  \n 4 Burkina Faso     1379 Not Married / Partnered Yes   Injectable (IM)         0.195  \n 5 Burkina Faso     1379 Not Married / Partnered Yes   IUD                     0.0516 \n 6 Burkina Faso     1379 Not Married / Partnered Yes   Male condom             0.359  \n 7 Burkina Faso     1379 Not Married / Partnered Yes   Pill                    0.0870 \n 8 Burkina Faso     1379 Married / Partnered     Yes   Other modern methods    0.00920\n 9 Burkina Faso     1379 Married / Partnered     Yes   Implant                 0.453  \n10 Burkina Faso     1379 Married / Partnered     Yes   Injectable (IM)         0.378  \n11 Burkina Faso     1379 Married / Partnered     Yes   IUD                     0.0164 \n12 Burkina Faso     1379 Married / Partnered     Yes   Male condom             0.00457\n13 Burkina Faso     1379 Married / Partnered     Yes   Pill                    0.139  \n14 Burkina Faso     1385 Not Married / Partnered Yes   Other modern methods    0.0166 \n15 Burkina Faso     1385 Not Married / Partnered Yes   Emergency contraception 0.0113 \n16 Burkina Faso     1385 Not Married / Partnered Yes   Implant                 0.229  \n17 Burkina Faso     1385 Not Married / Partnered Yes   Injectable (IM)         0.116  \n18 Burkina Faso     1385 Not Married / Partnered Yes   IUD                     0.0112 \n19 Burkina Faso     1385 Not Married / Partnered Yes   Male condom             0.480  \n20 Burkina Faso     1385 Not Married / Partnered Yes   Pill                    0.136  \n# … with 235 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\nOnly minor changes are needed to incorporate MARSTAT\ninto our graphic. We’ll switch from facet_wrap\nto facet_grid,\nwhere we’ll add new column facets for MARSTAT.\n\n\nmar_tbl %>% \n  ggplot(aes(\n    x = INTFQMED, \n    y = coef,\n    fill = FPCURREFFMETHRC,\n    stratum = FPCURREFFMETHRC,\n    alluvium = FPCURREFFMETHRC\n  )) + \n  facet_grid(\n    rows = vars(COUNTRY), \n    cols = vars(MARSTAT) # Add `MARSTAT`\n  ) + \n  geom_flow(decreasing = FALSE) + \n  geom_stratum(size = 0, width = 2, decreasing = FALSE) + \n  theme_pma()\n\n\n\n\nIn both countries, there’s quite a big difference in the popularity\nof modern methods between married / partnered and non-partnered women.\nOf course, the demand for modern family planning methods is probably\nvery different for women in each of these subgroups. In the next few\nweeks, we’ll dig deeper into issues surrounding measurement of demand\nfor family planning, and related measures like unmet\nneed.\n\nUSAID\n- Data for Impact↩︎\nIPUMS PMA includes a variable INTFQCMC,\nbut it is not currently available for all samples.↩︎\nNot included in the PMA graphic\nabove↩︎\n",
    "preview": "posts/2022-08-15-method-mix-trends/method-mix-trends_files/figure-html5/unnamed-chunk-16-1.png",
    "last_modified": "2022-09-01T11:33:32-04:00",
    "input_file": {},
    "preview_width": 2688,
    "preview_height": 1920
  },
  {
    "path": "posts/2022-08-01-youtube-transcripts/",
    "title": "Translated Youtube Transcripts with R and Python",
    "description": "With help from an imported Python module, you can get an automatically generated transcript for any IPUMS PMA video tutorial in your preferred language. No Python experience necessary!",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-08-01",
    "categories": [
      "Video",
      "Python",
      "reticulate",
      "translation",
      "transcription"
    ],
    "contents": "\n\nContents\nEnable Captions\nTranscripts\nBuilding a Python\nEnvironment\nUsing the API\nSummary\nExplore and Export\n\n\n\n\n\nIPUMS and IPUMS PMA offer several Youtube video tutorials\ncovering topics like:\nHow to create\nan account to use IPUMS PMA\nIPUMS PMA\nUnits of Analysis\nHow to create\nan extract using IPUMS PMA\nIPUMS PMA Case\nSelection Feature\nHow IPUMS PMA\npopulation expansion weights were created\nIntroduction to PMA\nLongitudinal Data\nUsing Female and Service\nDelivery Point Data Together\n\nLinks to all of our video tutorials and recorded webinars can be found\non this page.\nThese videos have been recorded in English but, as\nof spring 2022, Youtube now provides automatically generated\ncaptions in multiple languages. You’ll find captions available for all\nvideos posted on the IPUMS Youtube channel.\nNeither the transcription nor the translation are perfect, but because\nthese services are powered by\nartificial intelligence from Google, we expect their quality to\nimprove over time.\nEnable Captions\nTo turn on captions in your preferred language, click the cog icon\nnext to the CC button in the bottom-right corner of the\nvideo toolbar.\n\n\n\nYou can choose between “English (auto-generated)” or\n“Auto-translate”.\n\n\n\nThere are several language options available. We’ll choose\nFrench.\n\n\n\nFrench captions will appear on the bottom of your video right\naway.\n\n\n\n\n\n\nTranscripts\nCaptions are great, but sometimes it’s useful to have a full\ntranscript that you can read at your own pace. Fortunately, it’s\npossible to download a full-text version of these captions with help\nfrom the YouTube\nTranscript API for Python. And, thanks to the reticulate\npackage for R, those of us with little or no Python knowledge can use\nthis tool, too!\nBuilding a Python\nEnvironment\n\nTo get started, you’ll need to install reticulate if\nyou’ve never done so before:\n\n\ninstall.packages(\"reticulate\")\n\n\n\nThen, we’ll load it together with tidyverse tools we’ll need\nfor processing the downloaded text.\n\n\nlibrary(tidyverse)\nlibrary(reticulate)\n\n\n\n\n\n\n\n\n© Tomasz Kalinowski et al. (Apache 2.0)\n\n\nThe YouTube\nTranscript API is a Python package, which is analogous to an R\npackage you’d normally download from CRAN. With R, your downloaded\npackages get saved to a library on your computer. For example, here’s\nthe location of my own R library on my Mac:\n\n\n.libPaths()\n\n\n[1] \"/Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library\"\n\nPython packages will also be downloaded onto your computer, but it’s\nnot unusual for Python users to have multiple libraries setup for\nindividual projects. Moreover, it’s common to have different versions of\nPython associated with different projects. This ensures that your old\nPython projects won’t break when you upgrade to new tools.\n\nIf the idea of project-specific environments sounds appealing, check out\nthe renv package\nfor R.\nConda is a tool used to\nbuild and maintain Python environments. With reticulate,\nyou can quickly create a Conda environment with conda_create.\nLet’s call our environment pma_env:\n\n\n\nconda_create(\"./pma_env\")\n\n\n\nThis creates a new folder called pma_env in R’s working\ndirectory, and it installs several packages (including the most recent\nversion of Python and pip, a\nPython package installer) in that location.\nNext, we’ll tell reticulate to\nuse this environment for the duration of our R session.\n\n\nuse_condaenv(\"./pma_env\")\n\n\n\n\nconda_create\ncreates an environment by name or by path. We use\n./ to identify the path to R’s working directory. If you\nprovide only a name, the new environment will appear in a default\nlocation elsewhere on your computer.\n\nAnd finally, we’ll install the YouTube\nTranscript API (via pip)\nin our environment.\n\n\npy_install(packages = \"youtube_transcript_api\", pip = TRUE)\n\n\n\n\n\nJust like R packages, Python packages only need to be installed in your\nenvironment once! No need to run this in your next session.\nUsing the API\nBefore we can use the package, we’ll need to import\nit into R.\n\n\nimport(\"youtube_transcript_api\")\n\n\nModule(youtube_transcript_api)\n\nAs an R user, you might expect this to work like the library\nfunction we use to attach R\npackages. Instead, R returns an object wrapping a\nModule named youtube_transcript_api; if we\nlook in the R search path, we won’t find anything related to the API.\nWhat’s going on here?\n\n\nsearch()\n\n\n [1] \".GlobalEnv\"         \"package:reticulate\" \"package:showtext\"  \n [4] \"package:showtextdb\" \"package:sysfonts\"   \"package:here\"      \n [7] \"package:RCurl\"      \"package:htmltools\"  \"package:ipumsr\"    \n[10] \"package:forcats\"    \"package:stringr\"    \"package:dplyr\"     \n[13] \"package:purrr\"      \"package:readr\"      \"package:tidyr\"     \n[16] \"package:tibble\"     \"package:ggplot2\"    \"package:tidyverse\" \n[19] \"package:stats\"      \"package:graphics\"   \"package:grDevices\" \n[22] \"package:utils\"      \"package:datasets\"   \"package:methods\"   \n[25] \"Autoloads\"          \"package:base\"      \n\n\nThe search function\nshows all of our currently attached R packages. Many of these are loaded\nwith tidyverse, and\nothers are tools we use behind the scenes on this blog.\nUnlike R packages, Python packages are not attached with import.\nInstead, you’ll need to attach them to the Global\nEnvironment. We’ll call this module api:\n\n\napi <- import(\"youtube_transcript_api\")\n\n\n\nAn imported Python module works like named\nlist. Each item in the list is a method - a\nfunction associated with a particular object.\n\n\nnames(api)\n\n\n [1] \"CookiePathInvalid\"               \"CookiesInvalid\"                 \n [3] \"CouldNotRetrieveTranscript\"      \"FailedToCreateConsentCookie\"    \n [5] \"NoTranscriptAvailable\"           \"NoTranscriptFound\"              \n [7] \"NotTranslatable\"                 \"TooManyRequests\"                \n [9] \"Transcript\"                      \"TranscriptList\"                 \n[11] \"TranscriptsDisabled\"             \"TranslationLanguageNotAvailable\"\n[13] \"VideoUnavailable\"                \"YouTubeRequestFailed\"           \n[15] \"YouTubeTranscriptApi\"           \n\nHere, we’ll only need the last method\nYouTubeTranscriptApi, so we’ll drop the others from\napi.\n\n\napi <- api$YouTubeTranscriptApi\n\n\n\nThis method contains three sub-methods:\n\n\nnames(api)\n\n\n[1] \"get_transcript\"   \"get_transcripts\"  \"list_transcripts\"\n\nTo determine what each method does, you’ll need to visit the\ndocumentation page. We’ll focus here on\nlist_transcripts, which retrieves a full list of all\navailable transcripts for a certain YouTube video. The\nvideo_id is a character string in the URL for your video\nimmediately after https://www.youtube.com/watch?v=.\n\n\ntranscript_list <- api$list_transcripts(video_id = \"VwjYHDvpHk0\")\n\n\n\nIn fact, transcript_list returns a second layer of\nsub-methods:\n\n\nnames(transcript_list)\n\n\n[1] \"build\"                            \"find_generated_transcript\"       \n[3] \"find_manually_created_transcript\" \"find_transcript\"                 \n[5] \"video_id\"                        \n\nAmong these, we’ll use find_transcript to locate a\ntranscript associated with the original language spoken in the\nvideo, which is English. (We found this a bit tricky: you must provide\nthe two-letter language code as a list.)\n\n\ntranscript <- transcript_list$find_transcript(language_codes = list(\"en\"))\nnames(transcript)\n\n\n[1] \"fetch\"                 \"is_generated\"          \"is_translatable\"       \"language\"             \n[5] \"language_code\"         \"translate\"             \"translation_languages\" \"video_id\"             \n\nUse the fetch method to get the English transcript:\n\n\nenglish <- transcript$fetch()\n\n\n\nUse the translate method to get automatically translated\ntranscripts in a language of your choice. We’ll request a French version\nlike so:\n\n\nfrench <- transcript$translate(\"fr\")\nfrench <- french$fetch()\n\n\n\nSummary\nIf you were keeping track, you might have noticed that we had to sort\nthrough 5 nested levels of methods to find the function we needed to get\nan English transcript (and 6 levels for the French transcript).\nIf you know what you’re looking for, you can chain multiple methods\ntogether with the $ operator. This way, you can import the\nAPI and download both transcripts with just four lines of code:\n\n\napi <- import(\"youtube_transcript_api\")\ntranscript <- api$YouTubeTranscriptApi$list_transcripts(\"VwjYHDvpHk0\")$find_transcript(list(\"en\"))\nenglish <- transcript$fetch()\nfrench <- transcript$translate(\"fr\")$fetch()\n\n\n\nExplore and Export\nNow that we’ve got one english and one\nfrench transcript, we’ll use tidyverse tools to export\nthem in a reader-friendly format.\nThe API imports each transcript as a list, where\neach list item contains one line of text, a timestamp for\nthe start of that line, and a code marking its\nduration. For example, the very first line in the\nenglish transcript starts 0.64 seconds into the video:\n\n\nenglish[[1]]\n\n\n$text\n[1] \"this tutorial will show you how to\"\n\n$start\n[1] 0.64\n\n$duration\n[1] 4.4\n\nHere is the same line from the french transcript:\n\n\nfrench[[1]]\n\n\n$text\n[1] \"ce tutoriel vous montrera comment\"\n\n$start\n[1] 0.64\n\n$duration\n[1] 4.4\n\nBecause of linguistic differences in grammar or syntax, the two\ntranscripts contain a different total number of lines.\n\n\nlength(english)\n\n\n[1] 88\n\nlength(french)\n\n\n[1] 85\n\nEven so, it’s easy align both transcripts together in a table. First,\nwe’ll use map_dfr to\niteratively transform each english list-item into a tibble\n- the dfr suffix places the output in a data frame\n(df) rowwise (r).\n\n\nenglish <- map_dfr(english, as_tibble)\n\nenglish\n\n\n# A tibble: 88 × 3\n   text                                     start duration\n   <chr>                                    <dbl>    <dbl>\n 1 this tutorial will show you how to        0.64     4.4 \n 2 access longitudinal panel data on the     2.56     5.12\n 3 iphone's pma website                      5.04     5.84\n 4 starting in 2019 performance monitoring   7.68     6.00\n 5 for action adjusted its sampling design  10.9      6.40\n 6 to create a panel of women aged 15 to 49 13.7      5.76\n 7 to study contraceptive and fertility     17.3      4.40\n 8 dynamics over time                       19.4      4.40\n 9 the baseline survey is referred to as    21.7      4.88\n10 phase one the first follow-up survey is  23.8      4   \n# … with 78 more rows\n\nNext, we’ll do the same thing with our french\ntranscript:\n\n\nfrench <- map_dfr(french, as_tibble)\n\nfrench\n\n\n# A tibble: 85 × 3\n   text                                                                  start duration\n   <chr>                                                                 <dbl>    <dbl>\n 1 ce tutoriel vous montrera comment                                      0.64     4.4 \n 2 accéder aux données longitudinales du panel sur le                     2.56     5.12\n 3 site pma de l'iphone à                                                 5.04     5.84\n 4 partir de 2019 le suivi des performances                               7.68     6.00\n 5 pour l'action a ajusté son plan d'échantillonnage                     10.9      6.40\n 6 pour créer un panel de femmes âgées de 15 à 49 ans                    13.7      5.76\n 7 afin d'étudier la dynamique de la contraception et de la fécondité au 17.3      4.40\n 8 fil du temps                                                          19.4      4.40\n 9 l'enquête de référence est référée  en tant que                       21.7      4.88\n10 phase un, la première enquête de suivi est la                         23.8      4   \n# … with 75 more rows\n\nIf you want to merge the two table together, use full_join\nto ensure that all rows from both tables are kept. Just be sure to\nchange the column text so that it describes the language of\nthe source table (and relocate columns as you see fit):\n\n\noutput <- full_join(\n  english %>% rename(english = text),\n  french %>% rename(french = text),\n  by = c(\"start\", \"duration\")\n)\n\noutput <- output %>% relocate(french, .after = english)\n\noutput\n\n\n# A tibble: 88 × 4\n   english                                  french                                    start duration\n   <chr>                                    <chr>                                     <dbl>    <dbl>\n 1 this tutorial will show you how to       ce tutoriel vous montrera comment          0.64     4.4 \n 2 access longitudinal panel data on the    accéder aux données longitudinales du pa…  2.56     5.12\n 3 iphone's pma website                     site pma de l'iphone à                     5.04     5.84\n 4 starting in 2019 performance monitoring  partir de 2019 le suivi des performances   7.68     6.00\n 5 for action adjusted its sampling design  pour l'action a ajusté son plan d'échant… 10.9      6.40\n 6 to create a panel of women aged 15 to 49 pour créer un panel de femmes âgées de 1… 13.7      5.76\n 7 to study contraceptive and fertility     afin d'étudier la dynamique de la contra… 17.3      4.40\n 8 dynamics over time                       fil du temps                              19.4      4.40\n 9 the baseline survey is referred to as    l'enquête de référence est référée  en t… 21.7      4.88\n10 phase one the first follow-up survey is  phase un, la première enquête de suivi e… 23.8      4   \n# … with 78 more rows\n\nFrom here, you can use familiar R tools to apply changes to every\nline in one or both transcripts. Notice, for example, that the\ntranscript tends to hear “iphone’s pma” instead of “IPUMS PMA” (see line\n2). You could use str_replace\nfrom the stringr package to\nreplace every occurrence of “iphone’s” with “IPUMS” (but do so with care\n- it’s easy to make accidental changes!)\n\n\noutput %>% \n  mutate(english = english %>% str_replace(\"iphone's\", \"IPUMS\"))\n\n\n# A tibble: 88 × 4\n   english                                  french                                    start duration\n   <chr>                                    <chr>                                     <dbl>    <dbl>\n 1 this tutorial will show you how to       ce tutoriel vous montrera comment          0.64     4.4 \n 2 access longitudinal panel data on the    accéder aux données longitudinales du pa…  2.56     5.12\n 3 IPUMS pma website                        site pma de l'iphone à                     5.04     5.84\n 4 starting in 2019 performance monitoring  partir de 2019 le suivi des performances   7.68     6.00\n 5 for action adjusted its sampling design  pour l'action a ajusté son plan d'échant… 10.9      6.40\n 6 to create a panel of women aged 15 to 49 pour créer un panel de femmes âgées de 1… 13.7      5.76\n 7 to study contraceptive and fertility     afin d'étudier la dynamique de la contra… 17.3      4.40\n 8 dynamics over time                       fil du temps                              19.4      4.40\n 9 the baseline survey is referred to as    l'enquête de référence est référée  en t… 21.7      4.88\n10 phase one the first follow-up survey is  phase un, la première enquête de suivi e… 23.8      4   \n# … with 78 more rows\n\nYou’ll also notice that there are places where french is\nmore concise, so it requires fewer lines. In this case, you’ll find\nNA in the french column like so:\n\n\noutput %>% filter(start > 110)\n\n\n# A tibble: 43 × 4\n   english                                  french                                    start duration\n   <chr>                                    <chr>                                     <dbl>    <dbl>\n 1 identified a subsample that could be     identifié un sous-échantillon qui pourra…  112.     4   \n 2 used as a representative cross-sectional utilisé comme fichier transversal représ…  113.     3.20\n 3 file                                     <NA>                                       116.     3.04\n 4 ipham's pma also provides the            <NA>                                       117.     4.32\n 5 cross-sectional version of the data file version sectionnelle du fichier de donné…  119.     4.56\n 6 in which persons who are not a part of   dans laquelle les personnes qui ne font …  121.     4.56\n 7 the cross-section have been removed      la section transversale ont été supprimé…  123.     4.72\n 8 this allows for enough data to calculate cela permet d'avoir suffisamment de donn…  126.     5.52\n 9 indicators over time using previous pma  indicateurs au fil du temps en utilisant…  128.     6.32\n10 cross-sectional data                     <NA>                                       131.     3.12\n# … with 33 more rows\n\nIf you intend to paste these lines into a text document later, you\nmight want to use replace_na\nfrom tidyr to replace those\nvalues with an empty string, \"\".\n\n\noutput %>% \n  mutate(french = french %>% replace_na(\"\")) %>% \n  filter(start > 110) \n\n\n# A tibble: 43 × 4\n   english                                  french                                    start duration\n   <chr>                                    <chr>                                     <dbl>    <dbl>\n 1 identified a subsample that could be     \"identifié un sous-échantillon qui pourr…  112.     4   \n 2 used as a representative cross-sectional \"utilisé comme fichier transversal repré…  113.     3.20\n 3 file                                     \"\"                                         116.     3.04\n 4 ipham's pma also provides the            \"\"                                         117.     4.32\n 5 cross-sectional version of the data file \"version sectionnelle du fichier de donn…  119.     4.56\n 6 in which persons who are not a part of   \"dans laquelle les personnes qui ne font…  121.     4.56\n 7 the cross-section have been removed      \"la section transversale ont été supprim…  123.     4.72\n 8 this allows for enough data to calculate \"cela permet d'avoir suffisamment de don…  126.     5.52\n 9 indicators over time using previous pma  \"indicateurs au fil du temps en utilisan…  128.     6.32\n10 cross-sectional data                     \"\"                                         131.     3.12\n# … with 33 more rows\n\nOnce you’re finished tidying the data in R, you can write the result\nto a CSV file that can be opened in Excel or other similar programs.\n\n\noutput %>% write_csv(\"output.csv\")\n\n\n\n\n\n\n\n\n\n",
    "preview": "posts/2022-08-01-youtube-transcripts/images/logo.png",
    "last_modified": "2022-08-01T11:02:04-04:00",
    "input_file": {},
    "preview_width": 1050,
    "preview_height": 567
  },
  {
    "path": "posts/2022-07-15-facet-maps/",
    "title": "Arranging maps in a grid",
    "description": "Tools for creating spatial visualizations that compare change over time or differences between PMA countries.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-07-18",
    "categories": [
      "Data Analysis",
      "Data Visualization",
      "Spatial",
      "Mapping",
      "ggplot2",
      "cowplot",
      "purrr"
    ],
    "contents": "\n\nContents\nFacets: one country over\ntime\nCowplot: combining\ncountries\n\n\n\n\nBecause the IPUMS PMA data\nwebsite allows users to combine samples from multiple countries and\nmultiple years together in a single download, tools like facet_wrap\nand facet_grid\nare an indispensable part of our data visualization toolkit. As we’ve\nshown elsewhere on this blog, facets are a simple way\nto create plots for multiple samples displayed as an array of\npanels.\nFor instance, in this\nrecent post, we used faceted bar charts to show change in\ncontraceptive use status for women in six samples arranged over 18\npanels.\n\n\n\nIn this post, we’ll practice building choropleth\nmaps showing modern contraceptive prevalence1 for\nmajor (admin 1) regions in several PMA samples. As with the bar charts\nshown above, we’ll use facets to arrange data for each\nsample together in an array of panels; however, we’ll see that facet_wrap\nand facet_grid\nmay not always be the best option for maps. Instead, we’ll introduce a\nnew package, cowplot,\ndesigned to bring additional flexibility to the alignment and\narrangement of panels built with ggplot2.\nWe’ve created a summary table modern_tbl for this post\nwith variables from the current\nor recent family planning use variable group, where the column\nPCT gives the estimated modern method prevalence within the\npopulation of women aged 15-49 in each region GEO in each\nsample year YEAR for each of three countries - Burkina\nFaso, Ethiopia, and Uganda - listed in COUNTRY We’ve also\nattached GPS coordinate vectors representing the boundary of each region\nin the geometry column - these come from a shapefile\ndownloaded from this page\non the IPUMS PMA data website. (If you’re interested, check out our data\npreparation steps by clicking the button below).\n\n\nShow data preparation steps\n\nlibrary(tidyverse)\nlibrary(ipumsr)\nlibrary(srvyr)\nlibrary(sf)\nlibrary(ggspatial)\n\n# Load IPUMS PMA data extract into R\n# This sample includes data from 3 countries, all available cross-sections\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00143.xml\",\n  data = \"data/pma_00143.dat.gz\"\n)\n\n# `COUNTRY` as a factor (for readability)\ndat <- dat %>% mutate(COUNTRY = as_factor(COUNTRY))\n\n# Create unique `YEAR` labels where multiple rounds of data were drawn\ndat <- dat %>%\n  mutate(\n    YEAR = case_when(\n      COUNTRY == \"Ethiopia\" & ROUND == 1 ~ \"2014a\",\n      COUNTRY == \"Ethiopia\" & ROUND == 2 ~ \"2014b\",\n      COUNTRY == \"Uganda\" & ROUND == 2 ~ \"2015a\",\n      COUNTRY == \"Uganda\" & ROUND == 3 ~ \"2015b\",\n      COUNTRY == \"Burkina Faso\" & ROUND == 3 ~ \"2016a\",\n      COUNTRY == \"Burkina Faso\" & ROUND == 4 ~ \"2016b\",\n      TRUE ~ as.character(YEAR)\n    )\n  )\n\n# Uganda has 15 regions in one sample, but just 10 in others \n# Harmonize regions so that all samples have the same \ndat <- dat %>% \n  mutate(\n    GEOUG = GEOUG %>% \n      lbl_relabel(\n        lbl(5, \"Kampala\") ~ .val == 0,\n        lbl(1, \"Central 1\") ~ .val == 1,\n        lbl(2, \"Central 2\") ~ .val == 2,\n        lbl(3, \"East Central, Eastern\") ~ .val %in% 3:6,\n        lbl(6, \"Karamoja\") ~ .val == 7,\n        lbl(7, \"North\") ~ .val %in% 8:9,\n        lbl(8, \"South West\") ~ .val %in% 13:14,\n        lbl(9, \"West Nile\") ~ .val == 10,\n        lbl(10, \"Western\") ~ .val %in% 11:12\n      ) %>% \n      as_factor() %>% \n      if_else(is.na(.), as_factor(GEOUGSH), .)\n  )\n\n# Now, rename any regions that do not match the labels in our shapefile \n# Harmonize region vars for all countries together in a single var, `GEO`\ndat <- dat %>% \n  mutate(\n    across(starts_with(\"GEO\"), ~as_factor(.x) %>% as.character),\n    GEOBF = GEOBF %>% recode(\"Plateau-Central\" = \"Plateau Central\"),\n    GEOET = GEOET %>% recode(\"Oromiya\" = \"Oromia\"),\n    GEOUG = GEOUG %>% recode(\"South West\" = \"Southwest\"),\n    GEO = case_when(\n      !is.na(GEOUG) ~ GEOUG,\n      !is.na(GEOET) ~ GEOET,\n      !is.na(GEOBF) ~ GEOBF\n    )\n  )\n\n# A `modern_user` is anyone using a method other than rhythm, withdrawal, or\n# other traditional \ndat <- dat %>% \n  mutate(\n    modern_user = if_any(\n      starts_with(\"FPNOW\") & -c(FPNOWUSRHY, FPNOWUSWD, FPNOWUSTRAD),\n      ~.x %in% 1 # note: `%in%` generates FALSE if NA \n    )\n  )\n\n# Estimate the population proportion for modern use / non-use in each `GEO`\nmodern_tbl <- dat %>% \n  as_survey_design(weight = FQWEIGHT, id = EAID, strata = COUNTRY) %>%\n  group_by(YEAR, COUNTRY, GEO, modern_user) %>%\n  summarise(pct = 100*survey_mean(vartype = NULL)) %>% \n  ungroup()\n\n# We use `pivot_wider` to create 0% values if no modern users were found\nmodern_tbl <- modern_tbl %>% \n  pivot_wider(\n    c(YEAR, COUNTRY, GEO), \n    names_from = modern_user, \n    values_from = pct,\n    values_fill = 0\n  ) %>% \n  select(-`FALSE`) %>% \n  rename(PCT = `TRUE`)\n\n# Load shapefile and harmonize variable names with `dat`\n# Include only our 4 countries of interest\nshape <- st_read(\"../../data_local/shapefiles/subnational\") %>% \n  st_transform(crs = 4326) %>% \n  select(COUNTRY = CNTRY_NAME, GEO = ADMIN_NAME) %>% \n  filter(COUNTRY %in% c(\"Burkina Faso\", \"Ethiopia\", \"Uganda\"))\n\n# Ensure that all shapes are fully enclosed, and smooth borders to 1000 meters \n# Drop any regions marked \"Waterbodies\" (no households are there)\nshape <- shape %>% \n  st_make_valid() %>% \n  st_simplify(dTolerance = 1000) %>% \n  filter(GEO != \"Waterbodies\")\n\n# Attach shapes for each `GEO`\nmodern_tbl <- modern_tbl %>% full_join(shape) \n\n# If no data collected in a region, duplicate `NA` for each `YEAR`\n# This requires `pivot_wider` to create placeholder `NA` values\n# Then, `pivot_longer` again: new rows appear for each `YEAR`\nmodern_tbl <- modern_tbl %>% \n  pivot_wider(\n    names_from = YEAR,\n    values_from = PCT\n  ) %>% \n  select(-`NA`) %>% \n  pivot_longer(\n    where(is.double),\n    names_to = \"YEAR\",\n    values_to = \"PCT\"\n  ) \n\n# Note that some countries may have 2 samples drawn in the same year, but others \n# included only 1 sample. Drop any extra `YEAR` labels for each `COUNTRY` here\nmodern_tbl <- modern_tbl %>% \n  group_by(COUNTRY, YEAR) %>% \n  filter(!all(is.na(PCT))) %>% \n  ungroup()\n\n# Rearrange columns and rows for improved display \nmodern_tbl <- modern_tbl %>% \n  relocate(c(YEAR, PCT), .after = GEO) %>% \n  arrange(COUNTRY, YEAR, GEO)\n\n\n\n\n\n\n\n\nmodern_tbl\n\n\n# A tibble: 260 × 5\n   COUNTRY      GEO               YEAR    PCT                           geometry\n   <chr>        <chr>             <chr> <dbl>                 <MULTIPOLYGON [°]>\n 1 Burkina Faso Boucle du Mouhoun 2014  20.2  (((-3.190611 13.68045, -3.226559 …\n 2 Burkina Faso Cascades          2014  12.9  (((-5.39324 10.99398, -5.416136 1…\n 3 Burkina Faso Centre            2014  21.9  (((-1.572501 12.60137, -1.566564 …\n 4 Burkina Faso Centre-Est        2014  17.2  (((-0.2427228 12.55885, -0.292054…\n 5 Burkina Faso Centre-Nord       2014  11.4  (((-0.625751 13.99783, -0.6899 13…\n 6 Burkina Faso Centre-Ouest      2014  10.7  (((-2.519715 12.83308, -2.557285 …\n 7 Burkina Faso Centre-Sud        2014  28.1  (((-1.459765 12.19329, -1.508548 …\n 8 Burkina Faso Est               2014  19.0  (((0.0653133 13.48729, 0.0587278 …\n 9 Burkina Faso Hauts-Bassins     2014  18.6  (((-4.4633 12.07738, -4.499922 12…\n10 Burkina Faso Nord              2014   9.68 (((-2.119268 14.15666, -2.353057 …\n# … with 250 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\nFacets: one country over time\nLet’s look at an example featuring data from just one\ncountry first. We’ll use our favorite mapping package ggspatial, since it\nallows us to use familiar tools from ggplot2 to customize the layout\nof our panel array. Most crucially, we use facet_wrap\nto create one panel for each sample YEAR. Additionally,\nwe’ll define the fill color for each region with scale_fill_gradient:\nwe’ll use a red color #BD262D\nfor high-levels on modern method prevalence, and we’ll use\ntransparent for regions where no modern method users were\nsampled. The grey shade #CFCFCF\nwill represent regions were no women were sampled.\nFinally, we’ll customize the look of our plot with a theme we’ll call\ntheme_pma. We encourage you to experiment with your own\ntheme, but feel free to use ours as a template if you’re interested.\n\n\nHow to build theme_pma\n\n# Define `theme_pma` for maps\nlibrary(showtext)\nsysfonts::font_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext::showtext_auto()\n\ntheme_pma <- theme_void() %+replace% \n  theme(\n    text = element_text(family = \"cabrito\", size = 13),\n    plot.title = element_text(\n      size = 22, \n      color = \"#00263A\", \n      hjust = .5, \n      margin = margin(b = 10)\n    ),\n    plot.caption = element_text(\n      size = 22, \n      color = \"#00263A\", \n      hjust = .5, \n      margin = margin(t = 10)\n    ),\n    panel.spacing = unit(1, \"lines\"),\n    legend.position = \"right\"\n  )\n\n\n\n\n\nggplot() + \n  layer_spatial(modern_tbl %>% filter(COUNTRY == \"Ethiopia\"), aes(fill = PCT)) + \n  facet_wrap(vars(YEAR), strip.position = \"bottom\", ) + \n  scale_fill_gradient(\n    low = \"transparent\",\n    high = \"#BD262D\",\n    na.value = \"#CFCFCF\"\n  ) + \n  labs(\n    title = \"Modern Contraceptive Prevalence in Ethiopia: 2014-2019\",\n    fill = \"Percent Women \\nAge 15-49\"\n  ) + \n  theme_pma \n\n\n\n\nOur use of facet_wrap\nworks well in this case because the spatial extent of each panel is\nidentical: we’ve only plotted the same country seven times. Watch what\nhappens, though, when we try the same approach to faceting maps with\ndifferent spatial extents. Here, we’ll create one choloropleth\nfor each of three countries sampled by PMA in 2019.\n\n\nggplot() + \n  layer_spatial(modern_tbl %>% filter(YEAR == \"2019\"), aes(fill = PCT)) + \n  facet_wrap(vars(COUNTRY), strip.position = \"bottom\", ) + \n  scale_fill_gradient(\n    low = \"transparent\",\n    high = \"#BD262D\",\n    na.value = \"#CFCFCF\"\n  ) + \n  labs(\n    title = \"Modern Contraceptive Prevalence: 2019\",\n    fill = \"Percent Women \\nAge 15-49\"\n  ) + \n  theme_pma \n\n\n\n\nThe problem here is that facet_wrap\nattempts to use the same scales along the x and y-axes by default. When\nwe facet by COUNTRY, each map is drawn to scale and in\nabsolute position. Instead, we want each country’s map to appear\napproximately the same size and in the center of each panel.\nIn most ggplot2\napplications, we’d resolve this problem by setting\nscales = \"free\". This should allow facet_wrap\nto identify axes that fit the data in each panel. Instead, it generates\nthe following error:\n\n\nggplot() + \n  layer_spatial(modern_tbl %>% filter(YEAR == \"2019\"), aes(fill = PCT)) + \n  facet_wrap(vars(COUNTRY), strip.position = \"bottom\", scales = \"free\") + \n  scale_fill_gradient(\n    low = \"transparent\",\n    high = \"#BD262D\",\n    na.value = \"#CFCFCF\"\n  ) + \n  labs(\n    title = \"Modern Contraceptive Prevalence: 2019\",\n    fill = \"Percent Women \\nAge 15-49\"\n  ) + \n  theme_pma \n\n\n\nError in `f()`:\n! coord_sf doesn't support free scales\nFortunately, we were able to find this\nexcellent blog post with an explanation and work-around.\n\nIt turns out the the ggplot2 codebase assumes\nthat it can maniulate axes independently of one another. This is\nvery much not the case with geographic data where a meter vertically\nneeds to equal a meter horizontally, so coord_sf() locks\nthe axes in much the same manner as coord_fixed().\n\n— Rob Williams, Data Scientist\n\n\nWilliams suggests a different approach using the cowplot package\ndeveloped by biologist Claus O.\nWilke at the University of Texas at Austin. We’ve never featured\ncowplot before on our blog, so we first needed to install\nit from CRAN:\n\n\ninstall.packages(\"cowplot\")\n\n\n\n\n\nlibrary(cowplot)\n\n\n\nThe key difference in this approach is that you create each panel\nseparately, and then use cowplot to align\nthem. Panels can be arranged in rows or columns, and their sizes can be\nidentical or individually specified. You can also overlay plots on top\nof each other to produce annotations or even watermarks. A general\nintroduction is available here.\n\n\n\n\n\n© Claus O. Wilke (GPL-2)\n\n\n The cowplot\npackage is featured extensively in the book Fundamentals of Data\nVisualization.\nCowplot: combining countries\n\n\n\nThe function cowplot::plot_grid\ntakes a list of plots as input, so we first need to write a function\nthat will generate one plot for each of our four 2019 samples. We’ll\nstart with Ethiopia first:\n\n\nggplot() + \n  layer_spatial(\n    modern_tbl %>% filter(COUNTRY == \"Ethiopia\" & YEAR == 2019),\n    aes(fill = PCT)\n  ) + \n  scale_fill_gradient(\n    low = \"transparent\",\n    high = \"#BD262D\",\n    na.value = \"#CFCFCF\",\n    guide = guide_colorbar(\n      title.position = \"left\", \n      direction = \"horizontal\", \n      barwidth = unit(5, \"cm\")\n    )\n  ) + \n  labs(\n    caption = \"Ethiopia\",\n    fill = \"Percent Women \\nAge 15-49\"\n  ) + \n  theme_pma \n\n\n\n\nIf we want to switch countries to Burkina Faso, for example, we only\nneed to replace the string \"Ethiopia\" in two places.\n\n\nggplot() + \n  layer_spatial(\n    modern_tbl %>% filter(COUNTRY == \"Burkina Faso\" & YEAR == 2019),\n    aes(fill = PCT)\n  ) + \n  scale_fill_gradient(\n    low = \"transparent\",\n    high = \"#BD262D\",\n    na.value = \"#CFCFCF\",\n    guide = guide_colorbar(\n      title.position = \"left\", \n      direction = \"horizontal\", \n      barwidth = unit(5, \"cm\")\n    )\n  ) + \n  labs(\n    caption = \"Burkina Faso\",\n    fill = \"Percent Women \\nAge 15-49\"\n  ) + \n  theme_pma\n\n\n\n\nNotice that the range of values shown on our legend changes\nautomatically when we switch countries? When we combine countries into a\nsingle plot, we’ll want to specify these values manually so that the\nsame fill color represents the same value on every plot.\nWe’ll use 0% as a minimum value, but the maximum value should be only\nslightly higher than the maximum value in our data: this maximizes the\ndynamic color range between any two data points.\n\n\nmodern_tbl %>% filter(YEAR == 2019) %>% summarise(max(PCT, na.rm = TRUE))\n\n\n# A tibble: 1 × 1\n  `max(PCT, na.rm = TRUE)`\n                     <dbl>\n1                     36.5\n\nWe’ll now set limits at 0% and 37% in scale_fill_gradient.\n(As expected, this decreases the dynamic color range between each\nregion.)\n\n\nggplot() + \n  layer_spatial(\n    modern_tbl %>% filter(COUNTRY == \"Burkina Faso\" & YEAR == 2019),\n    aes(fill = PCT)\n  ) + \n  scale_fill_gradient(\n    low = \"transparent\",\n    high = \"#BD262D\",\n    na.value = \"#CFCFCF\",\n    guide = guide_colorbar(\n      title.position = \"left\", \n      direction = \"horizontal\", \n      barwidth = unit(5, \"cm\")\n    ),\n    limits = c(0, 37)  # Legend limits inserted here \n  ) + \n  labs(\n    caption = \"Burkina Faso\",\n    fill = \"Percent Women \\nAge 15-49\"\n  ) + \n  theme_pma \n\n\n\n\nFinally, we’ll use the map function\nfrom the purrr\npackage to build a list containing one map for each country. Remember:\nhere map refers to a function applied iteratively to each\nitem in a list - not the kind of spatial map we’re trying to add to our\nplot! The easiest way to reference a list item within a mapped function\nis to use the symbol ~, which signals an anonymous\nfunciton where the list item is represented by the variable\n.x. Here, we use .x in place of each country\nname in our data.\n\n\n\n\n© RStudio, Inc. (GPL-3)\n\n\n\n\nplotlist <- unique(modern_tbl$COUNTRY) %>% \n  map(~{\n    ggplot() + \n      layer_spatial(\n        modern_tbl %>% filter(COUNTRY == .x & YEAR == 2019),\n        aes(fill = PCT)\n      ) + \n      scale_fill_gradient(\n        low = \"transparent\",\n        high = \"#BD262D\",\n        na.value = \"#CFCFCF\",\n        guide = guide_colorbar(\n          title.position = \"left\", \n          direction = \"horizontal\", \n          barwidth = unit(10, \"cm\")\n        ),\n        limits = c(0, 37)\n      ) + \n      labs(\n        caption = .x,\n        fill = \"Percent Women \\nAge 15-49\"\n      ) + \n      theme_pma \n  })\n\n\n\nNow, plotlist is a list with four items: one plot per\ncountry. The function unique(modern_tbl$COUNTRY) listed our\ncountries alphabetically:\n\n\nplotlist[[1]]\n\n\n\nplotlist[[2]]\n\n\n\nplotlist[[3]]\n\n\n\n\nBefore we assemble these plots in an array, we’ll want to extract\none copy of the shared legend. Here, we use get_legend\nto extract the legend from Burkina Faso:\n\n\nlegend <- get_legend(plotlist[[1]])\n\n\n\nWe can now strip all of the legends from each of the individual\npanels with another map\nfunction.\n\n\nplotlist <- plotlist %>% map(~.x + theme(legend.position = \"none\"))\n\n\n\nWe’ll also build a title with ggdraw\nthat will span all three panels. Make sure to check out the complete\nlist of cowplot\nfunctions available to help customize your plot.\n\n\ntitle <- ggdraw() + \n  draw_label(\n    toupper(\"Modern Contraceptive Prevalence: 2019\"),\n    fontfamily = 'cabrito',\n    x = 0.5, \n    y = 0.5,\n    hjust = 0.5,\n    color = \"#00263A\",\n    size = 30\n  )\n\ntitle\n\n\n\n\nWe’ll build our final plot in two steps, both using plot_grid.\nThe first arranges our three panels in a single row with three columns.\nIt took some trial and error to get the set the relative width of each\npanel with rel_widths (for example, the Uganda plot is\nabout 72% narrower than the Burkina Faso plot: if both were plotted with\nthe same width, the Uganda plot would be taller).\n\n\noutput <- plot_grid(plotlist = plotlist, nrow = 1, rel_widths = c(1, 0.95, 0.72))\n\noutput\n\n\n\n\nThe second step arranges this output between our\ntitle and legend, creating three rows total.\nHere, we use rel_heights to make the output\nrow three times taller than the rows containing title and\nlegend.\n\n\nplot_grid(\n  title,\n  output,\n  legend,\n  ncol = 1, \n  rel_heights = c(1, 3, 1)\n)\n\n\n\n\nAnd there you have it! With cowplot, it’s easy to\nbuild an array of maps - or any combination of plots - with a shared\ntitle, legend, or any other annotation you might need. And, because it’s\nbuilt to work with ggplot2, cowplot works\nperfectly with our existing data visualization workflow.\n\nSurveyed methods may vary by country\nand within the same country following a survey redesign period between\nrounds. Modern methods could include: female sterilization, male\nsterilization, implants, IUDs, injectables, pills, emergency\ncontraception, male condoms, female condoms, diaphragms, foam, beads, N\ntablet, and lactational amenorrhea method (LAM).↩︎\n",
    "preview": "posts/2022-07-15-facet-maps/facet-maps_files/figure-html5/unnamed-chunk-24-1.png",
    "last_modified": "2022-09-01T11:33:32-04:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1344
  },
  {
    "path": "posts/2022-07-01-ined-revealjs/",
    "title": "Slide Presentations in R with Quarto",
    "description": "We've been preparing for an upcoming workshop by building our first presentation with Quarto and Revealjs. Here's what we've learned so far.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-07-01",
    "categories": [
      "Quarto",
      "RMarkdown",
      "Revealjs",
      "Slides",
      "R Tips"
    ],
    "contents": "\n\nContents\nWhat We Learned\nCustomization\nLayout and Animation\n\nOther Resources\n\n\n\n\n\n\nThis spring, it seemed like everyone in the R community was suddenly talking about Quarto, the new multi-language successor to RMarkdown.\n\n\n\nOver the weekend, I wrote up my notes about using and teaching Quarto, based on my experiences working with the development team for over a year.I think (hope?) it is safe to talk about it now 😆https://t.co/qg98fEsW7g\n\n— Alison Presmanes Hill (@apreshill) April 5, 2022\n\n\nHere at IPUMS PMA, we’ve been happy RMarkdown users for several years. After all, our blog is built entirely with Distill for RMarkdown - this allows readers to download every post as a fully executable R script right from our GitHub page. Internally, we use RMarkdown for all kinds of everyday tasks like:\nwriting shareable R code with full text comments\nautomating the production of fully-formatted PDFs, Word, and Excel files\nbuilding interactive Shiny applications for data exploration\neven running Stata code from a local installation of StataSE-64.exe\nFortunately, because Quarto and RMarkdown both use Knitr, it’s easy to upgrade! Almost everything we’ve ever made with RMarkdown can be rendered by Quarto (except for some changes to YAML fields in the header).\nOne notable exception: we’ve previously used the popular Xaringan R package to create slide presentations with RMarkdown. Because Quarto is entirely built on Pandoc, we figured it’s high time to adopt a Pandoc-defined output format, instead. Below is our first attempt at using Revealjs in Quarto!\n\nBrowser not supported! Visit https://ipums-global-health.github.io/ined-pma-2022/slides.html for slides.\n\nThese slides will be presented at the upcoming workshop Population-environment-health: connecting pixels hosted at The French Institute for Demographic Studies in Paris on July 6.\nYou can register here to attend remotely!\nClick here to view the slides in a full-screen browser window, and here for code and toy datasets discussed in the slides.\nWhat We Learned\nIf you’ve ever built slides in RMarkdown before, the basics you’ll need to get started with RevealJS in Quarto will be very familiar. First, we downloaded Quarto and created a new RStudio project containing a file called slides.qmd. We also created a few subfolders:\ndata includes the toy datasets featured in our workshop\nimages includes any image that appears on a slide (including gifs and png files)\nslides_files is created automatically when slides.qmd is rendered\nThe slides.qmd file looks very much like a standard RMarkdown file divided by several headings, each representing a new slide. Title slides for major sections can be created with a level-1 heading (#) like this:\n\n# 1 - IPUMS PMA DATA\n\n\nBrowser not supported! Visit https://ipums-global-health.github.io/ined-pma-2022/slides.html for slides.\n\nWithin sections, we built individual slides with titles set by level-2 headings (##) like this:\n\n## Mapping Birth Outcomes by EA\n\n```{r, fig.height=4, fig.align='center'}\nggplot() + \n  layer_spatial(ea_summary_gps, aes(fill = many_births)) + \n  layer_spatial(shape, alpha = 0) + \n  theme_minimal()\n```\n\n\nBrowser not supported! Visit https://ipums-global-health.github.io/ined-pma-2022/slides.html for slides.\n\n\nYou can also use --- to insert a slide with no title.\nCustomization\nAs you can see above, we’ve incorporated the same fonts that appear on our blog and across all IPUMS websites. These are applied in a custom.scss file in the root folder for our project. We’re certainly not experts at CSS, but this file was easy to build because Quarto provides great documentation for pre-defined Sass Variables. Our custom.scss file looks like this:\n\n/*-- scss:defaults --*/\n\n$font-family-sans-serif: cabrito_sans_norm_regular;\n$presentation-heading-font: cabrito_sans_norm_regular;\n$presentation-heading-color:  #00263A;\n$presentation-heading-text-transform: uppercase;\n$presentation-heading-font-weight: 500;\n$link-color: #98579B;\n$presentation-title-slide-text-align: left;\n$code-block-font-size:  0.6em;\n$presentation-font-smaller: .8;\n\nSass Variable\nWhat it does\n$font-family-sans-serif\nSets main serif font\n$presentation-heading-font\nSets font for headings\n$presentation-heading-color\nSets color for headings (Navy)\n$presentation-heading-text-transform\nAll headings to uppercase\n$presentation-heading-font-weight\nLighter font weight\n$link-color\nSets color for links (Pink)\n$presentation-title-slide-text-align\nTitle slides left aligned\n$code-block-font-size\nSlightly smaller code font\n$presentation-font-smaller\nProportional adjustment for all fonts\nClick here to see a list of all available Sass variables.\nAddtionally, we specified a few global settings in the YAML header of the slides.qmd file.\n\nformat: \n  revealjs: \n    theme: [default, custom.scss]\n    logo: images/logo-navy.png\n    chalkboard: true\n    smaller: true\n    scrollable: false\n    incremental: true\n    preview-links: true\n\nYAML option\nWhat it does\ntheme\nUse the default Bootstrap 5 theme, except where our custom.scss file says otherwise\nlogo\nPath the the IPUMS PMA logo image (inserted in the bottom-right of each slide)\nchalkboard\nEnables drawing on slides (see button at bottom-left)\nsmaller\nProportional size adjustment for all fonts (set in custom.scss)\nscrollable\nDisable scrolling: we wanted to adjust figure sizes manually so that everything fits on the page\nincremental\nDisplay bullets and content in fragment tags incrementally (on click)\npreview-links\nOpen external links in a preview window\nLayout and Animation\nOne thing that took practice: creating multiple columns with fenced div containers! A typical multi-column slides looks something like this:\n\n## Downloading IPUMS PMA data {.center .nonincremental}\n\n::: {.columns}\n:::: {.column width=\"50%\"}\n![](images/pma/home.png){}\n::::\n:::: {.column width=\"50%\"}\n[Visit the IPUMS PMA data website](https://pma.ipums.org/pma/)\n\n* Sample \n  * Burkina Faso\n  * Longitudinal \n  * Female Respondents Only\n* Variables \n  * [RESULTFQ](https://pma.ipums.org/pma-action/variables/RESULTFQ)\n  * [PANELBIRTH](https://pma.ipums.org/pma-action/variables/PANELBIRTH)\n  * [PANELWEIGHT](https://pma.ipums.org/pma-action/variables/PANELWEIGHT)\n  * [EAID](https://pma.ipums.org/pma-action/variables/EAID)\n  * [URBAN](https://pma.ipums.org/pma-action/variables/URBAN)\n::::\n:::\n\n\nNotice that we’re trying to show all bullets at once (rather than incrementally) by setting the slide option .nonincremental. As you can see, we’re still learning: the bullets show up incrementally anyway 😬\n\nBrowser not supported! Visit https://ipums-global-health.github.io/ined-pma-2022/slides.html for slides.\n\nThis works great, but things can get complicated quickly. In this slide, we wanted to show several sentences incrementally on the left column, but we didn’t want to waste space with bullets. Instead, we inserted .fragment tags around the text we wanted to highlight in each step. Then, we added the option .fade-in-then-semi-out to fade the color of each point once we’d moved on the the next one.\n\n## About PMA GPS data {auto-animate=\"true\"}\n\n::: {.columns}\n:::: {.column width=\"60%\"}\n::::: {.fragment .fade-in-then-semi-out}\nPMA uses spatially referenced sample clusters - called \"enumeration areas\" (EAs) - sampled by probability proportional to population size.\n:::::\n::::: {.fragment .fade-in-then-semi-out}\nAt the beginning of the panel study, 35 households were randomly selected within each EA.\n:::::\n::::\n:::: {.column width=\"40%\"}\n::::\n::: \n\nAfter the first two sentences, we wanted to show a figure in the right column representing a PMA sample cluster before moving on to the next two sentences. The easiest way we found to do this was to create a duplicate slide where the first two sentences were faded right away. It took quite a bit of trial-and-error to get the size and .absolute position of our figure just the way we wanted!\n\n## About PMA GPS data {auto-animate=\"true\" visibility=\"uncounted\"}\n\n::: {.columns}\n:::: {.column width=\"60%\"}\n::::: {style=\"opacity:0.5\"}\nPMA uses spatially referenced sample clusters - called \"enumeration areas\" (EAs) - sampled by probability proportional to population size.\n\nAt the beginning of the panel study, 35 households were randomly selected within each EA.\n::::: \n::::: {.fragment .fade-in-then-semi-out}\nIPUMS PMA does not disseminate the GPS coordinates for EAs, but you may [apply here](https://www.pmadata.org/data/request-access-datasets) for access directly from PMA.\n:::::\n::::: {.fragment .fade-in-then-semi-out}\nToday, we'll be using **falsified** GPS coordinates as an example. \n:::::\n::::\n:::: {.column width=\"40%\"}\n![](images/pma/gps1.png){.absolute top=100 right=50 height=300}\n::::\n::: \n\nNext, we wanted to demonstrate that we’d be using falsified locations for sample clusters in the workshop. In short, we’d created a toy version of the GPS data researchers can obtain from PMA, whereby we jittered each point in a random direction by a random distance within a preset range. To illustrate, we used the RevealJS auto-animate feature to drag the position of our figure across the slide. This required a second duplicate slide with a new .absolute position for our figure.\n\n## About PMA GPS data {auto-animate=\"true\" visibility=\"uncounted\"}\n\n::: {.columns}\n:::: {.column width=\"60%\"}\n::::: {style=\"opacity:0.5\"}\nPMA uses spatially referenced sample clusters - called \"enumeration areas\" (EAs) - sampled by probability proportional to population size.\n\nAt the beginning of the panel study, 35 households were randomly selected within each EA.\n\nIPUMS PMA does not disseminate the GPS coordinates for EAs, but you may [apply here](https://www.pmadata.org/data/request-access-datasets) for access directly from PMA.\n::::: \nToday, we'll be using **falsified** GPS coordinates as an example. \n::::\n:::: {.column width=\"40%\"}\n![](images/pma/gps1.png){.absolute top=300 right=0 height=300}\n::::\n::: \n\nFinally, we wanted to emphasize that our data only provide the centroid of a randomly displaced sample cluster, not the location of any household within the cluster. We added one more duplicate slide, except that it shows a modified figure with a red + sign in the middle.\n\n## About PMA GPS data {auto-animate=\"true\" visibility=\"uncounted\"}\n\n::: {.columns}\n:::: {.column width=\"60%\"}\n::::: {style=\"opacity:0.5\"}\nPMA uses spatially referenced sample clusters - called \"enumeration areas\" (EAs) - sampled by probability proportional to population size.\n\nAt the beginning of the panel study, 35 households were randomly selected within each EA.\n\nIPUMS PMA does not disseminate the GPS coordinates for EAs, but you may [apply here](https://www.pmadata.org/data/request-access-datasets) for access directly from PMA.\n\nToday, we'll be using **falsified** GPS coordinates as an example. \n::::: \n\nThe coordinates represent the <span style=\"color:red\">**centroid**<\/span> of an enumeration area, *not* the location of any sampled household. \n::::\n:::: {.column width=\"40%\"}\n![](images/pma/gps2.png){.absolute top=300 right=0 height=300}\n::::\n::: \n\nThe result looks like this:\n\nBrowser not supported! Visit https://ipums-global-health.github.io/ined-pma-2022/slides.html for slides.\n\nYou can also use animation together with line highlighting to incrementally build complex coding examples. Here, we use three copies of the same slide to show how we summarise births by enumeration area, and then divide all enumeration areas into upper and lower halves.\nIn each duplicate slide, we use code-line-numbers to specify highlighting for a different line in the subsequent code chunk.\n\n## Birth outcomes by EA {auto-animate=true}\n\n::: {.fragment .fade-in}\nWhere are the enumeration areas where more women gave birth than average? \n:::\n::: {.fragment .fade-in}\n```{r}\nea_summary <- pma %>% \n  as_survey_design(weight = PANELWEIGHT) %>% \n  group_by(ea = EAID_1, urban = URBAN == 1) %>% \n  summarise(birth_prop = survey_mean(PANELBIRTH_2 == 1, vartype = NULL)) %>% \n  ungroup()\n```\n:::\n::: {.fragment .fade-in}\n```{r, echo=FALSE}\nea_summary \n```\n:::\n\n\n## Birth outcomes by EA {auto-animate=\"true\" visibility=\"uncounted\"}\n\nWhere are the enumeration areas where more women gave birth than average?\n\n```{r, `code-line-numbers` = \"6-8\"}\nea_summary <- pma %>% \n  as_survey_design(weight = PANELWEIGHT) %>% \n  group_by(ea = EAID_1, urban = URBAN == 1) %>% \n  summarise(birth_prop = survey_mean(PANELBIRTH_2 == 1, vartype = NULL)) %>% \n  ungroup() %>% \n  mutate(\n    ntile = ntile(birth_prop, 2)\n  )\n```\n\n```{r, echo=FALSE}\nea_summary \n```\n\n## Birth outcomes by EA {auto-animate=\"true\" visibility=\"uncounted\"}\n\nWhere are the enumeration areas where more women gave birth than average?\n\n```{r,  `code-line-numbers` = \"8\"}\nea_summary <- pma %>% \n  as_survey_design(weight = PANELWEIGHT) %>% \n  group_by(ea = EAID_1, urban = URBAN == 1) %>% \n  summarise(birth_prop = survey_mean(PANELBIRTH_2 == 1, vartype = NULL)) %>% \n  ungroup() %>% \n  mutate(\n    ntile = ntile(birth_prop, 2),\n    many_births = ntile == 2\n  )\n```\n\n```{r, echo=FALSE}\nea_summary \n```\n\n\nBrowser not supported! Visit https://ipums-global-health.github.io/ined-pma-2022/slides.html for slides.\n\nOther Resources\nNeedless to say, we’ve very excited about Revealjs and all of the other new features made possible by Quarto! At the same time, we have a lot to learn (particularly around interactivity and custom styling). If you, too, are experimenting with your first Quarto project, we’d recommend any of these great resources to help get started:\n“A Quarto Tip a Day” from @quarto_pub on Twitter\nQuarto Documentation\nThe Untold Story of Palmerpenguins - a stellar Revealjs presentation by Drs. Kristen Gorman, Allison Horst, and Alison Hill given at the 2022 useR! conference\nWe don’t talk about Quarto from Dr. Allison Hill\nWith Quarto Coming, is R Markdown Going Away? No. - great explainer by Dr. Yihui Xie, principal author of the Knitr R package (any many others!)\nPorting a Distill blog to Quarto - from R devoloper / data scientist Dr. Danielle Navarro, a guide to blogging with Quarto (a change we’re not likely to make soon, ourselves)\nNotes on Changing from Rmarkdown/Bookdown to Quarto - for authors interested in writing their next book in Quarto, courtesy of Dr. Nick Tierney\n\n\n\n",
    "preview": "posts/2022-07-01-ined-revealjs/images/feature.png",
    "last_modified": "2022-11-28T16:32:46-05:00",
    "input_file": {},
    "preview_width": 2139,
    "preview_height": 1204
  },
  {
    "path": "posts/2022-06-15-phase2-webinar/",
    "title": "Webinar: Did COVID-19 Impact Contraceptive Use?",
    "description": "Breakout sessions for both R and Stata users show how to use panel data from IPUMS PMA to model contraceptive adoption and discontinuation during the first year of the pandemic.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      },
      {
        "name": "Devon Kristiansen",
        "url": "https://www.linkedin.com/in/devonkristiansen"
      }
    ],
    "date": "2022-06-15",
    "categories": [
      "Panel Data",
      "Data Analysis",
      "Stata",
      "Video"
    ],
    "contents": "\n\nContents\nR-users Breakout Session\nSetup\nAnalytic Sample\nRecoding Independent\nvariables\nDependent variables\nAnalysis\n\nStata-users Breakout\nSession\nSetup\nAnalytic Sample\nDependent variables\nData Visualization\nData Analysis\nLogistic regressions\nLogistic regressions\nwith parity\n\n\n\n\n\nLast month, PMA and IPUMS PMA co-hosted a webinar introducing both R\nand Stata users to the new family planning panel\nsurvey we’ve been covering recently here on the blog. In our example\nanalysis, we used interviews with women aged 15-49 in Burkina Faso and\nKenya to examine how COVID-19 impacted both adoption and discontinuation\nof contraceptives between Phase 1 and Phase 2 of the study.\nBelow you’ll find a video recording of the complete webinar,\nbeginning with an overview of the PMA panel study design. Attendees were\ninvited to create their own data extract through the IPUMS PMA website,\nand to try replicating our analysis with downloadable R or Stata\ncode.\n\n\n\nIn the breakout sessions, we walked R and Stata users through a few\nof the key data cleaning, visualization, and modeling steps we use in\nour analysis. You can download executable scripts from both the R\nsession and the Stata\nsession, or follow along with our example code shown below.\nR-users Breakout Session\n\n\n\nSetup\nR users should always select a .dat (fixed-width\ntext) data format on the IPUMS PMA website.\nYou’ll receive a compressed dat.gz file - no need to\ndecompress!\nSave both of those files in the “data” folder of your working\ndirectory.\n\n\n\n\n\nYou’ll need the ipumsr package to\nload them. If not installed, you can download from CRAN.\n\n\ninstall.packages(\"ipumsr\")\n\n\n\nEach session, load the ipumsr library before you import\ndata.\n\n\nlibrary(ipumsr)\n\n# Load data into R with `ipumsr`\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00093.xml\",\n  data = \"data/pma_00093.dat.gz\"\n)\n\n\n\n\n\n\n\n© IPUMS (MPL-2.0)\n\n\nOther useful packages for IPUMS data:\n\n\n# General toolkit \nlibrary(tidyverse)\n\n# For label manipulation: \nlibrary(labelled)\n\n# For survey analysis: \nlibrary(survey) \nlibrary(srvyr) \n\n\n\n\n\n\n\n© RStudio, Inc. (MIT)\n\n\nAnalytic Sample\nPMA uses an open panel design - women may enter the\npanel after Phase 1, and they may be lost to follow-up after any phase\n(see RESULTFQ).\nWomen who enter the panel at Phase 2 are NA for all\nvariables at Phase 1.\n\n\ndat %>% count(RESULTFQ_1)\n\n\n# A tibble: 3 × 2\n             RESULTFQ_1     n\n              <int+lbl> <int>\n1  1 [Completed]        16314\n2  5 [Partly completed]    34\n3 NA                     4514\n\nWomen whose households were not found again after Phase 1 are\nNA for all variables at Phase 2.\n\n\ndat %>% count(RESULTFQ_2)\n\n\n# A tibble: 11 × 2\n                                       RESULTFQ_2     n\n                                        <int+lbl> <int>\n 1  1 [Completed]                                 17015\n 2  2 [Not at home]                                 106\n 3  3 [Postponed]                                    24\n 4  4 [Refused]                                      87\n 5  5 [Partly completed]                             22\n 6  7 [Respondent moved]                             18\n 7 10 [Incapacitated]                                24\n 8 95 [Not interviewed (female questionnaire)]        4\n 9 96 [Not interviewed (household questionnaire)]   197\n10 99 [NIU (not in universe)]                      1353\n11 NA                                              2012\n\nWe will only include women who were available and completed the\nFemale Questionnaire for both Phase 1 and Phase 2.\n\n\ndat <- dat %>% filter(RESULTFQ_1 == 1 & RESULTFQ_2 == 1)\n\ndat %>% count(RESULTFQ_1, RESULTFQ_2)\n\n\n# A tibble: 1 × 3\n     RESULTFQ_1    RESULTFQ_2     n\n      <int+lbl>     <int+lbl> <int>\n1 1 [Completed] 1 [Completed] 12501\n\nAdditionally, PMA samples are only valid for the de facto\npopulation: women who slept in the household the night before the\nHousehold interview (see RESIDENT).\n\n\ndat %>% count(RESIDENT_1)\n\n\n# A tibble: 3 × 2\n                                         RESIDENT_1     n\n                                          <int+lbl> <int>\n1 11 [Visitor, slept in hh last night]                140\n2 21 [Usual member, did not sleep in hh last night]   194\n3 22 [Usual member, slept in hh last night]         12167\n\nWe’ll also drop cases where the woman was not part of the de\nfacto population in either Phase 1 or Phase 2.\n\n\ndat <- dat %>% filter(RESIDENT_1 %in% c(11, 22) & RESIDENT_2 %in% c(11, 22))\n\n\n\nHow many cases remain?\n\n\ndat %>% count(COUNTRY)\n\n\n# A tibble: 2 × 2\n           COUNTRY     n\n         <int+lbl> <int>\n1 1 [Burkina Faso]  5208\n2 7 [Kenya]         6935\n\nRecoding Independent\nvariables\nPMA surveys contain many categorical variables.\nThese are usually represented as factors in R.\nIn an IPUMS data extract, you won’t see factors!\nInstead, we generate labelled numeric\nvariables (note the label in brackets).\n\n\ndat %>% ipums_var_label(CVINCOMELOSS_2)\n\n\n[1] \"Income loss resulted from COVID-19 restrictions\"\n\ndat %>% count(CVINCOMELOSS_2)\n\n\n# A tibble: 4 × 2\n              CVINCOMELOSS_2     n\n                   <int+lbl> <int>\n1  0 [No]                      658\n2  1 [Yes]                    7566\n3 97 [Don't know]                2\n4 99 [NIU (not in universe)]  3917\n\nThe ipumsr\npackage contains tools for working with labelled IPUMS data.\nUsually, we handle codes like 99 [NIU (not in universe)]\nbefore transforming other missing data to NA.\n\n\ndat %>% count(CVINCOMELOSS_2, HHINCOMELOSSAMT_2)\n\n\n# A tibble: 7 × 3\n              CVINCOMELOSS_2           HHINCOMELOSSAMT_2     n\n                   <int+lbl>                   <int+lbl> <int>\n1  0 [No]                     2 [Partial]                  547\n2  0 [No]                     3 [Complete]                 111\n3  1 [Yes]                    2 [Partial]                 5449\n4  1 [Yes]                    3 [Complete]                2117\n5 97 [Don't know]             2 [Partial]                    2\n6 99 [NIU (not in universe)]  1 [None]                    3904\n7 99 [NIU (not in universe)] 98 [No response or missing]    13\n\n\n\n\n\nInformation on the code NIU (not in universe) can always be\nfound on a variable’s universe\ntab.\nFor CVINCOMELOSS_2,\n99 [NIU (not in universe)] may indicate that the household\nexperienced no income loss in the last year, or it may indicate\nthat HHINCOMELOSSAMT_2\nis 98 [No response or missing].\nWe should treat the NIU women from households without\nany income loss as “No” in CVINCOMELOSS_2.\n\n\ndat <- dat %>% \n  mutate(\n    CVINCOMELOSS_2 = CVINCOMELOSS_2 %>% \n      labelled::recode_if(HHINCOMELOSSAMT_2 == 1, 0)\n  )\n\ndat %>% count(CVINCOMELOSS_2, HHINCOMELOSSAMT_2)\n\n\n# A tibble: 7 × 3\n              CVINCOMELOSS_2           HHINCOMELOSSAMT_2     n\n                   <int+lbl>                   <int+lbl> <int>\n1  0 [No]                     1 [None]                    3904\n2  0 [No]                     2 [Partial]                  547\n3  0 [No]                     3 [Complete]                 111\n4  1 [Yes]                    2 [Partial]                 5449\n5  1 [Yes]                    3 [Complete]                2117\n6 97 [Don't know]             2 [Partial]                    2\n7 99 [NIU (not in universe)] 98 [No response or missing]    13\n\nNext, we’ll use NA to represent the remaining values\nabove 90:\n97 [Don't know] and\nremaining cases marked 99 [NIU (not in universe)]\n\n\ndat <- dat %>% \n  mutate(\n    CVINCOMELOSS_2 = CVINCOMELOSS_2 %>% \n      lbl_na_if(~.val > 90)\n  )  \n\ndat %>% count(CVINCOMELOSS_2, HHINCOMELOSSAMT_2)\n\n\n# A tibble: 7 × 3\n  CVINCOMELOSS_2           HHINCOMELOSSAMT_2     n\n       <int+lbl>                   <int+lbl> <int>\n1        0 [No]   1 [None]                    3904\n2        0 [No]   2 [Partial]                  547\n3        0 [No]   3 [Complete]                 111\n4        1 [Yes]  2 [Partial]                 5449\n5        1 [Yes]  3 [Complete]                2117\n6       NA        2 [Partial]                    2\n7       NA       98 [No response or missing]    13\n\nOnce you’re done with labels, we recommend transforming key variables\ninto factors with forcats::as_factor.\n\n\ndat <- dat %>% mutate(CVINCOMELOSS_2 = as_factor(CVINCOMELOSS_2))\n\ndat %>% count(CVINCOMELOSS_2)\n\n\n# A tibble: 3 × 2\n  CVINCOMELOSS_2     n\n  <fct>          <int>\n1 No              4562\n2 Yes             7566\n3 <NA>              15\n\n\nThe forcats package is\nincluded when you load library(tidyverse).\nThis will make categorical variables easier to use in data\nvisualization and as “dummy” variables in regression analysis.\nLikert-style questions can be treated as factors, too.\n\n\ndat %>% ipums_var_label(COVIDCONCERN_2)\n\n\n[1] \"Concerned about getting infected\"\n\ndat %>% count(COVIDCONCERN_2)\n\n\n# A tibble: 6 × 2\n                                      COVIDCONCERN_2     n\n                                           <int+lbl> <int>\n1  1 [Not concerned]                                   374\n2  2 [A little concerned]                              677\n3  3 [Concerned]                                      2470\n4  4 [Very concerned]                                 8610\n5  5 [Currently / previously infected with COVID-19]     9\n6 98 [No response or missing]                            3\n\nThis time we’ll treat codes 5 and above as\nNA.\n\n\ndat <- dat %>% \n  mutate(\n    COVIDCONCERN_2 = COVIDCONCERN_2 %>% \n      lbl_na_if(~.val >= 5) %>% \n      as_factor()\n  )\n\ndat %>% count(COVIDCONCERN_2)\n\n\n# A tibble: 5 × 2\n  COVIDCONCERN_2         n\n  <fct>              <int>\n1 Not concerned        374\n2 A little concerned   677\n3 Concerned           2470\n4 Very concerned      8610\n5 <NA>                  12\n\nYou can apply the same transformation to several variables with help\nfrom dplyr::across.\n\n\ndat <- dat %>% \n  mutate(\n    across(\n      c(COUNTRY, URBAN, WEALTHT_2, EDUCATTGEN_2),\n      ~.x %>% lbl_na_if(~.val >= 90) %>% as_factor()\n    )\n  )\n\n\n\ndplyr is another\npackage included when you load library(tidyverse).\nOften, it’s important to set a reference group\nagainst which all dummy variables will be compared.\nYou can manually specify a refernece group when you\nset factor “levels” with a function like forcats::fct_relevel.\n\n\ndat <- dat %>% \n  mutate(\n    AGE_2 = case_when(\n      AGE_2 < 25 ~ \"15-24\",\n      AGE_2 < 35 ~ \"25-34\",\n      AGE_2 < 50 ~ \"35-49\"\n    ),\n    AGE_2 = AGE_2 %>% fct_relevel(\"15-24\", \"25-34\", \"35-49\")\n  ) \n\n\n\nDependent variables\nWe’ll use our recoded variables to model the likelihood of\ncontraceptive method adoption and\ndiscontinuation between phases (see CP).\n\n\ndat <- dat %>% filter(CP_1 < 90 & CP_2 < 90)\n\ndat %>% count(CP_1, CP_2)\n\n\n# A tibble: 4 × 3\n       CP_1      CP_2     n\n  <int+lbl> <int+lbl> <int>\n1   0 [No]    0 [No]   5107\n2   0 [No]    1 [Yes]  1939\n3   1 [Yes]   0 [No]   1178\n4   1 [Yes]   1 [Yes]  3917\n\nA woman has adopted a method if she was not\nusing one at Phase 1, but then reported using one at Phase 2.\nShe has discontinued a method if she did\nuse one at Phase 1, but no longer uses one at Phase 2.\n\n\ndat <- dat %>% \n  mutate(\n    FPSTATUS = case_when(\n      CP_1 == 1 & CP_2 == 1 ~ \"User\",\n      CP_1 == 0 & CP_2 == 0 ~ \"Non-user\",\n      CP_1 == 1 & CP_2 == 0 ~ \"Discontinued\",\n      CP_1 == 0 & CP_2 == 1 ~ \"Adopted\"\n    ),\n    FPSTATUS = fct_infreq(FPSTATUS)\n  )\n\n\n\nUn-weighted sample proportions for FPSTATUS can be found\nwith count and prop.table:\n\n\ndat_nowt <- dat %>% \n  group_by(COUNTRY) %>% \n  count(FPSTATUS) %>% \n  mutate(prop = prop.table(n))\n\ndat_nowt\n\n\n# A tibble: 8 × 4\n# Groups:   COUNTRY [2]\n  COUNTRY      FPSTATUS         n   prop\n  <fct>        <fct>        <int>  <dbl>\n1 Burkina Faso Non-user      2589 0.497 \n2 Burkina Faso User          1241 0.238 \n3 Burkina Faso Adopted        821 0.158 \n4 Burkina Faso Discontinued   556 0.107 \n5 Kenya        Non-user      2518 0.363 \n6 Kenya        User          2676 0.386 \n7 Kenya        Adopted       1118 0.161 \n8 Kenya        Discontinued   622 0.0897\n\nWe’ll plot this table with ggplot2.\n\n\ndat_nowt %>% \n  ggplot(aes(x = prop, y = FPSTATUS, fill = FPSTATUS)) +  \n  geom_bar(stat = \"identity\") +\n  facet_wrap(~COUNTRY) + theme_minimal() + \n  theme(axis.title = element_blank(), legend.position = \"none\") + \n  scale_x_continuous(labels = scales::label_percent())\n\n\n\n\nggplot2 is\nanother package included when you load library(tidyverse).\nFor weighted population estimates, use as_survey_design\nand survey_mean\nfrom the srvyr\npackage.\nUse prop = TRUE to adjust standard errors near 0% or\n100% for proportions.\n\n\ndat_wtd <- dat %>% \n  as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_1) %>%\n  group_by(COUNTRY, FPSTATUS) %>% \n  summarise(survey_mean(prop = TRUE, prop_method = \"logit\", vartype = \"ci\"))\n\ndat_wtd\n\n\n# A tibble: 8 × 5\n# Groups:   COUNTRY [2]\n  COUNTRY      FPSTATUS       coef `_low` `_upp`\n  <fct>        <fct>         <dbl>  <dbl>  <dbl>\n1 Burkina Faso Non-user     0.563  0.529   0.596\n2 Burkina Faso User         0.188  0.164   0.214\n3 Burkina Faso Adopted      0.150  0.133   0.168\n4 Burkina Faso Discontinued 0.0999 0.0870  0.115\n5 Kenya        Non-user     0.378  0.361   0.396\n6 Kenya        User         0.366  0.350   0.382\n7 Kenya        Adopted      0.165  0.153   0.177\n8 Kenya        Discontinued 0.0912 0.0830  0.100\n\n\n\n\n\n© Greg Freedman Ellis (GPL-2 | GPL-3)\n\n\n\n\ndat_wtd %>% \n  ggplot(aes(x = coef, y = FPSTATUS, fill = FPSTATUS)) +  \n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(xmin = `_low`, xmax = `_upp`), width = 0.2, alpha = 0.5) +\n  facet_wrap(~COUNTRY) + theme_minimal() + \n  theme(axis.title = element_blank(), legend.position = \"none\") + \n  scale_x_continuous(labels = scales::label_percent())\n\n\n\n\nAnalysis\nThe same srvyr toolkit\ncan be used to model our dependent variables with survey::svyglm.\nConsider women who were not using a method at Phase 1:\n\n\nadopt_glm <- dat %>% \n  filter(CP_1 == 0) %>%\n  mutate(adopt = FPSTATUS == \"Adopted\") %>% \n  group_by(COUNTRY) %>%\n  summarise(\n    adopt = cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_1) %>% \n      svyglm(\n        adopt ~ CVINCOMELOSS_2 + COVIDCONCERN_2 + URBAN + WEALTHT_2 + EDUCATTGEN_2 + AGE_2,\n        family = \"quasibinomial\", design = .\n      ) %>% \n      broom::tidy(exp = TRUE) %>% \n      mutate(sig = gtools::stars.pval(p.value)) %>% \n      list()\n  )\n\nadopt_glm\n\n\n# A tibble: 2 × 2\n  COUNTRY      adopt            \n  <fct>        <list>           \n1 Burkina Faso <tibble [13 × 6]>\n2 Kenya        <tibble [13 × 6]>\n\nFor Phase 1 non-users in Burkina Faso, very high\nlevels of concern about becoming infected with COVID-19 are\nsignificantly associated with higher chances of adopting a contraceptive\nmethod (relative to women who had no such concern).\nLesser levels of concern are not statistically significant, nor is\nhousehold income loss from COVID-19.\n\n\nadopt_glm %>% \n  filter(COUNTRY == \"Burkina Faso\") %>% \n  unnest(adopt) \n\n\n# A tibble: 13 × 7\n   COUNTRY      term        estimate std.error statistic p.value sig  \n   <fct>        <chr>          <dbl>     <dbl>     <dbl>   <dbl> <chr>\n 1 Burkina Faso (Intercept)   0.0985     0.366    -6.33  2.62e-9 \"***\"\n 2 Burkina Faso CVINCOMELO…   1.28       0.155     1.61  1.09e-1 \" \"  \n 3 Burkina Faso COVIDCONCE…   1.80       0.373     1.58  1.17e-1 \" \"  \n 4 Burkina Faso COVIDCONCE…   1.37       0.351     0.891 3.75e-1 \" \"  \n 5 Burkina Faso COVIDCONCE…   1.91       0.318     2.02  4.46e-2 \"*\"  \n 6 Burkina Faso URBANUrban    1.36       0.186     1.65  1.01e-1 \" \"  \n 7 Burkina Faso WEALTHT_2M…   0.962      0.170    -0.230 8.18e-1 \" \"  \n 8 Burkina Faso WEALTHT_2H…   0.735      0.220    -1.40  1.64e-1 \" \"  \n 9 Burkina Faso EDUCATTGEN…   1.44       0.161     2.24  2.65e-2 \"*\"  \n10 Burkina Faso EDUCATTGEN…   1.51       0.181     2.27  2.46e-2 \"*\"  \n11 Burkina Faso EDUCATTGEN…   2.30       0.352     2.37  1.92e-2 \"*\"  \n12 Burkina Faso AGE_225-34    1.72       0.180     3.02  2.98e-3 \"**\" \n13 Burkina Faso AGE_235-49    1.08       0.195     0.385 7.01e-1 \" \"  \n\nIn Kenya, neither of these measures are significantly predictive of\nadoption among non-users.\n\n\nadopt_glm %>% \n  filter(COUNTRY == \"Kenya\") %>% \n  unnest(adopt) \n\n\n# A tibble: 13 × 7\n   COUNTRY term            estimate std.error statistic  p.value sig  \n   <fct>   <chr>              <dbl>     <dbl>     <dbl>    <dbl> <chr>\n 1 Kenya   (Intercept)        0.104     0.371    -6.09  3.76e- 9 \"***\"\n 2 Kenya   CVINCOMELOSS_2…    1.20      0.111     1.61  1.08e- 1 \" \"  \n 3 Kenya   COVIDCONCERN_2…    0.645     0.351    -1.25  2.13e- 1 \" \"  \n 4 Kenya   COVIDCONCERN_2…    0.794     0.256    -0.900 3.69e- 1 \" \"  \n 5 Kenya   COVIDCONCERN_2…    0.907     0.254    -0.385 7.00e- 1 \" \"  \n 6 Kenya   URBANUrban         1.17      0.147     1.06  2.92e- 1 \" \"  \n 7 Kenya   WEALTHT_2Middl…    1.12      0.112     1.01  3.15e- 1 \" \"  \n 8 Kenya   WEALTHT_2Highe…    0.817     0.151    -1.34  1.80e- 1 \" \"  \n 9 Kenya   EDUCATTGEN_2Pr…    2.30      0.273     3.05  2.53e- 3 \"**\" \n10 Kenya   EDUCATTGEN_2Se…    2.87      0.302     3.49  5.54e- 4 \"***\"\n11 Kenya   EDUCATTGEN_2Te…    3.63      0.306     4.21  3.51e- 5 \"***\"\n12 Kenya   AGE_225-34         3.06      0.128     8.71  2.98e-16 \"***\"\n13 Kenya   AGE_235-49         1.61      0.131     3.62  3.53e- 4 \"***\"\n\nWhat about method dicontinuation for women who\nwere using a method at Phase 1?\n\n\nstop_glm <- dat %>% \n  filter(CP_1 == 1) %>% \n  mutate(stop = FPSTATUS == \"Discontinued\") %>% \n  group_by(COUNTRY) %>%\n  summarise(\n    stop = cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_1) %>% \n      svyglm(\n        stop ~ CVINCOMELOSS_2 + COVIDCONCERN_2 + URBAN + WEALTHT_2 + EDUCATTGEN_2 + AGE_2,\n        family = \"quasibinomial\", design = .\n      ) %>% \n      broom::tidy(exp = TRUE) %>% \n      mutate(sig = gtools::stars.pval(p.value)) %>% \n      list()\n  )\n\nstop_glm\n\n\n# A tibble: 2 × 2\n  COUNTRY      stop             \n  <fct>        <list>           \n1 Burkina Faso <tibble [13 × 6]>\n2 Kenya        <tibble [13 × 6]>\n\nThis time, neither of the COVID-19 measures are significantly\nassociated with discontinuation for Phase 1\ncontraceptive users in Burkina Faso.\n\n\nstop_glm %>% \n  filter(COUNTRY == \"Burkina Faso\") %>% \n  unnest(stop) \n\n\n# A tibble: 13 × 7\n   COUNTRY      term        estimate std.error statistic p.value sig  \n   <fct>        <chr>          <dbl>     <dbl>     <dbl>   <dbl> <chr>\n 1 Burkina Faso (Intercept)    0.536     0.407    -1.53   0.127  \" \"  \n 2 Burkina Faso CVINCOMELO…    0.857     0.185    -0.835  0.405  \" \"  \n 3 Burkina Faso COVIDCONCE…    1.18      0.442     0.379  0.705  \" \"  \n 4 Burkina Faso COVIDCONCE…    0.922     0.425    -0.192  0.848  \" \"  \n 5 Burkina Faso COVIDCONCE…    0.935     0.335    -0.200  0.842  \" \"  \n 6 Burkina Faso URBANUrban     0.951     0.231    -0.215  0.830  \" \"  \n 7 Burkina Faso WEALTHT_2M…    1.47      0.211     1.82   0.0702 \".\"  \n 8 Burkina Faso WEALTHT_2H…    0.797     0.238    -0.952  0.343  \" \"  \n 9 Burkina Faso EDUCATTGEN…    1.29      0.212     1.21   0.226  \" \"  \n10 Burkina Faso EDUCATTGEN…    1.16      0.250     0.596  0.552  \" \"  \n11 Burkina Faso EDUCATTGEN…    0.787     0.289    -0.828  0.409  \" \"  \n12 Burkina Faso AGE_225-34     1.11      0.215     0.482  0.630  \" \"  \n13 Burkina Faso AGE_235-49     0.784     0.244    -0.997  0.320  \" \"  \n\nHowever, higher levels concern with becoming infected with COVID-19\nare significantly associated with higher odds of\ndiscontinuation for Phase 1 contraceptive users in Kenya.\n\n\nstop_glm %>% \n  filter(COUNTRY == \"Kenya\") %>% \n  unnest(stop) \n\n\n# A tibble: 13 × 7\n   COUNTRY term             estimate std.error statistic p.value sig  \n   <fct>   <chr>               <dbl>     <dbl>     <dbl>   <dbl> <chr>\n 1 Kenya   (Intercept)        0.0978     0.877   -2.65   8.53e-3 \"**\" \n 2 Kenya   CVINCOMELOSS_2Y…   1.01       0.158    0.0433 9.65e-1 \" \"  \n 3 Kenya   COVIDCONCERN_2A…   7.68       0.694    2.94   3.60e-3 \"**\" \n 4 Kenya   COVIDCONCERN_2C…   4.24       0.723    2.00   4.67e-2 \"*\"  \n 5 Kenya   COVIDCONCERN_2V…   3.77       0.719    1.85   6.61e-2 \".\"  \n 6 Kenya   URBANUrban         1.12       0.135    0.836  4.04e-1 \" \"  \n 7 Kenya   WEALTHT_2Middle…   0.843      0.153   -1.11   2.66e-1 \" \"  \n 8 Kenya   WEALTHT_2Highes…   0.888      0.180   -0.659  5.11e-1 \" \"  \n 9 Kenya   EDUCATTGEN_2Pri…   0.787      0.349   -0.687  4.93e-1 \" \"  \n10 Kenya   EDUCATTGEN_2Sec…   0.958      0.367   -0.118  9.07e-1 \" \"  \n11 Kenya   EDUCATTGEN_2Ter…   1.10       0.397    0.238  8.12e-1 \" \"  \n12 Kenya   AGE_225-34         0.783      0.153   -1.60   1.10e-1 \" \"  \n13 Kenya   AGE_235-49         0.589      0.153   -3.45   6.51e-4 \"***\"\n\nStata-users Breakout Session\n\n\n\nSetup\nStata users should select a .dta file from the IPUMS PMA\nwebsite.\n. cd \"Z:\\pma\\admin\\presentations\\workshop2022\"\nZ:\\pma\\admin\\presentations\\workshop2022\n\n. use workshop_2022.dta\nResult of the Female Questionnaire in Phase 1 vs Phase 2:\n. tab resultfq_2 resultfq_1, miss\n\n     result of female |  result of female questionnaire\n        questionnaire | completed  partly co          . |     Total\n----------------------+---------------------------------+----------\n            completed |    12,501          8      4,506 |    17,015 \n          not at home |       106          0          0 |       106 \n            postponed |        24          0          0 |        24 \n              refused |        87          0          0 |        87 \n     partly completed |        14          0          8 |        22 \n     respondent moved |        18          0          0 |        18 \n        incapacitated |        24          0          0 |        24 \nnot interviewed (fema |         4          0          0 |         4 \nnot interviewed (hous |       197          0          0 |       197 \nniu (not in universe) |     1,352          1          0 |     1,353 \n                    . |     1,987         25          0 |     2,012 \n----------------------+---------------------------------+----------\n                Total |    16,314         34      4,514 |    20,862 \n\nAnalytic Sample\nDropping women who did not complete a survey in both surveys:\n. keep if resultfq_1 == 1\n(4,548 observations deleted)\n\n. keep if resultfq_2 == 1\n(3,813 observations deleted)\nDropping women who were not part of the de facto\npopulation:\n. keep if (resident_1 == 11 | resident_1 == 22) & (resident_2 == 11 | resident_2 == 22)\n(358 observations deleted)\nDependent variables\nWe’ll call our dependent variable category.\n> gen category = .\n(12,143 missing values generated)\n\n. replace category = 1 if cp_1 == 0 & cp_2 == 0\n(5,107 real changes made)\n\n. replace category = 2 if cp_1 == 1 & cp_2 == 1\n(3,917 real changes made)\n\n. replace category = 3 if cp_1 == 0 & cp_2 == 1\n(1,939 real changes made)\n\n. replace category = 4 if cp_1 == 1 & cp_2 == 0\n(1,178 real changes made)\n\n“Non-users” were not using a method at the time of both of\ntheir interviews.\n“Users” were using a method at the time of both of their\ninterviews.\n. label define categorical 1 \"Non-user\" 2 \"User\" 3 \"Adopted FP\" 4 \"Discontinued FP\" \n\n. label values category categorical\n\n. tab category, gen(cat_)\n\n       category |      Freq.     Percent        Cum.\n----------------+-----------------------------------\n       Non-user |      5,107       42.06       42.06\n           User |      3,917       32.26       74.33\n     Adopted FP |      1,939       15.97       90.30\nDiscontinued FP |      1,178        9.70      100.00\n----------------+-----------------------------------\n          Total |     12,141      100.00\n\nData Visualization\nOur first graph uses counts of interviewed women\n. graph bar (sum) cat_1-cat_4, over(country) legend(label(1 \"Non-user\") \nlabel(2 \"User\") label(3 \"Adopted FP\") label(4 \"Discontinued FP\"))\n\n\n\nOur second graph uses proportions, so the visualization isn’t biased\nby a difference in sample sizes\n. graph bar cat_1-cat_4, over(country) legend(label(1 \"Non-user\") label(2 \"User\")\nlabel(3 \"Adopted FP\") label(4 \"Discontinued FP\"))\n\n\n\nData Analysis\nRename outcome variable\n. rename cat_3 adoption\n\n. rename cat_4 discontinue\n\nExplanatory variables\n. tab cvincomeloss_2, miss\n\n     income loss resulted from covid-19 |\n                           restrictions |      Freq.     Percent        Cum.\n----------------------------------------+-----------------------------------\n                                     no |        658        5.42        5.42\n                                    yes |      7,566       62.31       67.73\n                             don't know |          2        0.02       67.74\n                  niu (not in universe) |      3,917       32.26      100.00\n----------------------------------------+-----------------------------------\n                                  Total |     12,143      100.00\n\nUse hhincomelossamt\nto understand who did not lose income in\nr varlink(cvincomeloss)\n. tab cvincomeloss_2 hhincomelossamt_2\n\n income loss resulted |    household income loss since covid-19\n        from covid-19 |                restrictions\n         restrictions |      none    partial   complete  no respon |     Total\n----------------------+--------------------------------------------+----------\n                   no |         0        547        111          0 |       658 \n                  yes |         0      5,449      2,117          0 |     7,566 \n           don't know |         0          2          0          0 |         2 \nniu (not in universe) |     3,904          0          0         13 |     3,917 \n----------------------+--------------------------------------------+----------\n                Total |     3,904      5,998      2,228         13 |    12,143 \n\n. replace cvincomeloss_2 = 0 if hhincomelossamt_2 == 1\n(3,904 real changes made)\nLook at the other explanatory variable\n. tab country covidconcern_2, row\n\n             |            concerned about getting infected\n pma country | not conce  a little   concerned  very conc  currently |     Total\n-------------+-------------------------------------------------------+----------\nburkina faso |       212        461        955      3,576          1 |     5,208 \n             |      4.07       8.85      18.34      68.66       0.02 |    100.00 \n-------------+-------------------------------------------------------+----------\n       kenya |       162        216      1,515      5,034          8 |     6,935 \n             |      2.34       3.11      21.85      72.59       0.12 |    100.00 \n-------------+-------------------------------------------------------+----------\n       Total |       374        677      2,470      8,610          9 |    12,143 \n             |      3.08       5.58      20.34      70.91       0.07 |    100.00 \n\n             | concerned\n             |   about\n             |  getting\n             |  infected\n pma country | no respon |     Total\n-------------+-----------+----------\nburkina faso |         3 |     5,208 \n             |      0.06 |    100.00 \n-------------+-----------+----------\n       kenya |         0 |     6,935 \n             |      0.00 |    100.00 \n-------------+-----------+----------\n       Total |         3 |    12,143 \n             |      0.02 |    100.00 \n                      \nReplace NIU to missing\n. forvalues i = 1/2 {\n  foreach var in age marstat educattgen cvincomeloss covidconcern \n  hhincomelossamt wealtht cp {\n    replace `var'_`i' = . if `var'_`i' > 90\n  }\n}\n(0 real changes made)\n(1 real change made, 1 to missing)\n(2 real changes made, 2 to missing)\n(0 real changes made)\n(0 real changes made)\n(0 real changes made)\n(2 real changes made, 2 to missing)\n(2 real changes made, 2 to missing)\n(0 real changes made)\n(0 real changes made)\n(1 real change made, 1 to missing)\n(15 real changes made, 15 to missing)\n(3 real changes made, 3 to missing)\n(13 real changes made, 13 to missing)\n(993 real changes made, 993 to missing)\n(0 real changes made)\n\nEstablishing the survey weight settings\n. svyset [pw=panelweight], psu(eaid_1) strata(strata_1)\n\n      pweight: panelweight\n          VCE: linearized\n  Single unit: missing\n     Strata 1: strata_1\n         SU 1: eaid_1\n        FPC 1: <zero>\n\n. \n\nDemonstrating weighted proportions\n. tab country adoption, row\n\n                      | category==Adopted FP\n          pma country |         0          1 |     Total\n----------------------+----------------------+----------\n         burkina faso |     4,386        821 |     5,207 \n                      |     84.23      15.77 |    100.00 \n----------------------+----------------------+----------\n                kenya |     5,816      1,118 |     6,934 \n                      |     83.88      16.12 |    100.00 \n----------------------+----------------------+----------\n                Total |    10,202      1,939 |    12,141 \n                      |     84.03      15.97 |    100.00 \n\n. svy: tab country adoption, row\n(running tabulate on estimation sample)\n\nNumber of strata   =        23                  Number of obs     =     12,141\nNumber of PSUs     =       474                  Population size   = 12,134.981\n                                                Design df         =        451\n\n-------------------------------\npma       |category==Adopted FP\ncountry   |     0      1  Total\n----------+--------------------\n  burkina | .8503  .1497      1\n    kenya | .8353  .1647      1\n          | \n    Total | .8418  .1582      1\n-------------------------------\n  Key:  row proportion\n\n  Pearson:\n    Uncorrected   chi2(1)         =    5.0554\n    Design-based  F(1, 451)       =    1.8652     P = 0.1727\n\n\nCreating an age\ncategory recode\n. recode age_2 (15/24=1) (25/34=2) (35/49=3), gen(age_rec)\n(12143 differences between age_2 and age_rec)\n\n. label define agerecode 1 \"15-24\" 2 \"25-34\" 3 \"35-49\"\n\n. label values age_rec agerecode\n\n. \n. recode birthevent_2 (99=0) (0=0) (1/2=1) (else=2), gen(birth_rec)\n(10389 differences between birthevent_2 and birth_rec)\n\n. label define birthrecode 0 \"No births\" 1 \"1 or 2 births\" 2 \"3+ births\"\n\n. label values birth_rec birthrecode\nLogistic regressions\n. svy: logit adoption i.age_rec urban i.wealtht_2 i.educattgen_2 \ncvincomeloss_2 i.covidconcern_2 if country == 1 \n\n\n\n. svy: logit adoption i.age_rec urban i.wealtht_2 i.educattgen_2 \ncvincomeloss_2 i.covidconcern_2 if country == 7 \n\n\n\n. svy: logit discontinue i.age_rec urban i.wealtht_2 i.educattgen_2 \ncvincomeloss_2 i.covidconcern_2 if country == 1 \n\n\n\n. svy: logit discontinue i.age_rec urban i.wealtht_2 i.educattgen_2 \ncvincomeloss_2 i.covidconcern_2 if country == 7 \n\n\n\nLogistic regressions with\nparity\n. svy: logit adoption i.age_rec i.birth_rec urban i.wealtht_2 i.educattgen_2 \ncvincomeloss_2 i.covidconcern_2 if country == 1 \n\n\n\n. svy: logit adoption i.age_rec i.birth_rec urban i.wealtht_2 i.educattgen_2 \ncvincomeloss_2 i.covidconcern_2 if country == 7 \n\n\n\n. svy: logit discontinue i.age_rec i.birth_rec urban i.wealtht_2 i.educattgen_2 \ncvincomeloss_2 i.covidconcern_2 if country == 1 \n\n\n\n. svy: logit discontinue i.age_rec i.birth_rec urban i.wealtht_2 i.educattgen_2 \ncvincomeloss_2 i.covidconcern_2 if country == 7 \n\n\n\n\n\n\n",
    "preview": "posts/2022-06-15-phase2-webinar/images/feature.png",
    "last_modified": "2022-06-14T10:42:53-04:00",
    "input_file": {},
    "preview_width": 3448,
    "preview_height": 1938
  },
  {
    "path": "posts/2022-06-01-sdp-panel-release/",
    "title": "Introducing Longitudinal Service Delivery Point Data",
    "description": "A new feature makes it easy to locate facilities surveyed in multiple rounds of SDP data collection. Plus, new Client Exit Interview data are now available!",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-06-01",
    "categories": [
      "Panel Data",
      "Data Discovery",
      "New Data",
      "Service Delivery Points",
      "Client Exit Interviews"
    ],
    "contents": "\n\nContents\nNew SDP samples\nLongitudinal SDP data\nFormat\nData Availability\nApplications\n\nNew CEI data\n\n\n\n\nIn addition to the release of new samples from the service delivery\npoint (SDP) and client exit\ninterview (CEI) data series, this month IPUMS PMA is excited to\nannounce a new feature designed to help researchers study health\nfacilities over time.\nMuch like the family\nplanning (FP) panel surveys released earlier this year, SDP data are\nnow available in longitudinal format. That means we’ve\nmatched responses from the same facility if it was sampled in multiple\nrounds of data collection. These responses are organized together in\ncolumns numbered separately for up to four rounds - in other words,\nlongitudinal SDP data are organized with one row per\nfacility whether it was sampled once or multiple times.\nLet’s cover the new SDP data first, and then we’ll highlight new\nadditions to the companion CEI data series.\nNew SDP samples\nThis month’s release includes new SDP samples from eight countries\ncollected between 2020 and 2021. As always, SDP sampling is conducted\ncontemporaneously and in the same enumeration\nareas used to identify women in households sampled by FP\nsurveys. IPUMS PMA released the contemporaneous FP surveys for each\ncountry (except Ethiopia) earlier this year.\nThe new SDP surveys are designed to provide contextual information about\nthe health service environment experienced by women in a corresponding\nFP sample; later, we will discuss how to match women with nearby\nfacilities via EAID.\nCountry\nSDP Data Collection\nFP Data Collection\nBurkina Faso\nFeb 2021 - Mar 2021\nDec 2020 - Apr 2021\nCote d’Ivoire\nOct 2020 - Nov 2020\nSep 2020 - Nov 2020\nDRC (Kinshasa & Kongo Central)\nJan 2021 - Mar 2021\nDec 2020 - Mar 2021\nEthiopia\nNov 2020 - Jan 2021\n–\nIndia (Rajasthan)\nAug 2020 - Nov 2020\nAug 2020 - Oct 2020\nKenya\nNov 2020 - Feb 2021\nNov 2020 - Dec 2020\nNigeria (Kano & Lagos)\nDec 2020 - Jan 2021\nDec 2020 - Jan 2021\nUganda\nSep 2020 - Oct 2020\nSep 2020 - Oct 2020\nReminder: SDP samples are not\nrepresentative. They are intended to describe the environment\nexperienced by women in corresponding FP samples.\nFor more information, check out our guide to SDP data.\nDepending on your needs, you can still download these SDP samples in\ncross-sectional format. In that case, you’ll find each\nSDP interview in its own unique row.\n\n\n\nWith the exception of Ethiopia, all of these new SDP samples are\nlabelled P1 or P2 to help users match them to\na corresponding “phase” from the ongoing family planning panel study. Data\ncollection for the third and final phase of the panel study is currently\nunderway.\nLongitudinal SDP data\nIf you select the new longitudinal format, you’ll\nfind SDP samples organized by cohorts, each including up to four rounds\nof data collection. The same enumeration areas are used in every round\nwithin any given cohort, such that the same facility might be sampled\nfrom the same enumeration area up to four times in four years.\n\n\n\nFormat\nWhen you download a longitudinal data extract, you’ll find one unique\nFACILITYID\nin each row, regardless of whether the facility was sampled once or\nmultiple times. Here, we’ve created an extract containing all available\nsamples, with “Facility Respondents” only.1\nThis selects facilities where the SDP interview was fully or partly\ncompleted in at least one round of data collection. The first\nten records from the first country, Burkina Faso, are shown:\n\n\n\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\n\nsdp <- read_ipums_micro(\n  ddi = \"data/pma_00129.xml\",\n  data = \"data/pma_00129.dat.gz\"\n)\n\n# Use labels as factor levels for the following variables (for readability)\nsdp <- sdp %>% \n  mutate(\n    COUNTRY = as_factor(COUNTRY),\n    across(starts_with(\"RESULT\"), as_factor)\n  )\n\n\n\n\n\nsdp %>% select(COUNTRY, FACILITYID, starts_with(\"RESULT\"))\n\n\n# A tibble: 10,212 × 6\n   COUNTRY      FACILITYID RESULTSQ_1 RESULTSQ_2 RESULTSQ_3 RESULTSQ_4\n   <fct>        <chr+lbl>  <fct>      <fct>      <fct>      <fct>     \n 1 Burkina Faso 7298       Completed  Completed  Completed  Completed \n 2 Burkina Faso 7399       Completed  Completed  Completed  Completed \n 3 Burkina Faso 7627       Completed  Completed  Completed  Completed \n 4 Burkina Faso 7596       Completed  Completed  Completed  Completed \n 5 Burkina Faso 7316       Completed  Completed  Completed  Completed \n 6 Burkina Faso 7559       Completed  Completed  Completed  Completed \n 7 Burkina Faso 7989       Completed  Completed  Completed  Completed \n 8 Burkina Faso 7502       Completed  Completed  Partly co… Completed \n 9 Burkina Faso 7506       Completed  Completed  Completed  Completed \n10 Burkina Faso 7837       Completed  Completed  <NA>       <NA>      \n# … with 10,202 more rows\n\nThe variable RESULTSQ\nshows the result of the interview for each round of data collection\n(numbered _1 through _4). Nine of the first\nten facilities were interviewed four times, but the facility numbered\n7837 was only interviewed in rounds 1 and 2. We know that\nthere is no record for that facility in rounds 3 and 4 because\nRESULTSQ\ncontains the value NA.\nEach round of data collection is numbered chronologically, beginning\nwith the earliest round for the cohort. You’ll find the interview year\nfor each round in INTSQYEAR.\n\n\nsdp %>% select(COUNTRY, FACILITYID, starts_with(\"INTSQYEAR\")) \n\n\n# A tibble: 10,212 × 6\n   COUNTRY  FACILITYID INTSQYEAR_1 INTSQYEAR_2 INTSQYEAR_3 INTSQYEAR_4\n   <fct>    <chr+lbl>    <int+lbl>   <int+lbl>   <int+lbl>   <int+lbl>\n 1 Burkina… 7298              2014        2015        2016        2016\n 2 Burkina… 7399              2014        2015        2016        2017\n 3 Burkina… 7627              2014        2015        2016        2016\n 4 Burkina… 7596              2014        2015        2016        2017\n 5 Burkina… 7316              2014        2015        2016        2017\n 6 Burkina… 7559              2014        2015        2016        2017\n 7 Burkina… 7989              2014        2015        2016        2016\n 8 Burkina… 7502              2014        2015        2016        2016\n 9 Burkina… 7506              2014        2015        2016        2016\n10 Burkina… 7837              2014        2015          NA          NA\n# … with 10,202 more rows\n\nIn some cases, the end of one round may occur in the same calendar\nyear as the beginning of a subsequent round. This explains why you see\n2016 in both INTSQYEAR_3 and INTSQYEAR_4.\nThe variable INTSQMON\ngives the month for each interview.\nEach of these ten facilities are members of the same cohort from\nBurkina Faso, representing samples collected between 2014 and early\n2017. IPUMS has created a unique ID for each cohort in the new variable\nSDPCOHORT.\nYou can obtain a count of the\ntotal number of facilities included across all rounds for each\ncohort like so:\n\n\nsdp %>% count(COUNTRY, SDPCOHORT)\n\n\n# A tibble: 26 × 3\n   COUNTRY                    SDPCOHORT     n\n   <fct>                          <dbl> <int>\n 1 Burkina Faso                   85401   160\n 2 Burkina Faso                   85402   149\n 3 Burkina Faso                   85403   247\n 4 Congo, Democratic Republic     18001   547\n 5 Congo, Democratic Republic     18002   382\n 6 Congo, Democratic Republic     18003   234\n 7 Congo, Democratic Republic     18004   427\n 8 Ethiopia                       23101   570\n 9 Ethiopia                       23102   500\n10 Ethiopia                       23103   114\n# … with 16 more rows\n\nOr, you can group_by\nthese variables and use summarise\nto obtain the total number of facilities interviewed for each\nround:\n\n\nsdp %>% \n  group_by(COUNTRY, SDPCOHORT) %>% \n  summarise(across(\n    starts_with(\"RESULTSQ\"), \n    ~sum(!is.na(.x))\n  )) \n\n\n# A tibble: 26 × 6\n# Groups:   COUNTRY [11]\n   COUNTRY       SDPCOHORT RESULTSQ_1 RESULTSQ_2 RESULTSQ_3 RESULTSQ_4\n   <fct>             <dbl>      <int>      <int>      <int>      <int>\n 1 Burkina Faso      85401        106        103        133        131\n 2 Burkina Faso      85402        130         98          0          0\n 3 Burkina Faso      85403        234        244          0          0\n 4 Congo, Democ…     18001        248        245        226          0\n 5 Congo, Democ…     18002        171        175        186          0\n 6 Congo, Democ…     18003        102        115        124          0\n 7 Congo, Democ…     18004        356        375          0          0\n 8 Ethiopia          23101        389        400        440        455\n 9 Ethiopia          23102        442        470          0          0\n10 Ethiopia          23103        111         85          0          0\n# … with 16 more rows\n\nEach cohort contains a maximum of four rounds, but\nsome cohorts contain fewer rounds.\nFor example, the second Burkina Faso cohort 85402 contains\nonly two rounds (sample years 2017-2018).\nIndividual facilities may enter or exit their cohort any number of\ntimes. For example, it is possible that a facility might complete the\nSDP interview once in round one, skip round two, and then re-enter the\nsame cohort again in round three:\n\n\nsdp %>% \n  select(COUNTRY, SDPCOHORT, FACILITYID, starts_with(\"RESULTSQ\")) %>% \n  filter(!is.na(RESULTSQ_1) & is.na(RESULTSQ_2) & !is.na(RESULTSQ_3))\n\n\n# A tibble: 95 × 7\n   COUNTRY       SDPCOHORT FACILITYID RESULTSQ_1 RESULTSQ_2 RESULTSQ_3\n   <fct>             <dbl> <chr+lbl>  <fct>      <fct>      <fct>     \n 1 Burkina Faso      85401 7229       Completed  <NA>       Completed \n 2 Congo, Democ…     18001 5043       Completed  <NA>       Completed \n 3 Congo, Democ…     18001 5082       Completed  <NA>       Completed \n 4 Congo, Democ…     18001 5072       Completed  <NA>       Completed \n 5 Congo, Democ…     18001 5688       Completed  <NA>       Completed \n 6 Congo, Democ…     18001 5355       Completed  <NA>       Completed \n 7 Congo, Democ…     18001 5481       Completed  <NA>       Completed \n 8 Congo, Democ…     18001 5758       Completed  <NA>       Completed \n 9 Congo, Democ…     18001 5649       Completed  <NA>       Completed \n10 Congo, Democ…     18001 5112       Completed  <NA>       Completed \n# … with 85 more rows, and 1 more variable: RESULTSQ_4 <fct>\n\nOpen Design: these facilities were sampled in rounds\none and three. They were not included in round two.\nAlso, a facility may enter the cohort after round one.\n\n\nsdp %>% \n  select(COUNTRY, SDPCOHORT, FACILITYID, starts_with(\"RESULTSQ\")) %>% \n  filter(is.na(RESULTSQ_1) & !is.na(RESULTSQ_2))\n\n\n# A tibble: 1,892 × 7\n   COUNTRY      SDPCOHORT FACILITYID RESULTSQ_1 RESULTSQ_2 RESULTSQ_3\n   <fct>            <dbl> <chr+lbl>  <fct>      <fct>      <fct>     \n 1 Burkina Faso     85401 7256       <NA>       Completed  <NA>      \n 2 Burkina Faso     85401 7133       <NA>       Completed  <NA>      \n 3 Burkina Faso     85402 7840       <NA>       Completed  <NA>      \n 4 Burkina Faso     85402 7523       <NA>       Completed  <NA>      \n 5 Burkina Faso     85402 7941       <NA>       Completed  <NA>      \n 6 Burkina Faso     85402 7434       <NA>       Completed  <NA>      \n 7 Burkina Faso     85402 7786       <NA>       Completed  <NA>      \n 8 Burkina Faso     85402 7280       <NA>       Completed  <NA>      \n 9 Burkina Faso     85402 7135       <NA>       Completed  <NA>      \n10 Burkina Faso     85402 7854       <NA>       Completed  <NA>      \n# … with 1,882 more rows, and 1 more variable: RESULTSQ_4 <fct>\n\nDelayed entry: these facilities were sampled beginning\nin round two. They were not included in round one.\nHowever, each FACILITYID\nappears in only one cohort. In the event that a facility is\nrandomly selected into multiple cohorts, it would receive a new FACILITYID.\nIt is not possible to reliably match these facilities across\ncohorts.\n\n\nsdp %>% \n  group_by(FACILITYID) %>% \n  count(SDPCOHORT) %>% \n  ungroup() %>% \n  count(cohort_appearences = n)\n\n\n# A tibble: 1 × 2\n  cohort_appearences     n\n               <int> <int>\n1                  1 10212\n\n\nEach FACILITYID\nappears in only one SDPCOHORT.\nLastly, users should note that in some instances, the same FACILITYID\nwas listed in a different enumeration area in one or more rounds. This\noccurs in less than 4% of cases across cohorts.\n\n\nsdp %>% \n  select(COUNTRY, SDPCOHORT, FACILITYID, starts_with(\"EAID\")) %>% \n  pivot_longer(starts_with(\"EAID\"), values_to = \"EAID\") %>% \n  group_by(COUNTRY, SDPCOHORT, FACILITYID) %>%\n  summarise(ea_count = n_distinct(EAID, na.rm = TRUE), .groups = \"keep\") %>% \n  ungroup() %>% \n  count(ea_count > 1) %>% \n  mutate(prop = prop.table(n))\n\n\n# A tibble: 2 × 3\n  `ea_count > 1`     n   prop\n  <lgl>          <int>  <dbl>\n1 FALSE           9824 0.962 \n2 TRUE             388 0.0380\n\nMore than 96% of facilities are located in the same EAID\nacross rounds.\nFewer than 4% of facilities switched enumeration areas between rounds.\nData Availability\nWe’ve seen that the value NA is used to represent\nfacilities that were interviewed fewer than four times in the\nsame cohort: if, for example, no interview data exists for round 4, all\nvariables named with the suffix _4 are marked\nNA.\nHowever, there is is second reason why you might see NA\nvalues in a longitudinal data extract. These represent cases where the\nquestion associated with a particular variable was changed or omitted\nbetween rounds. For example, let’s take a look at contraceptive\nstock variable group:\n\n\n\nCertain contraceptive methods are included in every questionnaire\never administered across SDP samples, and every sample includes a\nquestion asking whether certain methods were in-stock and\nobserved by the interviewer. So, you’ll always find the\nfollowing variables available across samples:\nCONOBS\n- male condoms\nEMRGOBS\n- emergency contraception\nFCOBS\n- female condoms\nIMPOBS\n- contraceptive implants\nIUDOBS\n- IUDs\nPILLOBS\n- contraceptive pills\nEvery SDP questionnaire asks whether these six methods were\nin-stock.\nUsually, the interviewer also reported whether they\nobserved the stock. See our comparability\nnote for details.\nHowever, some questionnaires ask about the availability of additional\ncontraceptive methods. As a result, some samples contain additional\nvariables like:\nCYCBOBS\n- Standard Days / Cycle Beads\nDEPOOBS\n- Depo Provera\nDIAOBS\n- diaphragms\nFJOBS\n- contraceptive foam / jelly\nINJ1OBS\n- 1 month injectables\nINJ3OBS\n- 3 month injectables\nMIFEOBS\n- mifepristone\nMISOBS\n- misoprostol\nNTABOBS\n- N-tablets\nOTHEROBS\n- other methods\nPROPILLOBS\n- Progestin pills\nSAYOBS\n- Sayana Press\n\nThese variables are available for some samples, but not others. If not\navailable, they will be labelled NA.\nWhen you download an extract containing multiple samples, these\nvariables will contain NA values for samples that did not\nask about the availability of these additional methods.\nFortunately, in a longitudinal extract you’ll find that the same\nOBS variables are always available for all rounds\nwithin the same cohort. PMA might add or drop contraceptive methods\nfrom the questionnaire administered in a particular country, but\nonly during a redesign period before the selection of a new\ncohort.\nYou’ll can see this for yourself if you count the number of responses\nto all of the OBS variables and compare this to the number\nof facilities that completed all or part of the interview across rounds.\nWe’ll use pivot_longer\nto showcase these counts in separate rows for each round:\n\n\nsdp %>% \n  group_by(COUNTRY, SDPCOHORT) %>% \n  summarise(\n    across(matches(\"OBS\") | matches(\"RESULT\"), ~sum(!is.na(.x))),\n    .groups = \"keep\"\n  ) %>% \n  pivot_longer(\n    -c(COUNTRY, SDPCOHORT),\n    names_pattern = \"(.*)_(.*)\",\n    names_to = c(\".value\", \"ROUND\")\n  ) %>% \n  relocate(RESULTSQ, .after = ROUND) %>% \n  filter(RESULTSQ != 0) \n\n\n# A tibble: 68 × 23\n# Groups:   COUNTRY, SDPCOHORT [26]\n   COUNTRY      SDPCOHORT ROUND RESULTSQ CONOBS CYCBOBS DEPOOBS DIAOBS\n   <fct>            <dbl> <chr>    <int>  <int>   <int>   <int>  <int>\n 1 Burkina Faso     85401 1          106    106     106       0    106\n 2 Burkina Faso     85401 2          103    103     103       0    103\n 3 Burkina Faso     85401 3          133    133     133       0    133\n 4 Burkina Faso     85401 4          131    131     131       0    131\n 5 Burkina Faso     85402 1          130    130     130     130    130\n 6 Burkina Faso     85402 2           98     98      98      98     98\n 7 Burkina Faso     85403 1          234    234     234     234    234\n 8 Burkina Faso     85403 2          244    244     244     244    244\n 9 Congo, Demo…     18001 1          248    248     248       0    248\n10 Congo, Demo…     18001 2          245    245     245       0    245\n# … with 58 more rows, and 15 more variables: EMRGOBS <int>,\n#   FCOBS <int>, FJOBS <int>, IMPOBS <int>, INJOBS <int>,\n#   INJ1OBS <int>, INJ3OBS <int>, IUDOBS <int>, NTABOBS <int>,\n#   OTHEROBS <int>, PILLOBS <int>, PROPILLOBS <int>, SAYOBS <int>,\n#   MIFEOBS <int>, MISOBS <int>\n\nAgain, let’s focus our attention on the first cohort numbered\n85401 from Burkina Faso, which includes data collected in\nfour rounds. In the first round, 106 facilities completed all or part of\nthe questionnaire (RESULTSQ),\nand every one of those facilities answered a question about\ncontraceptive stock. That question included male condoms (CONOBS),\nbeads (CYCBOBS),\ndiaphragms (DEPOOBS),\nand more. However, it did not ask about Depo Provera, which is why DEPOOBS\nshows zero non-NA values.\nMoving downward, you see that DEPOOBS\nshows zero non-NA values in every round for cohort\n85401. That’s because the associated question was not\nmodified until the redesign period following round four.\nThen, a new cohort numbered 85402 was drawn from a new\nset of enumeration areas, and the questionnaire was adjusted to include\nDepo Provera. No further adjustments were made after round one was\ncompleted for cohort 85402: Depo Provera appears again in\nthe second and final round.\nIf you were to continue exploring this table, you would find that the\nvalue 0 appears consistently for all variables in all\nrounds for any given cohort.\nApplications\nIn the coming weeks, we’ll continue exploring longitudinal SDP data\nas a way to understand how facilities adapt in response to shifting\nmarkets, policies, and even climate conditions. However, we urge users\nto remember that SDP surveys are not collected through\nrandom sampling: they should not be used to estimate population-level\nstatistics for health service providers on a national or sub-national\nscale.\nInstead, we’ll show how to use SDP data as contextual information for\nwomen and households sampled in PMA family planning surveys. That’s\nbecause SDP samples are constructed to include up to three public-sector\nand three private-sector facilities serving each enumeration area\nincluded in a contemporaneous family planning sample. SDP data are\nintended to represent the health service environment experienced by the\nwomen included in these samples.\nNew CEI data\nCEI surveys are a relatively new addition to PMA, so you’ll find\nsamples available from 2020 onward. They represent interviews with\nactual clients visiting facilities included in a contemporaneous SDP\nsample. These clients are women from the community who sought family\nplanning services or products at the facility during a two-day data\ncollection period.\n\nCheck out our complete introduction to CEI\nsurveys published earlier this year.\nThis data release includes CEI samples corresponding with many of the\nsame SDP samples we mentioned above:\nCountry\nSDP Data Collection\nCEI Data Collection\nBurkina Faso\nFeb 2021 - Mar 2021\nFeb 2021 - Mar 2021\nCote d’Ivoire\nOct 2020 - Nov 2020\nOct 2020 - Nov 2020\nDRC (Kinshasa & Kongo Central)\nJan 2021 - Mar 2021\nFeb 2021 - Mar 2021\nEthiopia\nNov 2020 - Jan 2021\n–\nIndia (Rajasthan)\nAug 2020 - Nov 2020\n–\nKenya\nNov 2020 - Feb 2021\nDec 2020 - Mar 2021\nNigeria (Kano & Lagos)\nDec 2020 - Jan 2021\nDec 2020 - Jan 2021\nUganda\nSep 2020 - Oct 2020\n–\nYou’ll find CEI data on the IPUMS PMA website if select\nClient Exit Interview in the unit\nof analysis menu.\n\n\n\nFor now, CEI surveys are only available in cross-sectional format.\nHowever, we’ll demonstrate how to link them together with longitudinal\nSDP data in an upcoming post.\n\n\n\nAs we’ll see in the coming weeks, CEI surveys offer an important way\nto measure whether and how facilities meet family planning needs for\nwomen in the communities they serve. In turn, both surveys help to\ndescribe the health service environment experienced by women in FP\nsurveys, including those participating the new PMA panel study we’ve been\ndescribing in our most recent series on this blog. We’ll be focusing\nmuch more on ways to integrate all three of these surveys together\nthroughout this summer.\n\nAlternatively, you may request an\nextract containing “All Cases”, which includes records for facilities\nwhere SDP respondent declined or was unable to complete all or part of\nthe interview.↩︎\n",
    "preview": "posts/2022-06-01-sdp-panel-release/../../images/new_data.png",
    "last_modified": "2022-06-03T13:37:49-04:00",
    "input_file": {},
    "preview_width": 2555,
    "preview_height": 1437
  },
  {
    "path": "posts/2022-05-15-phase2-calendar/",
    "title": "Contraceptive Calendar Data in PMA Panel Surveys",
    "description": "PMA panel members report their contraceptive use, reasons for discontinuation, and pregnancy status for each month leading up to the Female Questionnaire. Here's how to get up and running with your first Time-to-Event analysis.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-05-15",
    "categories": [
      "Panel Data",
      "Contraceptive Calendar",
      "Data Analysis",
      "Survival Analysis",
      "survival",
      "ggplot2"
    ],
    "contents": "\n\nContents\nSetup\nCentury Month Codes (CMC)\nMerging Country Calendars\nStart\nand Stop Dates\nPivot Country Calendars\n\nData\nAvailability\nSplitting months into\ncolumns\nAnalysis\n\n\n\n\nWe’re wrapping up our introduction to the new PMA Panel Surveys this\nweek with an update to a topic we first introduced one year ago when IPUMS PMA released Phase 1 data\nfrom Burkina Faso, DRC, Kenya, and Nigeria. With the release of Phase 2\ndata from these countries this spring, it’s now possible to combine\nmonthly contraceptive\ncalendar data collected at multiple timepoints, each covering\npartially overlapping periods in the reproductive health history of\nevery panel member.\nThe contraceptive calendar data are particularly exciting because\nthey offer researchers an opportunity to explore longitudinal analysis\ntechniques that are otherwise not feasible with the first two phases of\npanel observations. For example, we’ll demonstrate how you might use survival analysis to\ntest whether women with unmet\nneed or plans\nto adopt a family planning method at Phase 1 were quicker to begin\nusing one in the months between Phase 1 and Phase 2. Additionally,\nbecause calendar data are collected once per phase, there are\nunique opportunities to study the reliability of self-reporting for the\nsame month recalled at different times (Anglewicz et al. 2022).\n\nNewcomers to the contraceptive calendar should check\nout our previous blog post,\nincluding video from a workshop from the 2021\nPopulation Association of America annual meeting.\nIn this post, we’ll share code you can use to parse and analyze\ncalendar data collected in each phase in a data extract containing\nmultiple samples. We’ll use the survival package for R\nto model “time-to-event” for adoption of a family planning method for\nwomen who were not using one on the day of the Phase 1 interview.\nFinally, we’ll use ggplot2 to build a\nKaplan-Meier curve for the cumulative incidence of adoption over each\nmonth between the Phase 1 and Phase 2 interviews.\nSetup\nOver on the contraceptive calendar variable\ngroup page, you’ll find two types of calendars for every sample:\n\n\n\nWe refer to the main calendar as the “contraceptive calendar”, and it\nincludes the following variables:\nCALENDARBF\nCALENDARCD\nCALENDARKE\nCALENDARNG\nThis calendar represents contraceptive use, pregnancy, pregnancy\ntermination, and birth information for each month preceding the\ninterview for the Female Questionnaire in a particular phase of the\npanel study. Women are asked to recall their status for each month in\nthe calendar period, and their responses are recorded in a single comma\ndelimited string with the following codes:\nB - Birth\nP - Pregnant\nT - Pregnancy ended\n0 - No family planning method used\n1 - Female Sterilization\n2 - Male Sterilization\n3 - Implant\n4 - IUD\n5 - Injectables\n7 - Pill\n8 - Emergency Contraception\n9 - Male Condom\n10 - Female Condom\n11 - Diaphragm\n12 - Foam / Jelly\n13 - Standard Days / Cycle beads\n14 - LAM\n30 - Rhythm method\n31 - Withdrawal\n39 - Other traditional methods\nThe second calendar is the “discontinuation calendar”, and it gives\nthe reason why a woman stopped using a family planning method for each\nmonth following an episode of continuous use. This calendar is\nrepresented by the following variables:\nCALENDARBFWHY\nCALENDARCDWHY\nCALENDARKEWHY\nCALENDARNGWHY\nLike the main contraceptive calendar, the discontinuation calendar is\na single comma delimited string. It contains the following codes for\nmonths when a method was discontinued (and is blank otherwise):\n1 - Infrequent sex / husband away\n2 - Became pregnant while using\n3 - Wanted to become pregnant\n4 - Husband / partner disapproved\n5 - Wanted more effective method\n6 - Side effects / health concerns\n7 - Lack of access / too far\n8 - Costs too much\n9 - Inconvenient to use\n10 - Up to God / fatalistic\n11 - Difficult to get pregnant / menopausal\n12 - Marital dissolution / separation\n96 - Other\nWe’ve created a data extract containing all of the eight calendar\nvariables, plus these additional variables that we’ll need for our\nanalysis:\nRESULTFQ\n- Result of female questionnaire\nFQINSTID\n- Unique ID for female questionnaire\nRESIDENT\n- Household residence / membership\nCOUNTRY\n- Country of residence\nINTFQMON\n& INTFQYEAR\n- Date of Female Questionnaire interview\nFPCURREFFMETHRC\n- Most effective current family planning method (recoded1)\nPREGNANT\n- Current pregnancy status\nUNMETYN\n- Total unmet need\nFPPLANVAL\n- When will start using FP method in the future - value\nFPPLANWHEN\n- When will start using FP method in the future - unit\nKID1STBIRTHMO\n& KID1STBIRTHYR\n- Date of first childbirth\nLASTBIRTHMO\n& LASTBIRTHYR\n- Date of most recent childbirth\nPANELBIRTHMO\n& PANELBIRTHYR\n- Date of childbirth during the panel study\nOTHERBIRTHMO\n& OTHERBIRTHYR\n- Date of any other childbirth during the calendar period\nPREGENDMO\n& PREGENDYR\n- Date of most recent pregnancy termination (miscarriage, abortion, or\nstillbirth)\nPANELPREGENDMO\n& PANELPREGENDYR\n- Date of pregnancy termination during the panel study (miscarriage,\nabortion, or stillbirth)\nFPBEGINUSEMO\n& FPBEGINUSEYR\n- Date of adoption for currently used family planning method\nOur extract contains data from all available longitudinal samples.2 As in previous posts, we’ve\nselected “Female Respondents” organized in wide format: each\nrow represents the Phase 1 and Phase 2 responses for\none female respondent. Variables from the Phase 1\nquestionnaire are named with the suffix _1\n(e.g. CALENDARKE_1), while variables from the Phase 2\nquestionnaire are named with the suffix _2\n(e.g. CALENDARKE_2).\nWe’ll load the data extract into R together with each of the packages\nwe’ll feature in this post. Then, we’ll drop cases for women who did not\nfully complete the Female Questionnaire or were not members of the\nde facto population in both phases.\nFinally, we’ll modify two variables to make this post a bit easier to\nread. First, we’ll transform COUNTRY\ninto a factor\ncontaining a two-letter ISO country code for each sample.3\nSecond, we’ll generate a short ID for each woman based on her location\nin the dataframe: this is for display purposes only -\nwe recommend that users adopt FQINSTID\nfor their own analyses.\n\nNote: there are two regionally representative samples each from DRC and\nNigeria. We’ll combine samples from the same country here, as both use\nthe same variables for the contraceptive calendar.\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\nlibrary(survival)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00111.xml\",\n  data = \"data/pma_00111.dat.gz\"\n) \n\ndat <- dat %>% \n  filter(\n    RESULTFQ_1 == 1 & RESULTFQ_2 == 1, \n    RESIDENT_1 %in% c(11, 22) & \n      RESIDENT_2 %in% c(11, 22)\n  ) %>% \n  mutate(COUNTRY = COUNTRY %>% as_factor %>% recode(\n    \"Burkina Faso\" = \"BF\",\n    \"Congo, Democratic Republic\" = \"CD\",\n    \"Kenya\" = \"KE\",\n    \"Nigeria\" = \"NG\"\n  )) %>% \n  rowid_to_column(\"ID\")\n\n\n\n\n\n\n\n© Terry M. Therneau et al. (LGPL >=2)\n\n\n\n\n\nCentury Month Codes (CMC)\nAs shown above, we’ll be referencing several variables representing\ndates in this post. Generally, IPUMS PMA publishes\nevery date with two variables: one representing the month (e.g. INTFQMON)\nand one representing the year (e.g. INTFQYEAR).\nSometimes, you’ll notice a third variable representing dates with a\ncentury month code (CMC): each CMC represents the\nnumber of months that have passed between a given date and January 1900.\nCMC dates are particularly useful for calculating the time between\nevents because they replace two variables (with different units) with\none simple integer.\nSome CMC variables are available directly from IPUMS PMA (e.g. INTFQCMC),\nbut we’ll create our own CMC variables for all of the dates we’ll\nreference in this post. CMC dates are simply calculated as follows:\n\\[CMC = Month + 12*(Year –\n1900)\\]\nBecause all or part of a date may be missing (the\nmonth or year), and because certain dates may be NIU (not in\nuniverse) (e.g. “date of most recent childbirth” for women who\nhave never given birth), we’ll need to consider specific circumstances\nwhere we should use the value NA in a CMC variable.\nIn the contraceptive calendar, we’ll be measuring the time between\nevents in months. Therefore, it would be insufficient to\ninclude cases where a woman only reported the year in which an\nevent occurred. We’ll create a function that generates NA\nvalues if the numeric code representing a month is 90 or\nhigher (all valid months are coded 1 through 12), and if a year is\n9000 or higher (all valid years are in the 1900s or 2000s).\nOtherwise, we’ll use the CMC formula to calculate the appropriate CMC\nvalue for each date.\n\nLet’s call this function make_cmc:\n\n\nmake_cmc <- function(mo, yr){\n  case_when(mo < 90 & yr < 9000 ~ mo + 12*(yr - 1900))\n}\n\n\n\n\n\nWith case_when,\nany “case” not explicitly covered by\nmo < 90 & yr < 9000 is assigned the value\nNA.\nYou can apply make_cmc to any combination of variables\nrepresenting the month and year for a date. We’ll create one\nCMC for each date in our data extract.\n\n\ndat <- dat %>% \n  mutate(\n    INTFQCMC_1 = make_cmc(INTFQMON_1, INTFQYEAR_1),\n    INTFQCMC_2 = make_cmc(INTFQMON_2, INTFQYEAR_2),\n    KID1STBIRTHCMC_1 = make_cmc(KID1STBIRTHMO_1, KID1STBIRTHYR_1),\n    KID1STBIRTHCMC_2 = make_cmc(KID1STBIRTHMO_2, KID1STBIRTHYR_2),\n    LASTBIRTHCMC_1 = make_cmc(LASTBIRTHMO_1, LASTBIRTHYR_1),\n    LASTBIRTHCMC_2 = make_cmc(LASTBIRTHMO_2, LASTBIRTHYR_2),\n    OTHERBIRTHCMC_1 = make_cmc(OTHERBIRTHMO_1, OTHERBIRTHYR_1),\n    OTHERBIRTHCMC_2 = make_cmc(OTHERBIRTHMO_2, OTHERBIRTHYR_2),\n    PANELBIRTHCMC_1 = make_cmc(PANELBIRTHMO_1, PANELBIRTHYR_1),\n    PANELBIRTHCMC_2 = make_cmc(PANELBIRTHMO_2, PANELBIRTHYR_2),\n    PREGENDCMC_1 = make_cmc(PREGENDMO_1, PREGENDYR_1),\n    PREGENDCMC_2 = make_cmc(PREGENDMO_2, PREGENDYR_2),\n    PANELPREGENDCMC_1 = make_cmc(PANELPREGENDMO_1, PANELPREGENDYR_1),\n    PANELPREGENDCMC_2 = make_cmc(PANELPREGENDMO_2, PANELPREGENDYR_2),\n    FPBEGINUSECMC_1 = make_cmc(FPBEGINUSEMO_1, FPBEGINUSEYR_1),\n    FPBEGINUSECMC_2 = make_cmc(FPBEGINUSEMO_2, FPBEGINUSEYR_2)\n  ) \n\n\n\nLet’s check our work. For example, consider how we’ve handled\nPANELBIRTHCMC_2 - the date of a woman’s childbirth that\nhappened during the panel study. If we count the dates by\nPANELBIRTHMO_2 and use tail to examine the last\nfew rows, we see that one woman reported code 97 indicating\nthat she did not know the precise month of birth. Meanwhile, there were\n15,064 cases coded 99 indicating that they were NIU\n(not in universe) (no birth occurred during the panel study).\nWe’ve coded both of these case types with the value NA; all\nother values follow the CMC formula to count the number of months\nbetween January 1900 and the month of birth.\n\n\ndat %>% \n  count(PANELBIRTHMO_2, PANELBIRTHYR_2, PANELBIRTHCMC_2) %>% \n  tail()\n\n\n# A tibble: 6 × 4\n              PANELBIRTHMO_2               PANELBIRTHYR_2 PANELBIRTHCMC_2     n\n                   <int+lbl>                    <int+lbl>           <dbl> <int>\n1 12 [December]              2017                                    1416     1\n2 12 [December]              2018                                    1428    13\n3 12 [December]              2019                                    1440    99\n4 12 [December]              2020                                    1452    90\n5 97 [Don't know]            2017                                      NA     1\n6 99 [NIU (not in universe)] 9999 [NIU (not in universe)]              NA 15064\n\nMerging Country Calendars\nYou may be wondering: why does IPUMS PMA publish a separate calendar\nvariable for each country?\nIn fact, the width of each calendar variable differs by the number of\nmonths women were asked to recall in a particular sample. This, in turn,\ndepends on the range of dates in which women were interviewed for the\nFemale Questionnaire in a particular phase.\nStart and Stop Dates\nYou can find the precise range of dates included in each calendar on\nthe description\ntab for each country’s calendar variable.\n\n\n\nThe first month in each country’s calendar is listed below:\nCountry\nPhase 1\nPhase 2\nBurkina Faso\nJan 2018\nJan 2018\nDRC\nJan 2017\nJan 2018\nKenya\nJan 2017\nJan 2018\nNigeria\nJan 2017\nJan 2018\nBefore we can merge calendars for multiple samples, we’ll need to\ndetermine the correct beginning and ending points for each woman’s\ncalendar. First, we’ll create CALSTART_1 and\nCALSTART_2 to record the CMC date for the first month.\n\n\ndat <- dat %>% \n  mutate(\n    CALSTART_1 = if_else(COUNTRY == \"BF\", 2018, 2017),\n    CALSTART_2 = 2018,\n    across(c(CALSTART_1, CALSTART_2), ~12*(.x - 1900) + 1)\n  ) \n\n\n\nNext, we’ll create CALSTOP_1 and CALSTOP_2\nto record the CMC date we created in INTFQCMC_1 and\nINTFQCMC_2. These dates cover a range of months in each\nsample.\nCountry\nPhase 1\nPhase 2\nBurkina Faso\nDec 2019 - Mar 2020\nDec 2020 - Apr 2021\nDRC\nDec 2019 - Feb 2020\nDec 2020 - Mar 2021\nKenya\nNov 2019 - Dec 2019\nNov 2020 - Dec 2020\nNigeria\nDec 2019 - Jan 2020\nDec 2020 - Feb 2021\n\n\ndat <- dat %>% \n  mutate(\n    CALSTOP_1 = INTFQCMC_1,\n    CALSTOP_2 = INTFQCMC_2\n  )\n\n\n\nNow, let’s take a look at the calendar variables we want to merge.\nYou’ll only find responses in the calendar for the country in which a\nwoman resides. The other calendars in her row will appear as an empty\ncharacter string, the value \"\". For example, notice that\nthe variable CALENDARKE_1 is blank for these women from\nBurkina Faso:\n\n\ndat %>% \n  filter(COUNTRY == \"BF\") %>% \n  select(ID, COUNTRY, CALENDARBF_1, CALENDARKE_1)\n\n\n# A tibble: 5,208 × 4\n      ID COUNTRY CALENDARBF_1                                       CALENDARKE_1\n   <int> <fct>   <chr+lbl>                                          <chr+lbl>   \n 1     1 BF      ,,,,,,,,,,0,0,0,0,0,0,0,0,0,0,0,0,B,P,P,P,P,P,P,P… \"\"          \n 2     2 BF      ,,,,,,,,,,,P,P,P,P,P,P,P,0,0,0,0,0,0,0,3,3,3,3,3,… \"\"          \n 3     3 BF      ,,,,,,,,,,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,… \"\"          \n 4     4 BF      ,,,,,,,,,,,0,0,0,5,5,5,5,5,5,5,5,5,5,5,0,0,0,0,0,… \"\"          \n 5     5 BF      ,,,,,,,,,,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,… \"\"          \n 6     6 BF      ,,,,,,,,,,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,… \"\"          \n 7     7 BF      ,,,,,,,,,,,0,0,0,0,0,0,0,0,0,0,0,0,0,T,P,P,P,P,P,… \"\"          \n 8     8 BF      ,,,,,,,,,,,B,P,P,P,P,P,P,P,P,P,0,0,0,0,0,0,0,0,0,… \"\"          \n 9     9 BF      ,,,,,,,,,,,,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3… \"\"          \n10    10 BF      ,,,,,,,,,,,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,… \"\"          \n# … with 5,198 more rows\n\nPivot Country Calendars\nWe’ll want to use pivot_longer\nto reformat dat so that each calendar variable appears\nin a separate row, including calendars collected in different\nphases of the panel study. Let’s call our reformatted data frame\ncals. For now, it will only include ID,\nCOUNTRY, and all variables that start with\nCAL.\n\n\ncals <- dat %>% select(ID, COUNTRY, starts_with(\"CAL\"))\n\n\n\nWe’ll “pivot” cals in two steps. First, we’ll strip the\nnumeric suffix from each calendar variable: we’ll store this information\nin a new column called PHASE. All of the calendar variables\nfrom the same phase will then be stored in a separate row (resulting in\ntwo rows per woman).\n\n\ncals <- cals %>% \n  pivot_longer(\n    cols = starts_with(\"CAL\"),\n    names_pattern = \"(.*)_(.*)\",\n    names_to = c(\".value\", \"PHASE\")\n  )\n\n\n\n\n\n\n\n\ncals \n\n\n# A tibble: 35,424 × 13\n      ID COUNTRY PHASE CALENDARBF         CALENDARBFWHY CALENDARKE CALENDARKEWHY\n   <int> <fct>   <chr> <chr+lbl>          <chr+lbl>     <chr+lbl>  <chr+lbl>    \n 1     1 BF      1     \",,,,,,,,,,0,0,0,… \",,,,,,,,,,,… \"\"         \"\"           \n 2     1 BF      2     \",,,,,,,,,,,3,3,3… \",,,,,,,,,,,… \"\"         \"\"           \n 3     2 BF      1     \",,,,,,,,,,,P,P,P… \",,,,,,,,,,,… \"\"         \"\"           \n 4     2 BF      2     \",,,,,,,,,,,,5,5,… \",,,,,,,,,,,… \"\"         \"\"           \n 5     3 BF      1     \",,,,,,,,,,,0,0,0… \"\"            \"\"         \"\"           \n 6     3 BF      2     \"\"                 \"\"            \"\"         \"\"           \n 7     4 BF      1     \",,,,,,,,,,,0,0,0… \",,,,,,,,,,,… \"\"         \"\"           \n 8     4 BF      2     \",,,,,,,,,,,,0,0,… \",,,,,,,,,,,… \"\"         \"\"           \n 9     5 BF      1     \",,,,,,,,,,,0,0,0… \",,,,,,,,,,,… \"\"         \"\"           \n10     5 BF      2     \"\"                 \"\"            \"\"         \"\"           \n# … with 35,414 more rows, and 6 more variables: CALENDARNG <chr+lbl>,\n#   CALENDARNGWHY <chr+lbl>, CALENDARCD <chr+lbl>, CALENDARCDWHY <chr+lbl>,\n#   CALSTART <dbl>, CALSTOP <dbl>\n\nBefore we “pivot” a second time, we’ll want to identify suffixes that\nwe can again strip and use as new column names (just as we did with\n_1 and _2 when we created PHASE).\nLet’s use FPSTATUS for the main contraceptive calendar, and\nWHYSTOP for the discontinuation calendar. When we pivot_longer\nagain, these suffixes will appear as two new columns containing each\ntype of calendar.\n\n\ncals <- cals %>% \n  rename_with(\n    ~paste0(.x, \"FPSTATUS\"),\n    .cols = starts_with(\"CALENDAR\") & !ends_with(\"WHY\")\n  ) %>% \n  rename_with(\n    ~paste0(.x, \"STOP\"),\n    .cols = starts_with(\"CALENDAR\") & ends_with(\"WHY\")\n  ) %>% \n  pivot_longer(\n    cols = starts_with(\"CALENDAR\"),\n    names_pattern = \"CALENDAR(..)(.*)\",\n    names_to = c(\"COUNTRY_CAL\", \".value\"),\n    values_to = \"CALENDAR_STRING\"\n  )\n\n\n\nNow, each woman occupies eight rows (4 country calendars per phase).\nWe’ve also stripped the 2-letter country code from each calendar name to\ncreate COUNTRY_CAL: this indicates the country associated\nwith each calendar.\n\n\ncals \n\n\n# A tibble: 141,696 × 8\n      ID COUNTRY PHASE CALSTART CALSTOP COUNTRY_CAL FPSTATUS             WHYSTOP\n   <int> <fct>   <chr>    <dbl>   <dbl> <chr>       <chr+lbl>            <chr+l>\n 1     1 BF      1         1417    1442 BF          \",,,,,,,,,,0,0,0,0,… \",,,,,…\n 2     1 BF      1         1417    1442 KE          \"\"                   \"\"     \n 3     1 BF      1         1417    1442 NG          \"\"                   \"\"     \n 4     1 BF      1         1417    1442 CD          \"\"                   \"\"     \n 5     1 BF      2         1417    1453 BF          \",,,,,,,,,,,3,3,3,3… \",,,,,…\n 6     1 BF      2         1417    1453 KE          \"\"                   \"\"     \n 7     1 BF      2         1417    1453 NG          \"\"                   \"\"     \n 8     1 BF      2         1417    1453 CD          \"\"                   \"\"     \n 9     2 BF      1         1417    1441 BF          \",,,,,,,,,,,P,P,P,P… \",,,,,…\n10     2 BF      1         1417    1441 KE          \"\"                   \"\"     \n# … with 141,686 more rows\n\nLastly, we can drop any row where COUNTRY does not match\nthe value in COUNTRY_CAL:\n\n\ncals <- cals %>% \n  filter(COUNTRY_CAL == COUNTRY) %>% \n  select(-COUNTRY_CAL)\n\ncals \n\n\n# A tibble: 35,424 × 7\n      ID COUNTRY PHASE CALSTART CALSTOP FPSTATUS                         WHYSTOP\n   <int> <fct>   <chr>    <dbl>   <dbl> <chr+lbl>                        <chr+l>\n 1     1 BF      1         1417    1442 \",,,,,,,,,,0,0,0,0,0,0,0,0,0,0,… \",,,,,…\n 2     1 BF      2         1417    1453 \",,,,,,,,,,,3,3,3,3,3,3,0,0,0,0… \",,,,,…\n 3     2 BF      1         1417    1441 \",,,,,,,,,,,P,P,P,P,P,P,P,0,0,0… \",,,,,…\n 4     2 BF      2         1417    1453 \",,,,,,,,,,,,5,5,5,5,5,5,5,5,5,… \",,,,,…\n 5     3 BF      1         1417    1441 \",,,,,,,,,,,0,0,0,0,0,0,0,0,0,0… \"\"     \n 6     3 BF      2         1417    1453 \"\"                               \"\"     \n 7     4 BF      1         1417    1441 \",,,,,,,,,,,0,0,0,5,5,5,5,5,5,5… \",,,,,…\n 8     4 BF      2         1417    1452 \",,,,,,,,,,,,0,0,0,0,0,0,0,0,0,… \",,,,,…\n 9     5 BF      1         1417    1441 \",,,,,,,,,,,0,0,0,0,0,0,0,0,0,0… \",,,,,…\n10     5 BF      2         1417    1453 \"\"                               \"\"     \n# … with 35,414 more rows\n\nWe’re nearly ready to split each string into more usable variables\nfor our analysis. But, before we do so: you might notice that there are\nstill some calendars represented by empty character strings\n\"\" (see FPSTATUS in rows 6 and 10 above).\nThese are cases where calendar data are not available.\nData Availability\nThere are two reasons why a woman’s calendar might be\nunavailable.\nFirst, these women might be NIU (not in universe),\nas described on the IPUMS PMA universe\ntab for each country’s contraceptive calendar. Generally, NIU cases\nare women who reported no qualifying event during the calendar period: a\nblank string could indicate that she was never pregnant and never\nadopted or discontinued a family planning method in any month during\nthat period.\n\n\n\n\nThe universe tab explains why some cases are\nNIU (not in universe).\nSecond, a blank might reflect missing data, like the\nduration of a pregnancy or an episode of continuous contraceptive use.\nContraceptive calendars do not contain missing values for\nindividual months, so you’ll find the complete calendar missing\nif data from any one month was missing.\nCurrently, about 1 in every 5 calendars is blank \"\" for\none of these two reasons.\n\n\ncals %>% count(FPSTATUS == \"\") %>% mutate(prop = prop.table(n))\n\n\n# A tibble: 2 × 3\n  `FPSTATUS == \"\"`     n  prop\n  <lgl>            <int> <dbl>\n1 FALSE            28153 0.795\n2 TRUE              7271 0.205\n\nIn some research applications, you might want to complete the empty\ncalendars for women who were NIU. For example: if a woman used the\ncontraceptive pill from the beginning of the calendar period\ncontinuously through the day of the interview, her calendar is currently\nblank because she did not adopt or discontinue using the pill in that\ntime span. You might want to fill her calendar with the value\n7 repeated once for every month between\nCALSTART and CALSTOP.\nSimilarly, we can complete all calendars for women who never used a\nfamily planning method and were never pregnant during the calendar\nperiod: in this case, we’ll repeat the value 0.\nNote, however, that it is not possible to complete calendars\nfor women who experienced birth or pregnancy termination during the\ncalendar period. If these calendars are blank, we cannot determine the\nduration of the pregnancy or whether any family planning method was used\nprior to the pregnancy. We’ll flag these cases with a new variable we’ll\ncall CALMISSING.\nWe’ll begin by attaching all of the CMC variables we\ncreated above (except INTFQCMC) along with the variables PREGNANT\nand FPCURREFFMETHRC.\nIn order to match the format of cals, we’ll again use pivot_longer\nto create separate rows for the dates collected from each\nPHASE.\n\n\ncals <- dat %>% \n  select(\n    ID, matches(\"CMC\") & !matches(\"INTFQ\"),\n    starts_with(\"PREGNANT\"), starts_with(\"FPCURREFFMETHRC\"),\n  ) %>% \n  pivot_longer(\n    !ID,\n    names_pattern = \"(.*)_(.*)\",\n    names_to = c(\".value\", \"PHASE\")\n  ) %>% \n  full_join(cals, by = c(\"ID\", \"PHASE\"))\n\ncals \n\n\n# A tibble: 35,424 × 16\n      ID PHASE KID1STBIRTHCMC FPBEGINUSECMC LASTBIRTHCMC OTHERBIRTHCMC\n   <int> <chr>          <dbl>         <dbl>        <dbl>         <dbl>\n 1     1 1               1314            NA         1430            NA\n 2     1 2               1314          1448         1430          1430\n 3     2 1                 NA            NA         1390            NA\n 4     2 2                 NA          1444         1443            NA\n 5     3 1                 NA            NA           NA            NA\n 6     3 2                 NA            NA           NA            NA\n 7     4 1               1324          1428         1406            NA\n 8     4 2               1324            NA         1406            NA\n 9     5 1               1366            NA         1422            NA\n10     5 2               1366            NA         1422            NA\n# … with 35,414 more rows, and 10 more variables: PANELBIRTHCMC <dbl>,\n#   PREGENDCMC <dbl>, PANELPREGENDCMC <dbl>, PREGNANT <int+lbl>,\n#   FPCURREFFMETHRC <int+lbl>, COUNTRY <fct>, CALSTART <dbl>, CALSTOP <dbl>,\n#   FPSTATUS <chr+lbl>, WHYSTOP <chr+lbl>\n\nNow, we’ll create CALMISSING to indicate whether women\nwith an empty value \"\" in FPSTATUS were\nactually pregnant or adopted a family planning method at some\npoint during the calendar period. In other words: we’ll test whether any\none of our CMC variables shows an event that occurred after\nCALSTART, but is not recorded in FPSTATUS.\nLikewise, this check will determine whether any such women are\ncurrently pregnant.\n\n\ncals <- cals %>% \n  mutate(\n    .after = PHASE,\n    CALMISSING = FPSTATUS == \"\" & WHYSTOP == \"\" & {\n      PREGNANT == 1 | if_any(ends_with(\"CMC\"), ~!is.na(.x) & .x >= CALSTART)\n    }\n  ) %>% \n  relocate(CALSTART, .after = CALMISSING)\n\ncals \n\n\n# A tibble: 35,424 × 17\n      ID PHASE CALMISSING CALSTART KID1STBIRTHCMC FPBEGINUSECMC LASTBIRTHCMC\n   <int> <chr> <lgl>         <dbl>          <dbl>         <dbl>        <dbl>\n 1     1 1     FALSE          1417           1314            NA         1430\n 2     1 2     FALSE          1417           1314          1448         1430\n 3     2 1     FALSE          1417             NA            NA         1390\n 4     2 2     FALSE          1417             NA          1444         1443\n 5     3 1     FALSE          1417             NA            NA           NA\n 6     3 2     FALSE          1417             NA            NA           NA\n 7     4 1     FALSE          1417           1324          1428         1406\n 8     4 2     FALSE          1417           1324            NA         1406\n 9     5 1     FALSE          1417           1366            NA         1422\n10     5 2     TRUE           1417           1366            NA         1422\n# … with 35,414 more rows, and 10 more variables: OTHERBIRTHCMC <dbl>,\n#   PANELBIRTHCMC <dbl>, PREGENDCMC <dbl>, PANELPREGENDCMC <dbl>,\n#   PREGNANT <int+lbl>, FPCURREFFMETHRC <int+lbl>, COUNTRY <fct>,\n#   CALSTOP <dbl>, FPSTATUS <chr+lbl>, WHYSTOP <chr+lbl>\n\nYou can see in this output, for example, that the woman in row 10\n(ID == 5 and PHASE == 2) should have a\ncalendar starting in month 1417. She tells us in\nLASTBIRTHCMC that she gave birth in month\n1422, 5 months after the calendar period began, but the\nstring we would expect to find in FPSTATUS is blank. We\nhave flagged this row with CALMISSING because we won’t be\nable to reconstruct her FPSTATUS calendar without knowing\nexactly when she became pregnant for this birth, or whether she was\nusing a family planning method in any month prior.\nOn the other hand, women with blank FPSTATUS calendars\nwho were not flagged with CALMISSING have not\ngiven birth or switched family planning methods during the calendar\nperiod. We can assume that they have held their current status between\nCALSTART and CALSTOP.\nPrior to this procedure, 1 in 5 rows in cals contained\nan empty FPSTATUS calendar. With help from\nCALMISSING, we’ll now be able to reduce the proportion of\nempty calendars to less than 1 in 20.\n\n\ncals %>% count(CALMISSING, FPSTATUS == \"\") %>% mutate(prop = prop.table(n))\n\n\n# A tibble: 3 × 4\n  CALMISSING `FPSTATUS == \"\"`     n   prop\n  <lgl>      <lgl>            <int>  <dbl>\n1 FALSE      FALSE            28153 0.795 \n2 FALSE      TRUE              5811 0.164 \n3 TRUE       TRUE              1460 0.0412\n\nWe’ll now complete the blank calendars for women who were not flagged\nby CALMISSING. First, we’ll recode\nFPCURREFFMETHRC to match the values used in the\ncalendar:\n\n\ncals <- cals %>% \n  mutate(\n    FPCURREFFMETHRC = FPCURREFFMETHRC %>% \n      zap_labels() %>% \n      # NA if \"No response or missing\" (1 case)\n      na_if(998) %>%\n      # Note: 5 is used twice, and 6 is not used \n      recode(\n        \"999\" = 0, \"101\" = 1, \"102\" = 2, \"111\" = 3, \"112\" = 4, \"121\" = 5,\n        \"123\" = 5, \"131\" = 7, \"132\" = 8, \"141\" = 9, \"142\" = 10, \"151\" = 11, \n        \"152\" = 12, \"160\" = 13, \"170\" = 14, \"210\" = 30, \"220\" = 31, \"240\" = 39\n      )\n  ) \n\n\n\nThen, we’ll create CALDUR to calculate the duration (in\nmonths) of each woman’s calendar.\n\n\ncals <- cals %>% mutate(CALDUR = CALSTOP - CALSTART + 1)\n\n\n\nFinally, we’ll complete each empty string in FPSTATUS\nfor women not flagged by CALMISSING (leaving it the same\notherwise). To clean-up, we’ll also drop any variables that are no\nlonger needed.\n\n\ncals <- cals %>% \n  mutate(FPSTATUS = if_else(\n    # If `FPSTATUS` is blank and `CALMISSING` is FALSE...\n    FPSTATUS == \"\" & !CALMISSING,\n    # Repeat \",\" and the value in `FPCURREFFMETHRC` as many times as `CALDUR`:\n    str_c(\",\", FPCURREFFMETHRC) %>% str_dup(CALDUR), \n    # Otherwise, recycle `FPSTATUS` as a character string:\n    as.character(FPSTATUS)\n  )) %>% \n  select(-c(\n    ends_with(\"CMC\"), CALDUR, CALSTOP, \n    CALMISSING, PREGNANT, FPCURREFFMETHRC\n  ))\n\n\n\nSplitting months into\ncolumns\nWe’ve now completed as many of the blank calendars as we can, so it’s\ntime to transform each calendar string into variables that will be\nusable in survival analysis.\nWe’ll begin with another pivot_longer\nfunction to position FPSTATUS and WHYSTOP\ntogether in a single column. Notice the temporary column\nname describes the type of calendar that appears in the\ntemporary column value.\n\n\ncals <- cals %>% pivot_longer(c(\"FPSTATUS\", \"WHYSTOP\"))\n\ncals \n\n\n# A tibble: 70,848 × 6\n      ID PHASE CALSTART COUNTRY name     value                                  \n   <int> <chr>    <dbl> <fct>   <chr>    <chr+lbl>                              \n 1     1 1         1417 BF      FPSTATUS \",,,,,,,,,,0,0,0,0,0,0,0,0,0,0,0,0,B,P…\n 2     1 1         1417 BF      WHYSTOP  \",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\"  \n 3     1 2         1417 BF      FPSTATUS \",,,,,,,,,,,3,3,3,3,3,3,0,0,0,0,0,0,0,…\n 4     1 2         1417 BF      WHYSTOP  \",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,…\n 5     2 1         1417 BF      FPSTATUS \",,,,,,,,,,,P,P,P,P,P,P,P,0,0,0,0,0,0,…\n 6     2 1         1417 BF      WHYSTOP  \",,,,,,,,,,,,,,,,,,,,,,,,,6,,,,,,,,,,\" \n 7     2 2         1417 BF      FPSTATUS \",,,,,,,,,,,,5,5,5,5,5,5,5,5,5,B,P,P,P…\n 8     2 2         1417 BF      WHYSTOP  \",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6…\n 9     3 1         1417 BF      FPSTATUS \",,,,,,,,,,,0,0,0,0,0,0,0,0,0,0,0,0,0,…\n10     3 1         1417 BF      WHYSTOP  \"\"                                     \n# … with 70,838 more rows\n\nNow, we’ll use separate to\nsplit each string into several columns. You can manually specify the\nmaximum number of columns you’ll need to hold all of the calendars in\nyour data extract, or you can let R determine the max length of each\nstring.4 We’ll call this number\nncols.\n\n\n# How many columns would be needed for the single longest calendar? \nncols <- max(str_count(cals$value, \",\"), na.rm = TRUE) + 1\nncols \n\n\n[1] 48\n\nIn separate, we\ntell R to split each string into 48 columns: if any given\ncalendar has fewer than 48 values, we fill the left-most\ncolumns with the value NA as needed.\n\n\n# Create one column for every month in the longest calendar\ncals <- cals %>% \n  separate(value, into = paste0(\"cal\", ncols:1), sep = \",\", fill = \"left\", )\n\ncals \n\n\n# A tibble: 70,848 × 53\n      ID PHASE CALSTART COUNTRY name   cal48 cal47 cal46 cal45 cal44 cal43 cal42\n   <int> <chr>    <dbl> <fct>   <chr>  <chr> <chr> <chr> <chr> <chr> <chr> <chr>\n 1     1 1         1417 BF      FPSTA…  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>\n 2     1 1         1417 BF      WHYST…  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>\n 3     1 2         1417 BF      FPSTA… \"\"    \"\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n 4     1 2         1417 BF      WHYST… \"\"    \"\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n 5     2 1         1417 BF      FPSTA…  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>\n 6     2 1         1417 BF      WHYST…  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>\n 7     2 2         1417 BF      FPSTA… \"\"    \"\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n 8     2 2         1417 BF      WHYST… \"\"    \"\"    \"\"    \"\"    \"\"    \"\"    \"\"   \n 9     3 1         1417 BF      FPSTA…  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>\n10     3 1         1417 BF      WHYST…  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA>\n# … with 70,838 more rows, and 41 more variables: cal41 <chr>, cal40 <chr>,\n#   cal39 <chr>, cal38 <chr>, cal37 <chr>, cal36 <chr>, cal35 <chr>,\n#   cal34 <chr>, cal33 <chr>, cal32 <chr>, cal31 <chr>, cal30 <chr>,\n#   cal29 <chr>, cal28 <chr>, cal27 <chr>, cal26 <chr>, cal25 <chr>,\n#   cal24 <chr>, cal23 <chr>, cal22 <chr>, cal21 <chr>, cal20 <chr>,\n#   cal19 <chr>, cal18 <chr>, cal17 <chr>, cal16 <chr>, cal15 <chr>,\n#   cal14 <chr>, cal13 <chr>, cal12 <chr>, cal11 <chr>, cal10 <chr>, …\n\nAs you can see, this produced 48 columns named cal48 to\ncal1, where cal1 is the earliest month in\nchronological time. You’ll notice some blank strings for women whose\ncalendar included empty placeholders\n(e.g. ,,,,,,,3,3,3...). We’ll now use across to\nconvert blank strings \"\" to NA as well.\n\n\ncals <- cals %>% \n  mutate(across(\n    starts_with(\"cal\", ignore.case = FALSE),\n    ~na_if(.x, \"\")\n  ))\n\ncals \n\n\n# A tibble: 70,848 × 53\n      ID PHASE CALSTART COUNTRY name   cal48 cal47 cal46 cal45 cal44 cal43 cal42\n   <int> <chr>    <dbl> <fct>   <chr>  <chr> <chr> <chr> <chr> <chr> <chr> <chr>\n 1     1 1         1417 BF      FPSTA… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 2     1 1         1417 BF      WHYST… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 3     1 2         1417 BF      FPSTA… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 4     1 2         1417 BF      WHYST… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 5     2 1         1417 BF      FPSTA… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 6     2 1         1417 BF      WHYST… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 7     2 2         1417 BF      FPSTA… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 8     2 2         1417 BF      WHYST… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n 9     3 1         1417 BF      FPSTA… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n10     3 1         1417 BF      WHYST… <NA>  <NA>  <NA>  <NA>  <NA>  <NA>  <NA> \n# … with 70,838 more rows, and 41 more variables: cal41 <chr>, cal40 <chr>,\n#   cal39 <chr>, cal38 <chr>, cal37 <chr>, cal36 <chr>, cal35 <chr>,\n#   cal34 <chr>, cal33 <chr>, cal32 <chr>, cal31 <chr>, cal30 <chr>,\n#   cal29 <chr>, cal28 <chr>, cal27 <chr>, cal26 <chr>, cal25 <chr>,\n#   cal24 <chr>, cal23 <chr>, cal22 <chr>, cal21 <chr>, cal20 <chr>,\n#   cal19 <chr>, cal18 <chr>, cal17 <chr>, cal16 <chr>, cal15 <chr>,\n#   cal14 <chr>, cal13 <chr>, cal12 <chr>, cal11 <chr>, cal10 <chr>, …\n\nWe’ll now pivot_longer\nagain, placing each month into a single column temporarily called\nvalue. The label in name describes whether a\nparticular value originated in the FPSTATUS or\nWHYSTOP calendar. We strip the numeric suffix from each\ncolumn to create MONTH, which indicates the sequential\nmonth associated with each value.\n\n\ncals <- cals  %>% \n  pivot_longer(\n    starts_with(\"cal\", ignore.case = FALSE), \n    names_to = \"MONTH\", \n    names_prefix = \"cal\"\n  )\n\ncals \n\n\n# A tibble: 3,400,704 × 7\n      ID PHASE CALSTART COUNTRY name     MONTH value\n   <int> <chr>    <dbl> <fct>   <chr>    <chr> <chr>\n 1     1 1         1417 BF      FPSTATUS 48    <NA> \n 2     1 1         1417 BF      FPSTATUS 47    <NA> \n 3     1 1         1417 BF      FPSTATUS 46    <NA> \n 4     1 1         1417 BF      FPSTATUS 45    <NA> \n 5     1 1         1417 BF      FPSTATUS 44    <NA> \n 6     1 1         1417 BF      FPSTATUS 43    <NA> \n 7     1 1         1417 BF      FPSTATUS 42    <NA> \n 8     1 1         1417 BF      FPSTATUS 41    <NA> \n 9     1 1         1417 BF      FPSTATUS 40    <NA> \n10     1 1         1417 BF      FPSTATUS 39    <NA> \n# … with 3,400,694 more rows\n\nFrom MONTH and CALSTART, we’ll derive\nCALCMC to mark the calendar month for each\nvalue.\n\n\ncals <- cals %>%\n  mutate(CALCMC = CALSTART + as.integer(MONTH) - 1)\n\ncals\n\n\n# A tibble: 3,400,704 × 8\n      ID PHASE CALSTART COUNTRY name     MONTH value CALCMC\n   <int> <chr>    <dbl> <fct>   <chr>    <chr> <chr>  <dbl>\n 1     1 1         1417 BF      FPSTATUS 48    <NA>    1464\n 2     1 1         1417 BF      FPSTATUS 47    <NA>    1463\n 3     1 1         1417 BF      FPSTATUS 46    <NA>    1462\n 4     1 1         1417 BF      FPSTATUS 45    <NA>    1461\n 5     1 1         1417 BF      FPSTATUS 44    <NA>    1460\n 6     1 1         1417 BF      FPSTATUS 43    <NA>    1459\n 7     1 1         1417 BF      FPSTATUS 42    <NA>    1458\n 8     1 1         1417 BF      FPSTATUS 41    <NA>    1457\n 9     1 1         1417 BF      FPSTATUS 40    <NA>    1456\n10     1 1         1417 BF      FPSTATUS 39    <NA>    1455\n# … with 3,400,694 more rows\n\nFinally, we’ll use pivot_wider\nto align the months for each available calendar, and then arrange each\nwoman’s calendar by CALCMC. If any month includes no value\nfrom either Phase 1 or Phase 2, we’ll use filter to\nremove it from our data frame (these are placeholder values for future\nmonths).\nIn its final format, cals contains one row for every\nmonth covered by the contraceptive calendar from either Phase 1 or Phase\n2. You’ll notice that the two calendars contain overlapping months, as\nwith the dates between CALCMC 1417 and 1442 for the first\nwoman shown below.\n\n\n\n\n\ncals <- cals %>% \n  select(ID, PHASE, CALCMC, name, value) %>% \n  pivot_wider(\n    names_from = c(name, PHASE), \n    values_from = value\n  ) %>% \n  filter(!(is.na(FPSTATUS_1) & FPSTATUS_2 == \"\")) %>% \n  arrange(ID, desc(CALCMC)) \n\ncals\n\n\n# A tibble: 769,071 × 6\n      ID CALCMC FPSTATUS_1 WHYSTOP_1 FPSTATUS_2 WHYSTOP_2\n   <int>  <dbl> <chr>      <chr>     <chr>      <chr>    \n 1     1   1453 <NA>       <NA>      3          <NA>     \n 2     1   1452 <NA>       <NA>      3          <NA>     \n 3     1   1451 <NA>       <NA>      3          <NA>     \n 4     1   1450 <NA>       <NA>      3          <NA>     \n 5     1   1449 <NA>       <NA>      3          <NA>     \n 6     1   1448 <NA>       <NA>      3          <NA>     \n 7     1   1447 <NA>       <NA>      0          <NA>     \n 8     1   1446 <NA>       <NA>      0          <NA>     \n 9     1   1445 <NA>       <NA>      0          <NA>     \n10     1   1444 <NA>       <NA>      0          <NA>     \n11     1   1443 <NA>       <NA>      0          <NA>     \n12     1   1442 0          <NA>      0          <NA>     \n13     1   1441 0          <NA>      0          <NA>     \n14     1   1440 0          <NA>      0          <NA>     \n15     1   1439 0          <NA>      0          <NA>     \n16     1   1438 0          <NA>      0          <NA>     \n17     1   1437 0          <NA>      0          <NA>     \n18     1   1436 0          <NA>      0          <NA>     \n19     1   1435 0          <NA>      0          <NA>     \n20     1   1434 0          <NA>      0          <NA>     \n21     1   1433 0          <NA>      0          <NA>     \n22     1   1432 0          <NA>      0          <NA>     \n23     1   1431 0          <NA>      0          <NA>     \n24     1   1430 B          <NA>      B          <NA>     \n25     1   1429 P          <NA>      P          <NA>     \n26     1   1428 P          <NA>      P          <NA>     \n27     1   1427 P          <NA>      P          <NA>     \n28     1   1426 P          <NA>      P          <NA>     \n29     1   1425 P          <NA>      P          <NA>     \n30     1   1424 P          <NA>      P          <NA>     \n31     1   1423 P          <NA>      P          <NA>     \n32     1   1422 P          <NA>      0          <NA>     \n33     1   1421 0          <NA>      0          <NA>     \n34     1   1420 0          <NA>      0          <NA>     \n35     1   1419 0          <NA>      0          <NA>     \n36     1   1418 0          <NA>      0          <NA>     \n37     1   1417 0          <NA>      0          <NA>     \n38     2   1452 <NA>       <NA>      5          <NA>     \n39     2   1451 <NA>       <NA>      5          <NA>     \n40     2   1450 <NA>       <NA>      5          <NA>     \n# … with 769,031 more rows\n\nAnalysis\n\n\n\nWe mentioned at the beginning of this post that there are many ways\nto work with the contraceptive calendar data once you’ve formatted it\nthis way. For example, we just saw that the FPSTATUS_1 and\nFPSTATUS_2 columns are a nearly perfect match for\nthe woman marked ID == 1: she reports that she used no\nmethod of contraception between month 1417 until month\n1421. Then, in Phase 1 she recalled that she became\npregnant in month 1422; in Phase 2, she instead recalled\nthat she became pregnant in month 1423. In both phases, she\nreports that she gave birth in month 1430, and then\nreturned to using no family planning method.\nWe encourage researchers to explore sources of recall\nbias that may account for discrepancies between the Phase 1 and\nPhase 2 calendars. Generally, we assume that individuals remember events\nmore reliably when they are in recent memory, but this may not always be\ntrue! For more on the reliability of responses in contraceptive\ncalendars across PMA samples, we strongly recommend checking out work by\nAnglewicz et al. (2022).\nHere, we’d like to highlight just one way that the PMA panel design\nmight help researchers understand patterns in the calendar data. When we\nintroduced the Phase 1 contraceptive calendars one year ago, we mentioned that\nPhase 2 calendars would allow researchers to compare the rate of\nadoption for women who were using no method at Phase 1; we also\nsuggested that you might compare adoption rates for women with unmet\nneed or plans\nto adopt a method within the next year. Let’s now check to see\nwhether these factors had any effect on the monthly contraceptive use\nstatus for each month between Phase 1 and Phase 2.\nFirst, we’ll need to identify women who were not using any family\nplanning method at Phase 1. These are cases where FPCURREFFMETHRC_1\nis coded 999 for NIU (not in universe).\nWe’ll drop any other cases from our original data frame\ndat, and we’ll call this new data frame\nnonusers.\n\n\nnonusers <- dat %>% filter(FPCURREFFMETHRC_1 == 999)\n\n\n\nWe’ll follow steps in a previous post to\nidentify women who meet the PMA criteria for “unmet need” in UNMETYN_1,\nand also those who planned to adopt a family planning method within one\nyear at Phase 1 as shown in FPPLANVAL_1\nand FPPLANWHEN_1.\n\n\nnonusers <- nonusers %>% \n  mutate(\n    UNMETYN_1 = UNMETYN_1 == 1,\n    FPPLANYR_1 = case_when(\n      FPPLANWHEN_1 == 1 & FPPLANVAL_1 <= 12 ~ TRUE, # Within 12 months \n      FPPLANWHEN_1 == 2 & FPPLANVAL_1 == 1 ~ TRUE, # Within 1 year\n      FPPLANWHEN_1 %in% c(3, 4) ~ TRUE, # Soon / now, after current pregnancy\n      TRUE ~ FALSE # Includes date unknown, no response, or no intention (FPUSPLAN)\n    )\n  ) \n\n\n\nIn that same post, we shared code you can use to create a custom theme\nfor graphics built with ggplot2. We named our theme\ntheme_pma; if you’d like to review the code for our\ngraphics theme, click the button below.\n\n\nShow code for theme_pma\n\nlibrary(showtext)\n\nsysfonts::font_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext::showtext_auto()\nupdate_geom_defaults(\"text\", list(family = \"cabrito\", size = 4))\n\ntheme_pma <- theme_minimal() %+replace% \n  theme(\n    text = element_text(family = \"cabrito\", size = 13),\n    plot.title = element_text(size = 22, color = \"#00263A\", \n                              hjust = 0, margin = margin(b = 5)),\n    plot.subtitle = element_text(hjust = 0, margin = margin(b = 10)),\n    strip.background = element_blank(),\n    strip.text.y = element_text(size = 16, angle = 0),\n    panel.spacing = unit(1, \"lines\"),\n    axis.title.y = element_text(angle = 0, margin = margin(r = 10)),\n    axis.title.x = element_text(margin = margin(t = 10))\n  )\n\n\n\nBefore we begin our analysis, let’s see the proportion of\nnonusers in each country who had unmet need or plans to\nadopt a family planning method within one year at Phase 1.\n\n\nShow code for this plot\n\nnonusers %>% \n  count(COUNTRY, UNMETYN_1, FPPLANYR_1) %>% \n  mutate( \n    UNMETYN_1 = if_else(UNMETYN_1, \"Unmet Need\\n\", \"No Unmet Need\\n\"),\n    FPPLANYR_1 = if_else(FPPLANYR_1, \"Plan 1 Yr\\n\", \"No Plan 1 Yr\\n\")\n  ) %>% \n  group_by(COUNTRY) %>% \n  mutate(prop = prop.table(n), tot = sum(n)) %>% # joint percentages\n  group_by(COUNTRY, UNMETYN_1) %>% \n  mutate(propcol = sum(n)/tot) %>% # column margins \n  group_by(COUNTRY, FPPLANYR_1) %>% \n  mutate(proprow = sum(n)/tot) %>% # row margins \n  ungroup() %>% \n  mutate(\n    propcol = paste(UNMETYN_1, scales::percent(propcol, .1)),\n    proprow = paste(FPPLANYR_1, scales::percent(proprow, .1)),\n    proplbl =  scales::percent(prop, .1)\n  ) %>% \n  ggplot(aes(x = propcol, y = proprow)) + \n  geom_tile(fill = \"#98579BB0\", aes(alpha = prop)) + \n  facet_wrap(vars(COUNTRY), scales = \"free\") + \n  geom_text(aes(label = proplbl)) + \n  labs(\n    title = \"Non-users: Unmet Need and Intentions to Adopt a Method within 1 Year\",\n    subtitle = \"Percentage among sampled women not currently using any method at Phase 1\",\n    x = NULL, y = NULL\n  ) + \n  theme_pma %+replace% \n  theme(panel.grid = element_blank(), legend.position = \"none\")\n\n\n\n\nAs you can see, a majority of Phase 1 nonusers in each\ncountry had both no unmet need and no plans to adopt a method within the\nnext year. We might expect these women to be least likely to\nadopt a method within the subsequent months covered by the Phase 2\ncontraceptive calendar. Conversely, we might expect that women who\nplanned to adopt a method within the year would be most likely\nto adopt a method during the calendar period, but this might be\nmitigated by factors related to unmet need.\nLet’s now attach the contraceptive calendar data from Phase 2 to\nnonusers. We’ll exclude months before\nINTFQCMC_1 and women we identified with\nCALMISSING (where all values in FPSTATUS_2 are\nnow NA). Finally, we’ll exclude women for whom either\nUNMETYN_1 or FPPLANYR_1 is missing, NIU, or\notherwise coded NA.\n\n\nnonusers <- nonusers %>% \n  select(ID, COUNTRY, INTFQCMC_1, UNMETYN_1, FPPLANYR_1) %>% \n  full_join(cals, ., by = \"ID\") %>% \n  filter(\n    CALCMC >= INTFQCMC_1, \n    !if_any(c(FPSTATUS_2, UNMETYN_1, FPPLANYR_1), is.na)\n  )\n\n\n\nThe next several steps will help us remove every month for each woman\nexcept for the last consecutive month in which she was not\nusing a family planning method after the Phase 1 interview. For those\nwho were still not using a method by the date of the Phase 2 interview,\nwe might say say she “survived” the full observation period. We’ll use\nthe survival package\nto model the likelihood that a woman would have progressed through each\nmonth of the calendar without adopting a family planning method.\nFirst, we’ll classify every month in each woman’s calendar with a new\nvariable USE indicating whether she used any family\nplanning method that month. We’ll then create MO to count\nthe number of months that have passed between each month and the\nearliest month in CALCMC.\n\n\nnonusers <- nonusers %>% \n  transmute(\n    ID, COUNTRY, CALCMC, \n    FPSTATUS_2, UNMETYN_1, FPPLANYR_1,\n    MO = CALCMC - INTFQCMC_1,\n    USE = !FPSTATUS_2 %in% c(\"0\", \"B\", \"P\", \"T\")\n  ) \n\nnonusers \n\n\n# A tibble: 116,860 × 8\n      ID COUNTRY CALCMC FPSTATUS_2 UNMETYN_1 FPPLANYR_1    MO USE  \n   <int> <fct>    <dbl> <chr>      <lgl>     <lgl>      <dbl> <lgl>\n 1     1 BF        1453 3          FALSE     TRUE          11 TRUE \n 2     1 BF        1452 3          FALSE     TRUE          10 TRUE \n 3     1 BF        1451 3          FALSE     TRUE           9 TRUE \n 4     1 BF        1450 3          FALSE     TRUE           8 TRUE \n 5     1 BF        1449 3          FALSE     TRUE           7 TRUE \n 6     1 BF        1448 3          FALSE     TRUE           6 TRUE \n 7     1 BF        1447 0          FALSE     TRUE           5 FALSE\n 8     1 BF        1446 0          FALSE     TRUE           4 FALSE\n 9     1 BF        1445 0          FALSE     TRUE           3 FALSE\n10     1 BF        1444 0          FALSE     TRUE           2 FALSE\n11     1 BF        1443 0          FALSE     TRUE           1 FALSE\n12     1 BF        1442 0          FALSE     TRUE           0 FALSE\n13     2 BF        1452 5          FALSE     FALSE         11 TRUE \n14     2 BF        1451 5          FALSE     FALSE         10 TRUE \n15     2 BF        1450 5          FALSE     FALSE          9 TRUE \n16     2 BF        1449 5          FALSE     FALSE          8 TRUE \n17     2 BF        1448 5          FALSE     FALSE          7 TRUE \n18     2 BF        1447 5          FALSE     FALSE          6 TRUE \n19     2 BF        1446 5          FALSE     FALSE          5 TRUE \n20     2 BF        1445 5          FALSE     FALSE          4 TRUE \n# … with 116,840 more rows\n\nNext, we’ll create USEMO to copy the month recorded in\nMO for each month of USE (otherwise, case_when\nassigns the value NA). If there are any months of\nUSE for an individual woman, we’ll identify the first such\nmonth with ADOPT; if there are no cases of\nUSE, ADOPT will record the last month in\nMO. Finally we’ll use RC to indicate whether\nADOPT is “right censored” - these are cases where\nADOPT is the last month in MO.\n\n\nnonusers <- nonusers %>% \n  group_by(ID) %>% \n  mutate(\n    USEMO = case_when(USE ~ MO),\n    ADOPT = ifelse(any(USE), min(USEMO, na.rm = T), max(MO)),\n    RC = case_when(ADOPT == MO ~ !USE)\n  ) %>% \n  ungroup() \n\nnonusers \n\n\n# A tibble: 116,860 × 11\n      ID COUNTRY CALCMC FPSTATUS_2 UNMETYN_1 FPPLANYR_1    MO USE   USEMO ADOPT RC   \n   <int> <fct>    <dbl> <chr>      <lgl>     <lgl>      <dbl> <lgl> <dbl> <dbl> <lgl>\n 1     1 BF        1453 3          FALSE     TRUE          11 TRUE     11     6 NA   \n 2     1 BF        1452 3          FALSE     TRUE          10 TRUE     10     6 NA   \n 3     1 BF        1451 3          FALSE     TRUE           9 TRUE      9     6 NA   \n 4     1 BF        1450 3          FALSE     TRUE           8 TRUE      8     6 NA   \n 5     1 BF        1449 3          FALSE     TRUE           7 TRUE      7     6 NA   \n 6     1 BF        1448 3          FALSE     TRUE           6 TRUE      6     6 FALSE\n 7     1 BF        1447 0          FALSE     TRUE           5 FALSE    NA     6 NA   \n 8     1 BF        1446 0          FALSE     TRUE           4 FALSE    NA     6 NA   \n 9     1 BF        1445 0          FALSE     TRUE           3 FALSE    NA     6 NA   \n10     1 BF        1444 0          FALSE     TRUE           2 FALSE    NA     6 NA   \n11     1 BF        1443 0          FALSE     TRUE           1 FALSE    NA     6 NA   \n12     1 BF        1442 0          FALSE     TRUE           0 FALSE    NA     6 NA   \n13     2 BF        1452 5          FALSE     FALSE         11 TRUE     11     3 NA   \n14     2 BF        1451 5          FALSE     FALSE         10 TRUE     10     3 NA   \n15     2 BF        1450 5          FALSE     FALSE          9 TRUE      9     3 NA   \n16     2 BF        1449 5          FALSE     FALSE          8 TRUE      8     3 NA   \n17     2 BF        1448 5          FALSE     FALSE          7 TRUE      7     3 NA   \n18     2 BF        1447 5          FALSE     FALSE          6 TRUE      6     3 NA   \n19     2 BF        1446 5          FALSE     FALSE          5 TRUE      5     3 NA   \n20     2 BF        1445 5          FALSE     FALSE          4 TRUE      4     3 NA   \n# … with 116,840 more rows\n\nNotice, for example, that the first month of USE for\nID == 1 occurs in month 6. Hence, ADOPT == 6\nand, because she adopted a method before the end of the calendar,\nRC == FALSE.\nFinally, we’ll now drop every row except for those matching\nADOPT. This leaves one row for each woman in\nnonusers.\n\n\nnonusers <- nonusers %>% filter(ADOPT == MO)\n\nnonusers \n\n\n# A tibble: 9,206 × 11\n      ID COUNTRY CALCMC FPSTATUS_2 UNMETYN_1 FPPLANYR_1    MO USE   USEMO ADOPT RC   \n   <int> <fct>    <dbl> <chr>      <lgl>     <lgl>      <dbl> <lgl> <dbl> <dbl> <lgl>\n 1     1 BF        1448 3          FALSE     TRUE           6 TRUE      6     6 FALSE\n 2     2 BF        1444 5          FALSE     FALSE          3 TRUE      3     3 FALSE\n 3     3 BF        1453 0          FALSE     FALSE         12 FALSE    NA    12 TRUE \n 4     6 BF        1453 0          FALSE     FALSE         12 FALSE    NA    12 TRUE \n 5     7 BF        1452 0          FALSE     FALSE         11 FALSE    NA    11 TRUE \n 6     8 BF        1452 0          TRUE      FALSE         11 FALSE    NA    11 TRUE \n 7    13 BF        1441 5          FALSE     TRUE           0 TRUE      0     0 FALSE\n 8    16 BF        1449 5          FALSE     FALSE          8 TRUE      8     8 FALSE\n 9    17 BF        1452 0          FALSE     TRUE          11 FALSE    NA    11 TRUE \n10    18 BF        1452 0          FALSE     FALSE         11 FALSE    NA    11 TRUE \n11    21 BF        1452 0          FALSE     FALSE         11 FALSE    NA    11 TRUE \n12    22 BF        1453 0          FALSE     FALSE         12 FALSE    NA    12 TRUE \n13    26 BF        1452 0          FALSE     FALSE         11 FALSE    NA    11 TRUE \n14    28 BF        1453 0          FALSE     FALSE         12 FALSE    NA    12 TRUE \n15    29 BF        1454 0          FALSE     FALSE         13 FALSE    NA    13 TRUE \n16    30 BF        1445 3          FALSE     TRUE           4 TRUE      4     4 FALSE\n17    31 BF        1453 0          FALSE     FALSE         12 FALSE    NA    12 TRUE \n18    32 BF        1454 0          FALSE     FALSE         13 FALSE    NA    13 TRUE \n19    33 BF        1452 P          TRUE      TRUE          11 FALSE    NA    11 TRUE \n20    34 BF        1452 B          TRUE      FALSE         11 FALSE    NA    11 TRUE \n# … with 9,186 more rows\n\nWe’ll now fit three survival models predicting the duration of\ncontinuous non-use for the women in nonusers: one model for\nUNMETYN_1, one for FPPLANYR_1, and one for\ntheir interaction effect, which we’ll call INTERACT_1. For\neach model, survfit\nreports the likelihood that a baseline non-user would have adopted any\nfamily planning method for each month in the calendar period. We’ll run\neach model separately for each country, and we’ll use broom::tidy to\ncreate a tidy summary table for each model.\n\n\nadopt_models <- nonusers %>% \n  # Create a variable capturing the interaction between intentions and unmet need\n  mutate(INTERACT_1 = case_when(\n    UNMETYN_1 & FPPLANYR_1 ~ \"Unmet Need, Plan 1 Yr\",\n    UNMETYN_1 & !FPPLANYR_1 ~ \"Unmet Need, No Plan 1 Yr\",\n    !UNMETYN_1 & FPPLANYR_1 ~ \"No Unmet Need, Plan 1 Yr\",\n    !UNMETYN_1 & !FPPLANYR_1 ~ \"No Unmet Need, No Plan 1 Yr\"\n  )) %>% \n  # Separate survival models for each country \n  group_by(COUNTRY) %>% \n  summarise(\n    unmet = survfit(Surv(MO, !RC) ~ UNMETYN_1, data = cur_group()) %>% list, \n    plan = survfit(Surv(MO, !RC) ~ FPPLANYR_1, data = cur_group()) %>% list, \n    interact = survfit(Surv(MO, !RC) ~ INTERACT_1, data = cur_group()) %>% list\n  ) %>% \n  # Tidy the output and relabel `COUNTRY` for the figure\n  mutate(\n    across(where(is.list), ~map(.x, broom::tidy)),\n    COUNTRY = COUNTRY %>% recode(\n      \"BF\" = \"Burkina Faso\",\n      \"CD\" = \"DRC\",\n      \"KE\" = \"Kenya\",\n      \"NG\" = \"Nigeria\"\n    )\n  )\n\n\n\nLet’s start with the model featuring UNMETYN_1. If you\nunnest the\nunmet model output, you’ll see a separate row for each\nmonth reported for women with “No Unmet Need” and “Unmet Need”.\n\n\nm_unmet <- adopt_models %>% \n  unnest(unmet) %>% \n  mutate(strata = if_else(\n    str_detect(strata, \"TRUE\"), \"Unmet Need\", \"No Unmet Need\"\n  )) %>% \n  relocate(strata, .after = COUNTRY)\n\nm_unmet\n\n\n# A tibble: 117 × 12\n   COUNTRY      strata   time n.risk n.event n.censor estimate std.error conf.high conf.low plan    \n   <fct>        <chr>   <dbl>  <dbl>   <dbl>    <dbl>    <dbl>     <dbl>     <dbl>    <dbl> <list>  \n 1 Burkina Faso No Unm…     0   2245     157        0    0.930   0.00579     0.941    0.920 <tibble>\n 2 Burkina Faso No Unm…     1   2088      20        0    0.921   0.00617     0.932    0.910 <tibble>\n 3 Burkina Faso No Unm…     2   2068      21        0    0.912   0.00656     0.924    0.900 <tibble>\n 4 Burkina Faso No Unm…     3   2047      25        0    0.901   0.00701     0.913    0.888 <tibble>\n 5 Burkina Faso No Unm…     4   2022      27        0    0.889   0.00747     0.902    0.876 <tibble>\n 6 Burkina Faso No Unm…     5   1995      22        0    0.879   0.00784     0.892    0.865 <tibble>\n 7 Burkina Faso No Unm…     6   1973      27        0    0.867   0.00827     0.881    0.853 <tibble>\n 8 Burkina Faso No Unm…     7   1946      26        0    0.855   0.00868     0.870    0.841 <tibble>\n 9 Burkina Faso No Unm…     8   1920      30        0    0.842   0.00915     0.857    0.827 <tibble>\n10 Burkina Faso No Unm…     9   1890      37        0    0.825   0.00971     0.841    0.810 <tibble>\n11 Burkina Faso No Unm…    10   1853      35       97    0.810   0.0102      0.826    0.794 <tibble>\n12 Burkina Faso No Unm…    11   1721      27      906    0.797   0.0107      0.814    0.781 <tibble>\n13 Burkina Faso No Unm…    12    788       5      687    0.792   0.0110      0.809    0.775 <tibble>\n14 Burkina Faso No Unm…    13     96       3       70    0.767   0.0214      0.800    0.736 <tibble>\n15 Burkina Faso No Unm…    14     23       0       23    0.767   0.0214      0.800    0.736 <tibble>\n16 Burkina Faso Unmet …     0    632      86        0    0.864   0.0158      0.891    0.838 <tibble>\n17 Burkina Faso Unmet …     1    546      15        0    0.840   0.0173      0.869    0.812 <tibble>\n18 Burkina Faso Unmet …     2    531       6        0    0.831   0.0180      0.860    0.802 <tibble>\n19 Burkina Faso Unmet …     3    525       9        0    0.816   0.0189      0.847    0.787 <tibble>\n20 Burkina Faso Unmet …     4    516       6        0    0.807   0.0195      0.838    0.777 <tibble>\n# … with 97 more rows, and 1 more variable: interact <list>\n\nThe column n.risk shows the total number of non-users\nremaining after the number of months passed in time. The\ncolumn estimate shows the estimated probability that a\nrandomly selected woman would remain in n.risk by that\nmonth (conf.high and conf.low report a 95%\nconfidence interval by default). For example, row 1 shows that there\nwere 2245 women in the Phase 1 Burkina Faso sample who were not using\nfamily planning did not meet PMA criteria for “unmet need”. Among these,\nn.event shows that 157 adopted a family planning method\nless than one month after the interview: this leaves 93.0% of the group\nremaining before one month had passed.\nBelow that, row 16 shows that there were 632 women in the Phase 1\nBurkina Faso sample who were not using family planning, but did\nmeet PMA criteria for “unmet need”. Among these, n.event\nshows that 86 adopted a family planning method less than one month after\nthe interview: this leaves 86.4% of the group remaining before one month\nhad passed.\nWe’ll produce a “time-to-event” plot by inverting the probabilities\nreported in event and its accompanying confidence interval.\nThis plot uses geom_step\nto draw a step-wise function, and geom_rect\nto create a shaded confidence interval for each step.\n\n\nm_unmet %>% \n  group_by(COUNTRY, strata) %>% \n  mutate(\n    across(where(is.double) & !time, ~1-.x),\n    xmax = if_else(time == max(time), time, time + 1), # horizontal ci shading\n  ) %>% \n  ggplot(aes(x = time, y = estimate, fill = strata)) + \n  geom_step() + \n  geom_rect(\n    aes(xmin = time, xmax = xmax, ymin = conf.low, ymax = conf.high),\n    alpha = 0.5, \n    color = 0\n  ) + \n  facet_wrap(~COUNTRY) + \n  scale_y_continuous(labels = scales::label_percent()) + \n  scale_fill_manual(values = c(\n    \"Unmet Need\" = \"#F2300E\", \n    \"No Unmet Need\" = \"#352749\"\n  )) + \n  labs(\n    title = \"Predicted Time to FP Adoption by Phase 1 Unmet Need Status\",\n    x = \"Consecutive Months after Phase 1 FQ Interview\", y = NULL, fill = NULL\n  ) +  \n  theme_pma \n\n\n\n\nIn general, we see evidence that non-users with unmet need at Phase 1\nwere significantly quicker to adopt a method compared to women with no\nunmet need in each country.\nLet’s now consider how the adoption rate might be influenced to by\nFPPLANYR_1.\n\n\nadopt_models %>% \n  unnest(plan) %>% \n  mutate(strata = if_else(\n    str_detect(strata, \"TRUE\"), \"Plan 1 Yr\", \"No Plan 1 Yr\"\n  )) %>% \n  group_by(COUNTRY, strata) %>% \n  mutate(\n    across(where(is.double) & !time, ~1-.x),\n    xmax = if_else(time == max(time), time, time + 1), \n  ) %>% \n  ggplot(aes(x = time, y = estimate, fill = strata)) + \n  geom_step() + \n  geom_rect(\n    aes(xmin = time, xmax = xmax, ymin = conf.low, ymax = conf.high),\n    alpha = 0.5, \n    color = 0\n  ) + \n  facet_wrap(~COUNTRY) + \n  scale_y_continuous(labels = scales::label_percent()) + \n  scale_fill_manual(values = c(\n    \"Plan 1 Yr\" = \"#EBCC2A\", \n    \"No Plan 1 Yr\" = \"#899DA4\" \n  )) +  \n  labs(\n    title = \"Predicted Time to FP Adoption by Intentions Within 1 Year of Phase 1\",\n    x = \"Consecutive Months after Phase 1 FQ Interview\", y = NULL, fill = NULL\n  ) + \n  theme_pma \n\n\n\n\nHere, we see that women who planned to adopt a method within 1 year\nfollowing the Phase 1 interview were significantly quicker to begin\nusing one compared to women who had no such plans (except within the\nfirst few months for women in Nigeria, where this difference was not\nstatistically significant). Finally, let’s consider the interaction\nreported in INTERACT_1.\n\n\nadopt_models %>% \n  unnest(interact) %>% \n  group_by(COUNTRY, strata) %>%\n  mutate(\n    across(where(is.double) & !time, ~1-.x),\n    xmax = if_else(time == max(time), time, time + 1), \n    strata = str_remove(strata, \".*=\")\n  ) %>% \n  ggplot(aes(x = time, y = estimate, fill = strata)) + \n  geom_step() + \n  geom_rect(\n    aes(xmin = time, xmax = xmax, ymin = conf.low, ymax = conf.high),\n    alpha = 0.5, \n    color = 0\n  ) + \n  facet_wrap(~COUNTRY) + \n  scale_y_continuous(labels = scales::label_percent()) + \n  scale_fill_manual(values = c(\n    \"Unmet Need, Plan 1 Yr\" = \"#98579B\",\n    \"Unmet Need, No Plan 1 Yr\" = \"#00263A\", \n    \"No Unmet Need, Plan 1 Yr\" = \"#CCBA72\",\n    \"No Unmet Need, No Plan 1 Yr\" = \"#81A88D\"\n  ))  +  \n  labs(\n    title = \"Predicted Time to FP Adoption by Phase 1 Intentions and Unmet Need\",\n    x = \"Consecutive Months after Phase 1 FQ Interview\", y = NULL, fill = NULL\n  ) + \n  theme_pma \n\n\n\n\nThe interaction between UNMETYN_1 and\nFPPLANYR_1 seems to confirm at least one of our hypotheses:\nnon-users who had no unmet need and no plans to adopt a method within\nthe year were significantly slower to do so (again, except for the first\nfew months shown in Nigeria). Women without plans to adopt a method were\nalso somewhat slower to adopt a method if they experienced unmet need,\nbut there are considerable differences in the strength of this finding\nacross countries and over the length of the calendar period. Overall,\nwomen who planned to adopt a method were significantly quicker to do so,\nbut the mitigating effects of unmet need are generally unclear.\nWe hope this preliminary analysis serves as an entry point for your\nown exploration of the contraceptive calendar data included in each PMA\npanel survey. Stay tuned here for updates in the coming months, when\nwe’ll return to the calendar to see how rainfall, temperature, and other\nclimate shocks impact monthly family planning behavior.\n\n\n\nAnglewicz, Philip, Dana Sarnak, Alison Gemmill, and Stan Becker. 2022.\n“Characteristics Associated with Consistency in Reporting of\nContraceptive Use: Assessing the Reliability of the Contraceptive\nCalendar in Eight Countries.” In PAA 2022 Annual\nMeeting. Atlanta, GA: Population Association of America. https://paa.confex.com/paa/2022/meetingapp.cgi/Paper/26280.\n\n\nThe related variable FPCURREFFMETH\nreports the most effective method reported by each woman. In FPCURREFFMETHRC,\nthese responses are combined with detailed information about her use of\nthe lactational amenorrhea method (LAM), emergency contraception, or\nspecific types of injectable methods.↩︎\nBurkina Faso, Kenya, DRC (Kinshasa\nand Kongo Central), and Nigeria (Kano and Lagos)↩︎\nCOUNTRYSTR\nalso contains ISO codes for each country, but it contains blank values\nfor women with responses from only one phase.↩︎\nHere, we’re counting the number of\ncommas in each string, so we add +1\n(e.g. 0,0,0 has two commas, but three responses).↩︎\n",
    "preview": "posts/2022-05-15-phase2-calendar/phase2-calendar_files/figure-html5/unnamed-chunk-48-1.png",
    "last_modified": "2022-07-26T12:38:22-04:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1536
  },
  {
    "path": "posts/2022-05-01-phase2-alluvial/",
    "title": "Data Visualization Toolkit for PMA Panel Data",
    "description": "Heatmaps and alluvial plots make it easy to compare key family planning indicators over time and across multiple populations sampled by PMA panel surveys.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-05-01",
    "categories": [
      "Panel Data",
      "Data Visualization",
      "Family Planning",
      "Weights",
      "heatmaps",
      "ggalluvial",
      "ggplot2",
      "srvyr"
    ],
    "contents": "\n\nContents\nSetup\nGrouped\nBar Charts\nHeatmaps\nAlluvial\nplots\nNext Steps\n\n\n\n\nIn our last post, we demonstrated how to calculate key\nindicators for women’s family planning status with new panel surveys from\nour partners at PMA. When you\ndownload PMA data from IPUMS PMA,\nyou can include multiple samples together in the same data extract.\nCurrently, Phase 1 and Phase 2 data are available for six samples, and\nwe’ve devoted much of this series to\nreproducing and synthesizing the major findings published in individual\nPMA\nreports for each sample:\nBurkina\nFaso\nDRC\n- Kinshasa\nDRC\n- Kongo Central\nKenya\nNigeria\n- Kano\nNigeria\n- Lagos\nNow that we’ve learned how to compare population-level estimates for\nindicators in each population with grouped bar\ncharts, we’d like to dig into some of the other data visualization\ntools that are commonly used for two-phase panel data. We’ll quickly\nrecap our approach to building bar charts, and then we’ll explore\ncolor-coded crosstabs - or heatmaps - followed by\nalluvial plots built with ggalluvial, an\nextension to the ggplot2\npackage for R.\nSetup\nIn addition to ggalluvial, we’ll\nalso showcase just a few of the helpful functions in scales, a package devoted to making\naxes, labels, and legends easier to read (in particular, we’ll use percent\nto transform proportions into percentages labeled with the\n% symbol). You’ll need those two packages, plus the three\npackages we’ve already used at length in this series: tidyverse, ipumsr, and srvyr.\n\n\nlibrary(tidyverse)\nlibrary(ipumsr)\nlibrary(srvyr)\nlibrary(ggalluvial)\nlibrary(scales)\n\n\n\nAs a reminder, our last post featured a wide format data extract with\n“Female Respondents” only (other household members not participating in\nthe panel study are excluded). If you’re following along with this\nseries, you can use the same extract again in this post; if not, you’ll\nneed to build a new extract that contains all of the variables we’ll use\nhere (preselected\nvariables are added automatically):\nRESULTFQ\n- Result of female questionnaire\nPANELWEIGHT\n- Phase 2 female panel weight\nRESIDENT\n- Household residence / membership\nPREGNANT\n- Pregnancy status\nGEOCD\n- Province, DRC\nGEONG\n- State, Nigeria\nCP\n- Contraceptive user\nCOUNTRY\n- PMA country (preselected)\nEAID\n- Enumeration area (preselected)\nToday’s analysis will focus on three recoded\nvariables we derived in our last post:\nPOP - Population of interest\nFPSTATUS_1 - Pregnant, using contraception, or using no\ncontraception at Phase 1\nFPSTATUS_2 - Pregnant, using contraception, or using no\ncontraception at Phase 2\nFinally, our analysis dropped cases for women who only completed one\nof the two Female Questionnaires, were not members of the de\nfacto population, or skipped critical questions regarding current\nuse of family planning. If you’d like a refresher on the steps we took\nto load, filter, and recode data from our previous post, click the\nbutton below:\n\n\nRemind me about our data cleaning steps\n\n# import the data extract and metadata files\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00106.xml\",\n  data = \"data/pma_00106.dat.gz\"\n) \n\n# inclusion criteria for analysis\ndat <- dat %>% \n  filter(\n    RESULTFQ_2 == 1,  # must have completed Phase 1 FQ\n    RESIDENT_1 %in% c(11, 22) & # must be de facto population (both phases)\n      RESIDENT_2 %in% c(11, 22),\n    CP_1 < 90 & CP_2 < 90 # must answer \"current FP use\" question (both phases)\n  ) \n\n# custom variables: `POP` and `FPSTATUS`\ndat <- dat %>% \n  mutate(\n    # Population of interest (country + region, where applicable)\n    POP = case_when(\n      !is.na(GEOCD) ~ paste(\"DRC -\", as_factor(GEOCD)),\n      !is.na(GEONG) ~ paste(\"Nigeria -\", as_factor(GEONG)),\n      TRUE ~ as_factor(COUNTRY) %>% as.character()\n    ),\n    # strata: includes placeholder values for DRC regions \n    STRATA_RECODE = if_else(\n      is.na(GEOCD), \n      as.numeric(STRATA_1), \n      as.numeric(GEOCD)\n    ),\n    # Family planning use-status at Phase 1 \n    FPSTATUS_1 = case_when(\n      PREGNANT_1 == 1 ~ \"Pregnant\",\n      CP_1 == 1 ~ \"Using FP\",\n      CP_1 == 0 ~ \"Not Using FP\"\n    ), \n    # Family planning use-status at Phase 2 \n    FPSTATUS_2 = case_when(\n      PREGNANT_2 == 1 ~ \"Pregnant\",\n      CP_2 == 1 ~ \"Using FP\",\n      CP_2 == 0 ~ \"Not Using FP\"\n    ),\n    # Create factors to control order of display in graphics output \n    across(\n      c(FPSTATUS_1, FPSTATUS_2),\n      ~.x %>% fct_relevel(\"Pregnant\", \"Not Using FP\", \"Using FP\")\n    )\n  )\n\n\n\nOne more thing: our blog uses a particular font, layout, and color\nscheme that we’ve incorporated into a custom\ntheme we call theme_pma. Feel free to use our theme,\ntweak it, or create your own. In case you’re interested, we’ve included\nthe code necessary to create our theme below (you’ll need the showtext\npackage to load a custom font).\n\n\nRemind me how we built theme_pma\n\n# Custom font \nlibrary(showtext)\nsysfonts::font_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext::showtext_auto()\nupdate_geom_defaults(\"text\", list(family = \"cabrito\", size = 4))\n\n# Theme \ntheme_pma <- theme_minimal() %+replace% \n  theme(\n    text = element_text(family = \"cabrito\", size = 13),\n    plot.title = element_text(size = 22, color = \"#00263A\",\n    hjust = 0, margin = margin(b = 5)),\n    plot.subtitle = element_text(hjust = 0, margin = margin(b = 10)),\n    strip.background = element_blank(),\n    strip.text.y = element_text(size = 16, angle = 0),\n    panel.spacing = unit(1, \"lines\"),\n    axis.title.y = element_text(angle = 0, margin = margin(r = 10))\n  )\n\n\n\nGrouped Bar Charts\nNow let’s revisit the grouped bar chart we made to\ncompare FPSTATUS_1 and FPSTATUS_2 for each\npopulation POP. We made this chart in basically two\nsteps.\nFirst, we used srvyr to\nbuild a summary table that incorporates survey weights from PANELWEIGHT\nand generates a 95% confidence interval for each estimate. We used EAID_1\nto generate the cluster-robust standard errors underlying each\nconfidence interval, and we stratified standard error estimation by\nSTRATA_RECODE.\nNotice that we group_by\nFPSTATUS_1 and FPSTATUS_2 here. When we do\nthis, survey_mean\nestimates the proportion of outcomes represented by the variable that\nappears last, which is FPSTATUS_2. The proportions\nsum to 1.0 for each combination of POP and\nFPSTATUS_1: in other words, we obtain the proportion of\nFPSTATUS_2 on the condition that women from a\ngiven POP held a particular status represented by\nFPSTATUS_1. For this reason, this is known as a\nconditional distribution.\n\n\nstatus_tbl <- dat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>%\n      group_by(FPSTATUS_1, FPSTATUS_2) %>% \n      summarise(survey_mean(prop = TRUE, prop_method = \"logit\", vartype = \"ci\"))\n  )\n\nstatus_tbl\n\n\n# A tibble: 54 × 6\n# Groups:   POP [6]\n   POP            FPSTATUS_1   FPSTATUS_2     coef `_low` `_upp`\n   <chr>          <fct>        <fct>         <dbl>  <dbl>  <dbl>\n 1 Burkina Faso   Pregnant     Pregnant     0.0302 0.0137 0.0652\n 2 Burkina Faso   Pregnant     Not Using FP 0.568  0.491  0.642 \n 3 Burkina Faso   Pregnant     Using FP     0.401  0.329  0.478 \n 4 Burkina Faso   Not Using FP Pregnant     0.0779 0.0651 0.0929\n 5 Burkina Faso   Not Using FP Not Using FP 0.739  0.711  0.765 \n 6 Burkina Faso   Not Using FP Using FP     0.183  0.158  0.211 \n 7 Burkina Faso   Using FP     Pregnant     0.0993 0.0815 0.121 \n 8 Burkina Faso   Using FP     Not Using FP 0.248  0.213  0.287 \n 9 Burkina Faso   Using FP     Using FP     0.653  0.609  0.694 \n10 DRC - Kinshasa Pregnant     Pregnant     0.0367 0.0140 0.0930\n# … with 44 more rows\n\nAs a second step, we plotted each conditional distribution as a\nseries of grouped bar charts arranged in facets\nby POP. Because we wanted to recycle the same layout for\nseveral similar variables, we wrapped all of the necessary ggplot2 tools together in a\ncustom function called pma_bars.\n\n\nRemind me how we built pma_bars\n\npma_bars <- function(\n  title = NULL,     # an optional title \n  subtitle = NULL,  # an optional subtitle \n  xaxis = NULL,     # an optional label for the x-axis (displayed above)\n  yaxis = NULL      # an optional label for the y-axis (displayed left)\n){\n  components <- list(\n    theme_pma,\n    labs(\n      title = title,\n      subtitle = subtitle,\n      y = str_wrap(yaxis, 10),\n      x = NULL,\n      fill = NULL\n    ),\n    scale_x_continuous(\n      position = 'bottom',\n      sec.axis = sec_axis(trans = ~., name = xaxis, breaks = NULL),\n      labels = scales::label_percent()\n    ),\n    scale_y_discrete(limits = rev),\n    geom_bar(stat = \"identity\", fill = \"#98579BB0\"),\n    geom_errorbar(\n      aes(xmin = `_low`, xmax = `_upp`), \n      width = 0.2, \n      color = \"#00263A\"\n    )\n  )\n}\n\n\n\n\n\nstatus_tbl %>% \n  ggplot(aes(x = coef, y = FPSTATUS_2)) + \n  facet_grid(cols = vars(FPSTATUS_1), rows = vars(POP)) + \n  pma_bars(\n    \"CHANGE IN CONTRACEPTIVE USE OR NON-USE\",\n    \"Percent women age 15-49 who changed contraceptive use status\",\n    xaxis = \"Phase 1 Status\",\n    yaxis = \"Phase 2 Status\"\n  )\n\n\n\n\nHeatmaps\nWe love this bar chart because it packs a lot of information into a\nsingle, reader-friendly graphic. However, we mentioned that it has some\nconsiderable drawbacks. Most importantly, we weren’t able to include\ninformation from the marginal distribution in each\nphase.\nA marginal distribution for FPSTATUS_1 would indicate\nthe likelihood that a woman began the survey period pregnant, using\nfamily planning, or not using family planning. Likewise the marginal\ndistribution for FPSTATUS_2 estimates the likelihood that a\nwoman would hold any such status at Phase 2, independently of\nher status at Phase 1. We call these distributions “marginal” because\nthey’re usually included in the row or column margins of a crosstab.\nLet’s return to status_tbl, but this time we’ll plot it\nas a crosstab with color and alpha\n(transparency) aesthetics. This type of crosstab is usually called a\nheatmap. First, we’ll again wrap a few cosmetic layout\noptions into a custom function we’ll call pma_heatmap.\n\nFor consistency, pma_heatmap uses the same color scheme\nshown in the first figure of each PMA report.\n\n\nShow me how pma_heatmap controls layout options\n\npma_heatmap <- function(\n    title = NULL,     # an optional title \n    subtitle = NULL,  # an optional subtitle \n    xaxis = NULL,     # an optional label for the x-axis (displayed below)\n    yaxis = NULL      # an optional label for the y-axis (displayed right)\n){\n  components <- list(\n    theme_pma %+replace% theme(\n      axis.text = element_text(size = 10),\n      strip.text.x = element_text(size = 16,\n                                  margin = margin(t = 10, b = 10)),\n      axis.title.y.right = element_text(angle = 0, margin = margin(l = 10)),\n      axis.title.x.bottom = element_text(margin = margin(t = 20)),\n      panel.grid = element_blank(),\n      legend.position = \"none\"\n    ),\n    labs(\n      title = title,\n      subtitle = subtitle,\n      x = xaxis,\n      y = str_wrap(yaxis, 10),\n    ),\n    scale_fill_manual(values = c(\n      \"Pregnant\" = \"#B4B3B3\",\n      \"Not Using FP\" = \"#4E4F71\",\n      \"Using FP\" = \"#EFD372\"\n    )),\n    scale_color_manual(values = c(\"black\", \"white\")),\n    scale_y_discrete(position = \"right\", limits = rev)\n  )\n}\n\n\n\nThe plot, itself, is built with rectangles from geom_tile\nand text labels from geom_text.\nBoth of these require a pair of x and y-coordinates, so we’ll specify\nthem globally in a ggplot\nfunction.\nThen, we tell geom_tile\nto use one fill color for each type of response in\nFPSTATUS_1: this makes it easy for the reader to see that\nthe totals in each tile sum to 100% in columns (not rows). The\nalpha aesthetic uses the value in coef to\ncontrol the transparency of each color (by default, our minimum value\n0 would be 100% transparent).\nThe aesthetics in geom_text\ninclude label and color. Only\nlabel is really necessary: it tells the function to use the\nvalue in coef as a text label, except that we use percent to stylize each number as a\npercentage rounded to the nearest integer. We’re also including\ncolor to switch the font color from black to white for\npurple tiles where coef is higher than 0.5:\nblack text would be too hard to read here.\nFinally, facet_wrap\nplots each POP separately. We use nrow = 3 to\nspecify three rows, and we use scales = \"fixed\" to save a\nbit of space: the labels for FPSTATUS_1 and\nFPSTATUS_2 are printed only once in the row and column\nmargins for the entire plot.\n\n\nstatus_tbl %>% \n  ggplot(aes(x = FPSTATUS_1, y = FPSTATUS_2)) +\n  geom_tile(aes(fill = FPSTATUS_1, alpha = coef)) + \n  geom_text(aes(\n    label = scales::percent(coef, 1),\n    color = coef > 0.5 & FPSTATUS_1 == \"Not Using FP\" # white vs black text\n  )) + \n  facet_wrap(~POP, nrow = 3, scales = \"fixed\") + \n  pma_heatmap(\n    \"CHANGE IN CONTRACEPTIVE USE OR NON-USE\",\n    \"Percent women age 15-49 who changed contraceptive use status\",\n    xaxis = \"Phase 1 Status\",\n    yaxis = \"Phase 2 Status\"\n  ) \n\n\n\n\nThe nice thing about this heatmap layout is that we can\neasily include data from the marginal distribution of\nFPSTATUS_1 and FPSTATUS_2. To do so, we’ll\nfirst need to add them to status_tbl. Note: because our\nheatmap is not well-suited for comparing confidence intervals, we’ll\nomit them in survey_mean\nwith the argument vartype = NULL.\n\n\ncol_margins <- dat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>%\n      group_by(FPSTATUS_1) %>% \n      summarise(cols = survey_mean(prop = TRUE, prop_method = \"logit\", vartype = NULL))\n  )\n  \nrow_margins <- dat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>%\n      group_by(FPSTATUS_2) %>% \n      summarise(rows = survey_mean(prop = TRUE, prop_method = \"logit\", vartype = NULL))\n  )\n\nstatus_tbl <- status_tbl %>% right_join(col_margins) %>% right_join(row_margins)\n\nstatus_tbl\n\n\n# A tibble: 54 × 8\n# Groups:   POP [6]\n   POP            FPSTATUS_1   FPSTATUS_2     coef `_low` `_upp`   cols   rows\n   <chr>          <fct>        <fct>         <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n 1 Burkina Faso   Pregnant     Pregnant     0.0302 0.0137 0.0652 0.0879 0.0799\n 2 Burkina Faso   Pregnant     Not Using FP 0.568  0.491  0.642  0.0879 0.583 \n 3 Burkina Faso   Pregnant     Using FP     0.401  0.329  0.478  0.0879 0.337 \n 4 Burkina Faso   Not Using FP Pregnant     0.0779 0.0651 0.0929 0.624  0.0799\n 5 Burkina Faso   Not Using FP Not Using FP 0.739  0.711  0.765  0.624  0.583 \n 6 Burkina Faso   Not Using FP Using FP     0.183  0.158  0.211  0.624  0.337 \n 7 Burkina Faso   Using FP     Pregnant     0.0993 0.0815 0.121  0.288  0.0799\n 8 Burkina Faso   Using FP     Not Using FP 0.248  0.213  0.287  0.288  0.583 \n 9 Burkina Faso   Using FP     Using FP     0.653  0.609  0.694  0.288  0.337 \n10 DRC - Kinshasa Pregnant     Pregnant     0.0367 0.0140 0.0930 0.0552 0.0533\n# … with 44 more rows\n\nTo keep things simple, we’ve named the marginal distribution for\nFPSTATUS_1 “cols”, and the marginal distribution for\nFPSTATUS_2 “rows”. Ultimately, we think it’s clearest to paste\nthese values (as percentages) together with the original labels from\nFPSTATUS_1 and FPSTATUS_2 (the symbol\n\\n represents a line break). We’ll also transform each\ncharacter string into a factor,\nwhich ensures that the values will be plotted in the same order that\nthey appear in our table.\nFinally, we switch from scales = \"fixed\" to\nscales = \"free\". This time, we’ll want to print the row and\ncolumn margins for each POP separately.\n\n\nstatus_tbl %>% \n  ggplot(aes(\n    x = paste0(scales::percent(cols, 1), \"\\n\", FPSTATUS_1) %>% as_factor, \n    y = paste0(scales::percent(rows, 1), \"\\n\", FPSTATUS_2) %>% as_factor\n  )) +\n  geom_tile(aes(fill = FPSTATUS_1, alpha = coef)) + \n  geom_text(aes(\n    label = scales::percent(coef, 1),\n    color = coef > 0.5 & FPSTATUS_1 == \"Not Using FP\"\n  )) + \n  facet_wrap(~POP, nrow = 3, scales = \"free\") + \n  pma_heatmap(\n    \"CHANGE IN CONTRACEPTIVE USE OR NON-USE\",\n    \"Percent women age 15-49 who changed contraceptive use status\",\n    xaxis = \"Phase 1 Status\",\n    yaxis = \"Phase 2 Status\"\n  )\n\n\n\n\nThe information contained in our heatmap is similar to what we saw in\nour bar chart, except for two things:\nThere are no error bars on our heatmap. If we wanted to include\ninformation about the confidence interval for each estimation, we would\nhave to include text\nsymbols.\nWhile both plots show information about the conditional distribution\nof FPSTATUS_2 given a starting point in\nFPSTATUS_1, only the heatmap includes the marginal\ndistribution of each variable in its row and column margins.\nThe marginal distribution may provide crucial information about the\nconditional distribution that we would otherwise miss. Consider Burkina\nFaso, where both users and non-users of family planning at Phase 1 were\ngenerally most likely to maintain their status at Phase 2. The marginal\ndistribution adds additional information: non-users comprise a larger\nshare of the overall population at Phase 1.\nIn certain contexts, you may want to combine information from the\nPhase 1 marginal distribution together with the conditional distribution\nof outcomes at Phase 2. To continue with our example from Burkina Faso,\nyou might report that - because non-users represent about 62% of the\npopulation, only about 11% of the population adopted family planning at\nPhase 2 following non-use at Phase 1. That is: 18% of 62% is 11%.\nIn contrast with the conditional distribution, this type of\ndistribution describes the share of the population that experiences some\ncombination of Phase 1 and Phase 2 outcomes without assuming a\nparticular starting point at Phase 1. It’s known as a joint\ndistribution because it gives the probability that two events\nwill happen together (in sequence). Let’s return to our summary table,\nstatus_tbl:\n\n\nstatus_tbl\n\n\n# A tibble: 54 × 8\n# Groups:   POP [6]\n   POP            FPSTATUS_1   FPSTATUS_2     coef `_low` `_upp`   cols   rows\n   <chr>          <fct>        <fct>         <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n 1 Burkina Faso   Pregnant     Pregnant     0.0302 0.0137 0.0652 0.0879 0.0799\n 2 Burkina Faso   Pregnant     Not Using FP 0.568  0.491  0.642  0.0879 0.583 \n 3 Burkina Faso   Pregnant     Using FP     0.401  0.329  0.478  0.0879 0.337 \n 4 Burkina Faso   Not Using FP Pregnant     0.0779 0.0651 0.0929 0.624  0.0799\n 5 Burkina Faso   Not Using FP Not Using FP 0.739  0.711  0.765  0.624  0.583 \n 6 Burkina Faso   Not Using FP Using FP     0.183  0.158  0.211  0.624  0.337 \n 7 Burkina Faso   Using FP     Pregnant     0.0993 0.0815 0.121  0.288  0.0799\n 8 Burkina Faso   Using FP     Not Using FP 0.248  0.213  0.287  0.288  0.583 \n 9 Burkina Faso   Using FP     Using FP     0.653  0.609  0.694  0.288  0.337 \n10 DRC - Kinshasa Pregnant     Pregnant     0.0367 0.0140 0.0930 0.0552 0.0533\n# … with 44 more rows\n\nTo find the estimated joint distribution for each combination of\nFPSTATUS_1 and FPSTATUS_2, you could simply\nmultiply each value in cols by the value in\ncoef:\n\n\nstatus_tbl %>% mutate(joint = cols * coef)\n\n\n# A tibble: 54 × 9\n# Groups:   POP [6]\n   POP            FPSTATUS_1   FPSTATUS_2     coef `_low` `_upp`   cols   rows   joint\n   <chr>          <fct>        <fct>         <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n 1 Burkina Faso   Pregnant     Pregnant     0.0302 0.0137 0.0652 0.0879 0.0799 0.00266\n 2 Burkina Faso   Pregnant     Not Using FP 0.568  0.491  0.642  0.0879 0.583  0.0499 \n 3 Burkina Faso   Pregnant     Using FP     0.401  0.329  0.478  0.0879 0.337  0.0353 \n 4 Burkina Faso   Not Using FP Pregnant     0.0779 0.0651 0.0929 0.624  0.0799 0.0486 \n 5 Burkina Faso   Not Using FP Not Using FP 0.739  0.711  0.765  0.624  0.583  0.461  \n 6 Burkina Faso   Not Using FP Using FP     0.183  0.158  0.211  0.624  0.337  0.114  \n 7 Burkina Faso   Using FP     Pregnant     0.0993 0.0815 0.121  0.288  0.0799 0.0286 \n 8 Burkina Faso   Using FP     Not Using FP 0.248  0.213  0.287  0.288  0.583  0.0713 \n 9 Burkina Faso   Using FP     Using FP     0.653  0.609  0.694  0.288  0.337  0.188  \n10 DRC - Kinshasa Pregnant     Pregnant     0.0367 0.0140 0.0930 0.0552 0.0533 0.00203\n# … with 44 more rows\n\nIn practice, you’ll usually want to let srvyr calculate a confidence interval\nfor each joint probability. To do so, we’ll add an interact\nfunction listing the variables in group_by that we\nwant to model jointly.\n\n\njoint_tbl <- dat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>%\n      group_by(interact(FPSTATUS_1, FPSTATUS_2)) %>% \n      summarise(joint = survey_mean(prop = TRUE, prop_method = \"logit\", vartype = \"ci\"))\n  )\n  \njoint_tbl\n\n\n# A tibble: 54 × 6\n# Groups:   POP [6]\n   POP            FPSTATUS_1   FPSTATUS_2     joint joint_low joint_upp\n   <chr>          <fct>        <fct>          <dbl>     <dbl>     <dbl>\n 1 Burkina Faso   Pregnant     Pregnant     0.00266  0.00120    0.00587\n 2 Burkina Faso   Pregnant     Not Using FP 0.0499   0.0404     0.0615 \n 3 Burkina Faso   Pregnant     Using FP     0.0353   0.0291     0.0427 \n 4 Burkina Faso   Not Using FP Pregnant     0.0486   0.0402     0.0588 \n 5 Burkina Faso   Not Using FP Not Using FP 0.461    0.428      0.495  \n 6 Burkina Faso   Not Using FP Using FP     0.114    0.100      0.130  \n 7 Burkina Faso   Using FP     Pregnant     0.0286   0.0228     0.0357 \n 8 Burkina Faso   Using FP     Not Using FP 0.0713   0.0613     0.0829 \n 9 Burkina Faso   Using FP     Using FP     0.188    0.164      0.214  \n10 DRC - Kinshasa Pregnant     Pregnant     0.00203  0.000794   0.00515\n# … with 44 more rows\n\nNow, the values in joint sum to 1.0 for\neach POP. Returning to our heatmap, we’ll want to use the\nsame color for every column, indicating that the percentages sum for\n100% for each population.\n\n\njoint_tbl %>% \n  ggplot(aes(x = FPSTATUS_1, y = FPSTATUS_2)) +\n  geom_tile(aes(alpha = joint), fill = \"#98579B\") + \n  geom_text(aes(\n    label = scales::percent(joint, 1),\n    color = joint > 0.5 & FPSTATUS_1 == \"Not Using FP\"\n  )) + \n  facet_wrap(~POP, nrow = 3, scales = \"fixed\") + \n  pma_heatmap(\n    \"CHANGE IN CONTRACEPTIVE USE OR NON-USE\",\n    \"Percent women age 15-49 who changed contraceptive use status\",\n    xaxis = \"Phase 1 Status\",\n    yaxis = \"Phase 2 Status\"\n  ) \n\n\n\n\nInformation provided by the joint distribution nuances our story a\nbit further. To continue with our examination of Burkina Faso: we knew\nthat family planning users and non-users at Phase 1 were each most\nlikely to maintain, rather than switch their status at Phase 2. However,\nit’s now clear that continuous non-users (non-users at both\nPhase 1 and Phase 2) represent a near-majority of the population.\nAlluvial plots\nAlluvial plots are an especially popular way to\nvisualize longitudinal data, in part, because they combine information\nfrom each of the three distributions we’ve discussed. They also make it\npossible to show data from more than two variables (we’ll use them again\nwhen Phase 3 data become available). You’ll find alluvial plots on the\nfirst two pages of the PMA report for each sample.\nIn an alluvial plot, the marginal distribution of responses for each\nvariable are usually plotted in vertical stacks. The ggalluvial\npackage authors refer to these stacks as “strata”, and they may be\nlayered onto a ggplot\nwith geom_stratum.\nIn our case, the strata will show the marginal distribution of women in\nFPSTATUS_1 and FPSTATUS_2.\nThe joint distribution for any pair of variables is\nplotted in horizontal splines called “alluvia”, which bridge the space\nbetween any given pair of strata. Alluvia are plotted with geom_flow.\nFinally, we’ll use color to map each alluvium with an originating\nstratum from FPSTATUS_1. This will help the reader\nvisualize the conditional distribution of FPSTATUS_2\nresponses given a starting point in FPSTATUS_1.\nTo begin, let’s revisit joint_tbl, which only contains\nthe joint distribution for FPSTATUS_1 and\nFPSTATUS_2. In fact, ggalluvial\nwill calculate the marginal distribution for both variables\nautomatically if we reshape joint_tbl with pivot_longer\nlike so:\n\n\njoint_tbl <- joint_tbl %>% \n  rowid_to_column(\"alluvium\") %>% \n  pivot_longer(\n    c(FPSTATUS_1, FPSTATUS_2), \n    names_to = \"x\", \n    values_to = \"stratum\"\n  ) %>% \n  mutate(x = ifelse(x == \"FPSTATUS_1\", \"Phase 1\", \"Phase 2\")) %>% \n  arrange(x, alluvium)\n\njoint_tbl\n\n\n# A tibble: 108 × 7\n# Groups:   POP [6]\n   alluvium POP              joint joint_low joint_upp x       stratum     \n      <int> <chr>            <dbl>     <dbl>     <dbl> <chr>   <fct>       \n 1        1 Burkina Faso   0.00266  0.00120    0.00587 Phase 1 Pregnant    \n 2        2 Burkina Faso   0.0499   0.0404     0.0615  Phase 1 Pregnant    \n 3        3 Burkina Faso   0.0353   0.0291     0.0427  Phase 1 Pregnant    \n 4        4 Burkina Faso   0.0486   0.0402     0.0588  Phase 1 Not Using FP\n 5        5 Burkina Faso   0.461    0.428      0.495   Phase 1 Not Using FP\n 6        6 Burkina Faso   0.114    0.100      0.130   Phase 1 Not Using FP\n 7        7 Burkina Faso   0.0286   0.0228     0.0357  Phase 1 Using FP    \n 8        8 Burkina Faso   0.0713   0.0613     0.0829  Phase 1 Using FP    \n 9        9 Burkina Faso   0.188    0.164      0.214   Phase 1 Using FP    \n10       10 DRC - Kinshasa 0.00203  0.000794   0.00515 Phase 1 Pregnant    \n# … with 98 more rows\n\nHere, we create the column alluvium to hold the original\nrow number for each of the 56 combinations of POP,\nFPSTATUS_1, and FPSTATUS_2. When we pivot_longer,\nwe repeat the value in joint once for each end of the same\nalluvium. The values in stratum describe the\nstrata to to which each alluvium is attached, and x\nindicates whether the stratum is located in the Phase 1 or Phase 2\nstack.\nAs with our heatmap, we’ll want to define some custom fonts, color,\nand layout options adapted from theme_pma. We’ll bundle\nthese together in a function called pma_alluvial - feel\nfree to use, adjust, or omit this function for your own purposes.\n\nFor consistency, pma_alluvial uses the same color scheme\nshown in the first alluvial plot in each PMA report.\n\n\nShow me how pma_alluvial controls layout options\n\npma_alluvial <- function(\n    title = NULL,     # an optional title \n    subtitle = NULL,  # an optional subtitle \n    xaxis = NULL,     # an optional label for the x-axis (displayed below)\n    yaxis = NULL      # an optional label for the y-axis (displayed left)\n){\n  components <- list(\n    theme_pma %+replace% theme(\n      plot.title = element_text(size = 22, color = \"#541E5A\", \n                                hjust = 0.5, mar = margin(b = 5)),\n      plot.subtitle = element_text(hjust = 0.5, margin = margin(b = 20)),\n      axis.text.x = element_text(color = \"#541E5A\", \n                                 margin = margin(t = 5, b = 10)),\n      strip.text.x = element_text(size = 13, margin = margin(b = 5)),\n      plot.margin = margin(0, 100, 0, 100),\n      legend.position = \"bottom\",\n      legend.title = element_blank(),\n      legend.spacing.x = unit(10, \"pt\"),\n      panel.grid = element_blank(),\n      axis.text.y = element_blank()\n    ),\n    labs(\n      title = title,\n      subtitle = subtitle,\n      x = xaxis,\n      y = str_wrap(yaxis, 10),\n    ),\n    scale_fill_manual(values = c(\n      \"Pregnant\" = \"#B4B3B3\", \n      \"Not Using FP\" = \"#4E4F71\", \n      \"Using FP\" = \"#EFD372\"\n    )),\n    scale_y_continuous(expand = c(0, 0))\n  )\n}\n\n\n\nWe’ll start by mapping common aesthetics in a ggplot\nfunction. We’ll map the values in x onto our x-axis, and\nwe’ll map the values in joint onto the y-axis. The\nremaining aesthetics are specific to the functions from ggalluvial:\nwe’ll use stratum to build vertical strata and to define\ncolors mapped with “fill”. We also use the identifying numbers in\nalluvium to organize responses into alluvia.\nThe remaining functions are straightforward, since they mainly use\ninformation passed from ggplot.\nWe make only one small modification to geom_stratum:\nsetting size = 0 removes border lines that appear around\neach stratum, by default.\n\n\nstatus_alluvial <- joint_tbl %>% \n  ggplot(aes(\n    x = x, \n    y = joint,\n    fill = stratum,\n    stratum = stratum,\n     alluvium = alluvium\n  )) + \n  geom_flow() + \n  geom_stratum(size = 0) + \n  facet_wrap(~POP, scales = \"free_x\", nrow = 1) + \n  pma_alluvial(\n    \"CHANGE IN CONTRACEPTIVE USE OR NON-USE\",\n    \"Percent women age 15-49 who changed contraceptive use status\",\n  ) \n\nstatus_alluvial\n\n\n\n\nOf course, you should always include either y-axis gridlines or text\nlabels for the probabilities shown on a plot like this one. We find it\nclearer to include the latter, which we’ll build with geom_text.\nThese labels are a bit tricky, but the basic idea is that you use\nstat = \"stratum\" to label strata, and\nstat = \"flow\" to label alluvia. Then, you use after_stat\nto build labels from statistics that ggalluvial\nuses to construct the plot - check out this\nlist of available statistics for details. We’ll use the\nprop statistic to obtain both the marginal and\njoint probabilities for each outcome (we’ll leave the conditional\nprobabilities unlabeled, but you could adjust this code to include them\nhere).\n\nValues may not add to 100% due to rounding (values rounded to 0% are not\nlabelled).\n\n\nstatus_alluvial +\n  geom_text(\n    stat = \"stratum\",   # label strata\n    aes(label = ifelse( \n      x == 1, # labels the strata for Phase 1, otherwise blank \"\"           \n      scales::percent(after_stat(prop), 1), \n      \"\"\n    )),\n    nudge_x = -0.2,  # nudge a bit to the left \n    hjust = \"right\", # right-justify\n  ) + \n  geom_text(\n    stat = \"stratum\", # label strata\n    aes(label = ifelse(\n      x == 2, # labels the strata for Phase 2, otherwise blank \"\"    \n      scales::percent(after_stat(prop), 1), \n      \"\"\n    )),\n    nudge_x = 0.2,  # nudge a bit to the right \n    hjust = \"left\", # left-justify\n  ) +\n  geom_text(\n    stat = \"flow\",   # label alluvia \n    aes(label = ifelse( \n      after_stat(flow) == \"to\" &  # only label the destination (right-side)\n        after_stat(prop) >= 0.01, # hide if 0%\n      scales::percent(after_stat(prop), 1), \n      \"\" \n    )),\n    nudge_x = -0.2,  # nudge a bit to the left\n    hjust = \"right\", # right-justify\n    size = 3         # use a slightly smaller font \n  ) \n\n\n\n\nNow, it’s easy to identify the proportion of women at each phase\nand the proportion who switched or maintained their status\nbetween phases. If possible, we recommend aligning alluvial plots for\nevery sample in a single row as shown: this allows the readers to\nvisually compare the relative size of strata and alluvia across\nsamples.\nNext Steps\nSo far in this\nseries, we’ve covered topics related to:\nData availability\nInstructions of obtaining\ndata\nSample design\nKey family planning\nindicators\nData Visualization\nIn two weeks, we’ll be wrapping up this introduction to PMA Panel\nData with an update on a topic we first covered last year: the contraceptive\ncalendar section of the Female Questionnaire. As we’ll see, the\ncalendar adds a different temporal dimension to the panel study: it\nrepresents the contraceptive use, non-use, and pregnancy status of women\nrecalled on a monthly basis for several months prior the\ninterview. We’ll show how to parse these data from string-format, and\nhow to merge responses obtained at Phase 1 and Phase 2 for each\nwoman.\n\n\n\n",
    "preview": "posts/2022-05-01-phase2-alluvial/images/long.png",
    "last_modified": "2022-07-26T12:38:22-04:00",
    "input_file": {},
    "preview_width": 2284,
    "preview_height": 1920
  },
  {
    "path": "posts/2022-04-15-phase2-indicators/",
    "title": "Calculating Key Indicators for Family Planning Panel Data",
    "description": "We show how to reproduce measures featured in PMA panel reports, and how to visualize significant differences between groups in figures built with ggplot2.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-04-19",
    "categories": [
      "Panel Data",
      "Data Visualization",
      "Data Analysis",
      "Family Planning",
      "Weights",
      "Sample Clusters",
      "ggplot2",
      "srvyr"
    ],
    "contents": "\n\nContents\nSetup\nPopulations of Interest\nPopulation Inference\nVisualization\nKey Indicators\nContraceptive Use or\nNon-Use\nContraceptive Method\nType\nContraceptive Dynamics\nby Subgroup\nAge\nEducation level\nMarital status\nParity\n\nOther Panel Dynamics\nUnmet need\nPartner support\nIntentions\n\n\nWrap-up\n\n\n\n\nWe’ve mentioned in previous posts in this series that data from the new\nPMA panel study\ngives researchers an important tool for understanding how women’s family\nplanning demand and utilization changes over time. In particular, PMA\nsurveys cover topics like:\npregnancy intentions and outcomes\ncurrent use of long-acting, short-acting, and traditional\ncontraceptives\ndiscontinuation of family planning\nintentions for future use of family planning\nunmet need for family planning\npartner’s support for use of family planning\nIPUMS PMA recently released harmonized data from\nfour of the participating countries where the first two phases of data\ncollection in this three-year panel study have already been completed.\nIn this post, we’ll demonstrate how to use an IPUMS PMA data extract to\ncalculate and compare key family planning indicators across multiple\nsamples.\nOur partners at PMA have published indicators for each of these\nsamples, individually. Phase 2 panel results summaries are available\nfor:\nBurkina\nFaso\nDRC\n- Kinshasa\nDRC\n- Kongo Central\nKenya\nNigeria\n- Kano\nNigeria\n- Lagos\n\nInterested in building the alluvial plots seen in these\nreports? Join us again in two weeks, when we’ll dig into the ggalluvial\npackage!\nHere, we’ll share code you can use to reproduce the findings in each\nreport, and we’ll demonstrate one simple approach to visualizing\nindicators across samples with ggplot2, a popular\ngraphics package included in the tidyverse toolkit\nfor R.\nSetup\nTo get started, you’ll need to load three main packages:\ntidyverse,\nwhich includes ggplot2 and other\ndata manipulation tools\nipumsr for working\nwith IPUMS data\nsrvyr for use of\nsurvey design information (survey weights and sample cluster IDs)\nsrvyr brings tidyverse syntax\nto the popular survey package.\n\n\nlibrary(tidyverse)\nlibrary(ipumsr)\nlibrary(srvyr)\n\n\n\nWe’ll feature data organized in wide format for each\nof the six samples currently available from IPUMS PMA. You’ll find the\n“wide” option under the “Longitudinal” sample button on our Select Samples\npage.\n\nIPUMS PMA also publishes panel data in long format.\nCheck out our complete guide to\nlongitudinal data extracts for details.\n\n\n\nNotice that, under “Sample Members”, we’ve selected the button for\n“Female Respondents”. This excludes records for all household members\nwho are not, themselves, members of the panel study. You’ll find one row\nfor each woman who completed all or part of the Female Questionnaire for\nat least one phase of the study.\n\nFor details on panel enrollment and loss to follow-up, see our panel membership guide.\nAdd the following variables to you Data Cart, then click the View\nCart button to begin checkout (preselected\nvariables are added automatically).\nRESULTFQ\n- Result of female questionnaire\nPANELWEIGHT\n- Phase 2 female panel weight\nRESIDENT\n- Household residence / membership\nAGE\n- Age in female questionnaire\nPREGNANT\n- Pregnancy status\nBIRTHEVENT\n- Number of birth events\nEDUCATTGEN\n- Highest level of school attended (4 categories)\nMARSTAT\n- Marital status\nGEOCD\n- Province, DRC\nGEONG\n- State, Nigeria\nCP\n- Contraceptive user\nFPCURREFFMETHRC\n- Most effective current FP method\nUNMETYN\n- Total unmet need\nFPPARTSUPPORT\n- Husband / partner would be supportive of FP use\nFPPLANVAL\n- When will start using FP method in the future - value\nFPPLANWHEN\n- When will start using FP method in the future - unit\nCOUNTRY\n- PMA country (preselected)\nEAID\n- Enumeration area (preselected)\nBefore completing checkout, make sure that you’ve selected the\ndat data format (fixed-width text).\n\n\n\nFinally, you’ll need to download 2 files: an xml\nmetadata file and a dat.gz compressed data file. We’ve\nsaved both of these files in the “data” folder in R’s working directory,\nso we’ll import both to create a dataframe called dat:\n\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00106.xml\",\n  data = \"data/pma_00106.dat.gz\"\n)\n\n\n\nPopulations of Interest\nWe’ve mentioned in previous posts that PMA samples are only valid for\nthe de\nfacto population: these are women who slept in the household during\nthe night before the interview for the Household Questionnaire in both\nphases. These women are coded either 11 or 22\nin both RESIDENT_1 and RESIDENT_2.\n\n\ndat <- dat %>% filter(RESIDENT_1 %in% c(11, 22) & RESIDENT_2 %in% c(11, 22))\n\n\n\nWe also mentioned in our sample membership guide that\nwomen who completed the Phase 1 Female Questionnaire may have been\nlost to follow-up at Phase 2. As a reminder, we’ll need\nto drop any cases where RESULTFQ_2 is not coded\n1 for “completed”.\n\n\ndat <- dat %>% filter(RESULTFQ_2 == 1)\n\n\n\nAdditionally, a small number of women in each sample elected not to\nrespond to key questions regarding current use of contraceptives. These\ncases are coded 90 and above, as shown on the CP\nCodes tab. In a wide extract, these cases can be\nidentified with CP_1 and CP_2.\n\n\ndat <- dat %>% filter(CP_1 < 90, CP_2 < 90) \n\n\n\nFinally, recall that only the Burkina Faso and Kenya samples are\nnationally representative. Samples from DRC represent\nregions identified by GEOCD,\nwhile samples from Nigeria represent regions identified by GEONG.\nIn order to distinguish each population of interest, we’ll define a\ncustom variable POP that shows each sample’s COUNTRY\nlabel concatenated with each of these regions where appropriate.\nPOP - Population of interest\n\n\ndat <- dat %>% \n  mutate(POP = case_when(\n    !is.na(GEOCD) ~ paste(\"DRC -\", as_factor(GEOCD)),\n    !is.na(GEONG) ~ paste(\"Nigeria -\", as_factor(GEONG)),\n    TRUE ~ as_factor(COUNTRY) %>% as.character()\n  ))\n\n\n\nThe remaining sample size for each population of interest is simply a\ncount of\neach level in POP.\n\n\ndat %>% count(POP)\n\n\n# A tibble: 6 × 2\n  POP                     n\n  <chr>               <int>\n1 Burkina Faso         5207\n2 DRC - Kinshasa       1967\n3 DRC - Kongo Central  1511\n4 Kenya                6934\n5 Nigeria - Kano        998\n6 Nigeria - Lagos      1088\n\nPopulation Inference\nWe’ll use the srvyr\npackage to incorporate survey design information into each of the\npopulation estimates calculated below. This includes PANELWEIGHT,\nwhich represents the calculated inverse selection probability for all\npanel members, adjusted for loss to follow-up.\nYou might remember from earlier\nposts that PMA surveys are collected within spatially-defined\nsample clusters. We’ll also include identifying numbers\nfor each cluster as survey design information via EAID.\nHere, we’ll use clusters identified in EAID_1.1\nMost PMA samples are also collected within separate strata indicated\nby STRATA.\nWe’ve previously\nnoted that STRATA is not available for samples\ncollected from DRC - Kinshasa and DRC - Kongo Central, so we\ndemonstrated how to create placeholder codes for those samples in a\nvariable we called STRATA_RECODE. To review:\nSTRATA_RECODE uses unique numeric codes from\nSTRATA, except that it also includes unique identifiers for\neach sampled region in GEOCD.\n\n\ndat <- dat %>% \n  mutate(\n    STRATA_RECODE = if_else(\n      is.na(GEOCD), \n      as.numeric(STRATA_1), \n      as.numeric(GEOCD)\n    )\n  ) \n\ndat %>% count(STRATA_1, GEOCD, STRATA_RECODE) \n\n\n# A tibble: 28 × 4\n                            STRATA_1              GEOCD STRATA_RECODE     n\n                           <int+lbl>          <int+lbl>         <dbl> <int>\n 1 40410 [Bungoma - urban, Kenya]    NA                         40410   153\n 2 40411 [Bungoma - rural, Kenya]    NA                         40411   488\n 3 40412 [Kakamega - urban, Kenya]   NA                         40412   133\n 4 40413 [Kakamega - rural, Kenya]   NA                         40413   438\n 5 40414 [Kericho - urban, Kenya]    NA                         40414   249\n 6 40415 [Kericho - rural, Kenya]    NA                         40415   453\n 7 40416 [Kiambu - urban, Kenya]     NA                         40416   213\n 8 40417 [Kiambu - rural, Kenya]     NA                         40417   311\n 9 40418 [Kilifi - urban, Kenya]     NA                         40418   170\n10 40419 [Kilifi - rural, Kenya]     NA                         40419   455\n11 40420 [Kitui - urban, Kenya]      NA                         40420   153\n12 40421 [Kitui - rural, Kenya]      NA                         40421   585\n13 40422 [Nairobi - urban, Kenya]    NA                         40422   493\n14 40423 [Nandi - urban, Kenya]      NA                         40423   260\n15 40424 [Nandi - rural, Kenya]      NA                         40424   711\n16 40425 [Nyamira - urban, Kenya]    NA                         40425   143\n17 40426 [Nyamira - rural, Kenya]    NA                         40426   382\n18 40427 [Siaya - urban, Kenya]      NA                         40427   130\n19 40428 [Siaya - rural, Kenya]      NA                         40428   437\n20 40429 [West Pokot - urban, Kenya] NA                         40429   104\n21 40430 [West Pokot - rural, Kenya] NA                         40430   473\n22 56606 [Lagos, Nigeria]            NA                         56606  1088\n23 56611 [Kano - Urban]              NA                         56611   437\n24 56612 [Kano - Rural]              NA                         56612   561\n25 85401 [Urban, Burkina Faso]       NA                         85401  3053\n26 85402 [Rural, Burkina Faso]       NA                         85402  2154\n27    NA                              1 [Kinshasa]                  1  1967\n28    NA                              2 [Kongo Central]             2  1511\n\nThe srvyr function as_survey_design\nallows us to pass the information in PANELWEIGHT,\nEAID_1, and STRATA_RECODE to other package\nfunctions like survey_mean.\nWe’ll also demonstrate how to use this information in formal\nsignificance tests within each sample via svychisq.\n\nCheck out this\npost for more information on PMA survey design and the srvyr package.\nLet’s begin with a simple example. The variable CP\nindicates whether a woman was currently using any family planning\nmethod. The variables CP_1 and CP_2 in our\nwide extract represent responses collected at Phase 1\nand Phase 2, respectively. With help from srvyr, we’ll obtain a\npopulation-level estimate of the proportion of women who were using a\nmethod at Phase 2, given their status at Phase 1.\n\n\ncp_tbl <- dat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n      group_by(CP_1, CP_2) %>% \n      summarise(survey_mean(vartype = \"ci\", prop = TRUE, prop_method = \"logit\"))\n  )\n\ncp_tbl\n\n\n# A tibble: 24 × 6\n# Groups:   POP [6]\n   POP                      CP_1      CP_2   coef `_low` `_upp`\n   <chr>               <int+lbl> <int+lbl>  <dbl>  <dbl>  <dbl>\n 1 Burkina Faso          0 [No]    0 [No]  0.790  0.763  0.815 \n 2 Burkina Faso          0 [No]    1 [Yes] 0.210  0.185  0.237 \n 3 Burkina Faso          1 [Yes]   0 [No]  0.347  0.306  0.391 \n 4 Burkina Faso          1 [Yes]   1 [Yes] 0.653  0.609  0.694 \n 5 DRC - Kinshasa        0 [No]    0 [No]  0.739  0.685  0.787 \n 6 DRC - Kinshasa        0 [No]    1 [Yes] 0.261  0.213  0.315 \n 7 DRC - Kinshasa        1 [Yes]   0 [No]  0.275  0.239  0.314 \n 8 DRC - Kinshasa        1 [Yes]   1 [Yes] 0.725  0.686  0.761 \n 9 DRC - Kongo Central   0 [No]    0 [No]  0.736  0.685  0.782 \n10 DRC - Kongo Central   0 [No]    1 [Yes] 0.264  0.218  0.315 \n11 DRC - Kongo Central   1 [Yes]   0 [No]  0.270  0.207  0.343 \n12 DRC - Kongo Central   1 [Yes]   1 [Yes] 0.730  0.657  0.793 \n13 Kenya                 0 [No]    0 [No]  0.697  0.676  0.717 \n14 Kenya                 0 [No]    1 [Yes] 0.303  0.283  0.324 \n15 Kenya                 1 [Yes]   0 [No]  0.200  0.183  0.217 \n16 Kenya                 1 [Yes]   1 [Yes] 0.800  0.783  0.817 \n17 Nigeria - Kano        0 [No]    0 [No]  0.946  0.910  0.968 \n18 Nigeria - Kano        0 [No]    1 [Yes] 0.0544 0.0321 0.0905\n19 Nigeria - Kano        1 [Yes]   0 [No]  0.440  0.308  0.581 \n20 Nigeria - Kano        1 [Yes]   1 [Yes] 0.560  0.419  0.692 \n21 Nigeria - Lagos       0 [No]    0 [No]  0.757  0.713  0.796 \n22 Nigeria - Lagos       0 [No]    1 [Yes] 0.243  0.204  0.287 \n23 Nigeria - Lagos       1 [Yes]   0 [No]  0.240  0.196  0.290 \n24 Nigeria - Lagos       1 [Yes]   1 [Yes] 0.760  0.710  0.804 \n\nHere, we first use group_by to\ndivide the data extract into individual samples defined by\nPOP. We then reference each of these samples as cur_data\ninside a summary function defined by summarise -\nthis ensures that the population estimates obtained from our combined\ndata extract are identical to those you would obtain if you downloaded\none extract for each sample and analyzed them separately.\nWithin summarise, we\nuse as_survey_design\nto specify information about the design of each sample, and we then use\na second group_by to\nidentify each of our variables of interest, CP_1 and\nCP_2. Finally, we use a second summarise\nfunction to calculate a srvyr summary statistic: in\nthis case, we use survey_mean\nto estimate proportions in the population.\nThe population estimate for each row appears in the column\n_coef. Looking at row 1, we would estimate that 79% of\nwomen aged 15-49 in Burkina Faso used no method both at Phase 1\nand again at Phase 2. The columns _low and\n_upp report the limits of a 95% confidence interval: 76.3%\nand 81.5%.\n\nYou may change the confidence interval to, for example, 99% by setting\nlevel = 0.99 in survey_mean.\nComparing these confidence intervals gives us an informal,\nconservative way to test for a significant difference between outcomes\nfor each POP: if the intervals for any pair of outcomes in\nthe same sample include no common values, we’ll say that a significant\ndifference exists. Formal testing may also reveal significant\ndifferences between pairs of outcomes where these intervals overlap only\nslightly. Our approach is well suited for data visualization, but\nit should not replace formal testing. Fortunately, you can adapt our\ncode to replace (or complement) the output from survey_mean.\nFor example, here we demonstrate how to calculate a Rao-Scott\nchi-square test for significant differences between the estimated\npopulation proportions for each POP and the proportions we\nwould expect to observe if Phase 2 outcomes were statistically\nindependent from Phase 1 conditions.2 Because we’re interested\nin just one summary statistic per sample, we no longer need to group_by\nCP_1 and CP_2; instead, we’ll use the formula\n~CP_1 + CP_2 in the function svychisq.\n\n\nrao_tbl <- dat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1,  strata = STRATA_RECODE) %>% \n      summarise(rao = svychisq(~CP_1 + CP_2, design = .) %>% list)\n  )\n\nrao_tbl\n\n\n# A tibble: 6 × 2\n# Groups:   POP [6]\n  POP                 rao    \n  <chr>               <list> \n1 Burkina Faso        <htest>\n2 DRC - Kinshasa      <htest>\n3 DRC - Kongo Central <htest>\n4 Kenya               <htest>\n5 Nigeria - Kano      <htest>\n6 Nigeria - Lagos     <htest>\n\nOur new summary column rao contains output for each\nsample’s test in a list.\nFrom here, you can extract output elements rowwise by\nname like so:\n\n\nrao_tbl %>% \n  rowwise() %>% \n  mutate(\n    `F` = rao$statistic, \n    p.value = rao$p.value,\n    sig95 = p.value < 0.05\n  )\n\n\n# A tibble: 6 × 5\n# Rowwise:  POP\n  POP                 rao          F   p.value sig95\n  <chr>               <list>   <dbl>     <dbl> <lgl>\n1 Burkina Faso        <htest>  468.  4.62e- 50 TRUE \n2 DRC - Kinshasa      <htest>  216.  4.80e- 21 TRUE \n3 DRC - Kongo Central <htest>  123.  9.43e- 16 TRUE \n4 Kenya               <htest> 1140.  8.58e-102 TRUE \n5 Nigeria - Kano      <htest>   89.2 2.23e-  9 TRUE \n6 Nigeria - Lagos     <htest>  204.  2.85e- 19 TRUE \n\nVisualization\nWe’ll use simple grouped bar charts to show\npopulation estimates for each proportion below. A grouped bar chart\ndiffers from the stacked bar charts shown in PMA\nreports in that each response is plotted along an axis (rather than\nstacked together in a single bar). We’ll show grouped bar\ncharts here so that we can also include error\nbars representing a 95% confidence interval for each\nproportion.\nFor example, let’s plot the estimates created in cp_tbl\nabove. As a preliminary step, we’ll recode CP_1 and\nCP_2 with as_factor\nand sort their levels with fct_relevel.\nThis ensures that the value labels for each variable will be\nprinted on our plot.\n\n\ncp_tbl <- cp_tbl %>% \n  mutate(\n    across(\n      c(CP_1, CP_2),\n      ~as_factor(.x) %>% fct_relevel(\"No\", \"Yes\")\n    )\n  )\n\n\n\nNext, we’ll use ggplot2\nto build the plot. Because our data includes multiple samples, we’ll use\nfacet_grid\nto plot all summary data in multiple panels. The functions geom_bar\nand geom_errorbar\nplot the grouped bars and error bars, respectively. A baseline plot\nshould look something like this:\n\n\ncp_tbl %>% \n  ggplot(aes(x = coef, y = CP_2)) + \n  facet_grid(rows = vars(POP), cols = vars(CP_1)) + \n  geom_bar(stat = \"identity\") + \n  geom_errorbar(aes(xmin = `_low`, xmax = `_upp`), width = 0.2)\n\n\n\n\nOne of the powerful features of ggplot2\nis that you can use pre-built\nthemes to customize this baseline layout. We’ll build on theme_minimal\nto create our own theme_pma (with custom fonts incorporated\nby the sysfonts and showtext\npackages). Feel free to use our theme, or tweak it to create\nyour own!\n\n\nlibrary(showtext)\n\nsysfonts::font_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext::showtext_auto()\n\ntheme_pma <- theme_minimal() %+replace% \n  theme(\n    text = element_text(family = \"cabrito\", size = 13),\n    plot.title = element_text(size = 22, color = \"#00263A\", \n                              hjust = 0, margin = margin(b = 5)),\n    plot.subtitle = element_text(hjust = 0, margin = margin(b = 10)),\n    strip.background = element_blank(),\n    strip.text.y = element_text(size = 16, angle = 0),\n    panel.spacing = unit(1, \"lines\"),\n    axis.title.y = element_text(angle = 0, margin = margin(r = 10))\n  )\n\n\n\nThroughout this post, we’ll be repeating the same functions to create\ngrouped bars, error bars, and labels for our plot. In order to avoid\nrepeating ourselves each time, we’ll combine these functions together\nwith theme_pma in a single function called\npma_bars.\n\n\npma_bars <- function(\n  title = NULL,     # an optional title \n  subtitle = NULL,  # an optional subtitle \n  xaxis = NULL,     # an optional label for the x-axis (displayed above)\n  yaxis = NULL      # an optional label for the y-axis (displayed left)\n){\n  components <- list(\n    if(exists(\"theme_pma\")){theme_pma},\n    labs(\n      title = title,\n      subtitle = subtitle,\n      y = str_wrap(yaxis, 10),\n      x = NULL,\n      fill = NULL\n    ),\n    scale_x_continuous(\n      position = 'bottom',\n      sec.axis = sec_axis(trans = ~., name = xaxis, breaks = NULL),\n      labels = scales::label_percent()\n    ),\n    scale_y_discrete(limits = rev),\n    geom_bar(stat = \"identity\", fill = \"#98579BB0\"),\n    geom_errorbar(\n      aes(xmin = `_low`, xmax = `_upp`), \n      width = 0.2, \n      color = \"#00263A\"\n    )\n  )\n}\n\n\n\nGoing forward, we’ll incorporate pma_bars together with\na ggplot\nand facet\nfunction for a given set of variables like so:\n\n\ncp_tbl %>% \n  ggplot(aes(x = coef, y = CP_2)) + \n  facet_grid(rows = vars(POP), cols = vars(CP_1)) + \n  pma_bars(\n    title = \"Change in Contracptive Use Status\",\n    subtitle = \"A grouped bar chart, faceted by population of interest\",\n    xaxis = \"Phase 1\",\n    yaxis = \"Phase 2\"\n  )\n\n\n\n\nKey Indicators\nContraceptive Use or Non-Use\nLet’s continue our examination of CP.\nIn the PMA reports for each sample linked above, you’ll notice that\nwomen who were pregnant at either phase are distinguished from women who\nreported use or non-use in CP_1 or CP_2. We’ll\nidentify these women in the variable PREGNANT,\nand then we’ll create a combined indicator called\nFPSTATUS.\nFPSTATUS - Pregnant, using contraception, or using no\ncontraception\n\n\ndat <- dat %>% \n  mutate(\n    FPSTATUS_1 = case_when(\n      PREGNANT_1 == 1 ~ \"Pregnant\",\n      CP_1 == 1 ~ \"Using FP\",\n      CP_1 == 0 ~ \"Not Using FP\"\n    ), \n    FPSTATUS_2 = case_when(\n      PREGNANT_2 == 1 ~ \"Pregnant\",\n      CP_2 == 1 ~ \"Using FP\",\n      CP_2 == 0 ~ \"Not Using FP\"\n    ),\n    across(\n      c(FPSTATUS_1, FPSTATUS_2),\n      ~.x %>% fct_relevel(\"Pregnant\", \"Not Using FP\", \"Using FP\")\n    )\n  )\n\n\n\nWe’ll now revise cp_tbl to include information from\nFPSTATUS_1 and FPSTATUS_2. This will help us\nanswer key questions like:\nAre women who were pregnant at Phase 1 more likely to use or not use\nfamily planning at Phase 2?\nAre women who were using (or not using) contraception at Phase 1\nlikely to maintain the same status at Phase 2?\n\n\ncp_tbl <- dat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n      group_by(FPSTATUS_1, FPSTATUS_2) %>% \n      summarise(survey_mean(vartype = \"ci\", prop = TRUE, prop_method = \"logit\"))\n  )\n\n\n\nNext, we’ll plot cp_tbl with pma_bars:\n\n\ncp_tbl %>% \n  ggplot(aes(x = coef, y = FPSTATUS_2)) + \n  facet_grid(cols = vars(FPSTATUS_1), rows = vars(POP)) + \n  pma_bars(\n    \"CHANGE IN CONTRACEPTIVE USE OR NON-USE\",\n    \"Percent women age 15-49 who changed contraceptive use status\",\n    xaxis = \"Phase 1 Status\",\n    yaxis = \"Phase 2 Status\"\n  )\n\n\n\n\nTo reiterate: comparing the error bars within each of these 18 panels\ngives us a informal, but conservative test for significant difference.\nWe’ll say that a significant difference occurs where two pairs of error\nbars do not overlap (but additional testing may be\nnecessary to determine whether a significant difference occurs where\nerror bars overlap only slightly). A few observations:\nFor women who were pregnant at Phase 1, there is usually no apparent\ndifference between using and not using family planning at Phase 2. Kenya\nand Nigeria - Kano are the exception: in Kenya, pregnant women at Phase\n1 were appear more likely to be using FP at Phase 2, while the opposite\nis true in Kano.\nOverall, non-pregnant women at Phase 1 appeared more likely to\nmaintain the same status (use or non-use) at Phase 2 than they were to\nswitch or become pregnant.\nContraceptive Method Type\nPMA surveys also ask contraceptive users to indicate which method\nthey are currently using at each phase of the study. If a woman reports\nusing more than one method, FPCURREFFMETH\nshows her most effective currently used method. These responses\nare combined with detailed information about use of the lactational\namenorrhea method (LAM), emergency contraception, or injectable type in\nFPCURREFFMETHRC.\nPMA reports use FPCURREFFMETHRC\nto determine whether each woman’s most effective current method is a\nshort-acting, long-acting, or traditional method.\nLong-acting methods include:\nIUDs\nimplants\nmale sterilization\nfemale sterilization\nShort-acting methods include:\ninjectables (intramuscular and subcutaneous)\nthe pill\nemergency contraception\nmale condoms\nfemale condoms\nLAM\ndiaphragm\nfoam/jelly\nstandard days method\nTraditional methods include:\nrhythm\nwithdrawal\nother traditional\nThese methods are coded sequentially by group in FPCURREFFMETHRC.\nWomen who are “NIU (not in universe)” were using no method.\n\n\ndat %>% count(FPCURREFFMETHRC_1)\n\n\n# A tibble: 19 × 2\n                           FPCURREFFMETHRC_1     n\n                                   <int+lbl> <int>\n 1 101 [Female Sterilization]                  198\n 2 102 [Male Sterilization]                      1\n 3 111 [Implants]                             2248\n 4 112 [IUD]                                   226\n 5 121 [Injectables (3 months)]               1412\n 6 123 [Injectables (Sayana Press)]            296\n 7 131 [Pill]                                  547\n 8 132 [Emergency Contraception]               243\n 9 141 [Male condom]                           791\n10 142 [Female condom]                           1\n11 151 [Diaphragm]                               1\n12 152 [Foam]                                    1\n13 160 [Standard Days/Cycle Beads Method]       70\n14 170 [Lactational amenorrhea method (LAM)]    24\n15 210 [Rhythm]                                569\n16 220 [Withdrawal]                            351\n17 240 [Other traditional]                     153\n18 998 [No response or missing]                  1\n19 999 [NIU (not in universe)]               10572\n\nWe’ll use across to\nrecode the Phase 1 and Phase 2 versions of FPCURREFFMETHRC\nsimultaneously. We’ll also attach the prefix CAT to each\nvariable, indicating that we’ve created “categorized” versions of\neach.\nCAT_FPSFPCURREFFMETHRC_1 - Phase 1 contraceptive method\ntype\nCAT_FPSFPCURREFFMETHRC_2 - Phase 2 contraceptive method\ntype\n\n\ndat <- dat %>% \n  mutate(\n    across(\n      c(FPCURREFFMETHRC_1, FPCURREFFMETHRC_2),\n      ~case_when(\n        .x < 120 ~ \"long-acting\",\n        .x < 200 ~ \"short-acting\",\n        .x < 900 ~ \"traditional\",\n        TRUE ~ \"none\") %>% \n        fct_relevel( \"long-acting\", \"short-acting\", \"traditional\", \"none\"),\n      .names = \"CAT_{.col}\"\n    )\n  ) \n\n\n\nNext, we’ll generate population estimates for our derived variables,\nCAT_FPCURREFFMETHRC_1 and\nCAT_FPCURREFFMETHRC_2.\n\n\nmeth_tbl <- dat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n      group_by(CAT_FPCURREFFMETHRC_1, CAT_FPCURREFFMETHRC_2) %>% \n      summarise(survey_mean(vartype = \"ci\", prop = TRUE, prop_method = \"logit\"))\n  )\n\n\n\nWe’ll again use pma_bars to plot the results.\n\n\nmeth_tbl %>% \n  ggplot(aes(x = coef, y = CAT_FPCURREFFMETHRC_2)) + \n  facet_grid(cols = vars(CAT_FPCURREFFMETHRC_1), rows = vars(POP)) + \n  pma_bars(\n    \"CHANGE IN CONTRACEPTIVE METHOD TYPE\",\n    \"Percent of women age 15-49 who changed contraceptive method or use status\",\n    xaxis = \"Phase 1 Method\",\n    yaxis = \"Phase 2 Method\"\n  )\n\n\n\n\nWhat do we learn from this plot? Let’s consider each column in\nturn:\nUsers of “long-acting” methods at Phase 1 appear more likely to have\nused “long-acting” methods at Phase 2 than to have changed status\n(except perhaps in Kano, where the intervals for “long-acting” and\n“none” overlap at Phase 2).\nUsers of “short-acting” methods at Phase 1 appeared generally likely\nto use them again at Phase 2, but some samples show that women are\nequally likely to be using “none” at Phase 2. A difference between these\ntwo outcomes is visually apparent only in Kinshasa, Kenya, and Lagos\n(where women were more likely to be using “short-acting” methods than\n“none”).\nThe status of Phase 1 “traditional” users is generally unclear at\nPhase 2. In Kinshasa, Kongo Central, and Lagos, these women seem most\nlikely to remain “traditional” users at Phase 2. Elsewhere, there are no\nclear trends.\nUsers of “none” at Phase 1 were clearly most likely to remain as\nsuch at Phase 2.\nContraceptive Dynamics by\nSubgroup\nWe can also use FPCURREFFMETHRC\nto see whether women switched methods, stopped using any method, started\nusing any method, or made no changes. Let’s summarize this information\nas CHG_FPCURR:\nCHG_FPCURR - Change in contraceptive use between Phase\n1 and Phase 2\n\n\ndat <- dat %>% \n  mutate(\n    CHG_FPCURR = case_when(\n      FPCURREFFMETHRC_1 > 900 & FPCURREFFMETHRC_2 > 900 ~ \"Continued non-use\",\n      FPCURREFFMETHRC_1 > 900 ~ \"Started using\",\n      FPCURREFFMETHRC_2 > 900 ~ \"Stopped using\",\n      FPCURREFFMETHRC_1 != FPCURREFFMETHRC_2 ~ \"Changed methods\",\n      FPCURREFFMETHRC_1 == FPCURREFFMETHRC_2 ~ \"Continued method\"\n    )\n  ) \n\n\n\nPMA reports disaggregate the outcomes captured in\nCHG_FPCURR by age, marital status, education level, and\nparity (number of live childbirths).\nAge\nWe’ll use PMA’s categorization of AGE_2 to examine\ndifferences between women in three categories.\nCAT_AGE_2 - Phase 2 age (3 categories)\n\n\ndat <- dat %>% \n  mutate(\n    CAT_AGE_2 = case_when(\n      AGE_2 < 20 ~ \"15-19\",\n      AGE_2 < 25 ~ \"20-24\",\n      TRUE ~ \"25-49\"\n    )\n  ) \n\n\n\nPlotting CAT_AGE_2 on the y-axis allows us to compare\nconfidence intervals across age groups. For example, notice that women\naged 15-19 in every population seem more likely to continue non-use than\nwomen who are aged 20-24 or 25-49 (column 3).\n\n\ndat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n      group_by(CAT_AGE_2, CHG_FPCURR) %>% \n      summarise(survey_mean(vartype = \"ci\", prop = TRUE, prop_method = \"logit\"))\n  ) %>% \n  ggplot(aes(x = coef, y = CAT_AGE_2)) + \n  facet_grid(cols = vars(CHG_FPCURR), rows = vars(POP)) + \n  pma_bars(\n    \"CHANGE IN CONTRACEPTIVEUSE STATUS, BY AGE\",\n    yaxis = \"Phase 2 Age\"\n  )\n\n\n\n\nEducation level\nThe variable EDUCATTGEN\nstandardizes educational categories across countries (see EDUCATT\nfor country-specific codes). To match PMA reports, we’ll recode EDUCATTGEN\ninto just three groups:\nCAT_EDUCATTGEN_2 - Phase 2 education level (3\ncategories)\n\n\ndat <- dat %>% \n  mutate(\n    CAT_EDUCATTGEN_2 = case_when(\n      EDUCATTGEN_2 < 3 ~ \"None / Primary\",\n      EDUCATTGEN_2 == 3 ~ \"Secondary\",\n      EDUCATTGEN_2 == 4 ~ \"Tertiary\"\n    )\n  ) \n\n\n\nAs with age, we’ll plot CAT_EDUCATTGEN_2 on the y-axis.\nThere aren’t many clear takeaways here: confidence intervals overlap in\neach column for almost every education level, so visual inspection\nreveals no clear significant differences:\n\n\ndat %>% \n  filter(EDUCATTGEN_2 < 90) %>% # drop if missing \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n      group_by(CAT_EDUCATTGEN_2, CHG_FPCURR) %>% \n      summarise(survey_mean(vartype = \"ci\", prop = TRUE, prop_method = \"logit\"))\n  ) %>% \n  ggplot(aes(x = coef, y = CAT_EDUCATTGEN_2)) + \n  facet_grid(cols = vars(CHG_FPCURR), rows = vars(POP)) + \n  pma_bars(\n    \"CHANGE IN CONTRACEPTIVEUSE STATUS, BY EDUCATION LEVEL\",\n    yaxis = \"Phase 2 Education Level\"\n  )\n\n\n\n\nMarital status\nThe variable MARSTAT\nindicates each woman’s marital / partnership status. PMA considers women\n“in union” to be those who are currently married (code 21)\nor currently living with their partner (code 22).\nOtherwise, women who were never married, divorced / separated, or\nwidowed are considered “not in union”.\nCAT_MARSTAT_2 - Phase 2 marital status (2\ncategories)\n\n\ndat <- dat %>% \n  mutate(\n    CAT_MARSTAT_2 = case_when(\n      MARSTAT_2 %in% 21:22 ~ \"In union\",\n      TRUE ~ \"Not in union\"\n    )\n  ) \n\n\n\nHere, we see that women who were not in a union at Phase 2\nwere significantly more likely to continue non-use of contraception\ncompared to married / partnered women in each population. On the other\nhand, women who were in a union mainly appeared more likely to\ncontinue using the same method, or perhaps to change methods (most\nclearly in Kenya).\n\n\ndat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n      group_by(CAT_MARSTAT_2, CHG_FPCURR) %>% \n      summarise(survey_mean(vartype = \"ci\", prop = TRUE, prop_method = \"logit\"))\n  ) %>% \n  ggplot(aes(x = coef, y = CAT_MARSTAT_2)) + \n  facet_grid(cols = vars(CHG_FPCURR), rows = vars(POP)) + \n  pma_bars(\n    \"CHANGE IN CONTRACEPTIVE METHOD TYPE, BY MARITAL STATUS\",\n    yaxis = \"Phase 2 Marital Status\"\n  )\n\n\n\n\nParity\nParity refers to the number of times a women has given live birth\n(excluding stillbirths). This information is recorded in the IPUMS\nvariable BIRTHEVENT,\nin which the values 0 and 99 (not in universe)\ncan both be interpreted as “none”.\nCAT_BIRTHEVENT_2 - Phase 2 number of live births (4\ncategories)\n\n\ndat <- dat %>% \n  mutate(\n    CAT_BIRTHEVENT_2 = case_when(\n      BIRTHEVENT_2 %in% c(0, 99) ~ \"None\",\n      BIRTHEVENT_2 %in% c(1, 2) ~ \"One-two\",\n      BIRTHEVENT_2 %in% c(3, 4) ~ \"Three-four\",\n      BIRTHEVENT_2 >= 5 ~ \"Five +\") %>% \n      fct_relevel(\"None\", \"One-two\", \"Three-four\", \"Five +\")\n  ) \n\n\n\nThere are few clear patterns related to parity, except that women who\nhave never given birth are also more likely to continue non-use of\ncontraception between phases.\n\n\ndat %>% \n  filter(BIRTHEVENT_2 != 98) %>% # drops 2 missing cases (code 98)\n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n      group_by(CAT_BIRTHEVENT_2, CHG_FPCURR) %>% \n      summarise(survey_mean(vartype = \"ci\", prop = TRUE, prop_method = \"logit\"))) %>% \n  ggplot(aes(x = coef, y = CAT_BIRTHEVENT_2)) + \n  facet_grid(cols = vars(CHG_FPCURR), rows = vars(POP)) + \n  pma_bars(\n    \"CHANGE IN CONTRACEPTIVE METHOD TYPE, BY PARITY\",\n    yaxis = \"Phase 2 Childbirths\"\n  )\n\n\n\n\nOther Panel Dynamics\nThe final page in each PMA report covers family planning dynamics\nrelated to unmet need, partner support, and plans for future use of\nfamily planning methods. In each case, we’ll be focusing on women who\nwere not using any method at Phase 1. We’ll show how each of\nthese dynamics impacts the likelihood that Phase 1 non-users would have\nadopted any family planning method at Phase 2.\n\n\ndat <- dat %>% filter(CP_1 == 0)\n\n\n\nUnmet need\nPMA defines unmet need for family planning according to each woman’s\nfertility preferences, current use of family planning methods, and risk\nfactors for pregnancy. Women may have “unmet need” for birth spacing\n(e.g. pregnant women whose pregnancy was mistimed) or for limiting\nbirths (e.g. pregnant women whose pregnancy was unwanted), while women\nare considered “not at risk” if they are not sexually active or cannot\nbecome pregnant. The variable UNMETNEED\nprovides detailed information on types of need for each woman, and on\nrelated variables that were used to calculate unmet need.\nThe binary variable UNMETYN\nrecodes UNMETNEED\nas either “Unmet need”, or “No unmet need”. We’ll reword these labels\nonly slightly to minimize the amount of repeated text on our plot:\n\n\ndat %>% \n  mutate(UNMETYN_1 = if_else(UNMETYN_1 == 1, \"Yes\", \"No\")) %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n      group_by(UNMETYN_1, CP_2) %>% \n      summarise(survey_mean(vartype = \"ci\", prop = TRUE, prop_method = \"logit\"))\n  ) %>% \n  filter(CP_2 == 1) %>% \n  ggplot(aes(x = coef, y = UNMETYN_1)) + \n  facet_grid(rows = vars(POP)) + \n  pma_bars(\n    \"UNMET NEED FOR FAMILY PLANNING\",\n    \"Percent of women age 15-49 who were not using a method at Phase 1\",\n    xaxis = \"Phase 2: Adopted a method\",\n    yaxis = \"Phase 1: Unmet Need\"\n  )\n\n\n\n\nOverall, these results suggest that non-users with unmet need for\nfamily planning at Phase 1 were more likely to adopt a method at Phase 2\ncompared to non-users who had none (e.g. women who were not sexually\nactive, could not become pregnant, etc.). However, formal testing is\nneeded to determine whether these trends were statistically significant\nin Burkina Faso and Nigeria - Lagos.\nPartner support\nWomen who were not using family planning and not pregnant at Phase 1\nwere asked whether they thought their husband / partner would be\nsupportive of use of family planning in the future. These results are\nrecorded in FPPARTSUPPORT.\nWe’ll exclude non-partnered women here, as they are “NIU (not in\nuniverse)”.\n\n\ndat %>% \n  filter(FPPARTSUPPORT_1 %in% c(0, 1, 97)) %>% \n  mutate(FPPARTSUPPORT_1 = FPPARTSUPPORT_1 %>% as_factor) %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n      group_by(FPPARTSUPPORT_1, CP_2) %>% \n      summarise(survey_mean(vartype = \"ci\", prop = TRUE, prop_method = \"logit\"))\n  ) %>% \n  filter(CP_2 == 1) %>% \n  ggplot(aes(x = coef, y = FPPARTSUPPORT_1)) + \n  facet_grid(rows = vars(POP)) + \n  pma_bars(\n    \"PARTNER SUPPORT FOR FAMILY PLANNING\",\n    \"Percent of women age 15-49 who were not using a method at Phase 1\",\n    xaxis = \"Phase 2: Adopted a method\",\n    yaxis = \"Phase 1: Partner would support FP\"\n  )\n\n\n\n\nWe’ve included responses for women who were unsure whether their\npartner would or would not support future use of FP (“Dont know”), but\nPhase 2 outcomes for these women were usually not visually distinct from\nthose who answered “Yes” or “No”. Formal testing is needed to determine\nwhether any significant differences exist.\nMeanwhile, women with Phase 1 partner support in DRC - Kongo Central\nand Kenya were more likely to adopt a method than not. Outcomes for\nwomen in other populations are not visibly different based on partner\nsupport, one way or the other (again, formal testing may prove\notherwise).\nIntentions\nLastly, we’ll demonstrate the impact of women’s plans for future\nfamily planning use at Phase 1. The variable FPUSPLAN\nindicates whether women had plans for future use at any point\nin the future, but here we’ll consider whether women had plans to adopt\na method within the next year to correspond with the timing of\nPhase 2 surveys.\nThere are two variables that describe the approximate time when women\nsaid they would adopt a family planning method (if at all). FPPLANVAL\ncontains a raw number that should be matched with a unit of\ntime (months, years) or a categorical response (“soon / now”, “after the\nbirth of this child”) in FPPLANWHEN:\n\n\ndat %>% count(FPPLANWHEN_1)\n\n\n# A tibble: 7 × 2\n                        FPPLANWHEN_1     n\n                           <int+lbl> <int>\n1  1 [Months]                          932\n2  2 [Years]                          3039\n3  3 [Soon / Now]                      685\n4  4 [After the birth of this child]   338\n5 97 [Don't know]                      893\n6 98 [No response or missing]           18\n7 99 [NIU (not in universe)]          4668\n\nWe’ll create FPPLANYR_1 to indicate whether each woman\nplanned to use family planning within a year’s time at Phase 1.\nFPPLANYR_1 - Phase 1 plans to use FP within one\nyear\n\n\ndat <- dat %>% \n  mutate(\n    FPPLANYR_1 = case_when(\n      FPPLANWHEN_1 == 1 & FPPLANVAL_1 <= 12 ~ \"Yes\", # Within 12 months \n      FPPLANWHEN_1 == 2 & FPPLANVAL_1 == 1 ~ \"Yes\", # Within 1 year\n      FPPLANWHEN_1 %in% c(3, 4) ~ \"Yes\", # Soon / now or after current pregnancy\n      TRUE ~ \"No\" # Includes date unknown, no response, or no intention (FPUSPLAN)\n    )\n  )\n\n\n\nOur final plot shows the difference in FP adoption between women who\nplanned to do so within the year, compared with women with no such\nplans.\n\n\ndat %>% \n  group_by(POP) %>% \n  summarise(\n    .groups = \"keep\",\n    cur_data() %>% \n      as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n      group_by(FPPLANYR_1, CP_2) %>% \n      summarise(survey_mean(vartype = \"ci\", prop = TRUE, prop_method = \"logit\"))\n  ) %>% \n  filter(CP_2 == 1) %>% \n  ggplot(aes(x = coef, y = FPPLANYR_1)) + \n  facet_grid(rows = vars(POP)) + \n  pma_bars(\n    \"INTENTION TO USE FAMIILY PLANNING WITHIN ONE YEAR\",\n    \"Percent of women age 15-49 who were not using a method at Phase 1\",\n    xaxis = \"Phase 2: Adopted a method\",\n    yaxis = \"Phase 1: Plan to use FP\"\n  )\n\n\n\n\nIn every population, Phase 1 non-users who planned to adopt a method\nby Phase 2 were significantly more likely to do so. However, a\nsignificant majority of Phase 1 non-users with plans to adopt a\nmethod actually did so only in Kenya, where the 95% confidence interval\nfor “Yes” responses includes only proportions greater than the 50%\nthreshold. In fact, women who adopted a method at Phase 2 represent a\nsignificant minority of Phase 1 non-users who planned to do so\nin Burkina Faso, DRC - Kongo Central, and Nigeria - Kano.\nWrap-up\nAs we’ve seen, grouped bar charts give us a simple\nway to identify clear differences between Phase 2 outcomes for subgroups\ndefined by baseline family planning conditions or key demographic\nfeatures. Additionally, when we facet populations of\ninterest on the same axis, we can easily compare differences between\nsubgroups for many samples in a single figure.\nOne drawback to this approach is that it’s more conservative than\nformal statistical tests. We are not able to easily spot differences\nnear the conventional 95% certainty threshold. However, we demonstrated\nhow you can adapt our code to conduct formal hypothesis tests like the\nRao-Scott\nchi-square test for weighted proportions.\nAnother drawback to this approach is that we’ve been unable to\nshowcase estimates for the proportion of responses at any one\nphase of the study. For example, in our last figure, we estimated that\nabout 35% of women who planned to use contraception within the\nyear at Phase 1 did so at Phase 2; our figure does not show how many\nwomen planned to use contraception within the year as a share of the\nPhase 1 population.\nTo better understand the change over time relative to the size of\neach subgroup in our analysis, we’ll turn to a slightly more complicated\ndata visualization method. In our next post, we’ll show how to create\nalluvial plots, like those shown in the first two pages\nof each PMA report.\n\nBecause women are considered “lost to\nfollow-up” if they moved outside the study area, EAID_1 and\nEAID_2 are identical for all panel members: you can use\neither one to identify sample clusters.↩︎\nThe Rao-Scott second-order correction\nto Pearson’s chi-square test is used to incorporate survey design\ninformation from as_survey_design,\nreflecting weighted population estimates. Wald-type chi-square tests are\nalso available: see svychisq for\ndetails.↩︎\n",
    "preview": "posts/2022-04-15-phase2-indicators/phase2-indicators_files/figure-html5/unnamed-chunk-21-1.png",
    "last_modified": "2022-08-01T11:02:28-04:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1536
  },
  {
    "path": "posts/2022-04-01-phase2-members/",
    "title": "Visualizing Panel Membership",
    "description": "Your guide to inclusion criteria, loss to follow-up, and key technical variables for Family Planning panel data from IPUMS PMA.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-04-01",
    "categories": [
      "Panel Data",
      "Data Discovery",
      "Data Visualization",
      "Family Planning"
    ],
    "contents": "\n\nContents\nCONSORT Diagram\nSetup\nPhase 1\nHousehold Questionnaire\nFemale Questionnaire\n\nPhase 2\nHousehold\nQuestionnaire\nFemale Questionnaire\n\nSummary\n\nWhen we introduced new Family Planning Panel\nData from PMA last month, we mentioned that PMA uses a\nmulti-stage cluster sample design for each phase of the\npanel study. This means you’ll find data from a Household Questionnaire\nadministered once each year, and you’ll find data from a subsequent\nFemale Questionnaire collected shortly afterward. Three years - or\nphases - of data will be collected in total.\nBecause data are collected through two questionnaires administered in\nthree phases, there are several places where incomplete or missing data\nmay indicate loss to follow-up - dropped cases from the\noriginal panel design. At the same time, PMA uses an open\npanel design, whereby women who move into the study area or\nreach participation age after Phase 1 are permitted to join the panel at\nany subsequent phase.\nIn this post, we’ll cover these issues in detail. To illustrate,\nwe’ll be using a wide format data extract from IPUMS PMA that includes “All\ncases” from both currently available phases. In other words, we’ll\ninclude every member of the household roster collected in the Household\nQuestionnaire at the start of each phase (even if no Female\nQuestionnaire was completed by that person).\n\nCheck out our last post for\ninformation on advantages of wide\nvs. long data extracts, and for details on case\nselection.\nTo make our explanation easier to follow, we’ll make use of a data\nvisualization tool known in clinical research settings as a CONSORT\ndiagram.\nCONSORT Diagram\nA CONSORT diagram is a flowchart showing enrollment and attrition\npoints, most typically in longitudinal studies. PMA publishes a CONSORT\ndiagram together with the User Notes for each longitudinal sample. We’ll\nconsider the 6 samples for which harmonized Phase 1 and Phase 2 data are\ncurrently available:\nBurkina\nFaso\nDRC\n- Kinshasa\nDRC\n- Kongo Central\nKenya\nNigeria\n- Lagos\nNigeria\n- Kano\nWe’ve constructed a multi-sample CONSORT diagram for this post using\nthe ggplot2\npackage for R, but we’ve hidden the source code for readers who might\nwant to stay focused on our sample design discussion. In you’re\ninterested, click the “Show CONSORT diagram source code” button to\nfollow along as we build our diagram below.\n\n\n\n\n\nShow CONSORT diagram source code\n\n# load custom font\nlibrary(sysfonts)\nlibrary(showtext)\nsysfonts::font_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext::showtext_auto()\n\n# define consort function \nconsort <- function(dat){\n  dat <- dat %>%\n    ungroup() %>%\n    arrange(pop, step, keep) %>%\n    mutate(\n      across(c(pop, label), ~as_factor(.x)),\n      label = fct_rev(label),\n      x = as.double(pop) %>% ifelse(keep, ., . + 0.19),\n      y = as.double(label),\n      x_line1 = ifelse(keep, x, x - 0.19), # start horiz line at origin\n      x_line2 = ifelse(keep, x, x - 0.05), # end horiz line 0.05 before label\n      y_line1 = ifelse(keep, y - 0.3, y),\n      y_line2 = ifelse(keep, y - 1.7, y),\n      across(\n        starts_with(\"x\"),\n        ~case_when(\n          step <= 6 & (is.na(samedw) | !keep) ~ .x,  # leave as-is\n          step == 9 ~ .x,                            # leave as-is\n          keep & samedw ~ .x + 0.19,                 # right-side dwelling\n          keep & !samedw ~ .x - 0.19,                # left-side dwelling\n          !keep ~ .x + .19,                          # dwelling discard \n        )\n      ),\n      across(\n        starts_with(\"x\"), # flip dwelling discard \n        ~case_when(!keep & !samedw ~ .x - 2*(.x - floor(.x)), T ~.x)\n      ),\n      x_line2 = case_when(\n        step == 8 & keep & samedw ~ x_line2 - 0.13,  # back to origin  at step 8\n        step == 8 & keep & !samedw ~ x_line2 + 0.13, \n        TRUE ~ x_line2\n      ),\n      across(\n        matches(\"line\"), \n        ~ifelse(keep & step == max(step), NA, .x) %>%   # no lines at final step\n          as.double()\n      ),\n      y = case_when(step == 9 ~ y - 1, TRUE ~ as.double(y)),\n      y_line1 = ifelse(step == 6 & keep, y_line1 - 0.5, y_line1),\n      hjust = case_when(\n        keep ~ \"center\",\n        !keep & !samedw ~ \"right\",\n        TRUE ~ \"left\"\n      )\n    )\n  \n  dat %>% \n    ggplot(aes(x = x, y = y)) + \n    geom_text(\n      aes(label = n, hjust = hjust),\n      size = 3,\n      family = \"cabrito\"\n    ) + \n    geom_segment(\n      arrow = arrow(length = unit(0.008, \"npc\")),\n      aes(x = x_line1, xend = x_line2, y = y_line1, yend = y_line2),\n      size = .3\n    )  +\n    scale_x_continuous(\n      position = \"top\", \n      breaks = 1:6, \n      labels = levels(dat$pop)\n    ) +\n    scale_y_continuous(\n      breaks = if(max(dat$step) == 9){\n        seq(0, 2*max(dat$step)-1, by = 2)\n      } else if(max(dat$step) == 1){\n        1\n      } else {\n        seq(0, 2*max(dat$step)-1, by = 2) + 1\n      },\n      labels = dat %>% filter(keep) %>%\n        count(label) %>% pull(label) %>% str_wrap(20),\n      sec.axis = sec_axis(\n        trans = ~.,\n        breaks = if(max(dat$step) == 9){\n          seq(3, 2*max(dat$step)-2, by = 2)\n        } else if(max(dat$step) == 1){\n          NULL\n        } else {\n          seq(2, 2*max(dat$step)-1, by = 2)\n        },\n        labels = if(max(dat$step) > 1){\n          dat %>% filter(!keep) %>% count(label) %>% \n            pull(label) %>% str_wrap(20)\n        } else {\n          NULL\n        }\n      ),\n      expand = if(max(dat$step) > 4){\n        expansion(mult = 0.05)\n      } else {\n        expansion(mult = 0.3)\n      }\n    ) +\n    theme_minimal() + \n    theme(\n      text = element_text(family = \"cabrito\"),\n      axis.ticks = element_blank(),\n      axis.title = element_blank(),\n      axis.text.x = element_text(size = 12),\n      panel.grid = element_blank(),\n      panel.border = element_blank(),\n      plot.margin = margin(20, 100, 20, 100)\n    )\n}\n\n\n\n\n\n\nSetup\nTo get started, we’ll need to request a wide\nlongitudinal extract from the IPUMS\nPMA data website. As shown above, we’ll select all 6 of the\navailable samples, and choose “All Cases (Respondents and\nNon-respondents to Household and Female Questionnaires)”. Notice that\nboth phases are included with each sample when you request a\nlongitudinal extract.\n\n\n\nVariables describing sample composition are located under the\n“Technical” topics heading. Our extract will contain all of the\nvariables in the “Technical Variables” and “Longitudinal Panel”\nsubheadings shown:\n\n\n\nOnce you’ve finished selecting variables and downloaded an extract,\nyou’ll receive two files: an .xml DDI codebook, and a\n.dat.gz data file. We’ve saved both of these files in a\nfolder called “data” in our R Working Directory, so we’ll load them into\nR together with the tidyverse and ipumsr packages.\n\nNeed help downloading an IPUMS PMA data extract? Check out our full walkthrough.\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00086.xml\",\n  data = \"data/pma_00086.dat.gz\"\n)\n\n\n\nWhen you first load your wide data extract into R,\nyou’ll notice that most variable names are duplicated: the same variable\nwill appear once with the suffix “1” for Phase 1 variables, and again\nwith the suffix “2” for Phase 2 variables. For example, you’ll find two\ncopies of SAMPLE:\n\n\ndat %>% count(SAMPLE_1)\n\n\n# A tibble: 5 × 2\n                                                        SAMPLE_1     n\n                                                       <int+lbl> <int>\n1 18012 [Congo, Democratic Republic (Kinshasa and Kongo Central… 19245\n2 40410 [Kenya 2019 Baseline]                                    42708\n3 56609 [Nigeria (Kano and Lagos) 2019 Baseline]                 12000\n4 85409 [Burkina Faso 2019 Baseline]                             30357\n5    NA                                                          98687\n\ndat %>% count(SAMPLE_2)\n\n\n# A tibble: 5 × 2\n                                                        SAMPLE_2     n\n                                                       <int+lbl> <int>\n1 18015 [Congo, Democratic Republic (Kinshasa and Kongo Central… 23186\n2 40413 [Kenya 2020 Phase 2]                                     48975\n3 56612 [Nigeria (Kano and Lagos) 2020 Phase 2]                  13227\n4 85412 [Burkina Faso 2021 Phase 2]                              33931\n5    NA                                                          83678\n\nIPUMS PMA combines sub-nationally representative samples for DRC\n(Kinshasa and Kongo Central) and Nigeria (Kano and Lagos) with one SAMPLE\ncode each. Here, we’ll separate those samples and abbreviate country\nnames to ensure that everything fits nicely in our graphics output.\nWe’ll also use the same recoded variable for Phase 1 and Phase 2 samples\ntogether. Let’s call this variable pop (for “population of\nstudy”).\nWe’ll combine the COUNTRY\nname for each sample together with the DRC and Nigeria regions shown in\nGEOCD\nand GEONG,\nrespectively.\n\n\n# Preview country and region names \ndat %>% count(COUNTRY, GEOCD, GEONG)\n\n\n# A tibble: 6 × 4\n                         COUNTRY              GEOCD      GEONG     n\n                       <int+lbl>          <int+lbl>  <int+lbl> <int>\n1 1 [Burkina Faso]               NA                 NA         57990\n2 2 [Congo, Democratic Republic]  1 [Kinshasa]      NA         20831\n3 2 [Congo, Democratic Republic]  2 [Kongo Central] NA         17625\n4 7 [Kenya]                      NA                 NA         83645\n5 9 [Nigeria]                    NA                  2 [Lagos] 11936\n6 9 [Nigeria]                    NA                  4 [Kano]  10970\n\n# Abbreviate \"DRC\" and combine `COUNTRY` with `GEOCD` and `GEONG`\ndat <- dat %>% \n  mutate(\n    across(\n      c(COUNTRY, GEOCD, GEONG),\n      ~as_factor(.x) %>% as.character()\n    ),\n    COUNTRY = if_else(str_detect(COUNTRY, \"Congo\"), \"DRC\", COUNTRY),\n    pop = case_when(\n      !is.na(GEOCD) ~ paste(COUNTRY, \"-\", GEOCD),\n      !is.na(GEONG) ~ paste(COUNTRY, \"-\", GEONG),\n      TRUE ~ COUNTRY\n    )\n  )\n\ndat %>% count(pop)\n\n\n# A tibble: 6 × 2\n  pop                     n\n  <chr>               <int>\n1 Burkina Faso        57990\n2 DRC - Kinshasa      20831\n3 DRC - Kongo Central 17625\n4 Kenya               83645\n5 Nigeria - Kano      10970\n6 Nigeria - Lagos     11936\n\nPhase 1\nPhase 1 marks the beginning of the PMA panel study (baseline). As\nwe’ve mentioned, it consists of two separate questionnaires administered\nin stages: first, resident enumerators visited 35 household dwellings\nselected at random within each sample cluster, or enumeration area. If\na qualifying respondent was available, they were invited to complete a\nHousehold\nQuestionnaire1 including a census of all household\nmembers and visitors who stayed there during the night before the\ninterview. If this census included any women aged 15-49, the enumerator\nwould later return to the household and invite each eligible woman to\ncomplete a Female\nQuestionnaire2 and participate in the three-year\npanel study.\nWe’ll take a look at the inclusion criteria and missing data codes\nfor each questionnaire, in turn.\nHousehold Questionnaire\nIn our wide data extract, each PANELWOMAN\nis a woman who completed all or part of the Phase 1 Female Questionnaire\nand agreed to participate in the longitudinal panel study: as a result,\nyou’ll find all of her Phase 1 responses and her Phase 2 responses\ntogether in a single row.\nThis is not the case for household members who are not,\nthemselves, participants in the panel study. These household members are\nrepresented by one row per phase. For example, if a young child\nwas listed on the Phase 1 Household Questionnaire, you’ll find details\nabout their age in AGEHQ_1,\ntheir sex in SEX_1, and\ntheir relationship to the head of household in RELATE_1.\nIf you look in the same row for corresponding Phase 2 variables (AGEHQ_2, SEX_2, and RELATE_2),\nyou’ll find NA values even if the child still lived in the\nhousehold at Phase 2: their Phase 2 data may be located in another row\n(with NA values listed for Phase 1), or it may not exist if\nthe child was not listed on the Phase 2 household roster. It is not\npossible to link Phase 1 and Phase 2 responses for household members who\nwere not participants in the panel study.\nThis explains why, for example, you’ll see a large number of\nNA values in RESULTHQ_1,\nwhich gives the result of the Phase 1 Household Questionnaire.\n\n\ndat %>% count(RESULTHQ_1)\n\n\n# A tibble: 10 × 2\n                      RESULTHQ_1      n\n                       <int+lbl>  <int>\n 1  1 [Completed]                103411\n 2  2 [Not at home]                 210\n 3  3 [Postponed]                     8\n 4  4 [Refused]                     230\n 5  5 [Partly completed]             47\n 6  6 [Vacant or not a dwelling]     95\n 7  7 [Destroyed]                    10\n 8  8 [Not found]                     3\n 9  9 [Absent extended period]      296\n10 NA                             98687\n\nClose to half of the values in RESULTHQ_1\nare NA: these are household members for whom no linked\nPhase 2 data exists.\nWhat about the other values in RESULTHQ_1?\nYou’ll notice a range of outcomes including:\n1 - Completed\n5 - Partly completed\nseveral other codes giving the reason why no household interview\noccurred\nIf no household interview occurred, PMA creates one row to represent\nthe household in RESULTHQ_1.\nOtherwise, if the household roster was completed during the interview,\nPMA creates one row for each person on the roster.\nIn order to determine the proportion of households that completed all\nor part of the Household Questionnaire - or any other\nhousehold-level statistics - you must count only one\nrow per household. Each Phase 1 household receives a unique identifier\nin HHID_1\n- this value is an empty string \"\" for household members\nincluded only in Phase 2. All Phase 1 households have a unique HHID_1,\nregardless of the outcome recorded in RESULTHQ_1.\nTherefore, you can use group_by\nto find the RESULTHQ_1\noutcome for each household via HHID_1. To\nobtain the proportion of Phase 1 households that completed all or part\nof the questionnaire, we’ll first use filter to\ndrop Phase 2 households with the value \"\". Then, we’ll use\nslice to\ninclude only the first row in each household. Finally, we’ll count the\nnumber of fully (code 1) or partly (code 5) completed questionnaires in\nRESULTHQ_1\n- the base R function prop.table\nderives proportions for these counts.\n\n\ndat %>% \n  filter(HHID_1 != \"\") %>% # drop Phase 2 households\n  group_by(HHID_1) %>%     \n  slice(1) %>%  # include only the first row in each household\n  ungroup() %>%            \n  count(RESULTHQ_1 %in% c(1, 5)) %>% # how many households completed all / part?\n  mutate(prop = prop.table(n))\n\n\n# A tibble: 2 × 3\n  `RESULTHQ_1 %in% c(1, 5)`     n   prop\n  <lgl>                     <int>  <dbl>\n1 FALSE                       852 0.0365\n2 TRUE                      22494 0.964 \n\n\nAcross samples, 96.4% of households completed all or part of the Phase 1\nHousehold Questionnaire.\nConversely, it is often useful to exclude non-interviewed households\nwhen calculating person-level statistics. In the first\nrow of our CONSORT diagram above, we drop these households before we\ncount the total number of sampled Phase 1 household members.\n\n\ndat %>%\n  filter(RESULTHQ_1 %in% c(1, 5)) %>% \n  count(pop)\n\n\n# A tibble: 6 × 2\n  pop                     n\n  <chr>               <int>\n1 Burkina Faso        30210\n2 DRC - Kinshasa      10309\n3 DRC - Kongo Central  8847\n4 Kenya               42308\n5 Nigeria - Kano       5722\n6 Nigeria - Lagos      6062\n\n\n\nShow CONSORT diagram source code\n\nhh <- dat \n\n# Step 1: Household members at Phase 1\nhh <- hh %>% group_by(pop) %>%  mutate(step = 1, keep = RESULTHQ_1 %in% c(1, 5))\nhh_plot <- hh %>% \n  filter(keep) %>% \n  count(step, keep) %>% \n  mutate(\n    samedw = NA,\n    label = \"Phase 1 household members\"\n  )\n\nconsort(hh_plot)\n\n\n\n\nFemale Questionnaire\nIPUMS PMA uses a non-response code labeled “Not\ninterviewed (household questionnaire)” for variables related to\nquestions that were only relevant if the Household Questionnaire was\nfully or partly completed. This includes ELIGIBLE_1,\nwhich indicates whether a particular household member was a woman aged\n15-49 at Phase 1, and therefore eligible for the Phase 1 Female\nQuestionnaire. If the household was not interviewed, eligibility for the\nFemale Questionnaire could not be determined.\n\n\ndat %>% count(RESULTHQ_1, ELIGIBLE_1)\n\n\n# A tibble: 12 × 3\n                      RESULTHQ_1                                     ELIGIBLE_1     n\n                       <int+lbl>                                      <int+lbl> <int>\n 1  1 [Completed]                 0 [No]                                        79091\n 2  1 [Completed]                 1 [Yes, eligible female respondent]           24320\n 3  2 [Not at home]              96 [Not interviewed (household questionnaire)]   210\n 4  3 [Postponed]                96 [Not interviewed (household questionnaire)]     8\n 5  4 [Refused]                  96 [Not interviewed (household questionnaire)]   230\n 6  5 [Partly completed]          0 [No]                                           31\n 7  5 [Partly completed]          1 [Yes, eligible female respondent]              16\n 8  6 [Vacant or not a dwelling] 96 [Not interviewed (household questionnaire)]    95\n 9  7 [Destroyed]                96 [Not interviewed (household questionnaire)]    10\n10  8 [Not found]                96 [Not interviewed (household questionnaire)]     3\n11  9 [Absent extended period]   96 [Not interviewed (household questionnaire)]   296\n12 NA                            NA                                             98687\n\nRESULTLFQ_1\nshows the result of the Female Questionnaire for eligible women. The\nnon-response code “NIU (not in universe)” is used for\nhousehold members who were not eligible.\n\n\ndat %>% count(RESULTFQ_1)\n\n\n\n\n# A tibble: 9 × 2\n                                      RESULTFQ_1     n\n                                       <int+lbl> <int>\n1  1 [Completed]                                 23542\n2  2 [Not at home]                                 427\n3  3 [Postponed]                                    20\n4  4 [Refused]                                     150\n5  5 [Partly completed]                             49\n6 10 [Incapacitated]                               145\n7 96 [Not interviewed (household questionnaire)]   852\n8 99 [NIU (not in universe)]                     79124\n9 NA                                             98687\n\nYou can calculate the proportion of eligible women who completed the\nPhase 1 Female Questionnaire like so:\n\n\ndat %>% \n  filter(ELIGIBLE_1 == 1) %>% # drops ineligible / Phase 2 household members\n  count(RESULTFQ_1 %in% c(1, 5)) %>% \n  mutate(prop = prop.table(n))\n\n\n# A tibble: 2 × 3\n  `RESULTFQ_1 %in% c(1, 5)`     n   prop\n  <lgl>                     <int>  <dbl>\n1 FALSE                       745 0.0306\n2 TRUE                      23591 0.969 \n\n\nAcross samples, 96.9% of eligible women completed the Phase 1 Female\nQuestionnaire.\nOur CONSORT diagram shows the total number of women who were eligible\nto participate in the panel study at Phase 1, after excluding women\nwho:\nwere members of a household where no Phase 1 Household Questionnaire\nwas administered\nwere not eligible (aged 15-49)\ndid not complete at least part of the Phase 1 Female\nQuestionnaire\n\n\ndat %>% \n  filter(RESULTFQ_1 %in% c(1, 5)) %>% \n  count(pop)\n\n\n# A tibble: 6 × 2\n  pop                     n\n  <chr>               <int>\n1 Burkina Faso         6790\n2 DRC - Kinshasa       2639\n3 DRC - Kongo Central  1970\n4 Kenya                9558\n5 Nigeria - Kano       1127\n6 Nigeria - Lagos      1507\n\n\nIf you select a data extract with “Female Respondents” rather than “All\ncases”, you will receive only records for women who completed all or\npart of the Female Questionnaire in at least one phase. See our last post for details.\n\n\nShow CONSORT diagram source code\n\n# Step 2: HH members Eligible at Phase 1\nhh <- hh %>% filter(keep) %>% mutate(step = 2, keep = ELIGIBLE_1 == 1)\nhh_plot <- hh %>% \n  count(step, keep) %>% \n  mutate(label = if_else(\n    keep,\n    \"Women aged 15-49\",\n    \"Not eligible for Phase 1 FQ\"\n  )) %>% \n  bind_rows(hh_plot)\n\n# Step 3: Result of Phase 1 FQ\nhh <- hh %>% filter(keep) %>% mutate(step = 3, keep = RESULTFQ_1 %in% c(1, 5))\nhh_plot <- hh %>% \n  count(step, keep) %>% \n  mutate(label = if_else(\n    keep,\n    \"Completed all / part of Phase 1 FQ\",\n    \"Not interviewed for Phase 1 FQ: not home, refused, vacant, etc\"\n  )) %>% \n  bind_rows(hh_plot)\n\nconsort(hh_plot)\n\n\n\n\nEnumerators invited these women to participate in Phase 2 of the\npanel study one year later. Only women who agreed to participate at that\ntime are considered panel members at Phase 2, as shown in PANELWOMAN_2.3\nTheir responses to the panel invitation are recorded in SURVEYWILLING_1.\nIPUMS PMA uses the non-response code “Not interviewed\n(female questionnaire)” to indicate women who were eligible, but not\ninterviewed for the Female Questionnaire as shown in RESULTLFQ_1.\nAdditionally, “No response or missing” is used for women who did not\nrespond to the panel invitation.\n\n\ndat %>% count(SURVEYWILLING_1)\n\n\n# A tibble: 7 × 2\n                                 SURVEYWILLING_1     n\n                                       <int+lbl> <int>\n1  0 [No]                                         1023\n2  1 [Yes]                                       22515\n3 95 [Not interviewed (female questionnaire)]      743\n4 96 [Not interviewed (household questionnaire)]   852\n5 98 [No response or missing]                       53\n6 99 [NIU (not in universe)]                     79124\n7 NA                                             98687\n\nYou should include “No response or missing” cases when calculating\nthe proportion of Phase 1 female respondents who agreed to participate\nin the panel follow-up:\n\n\ndat %>% \n  filter(RESULTFQ_1 %in% c(1, 5)) %>% # Drops NIU and Not interviewed cases \n  count(SURVEYWILLING_1) %>% \n  mutate(prop = prop.table(n))\n\n\n# A tibble: 3 × 3\n              SURVEYWILLING_1     n    prop\n                    <int+lbl> <int>   <dbl>\n1  0 [No]                      1023 0.0434 \n2  1 [Yes]                    22515 0.954  \n3 98 [No response or missing]    53 0.00225\n\n\nAcross samples, 95.4% of women who completed the Phase 1 Female\nQuestionnaire agreed to participate in panel follow-ups one year later.\n\n\nShow CONSORT diagram source code\n\n# Step 4: Willing to participate in Phase 2\nhh <- hh %>% filter(keep) %>% mutate(step = 4, keep = SURVEYWILLING_1 == 1)\nhh_plot <- hh %>% \n  count(step, keep) %>% \n  mutate(label = if_else(\n    keep,\n    \"Consented at Phase 1 to Phase 2 follow-up\",\n    \"Declined Phase 2 follow-up at Phase 1\"\n  )) %>% \n  bind_rows(hh_plot)\n\nconsort(hh_plot)\n\n\n\n\nPhase 2\nBoth questionnaires were administered again in Phase 2, approximately\none year later. Resident enumerators visited the same dwellings where\nPhase 1 interviews occurred; if the woman’s household had moved\nelsewhere within the study area,4 enumerators used local\ncontacts to find its new location. If found, they administered a\nHousehold Questionnaire including an updated household roster.\nAs we’ve mentioned, any woman aged 15-49 listed on the Phase 2\nhousehold roster was eligible to complete a Phase 2 Female\nQuestionnaire. However, only women who completed all or part of a Phase\n1 Female Questionnaire are considered members of the panel in PANELWOMAN_2.\nHousehold Questionnaire\nSeveral variables are available to describe the status\nof households surveyed at Phase 2. As with Phase 1, RESULTHQ_2\ndescribes the result of the Phase 2 Household Questionnaire.\n\n\ndat %>% count(RESULTHQ_2)\n\n\n# A tibble: 10 × 2\n                      RESULTHQ_2      n\n                       <int+lbl>  <int>\n 1  1 [Completed]                116955\n 2  2 [Not at home]                 298\n 3  3 [Postponed]                    15\n 4  4 [Refused]                     425\n 5  5 [Partly completed]             16\n 6  6 [Vacant or not a dwelling]    861\n 7  7 [Destroyed]                   227\n 8  8 [Not found]                   209\n 9  9 [Absent extended period]      313\n10 NA                             83678\n\nSAMEDWELLING_2\nindicates whether the Household Questionnaire was administered at the\nsame physical dwelling from Phase 1, or whether the enumerator located\nthe woman’s household in a new dwelling.\n\n\ndat %>% count(SAMEDWELLING_2)\n\n\n# A tibble: 6 × 2\n                                  SAMEDWELLING_2      n\n                                       <int+lbl>  <int>\n1  0 [No]                                          7255\n2  1 [Yes]                                       110973\n3 95 [Not interviewed (female questionnaire)]        15\n4 96 [Not interviewed (household questionnaire)]     19\n5 99 [NIU (not in universe)]                       1057\n6 NA                                              83678\n\nEach Phase 2 sample may also include new households that were not\nincluded in Phase 1, as indicated by HHTYPE_2:\nthese are replacement households drawn for enumeration areas where more\nthan 10% of Phase 1 households were no longer present. They account for\nall of the non-response code shown in SAMEDWELLING_2,\nas no prior dwelling was sampled.\n\n\ndat %>% count(SAMEDWELLING_2, HHTYPE_2)\n\n\n# A tibble: 6 × 3\n                                  SAMEDWELLING_2                       HHTYPE_2      n\n                                       <int+lbl>                      <int+lbl>  <int>\n1  0 [No]                                         3 [Panel woman followup]        7255\n2  1 [Yes]                                        1 [Phase 1 Dwelling]          110973\n3 95 [Not interviewed (female questionnaire)]     2 [Replacement cross-section]     15\n4 96 [Not interviewed (household questionnaire)]  2 [Replacement cross-section]     19\n5 99 [NIU (not in universe)]                      2 [Replacement cross-section]   1057\n6 NA                                             NA                              83678\n\nAs mentioned above, it is not possible to link Phase 1 and Phase 2\nrecords for household members who were not women participating in the\npanel study. However, the variable HHMEMSTAT_2\ndoes describe whether a Phase 1 household member was listed on the\nhousehold roster for Phase 2; if not, PMA creates a Phase 2 record for\nthat person indicating whether they moved or were deceased.\n\n\ndat %>% count(HHMEMSTAT_2)\n\n\n# A tibble: 10 × 2\n                                      HHMEMSTAT_2     n\n                                        <int+lbl> <int>\n 1  1 [Still a resident in household]             84402\n 2  2 [Moved within EA]                            1155\n 3  3 [Moved outside of EA]                        4815\n 4  4 [Moved out of household for school]          1117\n 5  5 [Deceased]                                    437\n 6 95 [Not interviewed (female questionnaire)]      213\n 7 96 [Not interviewed (household questionnaire)]  2337\n 8 97 [Don't know]                                   30\n 9 99 [NIU (not in universe)]                     24813\n10 NA                                             83678\n\nAfter excluding women who reached age 50 at Phase 2, our CONSORT\ndiagram diverges to show whether panel members were found in their Phase\n1 dwelling or a new one. Women whose household was not found in the\nstudy area are considered lost to follow-up, as are\nthose where the Phase 2 Household Questionnaire was not completed.\nThe variable HHPANELP2_2\nindicates whether any woman who completed the Phase 1 Female\nQuestionnaire was living in the dwelling at Phase 2. Women who were no\nlonger residents of the household are also considered lost to\nfollow-up.\n\n\ndat %>% count(HHPANELP2_2)\n\n\n# A tibble: 3 × 2\n  HHPANELP2_2     n\n    <int+lbl> <int>\n1     0 [No]  29587\n2     1 [Yes] 89732\n3    NA       83678\n\n\n\nShow CONSORT diagram source code\n\n# Step 5: Aged out \nhh <- hh %>% filter(keep) %>% mutate(step = 5, keep = AGE_1 < 49)\nhh_plot <- hh %>% \n  count(step, keep) %>% \n  mutate(label = if_else(\n    keep,\n    \"Women aged 15-49 at Phase 2\",\n    \"Women age 50 at Phase 2\"\n  )) %>% \n  bind_rows(hh_plot)\n\n# Step 6: Same dwelling \nhh <- hh %>% \n  filter(keep) %>% \n  mutate(\n    step = 6, \n    keep = RESULTHQ_2 %in% 1,\n    samedw = SAMEDWELLING_2 %in% 1\n  ) %>%\n  group_by(pop, samedw)\nhh_plot <- hh %>%\n  mutate(samedw = ifelse(!keep, TRUE, samedw)) %>% \n  count(step, keep) %>% \n  mutate(\n    n = case_when(\n      keep & samedw ~ paste(n, \"Phase 1\", \"Dwelling\", sep = \"\\n\"),\n      keep & !samedw ~ paste(n, \"New\", \"Dwelling\", sep = \"\\n\"), \n      !keep ~ as.character(n)\n    ),\n    label = if_else(\n      keep,\n      \"Completed all of the Phase 2 HQ survey\",\n      \"Household not found, HQ incomplete, or woman missing from HQ roster\"\n    )\n  ) %>%\n  bind_rows(hh_plot %>% mutate(n = as.character(n))) \n\n# Step 7: Resident in dwelling\nhh <- hh %>% filter(keep) %>% mutate(step = 7, keep = HHMEMSTAT_2 %in% c(1, 99))\nhh_plot <- hh %>%\n  count(step, keep) %>%\n  mutate(\n    n = as.character(n),\n    label = if_else(\n      keep,\n      \"Resident in dwelling\",\n      \"No longer residents\"\n    )\n  ) %>%\n  bind_rows(hh_plot)\n\nconsort(hh_plot)\n\n\n\n\nFemale Questionnaire\nFinally, eligible women who were found in a household at Phase 2 were\ninvited to complete a Female Questionnaire. RESULTFQ_2\nindicates the result of the Phase 2 Female Questionnaire both for panel\nmembers and women who were otherwise eligible to participate.\n\n\ndat %>% count(RESULTFQ_2)\n\n\n# A tibble: 11 × 2\n                                       RESULTFQ_2     n\n                                        <int+lbl> <int>\n 1  1 [Completed]                                 24756\n 2  2 [Not at home]                                 343\n 3  3 [Postponed]                                    40\n 4  4 [Refused]                                     278\n 5  5 [Partly completed]                             24\n 6  7 [Respondent moved]                             57\n 7 10 [Incapacitated]                               241\n 8 95 [Not interviewed (female questionnaire)]        9\n 9 96 [Not interviewed (household questionnaire)]  2337\n10 99 [NIU (not in universe)]                     91234\n11 NA                                             83678\n\nYou can find the proportion of women who completed the Phase 2 Female\nQuestionnaire that were also available at Phase 1 (i.e. panel members)\nlike so:\n\n\ndat %>% \n  filter(RESULTFQ_2 == 1) %>% \n  count(PANELWOMAN_2) %>% \n  mutate(prop = prop.table(n))\n\n\n# A tibble: 2 × 3\n  PANELWOMAN_2     n  prop\n     <int+lbl> <int> <dbl>\n1      0 [No]   6576 0.266\n2      1 [Yes] 18180 0.734\n\nAcross samples, Phase 1 data are available for 73.4% of women who\ncompleted the Phase 2 Female Questionnaire.\n26.6% of these women are newcomers at Phase 2.\nWide data extracts make it particularly easy to\ncombine Phase 1 and Phase 2 variables for the same woman. Note that\npotential panel members were identified at Phase 1: they are women who\nagreed to participate in SURVEYWILLING_1\nand were under age 49 in AGE_1. In\norder to calculate the proportion of potential panel members who\nultimately completed the Female Questionnaire at Phase 2, you must\ninclude Phase 1 female respondents for whom no Phase 2 data exists.\nThese cases are marked NA in RESULTFQ_2,\nso they are easily included like so:\n\n\ndat %>% \n  filter(SURVEYWILLING_1 == 1 & AGE_1 < 49) %>% \n  count(RESULTFQ_2 == 1) %>% \n  mutate(prop = prop.table(n))\n\n\n# A tibble: 3 × 3\n  `RESULTFQ_2 == 1`     n   prop\n  <lgl>             <int>  <dbl>\n1 FALSE              2452 0.110 \n2 TRUE              18180 0.817 \n3 NA                 1632 0.0733\n\n\nAcross samples, 81.7% of potential panel members completed the Phase 2\nFemale Questionnaire.\nThe final row of our CONSORT diagram shows the total number of\ncompleted Phase 2 Female Questionnaires for each sample. The totals\nbelow match the results reported in each of the PMA User Guides\npublished for individual samples.\n\n\ndat %>% \n  group_by(pop) %>% \n  # denominator: potential panel members at Phase 1\n  filter(SURVEYWILLING_1 == 1 & AGE_1 < 49) %>% \n  # numerator: did a potential panel member complete Phase 2 FQ? \n  count(final = RESULTFQ_2 == 1) %>% \n  mutate(prop = prop.table(n)) %>% \n  # drop members who did not compete Phase 2 FQ / no record in Phase 2\n  filter(final) %>% \n  select(-final)\n\n\n# A tibble: 6 × 3\n# Groups:   pop [6]\n  pop                     n  prop\n  <chr>               <int> <dbl>\n1 Burkina Faso         5491 0.841\n2 DRC - Kinshasa       2006 0.787\n3 DRC - Kongo Central  1534 0.807\n4 Kenya                7018 0.798\n5 Nigeria - Kano       1001 0.923\n6 Nigeria - Lagos      1130 0.808\n\n\n\nShow CONSORT diagram source code\n\n# Step 8: Result of Phase 2 FQ\nhh <- hh %>% filter(keep) %>% mutate(step = 8, keep = RESULTFQ_2 == 1)\nhh_plot <- hh %>%\n  count(step, keep) %>%\n  mutate(\n    n = as.character(n),\n    label = if_else(\n      keep,\n      \"Completed all of the Phase 2 FQ survey\",\n      \"Incomplete Phase 2 FQ survey: not home, refused, incapacitated, etc\"\n    )\n  ) %>% \n  bind_rows(hh_plot)\n\n# Step 9: Final diagram\nhh <- hh %>% filter(keep) %>% mutate(step = 9, keep = TRUE)\nhh_plot <- hh %>%\n  group_by(pop) %>%\n  count(step, keep) %>%\n  mutate(\n    n = as.character(n),\n    label = \"Panel Members at Phase 2\"\n  ) %>%\n  bind_rows(hh_plot)\n\nconsort(hh_plot)\n\n\n\n\nSummary\nThere are ultimately several causes of loss to\nfollow-up that may occur at different time points throughout\nthe panel study. An individual is considered lost to\nfollow-up if:\nThe household moved out of the Phase 1 dwelling, and the new\ndwelling could not be located within the study area\nThe Phase 2 Household Questionnaire was not completed (a respondent\nrefused, was not available, etc)\nA panel member from the household was no longer a resident\n(deceased, moved, or status unknown)\nA panel member did not complete a Phase 2 Household Questionnaire\n(she refused, was not available, etc)\nAt the same time, the open panel design allows new\nparticipants to complete a Female Questionnaire at any phase. These\nwomen are not panel members at Phase 2, but they may become panel\nmembers at Phase 3 if they are eligible and agree to complete a\nforthcoming Phase 3 Female Questionnaire. Women can join the panel at\nPhase 2, for example, if they:\nReach age 15 only after Phase 1 interviews were completed\nMove into a household sampled at Phase 2\nFor more details on sample design, check out the IPUMS PMA sample\nnotes and User Guides published for individual samples at pmadata.org.\n\nQuestionnaires administered in each\ncountry may vary from this Core Household Questionnaire\n- click\nhere for details.↩︎\nQuestionnaires administered in each\ncountry may vary from this Core Female Questionnaire -\nclick here\nfor details.↩︎\nWomen who completed the Phase 1\nFemale Questionnaire but declined to participate in the panel were given\nan opportunity to join the panel again at Phase 2 (if eligible). They\nare not panel members as shown in PANELWOMAN_2,\nbut they may be listed as such in PANELWOMAN_3\nif they agree to participation in the panel going forward.↩︎\nThe “study area” is area within which\nresident enumerators should attempt to find panel women that have moved\nout of their Phase 1 dwelling. This may extend beyond the woman’s\noriginal EA as determined by in-country administrators - see PMA Phase 2 and\nPhase 3 Survey Protocol for details.↩︎\n",
    "preview": "posts/2022-04-01-phase2-members/phase2-members_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2022-05-02T18:12:33-04:00",
    "input_file": {},
    "preview_width": 3072,
    "preview_height": 1920
  },
  {
    "path": "posts/2022-03-15-phase2-formats/",
    "title": "Longitudinal Data Extracts",
    "description": "Getting started with new \"long\" and \"wide\" data formats in R.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      },
      {
        "name": "Devon Kristiansen",
        "url": "https://www.linkedin.com/in/devonkristiansen"
      }
    ],
    "date": "2022-03-15",
    "categories": [
      "Panel Data",
      "Data Discovery",
      "Family Planning",
      "Importing Data",
      "ipumsr"
    ],
    "contents": "\n\nContents\nGetting Started\nSample Selection\nVariable Selection\nLoading an Extract into R\nLong Data Structure\nWide Data Structure\nWhich format is best for me?\n\n\n\n\nWhen we introduced new harmonized panel data from PMA in our last post, we mentioned that we’ve made big changes to the IPUMS PMA website making it easy to compare women’s responses across each phase of data collection. This includes a new option allowing users to choose whether to organize panel data in either long or wide format. In this post, we’ll practice building a data extract in both formats and discuss the advantages of each.\nNew users: make sure you register for a free IPUMS account! See our user guide for details.\n\n\nGetting Started\nPMA panel data represent women aged 15-49 from sampled households in eight participating countries. IPUMS PMA makes it possible to combine data from multiple samples from the same unit of analysis: you’ll need to select the Family Planning topic under the Person unit of analysis to begin browsing available samples and variables.\n\n\n\n\n\n\n\n\n\nCheck out our previous series on the Nutrition, Client Exit Interview, COVID-19, and Service Delivery Point surveys you’ll also find in the unit of analysis menu.\nSample Selection\nOnce you’ve selected the Family Planning option, you’ll next need to choose between cross-sectional or longitudinal samples. Cross-sectional samples are selected by default; these are nationally or sub-nationally representative samples collected each year dating backward as far as 2013.\n\n\n\n\nAnnual cross-sectional samples are also available for each of the countries participating in the new PMA panel study. See our last post for details.\nLongitudinal samples are only available from 2019 onward, and they include all of the available phases for each sampled country (sub-nationally representative samples for DRC and Nigeria are listed separately). You’ll only find longitudinal samples for countries where Phase 2 data has been made available; Phase 1 data for Cote d’Ivoire, India, and Uganda can currently be found under the Cross-sectional sample menu (Phase 2 data will be released soon!).\nClicking the Longitudinal button reveals options for either long or wide format. You’ll find the same samples available in either case:\n\n\n\nImportant: if you decide to change formats after selecting variables, your Data Cart will be emptied and you’ll need to begin again from scratch.\n\n\n\nAfter you’ve selected one of the available longitudinal formats, choose one or more samples listed below. There are also several Sample Members options listed:\nFemale Respondents only includes women who completed all or part of a Female Questionnaire. This option selects all members of the panel study. In addition, it includes women who only participated in only one phase - we will demonstrate how to identify and drop these cases below.1\nFemale Respondents and Household Members adds records for all other members of a Female Respondent’s household. These household members did not complete the Female Questionnaire, but were listed on the household roster provided by the respondent to a Household Questionnaire. Basic demographic variables are available for each household member, as are common wealth, water, sanitation, and other variables shared for all members of the same household.\nFemale Respondents and Female Non-respondents includes all women who were eligible to participate in a Female Questionnaire. Eligible women are those age 15-49 who were listed on the roster collected in a Household Questionnaire. If an eligible woman declined the Female Questionnaire or was not available, variables associated with that questionnaire will be coded “Not interviewed (female questionnaire)”.\nAll Cases includes all members listed on the household roster from a Household Questionnaire. If the Household Questionnaire was declined or if no respondent was available, any panel member appearing in other phases of the study will be coded “Not interviewed (household questionnaire)” for variables associated with the missing Household Questionnaire.\nPANELWOMAN indicates whether an individual is a member of the panel study.\nRESULTFQ indicates whether an individual completed the Female Questionnaire.\nRESIDENT indicates whether an individual is included in the de facto population.\nELIGIBLE indicates whether an individual was eligible for the female questionnaire.\nRESULTHQ indicates whether a member of the individual’s household completed the Household Questionnaire.\n\n\n\nAfter you’ve selected samples and sample members for your extract, click the “Submit Sample Selections” button to return to the main data browsing menu.\nVariable Selection\nYou can browse IPUMS PMA variables by topic or alphabetically by name, or you can search for a particular term in a variable name, label, value labels, or description.\n\n\n\nIn this example, we’ll select the Discontinuation of Family Planning topic. The availability of each associated variable is shown in a table containing all of the samples we’ve selected.\nX indicates that the variable is available for all phases\n/ indicates that the variable is available for one phase\n- indicates that the variable is not available for any phase\nYou can click the + button to add a variable to your cart, or click a variable name to learn more.\n\n\n\nLet’s take a look at the variable PREGNANT. You’ll find the variable name and label shown at the top of the page. Below, you’ll see several tabs beginning with the CODES tab. For discrete variables, this tab shows all of the available codes and value labels associated with each response. You’ll also see the same X, /, and - symbols in a table indicating the availability of each response in each sample.\n\n\n\n\n“Case-count view” is not available for longitudinal samples, where each sample includes data from multiple phases. For cross-sectional samples, this option shows the frequency of each response.\nAbove, there are no responses for “Not interviewed (female questionnaire)” and “Not interviewed (household questionnaire)”; this is because only samples members included in a “Female Respondents” extract are displayed by default. If we instead choose “All Cases”, this variable will include those response options because we’ll include every person listed on the household roster (even if the Household or Female Questionnaire was not completed).\n\n\n\nThe symbol / again indicates that a particular response is available for some - but not all - phases of the study. For PREGNANCY it indicates that one of the options was either unavailable or was not selected by any sample respondents in a particular phase. If a variable was not included in all phases of the study, all response options will be marked with this symbol. For example, consider the variable COVIDCONCERN, indicating the respondent’s level of concern about becoming infected with COVID-19.\n\n\n\nBecause Phase 1 questionnaires were administered prior to the emergence of COVID-19, this variable only appeared on Phase 2 questionnaires. The symbol / indicates limited availability across phases.\nYou’ll find a detailed description for each variable on the DESCRIPTION tab. This tab also indicates whether a particular question appeared on the Household or Female Questionnaire.\n\n\n\nThe COMPARABILITY tab describes important differences between samples. Additionally, it may contain information about similar variables appearing in DHS samples provided by IPUMS DHS.\n\n\n\nThe UNIVERSE tab describes selection criteria for this question. In this case, there are some differences between samples:\nIn DRC samples, all women aged 15-49 received this question.\nFor all other samples, the question was skipped if any such woman previously indicated that she was menopausal or had a hysterectomy.\n\n\n\nThe AVAILABILITY tab shows all other samples (including cross-sectional samples) where this variable is available.\n\n\n\nFinally, you’ll find the full text of each question on the QUESTIONNAIRE TEXT tab. Each phase of the survey is shown separately, and you may click the “view entire document: text” link to view the complete questionnaire for a particular sample in any given phase.\n\n\n\nUse the buttons at the top of this page to add the variable to your Data Cart, or to “VIEW CART” and begin checkout.\n\n\n\nLoading an Extract into R\nYour Data Cart shows all of the variables you’ve selected, plus several “preselected” variables that will be automatically included in your extract. Click the “CREATE DATA EXTRACT” button to prepare your download.\n\n\n\nBefore you submit an extract request, you’ll have the opportunity to choose a “Data Format”. R users should selected Fixed-width text (.dat) - you’ll notice that data formatted for Stata, SPSS, and SAS are also available. CSV files are provided, but not recommended. (If you wish to change Sample Members, you may do so again here.)\n\n\n\n\n\n\nClick “APPLY SELECTIONS” to return to the previous screen. There, you may add a description and then proceed to the download page.\n\n\n\nAfter a few moments, you’ll receive an email indicating that your extract has been created. You’ll need to obtain two files from the download page:\nClick the green “Download DAT” button to download the data file. You’ll receive a file with a number like “pma_00001.dat.gz”.\nRight click on “DDI” and click “Save link as”. You’ll receive a corresponding XML file like “pma_00001.xml”.\n\n\n\n\nPlace both files in a folder that R can use as its working directory. We strongly recommend using RStudio projects to manage all of the files and analysis scripts used for a particular research project. We’ll place our files in a subfolder called “data” within our own RStudio project folder.\nThe ipumsr package offers the easiest way to import an IPUMS PMA extract into R. You can install it from CRAN like so:\n\n\ninstall.packages(\"ipumsr\")\n\n\n\nAfter installation, you’ll be able to load ipumsr and use the function read_ipums_micro to import your data extract. We’ll now demonstrate loading both a long and a wide extract, and we’ll take a brief look at the structure of each.\n\n\n\n\n\n© IPUMS (MPL-2.0)\n\n\n\nTo do so, we’ll use functions from the tidyverse family of R packages. You can install all of the tidyverse packages in a single step:\n\n\ninstall.packages(\"tidyverse\")\n\n\n\nOnce per session, you’ll need to load the ipumsr and tidyverse packages into R.\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\n\n\n\n\n\n\n\n\n© RStudio, Inc. (MIT)\n\n\n\n\n\nLong Data Structure\nWe’ve downloaded a long data extract (Female Respondents only) and saved it in a folder called “data” in our working directory. We’ll now load it into R as an object called long.\n\n\nlong <- read_ipums_micro(\n  ddi = \"data/pma_00095.xml\",\n  data = \"data/pma_00095.dat.gz\"\n)\n\n\n\nIn a long extract, data from each phase will be organized in separate rows. Here, responses from three panel members are shown:\n\n\nlong %>% \n  filter(FQINSTID %>% str_starts(\"011\") | FQINSTID %>% str_starts(\"015\")) %>% \n  arrange(FQINSTID) %>% \n  select(FQINSTID, PHASE, AGE, PANELWOMAN)\n\n\n# A tibble: 6 × 4\n  FQINSTID                                PHASE       AGE PANELWOMAN\n  <chr>                               <int+lbl> <int+lbl>  <int+lbl>\n1 011W5S0HN91I4H4I3T9JCMBHB 1 [Baseline]               29   NA      \n2 011W5S0HN91I4H4I3T9JCMBHB 2 [First follow up]        30    1 [Yes]\n3 015NP6FJTIA98FYCBBBS1FOF7 1 [Baseline]               47   NA      \n4 015NP6FJTIA98FYCBBBS1FOF7 2 [First follow up]        48    1 [Yes]\n5 015WYNNO2WXHH6JA4HA9PL1MR 1 [Baseline]               20   NA      \n6 015WYNNO2WXHH6JA4HA9PL1MR 2 [First follow up]        21    1 [Yes]\n\nEach panel member receives a unique ID shown in FQINSTID. The variable PHASE shows that each woman’s responses to the Phase 1 Female Questionnaire appears in the first row, while her Phase 2 responses appear in the second. AGE shows each woman’s age when she completed the Female Questionnaire for each phase.\nPANELWOMAN indicates whether the woman completed all or part of the Female Questionnaire in a prior phase, and that she’d agreed to continue participating in the panel study at that time. The value NA appears in the rows for Phase 1, as PANELWOMAN was not included in Phase 1 surveys.\nWe mentioned above that you’ll also include responses from some non-panel members when you request an extract with Female Respondents. These include women who did not complete all or part the Female Questionnaire in a prior phase, as indicated by PANELWOMAN. These women are not assigned a value for FQINSTID - instead, you’ll find an empty string:\n\n\nlong %>% count(PHASE, PANELWOMAN, FQINSTID == \"\")\n\n\n# A tibble: 3 × 4\n                PHASE PANELWOMAN `FQINSTID == \"\"`     n\n            <int+lbl>  <int+lbl> <lgl>            <int>\n1 1 [Baseline]          NA       FALSE            23591\n2 2 [First follow up]    0 [No]  TRUE              6586\n3 2 [First follow up]    1 [Yes] FALSE            18194\n\nFor most longitudinal analysis applications, you’ll need to drop non-panel members together with any women who did not fully complete the Phase 2 Female Questionnaire. We’ll demonstrate using group_by to ensure that there is one row for every FQINSTID where PHASE == 1 and another row where PHASE == 2 & RESULTFQ == 1.\n\n\nlong <- long %>% \n  group_by(FQINSTID) %>% \n  filter(any(PHASE == 1) & any(PHASE == 2 & RESULTFQ == 1)) %>% \n  ungroup() \n\n\n\nThe PMA Longitudinal Briefs published for each sample also include only members of the de facto population. These are women who slept in the household during the night prior to the interview for each Household Questionnaire, such that RESIDENT takes the value 11 or 22. We’ll use group_by again to include only de facto women from both phases.\n\n\nlong <- long %>% \n  group_by(FQINSTID) %>% \n  filter(all(RESIDENT %in% c(11, 22))) %>% \n  ungroup() \n\n\n\nFollowing these steps, you can check the size of each analytic sample like so:\n\n\nlong %>% count(COUNTRY, GEOCD, GEONG, PHASE)\n\n\n# A tibble: 12 × 5\n                          COUNTRY       GEOCD    GEONG     PHASE     n\n                        <int+lbl>   <int+lbl> <int+lb> <int+lbl> <int>\n 1 1 [Burkina Faso]               NA          NA       1 [Basel…  5212\n 2 1 [Burkina Faso]               NA          NA       2 [First…  5212\n 3 2 [Congo, Democratic Republic]  1 [Kinsha… NA       1 [Basel…  1973\n 4 2 [Congo, Democratic Republic]  1 [Kinsha… NA       2 [First…  1973\n 5 2 [Congo, Democratic Republic]  2 [Kongo … NA       1 [Basel…  1514\n 6 2 [Congo, Democratic Republic]  2 [Kongo … NA       2 [First…  1514\n 7 7 [Kenya]                      NA          NA       1 [Basel…  6939\n 8 7 [Kenya]                      NA          NA       2 [First…  6939\n 9 9 [Nigeria]                    NA           2 [Lag… 1 [Basel…  1089\n10 9 [Nigeria]                    NA           2 [Lag… 2 [First…  1089\n11 9 [Nigeria]                    NA           4 [Kan… 1 [Basel…   998\n12 9 [Nigeria]                    NA           4 [Kan… 2 [First…   998\n\n\nReminder: samples for DRC and Nigeria are sub-nationally representative, so we’ll show separate frequencies for each GEOCD and GEONG.\nWide Data Structure\nWe’ve also downloaded a wide data extract (Female Respondents only) and saved it in the “data” folder in our working directory. We’ll also load this extract into R as an object named wide.\n\n\nwide <- read_ipums_micro(\n  ddi = \"data/pma_00084.xml\",\n  data = \"data/pma_00084.dat.gz\"\n)\n\n\n\nIn a wide extract, all of the responses from one woman appear in the same row. The IPUMS extract system appends a numeric suffix to each variable name corresponding with the phase from which it was drawn. Consider our three example panel members again:\n\n\nwide %>% \n  filter(FQINSTID %>% str_starts(\"011\") | FQINSTID %>% str_starts(\"015\")) %>% \n  select(FQINSTID, AGE_1, AGE_2, PANELWOMAN_1, PANELWOMAN_2)\n\n\n# A tibble: 3 × 5\n  FQINSTID                      AGE_1  AGE_2 PANELWOMAN_1 PANELWOMAN_2\n  <chr>                     <int+lbl> <int+>    <int+lbl>    <int+lbl>\n1 011W5S0HN91I4H4I3T9JCMBHB        29     30           NA      1 [Yes]\n2 015NP6FJTIA98FYCBBBS1FOF7        47     48           NA      1 [Yes]\n3 015WYNNO2WXHH6JA4HA9PL1MR        20     21           NA      1 [Yes]\n\nEach panel member has one unique ID shown in FQINSTID. However, AGE is parsed into two columns: AGE_1 shows each woman’s age at Phase 1, and AGE_2 shows her age at Phase 2.\nAs we’ve discussed, PANELWOMAN is not available for Phase 1, as it indicates whether the woman completed all or part of the Female Questionnaire in a prior phase. For this reason, all values in PANELWOMAN_1 are NA. Most variables are copied once for each phase, even if they - like PANELWOMAN_1 - are not available for all phases.\nYou might expect the total length of a wide extract to be half the length of a corresponding long extract. This is not the case! A wide extract includes one row for each woman who completed all or part of the Female Questionnaire for any phase - you’ll find placeholder columns for phases where the interview was not conducted.\n\n\nwide %>% \n  filter(FQINSTID == \"0C8VQU6B03BXLAVVZ8SB90EKQ\") %>% \n  select(RESULTFQ_1, AGE_1, RESULTFQ_2, AGE_2)\n\n\n# A tibble: 1 × 4\n     RESULTFQ_1     AGE_1      RESULTFQ_2                        AGE_2\n      <int+lbl> <int+lbl>       <int+lbl>                    <int+lbl>\n1 1 [Completed]        31 2 [Not at home] 95 [Not interviewed (female…\n\nIn a long extract, rows for the missing phase are dropped. In this example, the woman was “not at home” for the Phase 2 Female Questionnaire. When we select a long extract containing only Female Respondents, her Phase 2 row is excluded automatically (it will be included if you request an extract containing Female Respondents and Female Non-respondents).\n\n\n\n\n\nlong %>% \n  filter(FQINSTID == \"0C8VQU6B03BXLAVVZ8SB90EKQ\") %>% \n  select(PHASE, RESULTFQ, AGE)\n\n\n# A tibble: 1 × 3\n         PHASE      RESULTFQ       AGE\n     <int+lbl>     <int+lbl> <int+lbl>\n1 1 [Baseline] 1 [Completed]        31\n\nAgain: for most longitudinal analysis applications, you’ll need to remove cases where women were not interviewed for Phase 1 or where the Phase 2 Female Questionnaire was not completed:\n\n\nwide <- wide %>% filter(RESULTFQ_2 == 1 & !is.na(RESULTFQ_1)) \n\n\n\nThe de facto population appearing in PMA Longitudinal Briefs is defined in wide extracts by cases where the values 11 or 12 appear in both RESIDENT_1 and RESIDENT_2:\n\n\nwide <- wide %>% filter(RESIDENT_1 %in% c(11, 22) & RESIDENT_2 %in% c(11, 22))\n\n\n\nFollowing these steps, each analytic sample contains the same number of cases shown in the final long format extract above.\n\n\nwide %>%\n  group_by(COUNTRY, GEOCD, GEONG) %>%\n  count()\n\n\n# A tibble: 6 × 4\n# Groups:   COUNTRY, GEOCD, GEONG [6]\n                         COUNTRY              GEOCD      GEONG     n\n                       <int+lbl>          <int+lbl>  <int+lbl> <int>\n1 1 [Burkina Faso]               NA                 NA          5212\n2 2 [Congo, Democratic Republic]  1 [Kinshasa]      NA          1973\n3 2 [Congo, Democratic Republic]  2 [Kongo Central] NA          1514\n4 7 [Kenya]                      NA                 NA          6939\n5 9 [Nigeria]                    NA                  2 [Lagos]  1089\n6 9 [Nigeria]                    NA                  4 [Kano]    998\n\nWhich format is best for me?\nThe choice between long and wide formats ultimately depends on your research objectives.\nMany data manipulation tasks, for example, are faster and easier to perform in the wide format. In the example above, we needed to identify women who completed a Female Questionnaire and were members of the de facto population in both phases. In the long format, we first had to group the data by FQINSTID with group_by, thereby ensuring that a Phase 1 and Phase 2 check could be performed for each woman. In preparing for this post, this approach took about 36.5 seconds. By comparison, the same task was achieved without group_by in wide format in just 0.16 seconds. If your workflow requires multiple comparisons between phases, the wide format may be the best choice!\nOn the other hand, many of the longitudinal modeling packages available for R require data to be in a long format - this includes both the survival package for Cox regression and the lme4 package for multilevel models. Users who prefer the wide format for data cleaning and exploration can manually switch to long format with help from pivot_longer, for example:\n\n\nwide %>% select(FQINSTID, AGE_1, PREGNANT_1, AGE_2, PREGNANT_2)\n\n\n# A tibble: 17,725 × 5\n   FQINSTID                        AGE_1 PREGNANT_1   AGE_2 PREGNANT_2\n   <chr>                         <int+l>  <int+lbl> <int+l>  <int+lbl>\n 1 uuid:0005f6d7-b7cd-46f6-8a6f…      30    0 [No]       31     0 [No]\n 2 uuid:0006cb76-09d1-4f2a-a92d…      34    1 [Yes]      34     0 [No]\n 3 uuid:00204481-5cae-4188-abb3…      17    0 [No]       18     0 [No]\n 4 uuid:002398f4-8f2d-4095-8019…      29    0 [No]       29     0 [No]\n 5 uuid:00407300-c1e6-4e24-ab8d…      25    0 [No]       25     0 [No]\n 6 uuid:00413ed1-d176-44fb-a232…      32    0 [No]       32     0 [No]\n 7 uuid:0048a052-66ff-4ed5-9fa9…      38    0 [No]       39     0 [No]\n 8 uuid:004d80f0-90c6-4b77-bb4d…      38    0 [No]       38     0 [No]\n 9 uuid:00504cf5-870c-4a02-aad7…      33    0 [No]       34     0 [No]\n10 uuid:00534792-fb84-47b4-8606…      24    0 [No]       25     0 [No]\n# … with 17,715 more rows\n\nWith pivot_longer, you can strip the suffix 1 or 2 from each variable, placing the result in a new column called PHASE. Then, we’ll pivot each woman’s age and pregnancy status from 2 wide columns into a single long one.\n\n\nwide %>% \n  select(FQINSTID, AGE_1, PREGNANT_1, AGE_2, PREGNANT_2) %>% \n  pivot_longer(\n    !FQINSTID, \n    names_pattern = \"(.*)_([1-2])\",\n    names_to = c(\".value\", \"PHASE\")\n  )\n\n\n# A tibble: 35,450 × 4\n   FQINSTID                                  PHASE       AGE  PREGNANT\n   <chr>                                     <chr> <int+lbl> <int+lbl>\n 1 uuid:0005f6d7-b7cd-46f6-8a6f-5f051b6ab4a2 1            30   0 [No] \n 2 uuid:0005f6d7-b7cd-46f6-8a6f-5f051b6ab4a2 2            31   0 [No] \n 3 uuid:0006cb76-09d1-4f2a-a92d-c12fcaf194b5 1            34   1 [Yes]\n 4 uuid:0006cb76-09d1-4f2a-a92d-c12fcaf194b5 2            34   0 [No] \n 5 uuid:00204481-5cae-4188-abb3-0367d0ed9c14 1            17   0 [No] \n 6 uuid:00204481-5cae-4188-abb3-0367d0ed9c14 2            18   0 [No] \n 7 uuid:002398f4-8f2d-4095-8019-c306d39cf2b9 1            29   0 [No] \n 8 uuid:002398f4-8f2d-4095-8019-c306d39cf2b9 2            29   0 [No] \n 9 uuid:00407300-c1e6-4e24-ab8d-8af5e1ca85a6 1            25   0 [No] \n10 uuid:00407300-c1e6-4e24-ab8d-8af5e1ca85a6 2            25   0 [No] \n# … with 35,440 more rows\n\n\nFor more examples using pivot_longer, check out our posts on contraceptive calendar and migration data!\nManipulating patterns in variable names with pivot_longer takes practice, and we imagine many users will find it easier to simply work with data in the long format from the beginning.\nFortunately, the updated IPUMS PMA extract system makes it easy to select the samples, sample members, and variables that matter to your particular research question. New choices for long and wide data formats save an additional data cleaning step, allowing you to jump into longitudinal analysis as quickly as possible.\n\nWomen who completed all or part of the Female Questionnaire in more than one phase of the study are considered panel members. Women who completed it only at Phase 1 are included in a longitudinal extract, but they are not panel members. Likewise, women who completed it for the first time at Phase 2 are included, but are not panel members if they 1) will reach age 50 before Phase 3, or 2) declined the invitation to participate again in Phase 3.↩︎\n",
    "preview": "posts/2022-03-15-phase2-formats/images/video.png",
    "last_modified": "2022-03-15T17:02:55-04:00",
    "input_file": {},
    "preview_width": 1406,
    "preview_height": 718
  },
  {
    "path": "posts/2022-03-01-phase2-discovery/",
    "title": "Family Planning Panel Data Now Available from IPUMS PMA",
    "description": "This month's data release includes Phase 2 panel data from 6 samples, plus Phase 1 panel data from 3 new countries.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      },
      {
        "name": "Devon Kristiansen",
        "url": "https://www.linkedin.com/in/devonkristiansen"
      }
    ],
    "date": "2022-03-01",
    "categories": [
      "Panel Data",
      "Data Discovery",
      "New Data",
      "Family Planning",
      "Weights",
      "Cluster Sampling"
    ],
    "contents": "\n\nContents\nBackground\nSampling\nSurvey Design Elements\nInclusion Criteria for\nAnalysis\n\n\n\n\nThis month, IPUMS is excited to announce the release of\nharmonized panel data focused on the reproductive and\nsexual health of women surveyed by our partners at Performance Monitoring for Action\n(PMA). Participating women will be interviewed up to three times over\nthree years, so we’ve made big changes to our data extract system making it easy to\ncompare an individual’s responses across multiple rounds of data\ncollection. Cross-sectional samples of women, households, and service\ndelivery points remain available as before, but we’ve also streamlined\nnavigation for users interested in longitudinal analysis with these new\npanel surveys.\nHere on the IPUMS PMA blog, today marks the beginning of a new series in which\nwe’ll be using R to:\nimport and explore the structure of IPUMS PMA panel data\nunderstand key sample design and follow-up issues\nbuild indicators measuring change in contraceptive use status and\nfamily planning outcomes\nanalyze monthly recall data from the included contraceptive\ncalendar\nAdditionally, we’re also developing a second online\ncourse for newcomers to longitudinal analysis that will\ncomplement our existing Introduction\nto IPUMS PMA Data Analysis. Later this year, we also plan to release\na PDF longitudinal handbook adapted from this blog that\nwill include examples in both R and Stata. Stay tuned\nfor further announcements here and on Twitter in the coming\nweeks.\n\nPMA has also published a cross-sectional handbook in\nboth English\nand French.\nBackground\nDating back to 2013, the original PMA survey design included\nhigh-frequency, cross-sectional samples of women and\nservice delivery points collected from eleven countries participating in\nFamily Planning\n2020 (FP2020) - a global partnership that supports the rights of\nwomen and girls to decide for themselves whether, when, and how many\nchildren they want to have. These surveys were designed to monitor\nannual progress towards FP2020\ngoals via population-level estimates for several core\nindicators.\nBeginning in 2019, PMA surveys were redesigned under a renewed\npartnership called Family Planning\n2030 (FP2030). These new surveys have been refocused on reproductive\nand sexual health indicators, and they feature a longitudinal\npanel of women of childbearing age. This design will allow\nresearchers to measure contraceptive dynamics and changes in women’s\nfertility intentions over a three year period via\nannual in-person interviews.1\nQuestions on the redesigned survey cover topics like:\nawareness, perception, knowledge, and use of contraceptive\nmethods\nperceived quality and side effects of contraceptive methods among\ncurrent users\nbirth history and fertility intentions\naspects of health service provision\ndomains of empowerment\nSampling\nPMA panel data includes a mixture of nationally\nrepresentative and sub-nationally\nrepresentative samples from eight participating countries. The\npanel study consists of three data collection phases, each spaced one\nyear apart. IPUMS PMA has released data from the first two\nphases for countries where Phase 1 data collection began in 2019; we\nhave released data from only the first phase for countries\nwhere Phase 1 data collection began in August or September 2020. Phase 3\ndata collection and processing is currently underway.\n\n\n\n\n\n\nNow Available from IPUMS PMA\n\n\n\nSample\n\n\nPhase 1 Data Collection*\n\nPhase 1\n\n\nPhase 2\n\n\nPhase 3\n\n\nBurkina Faso\n\n\nDec 2019 - Mar 2020\n\n\nx\n\n\nx\n\n\n\n\nCote d’Ivoire\n\n\nSep 2020 - Dec 2020\n\n\nx\n\n\n\n\n\n\nDRC - Kinshasa\n\n\nDec 2019 - Feb 2020\n\n\nx\n\n\nx\n\n\n\n\nDRC - Kongo Central\n\n\nDec 2019 - Feb 2020\n\n\nx\n\n\nx\n\n\n\n\nIndia - Rajasthan\n\n\nAug 2020 - Oct 2020\n\n\nx\n\n\n\n\n\n\nKenya\n\n\nNov 2019 - Dec 2019\n\n\nx\n\n\nx\n\n\n\n\nNigeria - Kano\n\n\nDec 2019 - Jan 2020\n\n\nx\n\n\nx\n\n\n\n\nNigeria - Lagos\n\n\nDec 2019 - Jan 2020\n\n\nx\n\n\nx\n\n\n\n\nUganda\n\n\nSep 2020 - Oct 2020\n\n\nx\n\n\n\n\n\n\n*Each data collection phase is spaced one year\napart\n\n\n\n\nPMA uses a multi-stage clustered sample design, with stratification\nat the urban-rural level or by sub-region. Geographically defined sample\nclusters - called enumeration\nareas (EAs) – are provided by the national statistics agency in each\ncountry.2 These EAs are sampled using a\nprobability proportional to size (PPS) method relative to the\npopulation distribution in each stratum.\nAt Phase 1, 35 household dwellings were selected at random within\neach EA. Resident enumerators visited each dwelling and invited one\nhousehold member to complete a Household\nQuestionnaire3 that includes a census of all\nhousehold members and visitors who stayed there during the night before\nthe interview. Female household members and visitors aged 15-49 were\nthen invited to complete a subsequent Phase 1 Female\nQuestionnaire.4\n\n\nQuestionnaires are administered in-person by resident\nenumerators visiting selected households in each EA. These are\ntypically women over age 21 living in (or near) each EA and who hold at\nleast a high school diploma.\nOne year later, resident enumerators visited the same dwellings and\nadministered a Phase 2 Household Questionnaire. A panel member in Phase\n2 is any woman still age 15-49 who could be reached for a second Female\nQuestionnaire, either because:\nshe still lived there, or\nshe had moved elsewhere within the study area,5 but\nat least one member of the Phase 1 household remained and could help\nresident enumerators locate her new dwelling.6\nSAMEDWELLING\nindicates whether a Phase 2 female respondent resided in her Phase 1\ndwelling or a new one.\nAdditionally, resident enumerators administered the Phase 2 Female\nQuestionnaire to new women in sampled households who:\nreached age 15 after Phase 1\njoined the household after Phase 1\ndeclined the Female Questionnaire at Phase 1, but agreed to complete\nit at Phase 2\nPANELWOMAN\nindicates whether a Phase 2 household member completed the Phase 1\nFemale Questionnaire.\nWhen you select the new Longitudinal sample option\nat checkout, you’ll be able to include responses from every available\nphase of the study. These samples are available in either “long” format\n(responses from each phase will be organized in separate rows) or “wide”\nformat (responses from each phase will be organized in columns).\n\n\n\nIn addition to following up with women in the panel over time, PMA\nalso adjusted sampling so that a cross-sectional sample could be\nproduced concurrently with each data collection phase. These samples\nmainly overlap with the data you’ll obtain for a particular phase in the\nlongitudinal sample, except that replacement households were drawn from\neach EA where more than 10% of households from the previous phase were\nno longer there. Conversely, panel members who were located in a new\ndwelling at Phase 2 will not be represented in the cross-sectional\nsample drawn from that EA. These adjustments ensure that\npopulation-level indicators may be derived from cross-sectional samples\nin a given year, even if panel members move or are lost to\nfollow-up.\nCROSS_SECTION\nindicates whether a household member in a longitudinal sample is also\nincluded in the cross-sectional sample for a given year (every person in\na cross-sectional sample is included in the longitudinal sample).\nWe’ll cover sample composition in much greater detail\nin an upcoming post.\nYou’ll find PMA cross-sectional samples dating back to 2013 if you\nselect the Cross-sectional sample option at\ncheckout.\n\n\n\nSurvey Design Elements\nIn upcoming posts, we’ll demonstrate how to incorporate PMA sampling\nweights and information about its stratified cluster sampling procedure\ninto your analysis. To do so, we’ll rely on tools from the srvyr package.7\nWhether you intend to work with a new Longitudinal\nor Cross-sectional data extract, you’ll find the same\nset of sampling weights available for all PMA Family Planning surveys\ndating back to 2013.\nHQWEIGHT\ncan be used to generate cross-sectional population estimates from\nquestions on the Household Questionnaire.8\nFQWEIGHT\ncan be used to to generate cross-sectional population estimates from\nquestions on the Female Questionnaire.9\nEAWEIGHT\ncan be used to compare the selection probability of a particular\nhousehold with that of its EA.\n\nA fourth Family Planning survey weight, POPWT,\nis currently available only for Cross-sectional data\nextracts and Phase 1 panel data.10\nAdditionally, PMA created a new weight, PANELWEIGHT,\nwhich should be used in longitudinal analyses spanning multiple phases,\nas it adjusts for loss to follow-up. PANELWEIGHT is\navailable only for Longitudinal data extracts.\nFor example, suppose we wanted to estimate the proportion of\nreproductive age women in Burkina Faso who were using contraception at\nthe time of data collection for both Phase 1 and Phase 2. In a\ncross-sectional or “long” longitudinal extract, you’ll find this\ninformation in the variable CP.\nIn a “wide” longitudinal extract, you’ll find it in CP_1\nfor Phase 1, and in CP_2 for Phase 2. We’ll be working with\na “wide” extract loaded into R as an object called dat.\n\nVariable names in a “wide” extract have a numeric suffix corresponding\nwith a data collection phase. CP_1 is the Phase 1 version\nof CP,\nwhile CP_2 comes from Phase 2.\n\n\n\n\n\ndat %>% count(CP_1, CP_2)\n\n\n# A tibble: 5 × 3\n                                   CP_1      CP_2     n\n                              <int+lbl> <int+lbl> <int>\n1  0 [No]                                 0 [No]   2589\n2  0 [No]                                 1 [Yes]   821\n3  1 [Yes]                                0 [No]    556\n4  1 [Yes]                                1 [Yes]  1241\n5 99 [NIU (not in universe) or missing]   0 [No]      5\n\nThe srvyr package provides two functions we’ll need to\nobtain our population estimate. The first, as_survey_design,\nallows us to specify PANELWEIGHT as a sampling weight. The\nsecond, survey_mean,\nuses that weight in an estimating function; in this case, we’ll get the\nestimated proportion where CP_1 and CP_2 both\nhave the value 1 [Yes] after removing missing / NIU\nresponses with CP_1 < 90 & CP_2 < 90.\nIn upcoming posts, we’ll use vartype = \"ci\" to include a\n95% confidence interval set by level = 0.95 any time we\ncalculate a population estimate. For discrete variables, we’ll also\ninclude proportion = TRUE and\nprop_method = \"logit\". In practice, there are large number\nof ways to calculate a confidence interval for a proportion.11 The srvyr package includes\nseveral options for prop_method,12\nbut we’ll use these settings because:\nthey ensure that each proportion’s confidence interval only includes\nvalues between 0% and 100%,\nthey will include the real-world population proportion close to 95%\nof the time,\nthe logit method yields a relatively narrow interval\ncompared with other options, and\nthese intervals will match the default intervals reported by Stata\nand SPSS survey proportion functions.\n\n\n\nlibrary(srvyr)\n\ndat %>% \n  as_survey_design(weight = PANELWEIGHT) %>% \n  filter(CP_1 < 90 & CP_2 < 90) %>% \n  summarise(\n    survey_mean(\n      CP_1 * CP_2,\n      vartype = \"ci\",\n      level = 0.95,\n      proportion = TRUE,\n      prop_method = \"logit\"\n    )\n  )\n\n\n# A tibble: 1 × 3\n   coef `_low` `_upp`\n  <dbl>  <dbl>  <dbl>\n1 0.188  0.174  0.203\n\n\ncoef shows the estimated population proportion\n_low and _upp show the lower and upper bounds\nof a 95% confidence interval\nYou can also provide information about sample clusters via as_survey_design.\nIn general, we expect households selected from the same EA to share\ncertain characteristics, such that some degree of variation seen in a\nvariable of interest may be non-random at the EA-level. To compensate,\nyou may wish the expand the standard errors produced by\nsurvey_mean by providing EA identifiers in EAID.\nHere, we include id = EAID_1.13\nCompared with our original estimate, notice that the 95% confidence\ninterval for our contraceptive use estimate is wider when we provide\ninformation about the clustered sample design - these are\n“cluster-robust” standard errors.\n\n\ndat %>% \n  as_survey_design(weight = PANELWEIGHT, id = EAID_1) %>% \n  filter(CP_1 < 90 & CP_2 < 90) %>% \n  summarise(\n    survey_mean(\n      CP_1 * CP_2,\n      vartype = \"ci\",\n      level = 0.95,\n      proportion = TRUE,\n      prop_method = \"logit\"\n    )\n  )\n\n\n# A tibble: 1 × 3\n   coef `_low` `_upp`\n  <dbl>  <dbl>  <dbl>\n1 0.188  0.163  0.215\n\nFinally, we’ll also use as_survey_design\nto specify sample strata. For most samples, including Burkina Faso, this\ninformation is included in the variable STRATA.\nWe’ll include it here with strata = STRATA_1.14\n\n\ndat %>% \n  as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_1) %>% \n  filter(CP_1 < 90 & CP_2 < 90) %>% \n  summarise(\n    survey_mean(\n      CP_1 * CP_2,\n      vartype = \"ci\",\n      level = 0.95,\n      proportion = TRUE,\n      prop_method = \"logit\"\n    )\n  )\n\n\n# A tibble: 1 × 3\n   coef `_low` `_upp`\n  <dbl>  <dbl>  <dbl>\n1 0.188  0.164  0.214\n\nThe variable STRATA\nis not available for samples collected from DRC - Kinshasa or\nDRC - Kongo Central. If your extract includes any DRC sample, you’ll\nneed to amend this variable to include one unique numeric code for each\nof those regions.\nFor example, let’s look at a different “wide” extract,\ndat2, containing all of the samples included in this data\nrelease. Notice that STRATA_1 lists the sample strata for\nevery COUNTRY\nexcept for DRC, where you see the value NA.\n\n\n\n\n\ndat2 %>% count(COUNTRY, STRATA_1)\n\n\n# A tibble: 27 × 3\n                          COUNTRY                          STRATA_1     n\n                        <int+lbl>                         <int+lbl> <int>\n 1 1 [Burkina Faso]               85401 [Urban, Burkina Faso]        3058\n 2 1 [Burkina Faso]               85402 [Rural, Burkina Faso]        2154\n 3 2 [Congo, Democratic Republic]    NA                              3487\n 4 7 [Kenya]                      40410 [Bungoma - urban, Kenya]      153\n 5 7 [Kenya]                      40411 [Bungoma - rural, Kenya]      489\n 6 7 [Kenya]                      40412 [Kakamega - urban, Kenya]     133\n 7 7 [Kenya]                      40413 [Kakamega - rural, Kenya]     438\n 8 7 [Kenya]                      40414 [Kericho - urban, Kenya]      249\n 9 7 [Kenya]                      40415 [Kericho - rural, Kenya]      453\n10 7 [Kenya]                      40416 [Kiambu - urban, Kenya]       214\n11 7 [Kenya]                      40417 [Kiambu - rural, Kenya]       311\n12 7 [Kenya]                      40418 [Kilifi - urban, Kenya]       170\n13 7 [Kenya]                      40419 [Kilifi - rural, Kenya]       455\n14 7 [Kenya]                      40420 [Kitui - urban, Kenya]        153\n15 7 [Kenya]                      40421 [Kitui - rural, Kenya]        586\n16 7 [Kenya]                      40422 [Nairobi - urban, Kenya]      494\n17 7 [Kenya]                      40423 [Nandi - urban, Kenya]        260\n18 7 [Kenya]                      40424 [Nandi - rural, Kenya]        711\n19 7 [Kenya]                      40425 [Nyamira - urban, Kenya]      143\n20 7 [Kenya]                      40426 [Nyamira - rural, Kenya]      382\n21 7 [Kenya]                      40427 [Siaya - urban, Kenya]        130\n22 7 [Kenya]                      40428 [Siaya - rural, Kenya]        437\n23 7 [Kenya]                      40429 [West Pokot - urban, Kenya]   104\n24 7 [Kenya]                      40430 [West Pokot - rural, Kenya]   474\n25 9 [Nigeria]                    56606 [Lagos, Nigeria]             1089\n26 9 [Nigeria]                    56611 [Kano - Urban]                437\n27 9 [Nigeria]                    56612 [Kano - Rural]                561\n\nNow let’s see what happens when we try to produce population-level\nestimates with STRATA_1:\n\n\ndat2 %>% \n  as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_1) %>% \n  filter(CP_1 < 90 & CP_2 < 90) %>% \n  group_by(COUNTRY, GEOCD, GEONG) %>% \n  summarise(\n    survey_mean(\n      CP_1 * CP_2,\n      vartype = \"ci\",\n      level = 0.95,\n      proportion = TRUE,\n      prop_method = \"logit\"\n    )\n  )\n\n\nError in (function (object, ...) : missing values in `strata'\n\nThis fails because as_survey_design\nencounters NA values in STRATA_1. Fortunately,\nwe can replace those values with numeric codes from the variable GEOCD:\n\n\ndat2 %>% count(GEOCD)\n\n\n# A tibble: 3 × 2\n               GEOCD     n\n           <int+lbl> <int>\n1  1 [Kinshasa]       1973\n2  2 [Kongo Central]  1514\n3 NA                 14238\n\nIf GEOCD is not NA, we’ll use its numeric\ncode in place of STRATA_1. Otherwise, we’d like to leave\nSTRATA_1 unchanged. However, because both variables include\nvalue labels, we’ll first need remove them with as.numeric. To avoid\nconfusion with the original variable STRATA_1, we’ll call\nour new variable STRATA_RECODE.\n\n\ndat2 <- dat2 %>% \n  mutate(\n    STRATA_RECODE = if_else(\n      is.na(GEOCD), \n      as.numeric(STRATA_1), \n      as.numeric(GEOCD)\n    )\n  ) \n\ndat2 %>% count(GEOCD, STRATA_1, STRATA_RECODE)\n\n\n# A tibble: 28 × 4\n                GEOCD                          STRATA_1 STRATA_RECODE     n\n            <int+lbl>                         <int+lbl>         <dbl> <int>\n 1  1 [Kinshasa]         NA                                         1  1973\n 2  2 [Kongo Central]    NA                                         2  1514\n 3 NA                 40410 [Bungoma - urban, Kenya]            40410   153\n 4 NA                 40411 [Bungoma - rural, Kenya]            40411   489\n 5 NA                 40412 [Kakamega - urban, Kenya]           40412   133\n 6 NA                 40413 [Kakamega - rural, Kenya]           40413   438\n 7 NA                 40414 [Kericho - urban, Kenya]            40414   249\n 8 NA                 40415 [Kericho - rural, Kenya]            40415   453\n 9 NA                 40416 [Kiambu - urban, Kenya]             40416   214\n10 NA                 40417 [Kiambu - rural, Kenya]             40417   311\n11 NA                 40418 [Kilifi - urban, Kenya]             40418   170\n12 NA                 40419 [Kilifi - rural, Kenya]             40419   455\n13 NA                 40420 [Kitui - urban, Kenya]              40420   153\n14 NA                 40421 [Kitui - rural, Kenya]              40421   586\n15 NA                 40422 [Nairobi - urban, Kenya]            40422   494\n16 NA                 40423 [Nandi - urban, Kenya]              40423   260\n17 NA                 40424 [Nandi - rural, Kenya]              40424   711\n18 NA                 40425 [Nyamira - urban, Kenya]            40425   143\n19 NA                 40426 [Nyamira - rural, Kenya]            40426   382\n20 NA                 40427 [Siaya - urban, Kenya]              40427   130\n21 NA                 40428 [Siaya - rural, Kenya]              40428   437\n22 NA                 40429 [West Pokot - urban, Kenya]         40429   104\n23 NA                 40430 [West Pokot - rural, Kenya]         40430   474\n24 NA                 56606 [Lagos, Nigeria]                    56606  1089\n25 NA                 56611 [Kano - Urban]                      56611   437\n26 NA                 56612 [Kano - Rural]                      56612   561\n27 NA                 85401 [Urban, Burkina Faso]               85401  3058\n28 NA                 85402 [Rural, Burkina Faso]               85402  2154\n\nNow, we can use STRATA_RECODE with as_survey_design\nto obtain population estimates for each nationally representative or\nsub-nationally representative sample.\n\n\ndat2 %>% \n  as_survey_design(weight = PANELWEIGHT, id = EAID_1, strata = STRATA_RECODE) %>% \n  filter(CP_1 < 90 & CP_2 < 90) %>% \n  group_by(COUNTRY, GEOCD, GEONG) %>%\n  summarise(\n    survey_mean(\n      CP_1 * CP_2,\n      vartype = \"ci\",\n      level = 0.95,\n      proportion = TRUE,\n      prop_method = \"logit\"\n    )\n  )\n\n\n# A tibble: 6 × 6\n# Groups:   COUNTRY, GEOCD [5]\n                         COUNTRY              GEOCD      GEONG   coef `_low` `_upp`\n                       <int+lbl>          <int+lbl>  <int+lbl>  <dbl>  <dbl>  <dbl>\n1 1 [Burkina Faso]               NA                 NA         0.188  0.164  0.214 \n2 2 [Congo, Democratic Republic]  1 [Kinshasa]      NA         0.320  0.288  0.353 \n3 2 [Congo, Democratic Republic]  2 [Kongo Central] NA         0.268  0.215  0.329 \n4 7 [Kenya]                      NA                 NA         0.366  0.350  0.382 \n5 9 [Nigeria]                    NA                  2 [Lagos] 0.293  0.259  0.330 \n6 9 [Nigeria]                    NA                  4 [Kano]  0.0537 0.0322 0.0880\n\nInclusion Criteria for\nAnalysis\nIn the remainder of this series, we’ll be\nshowcasing code you can use to reproduce key indicators included in the\nPMA Longitudinal Brief for each sample. In many cases,\nyou’ll find separate reports available in English and French, and for\nboth national and sub-national summaries. For reference, here are the\nhighest-level population summaries available in English for each sample\nwhere Phase 2 IPUMS PMA data is currently available:\nBurkina\nFaso\nDRC\n- Kinshasa\nDRC\n- Kongo Central\nKenya\nNigeria\n- Kano\nNigeria\n- Lagos\nPanel data in these reports is limited to the de facto\npopulation of women who completed the Female Questionnaire in both Phase\n1 and Phase 2. This includes women who slept in the household during the\nnight before the interview for the Household Questionnaire. The de\njure population includes women who are usual household members, but\nwho slept elsewhere that night. We’ll remove de jure cases\nrecorded in the variable RESIDENT.\nFor example, returning to our “wide” data extract for Burkina Faso,\nyou can see the number of women who slept in the household before the\nHousehold Questionnaire for each phase reported in\nRESIDENT_1 and RESIDENT_2:\n\n\n\n\n\ndat %>% count(RESIDENT_1)\n\n\n# A tibble: 3 × 2\n                                         RESIDENT_1     n\n                                          <int+lbl> <int>\n1 11 [Visitor, slept in hh last night]                106\n2 21 [Usual member, did not sleep in hh last night]   174\n3 22 [Usual member, slept in hh last night]          6510\n\ndat %>% count(RESIDENT_2)\n\n\n# A tibble: 5 × 2\n                                                       RESIDENT_2     n\n                                                        <int+lbl> <int>\n1 11 [Visitor, slept in hh last night]                               74\n2 21 [Usual member, did not sleep in hh last night]                 230\n3 22 [Usual member, slept in hh last night]                        5993\n4 31 [Slept in hh last night, no response if usually lives in hh]     1\n5 NA                                                                492\n\nNA cases in RESIDENT_2 represent women who\nwere lost to follow-up in Phase 2. In Stata, these cases will be\nrepresented by blank values.\nThe de facto population is represented in codes 11 and 22.\nWe’ll use filter to include only those cases.\n\n\ndat_2 <- dat %>% \n  filter(\n    RESIDENT_1 == 11 | RESIDENT_1 == 22, \n    RESIDENT_2 == 11 | RESIDENT_2 == 22\n  ) \n\ndat_2 %>% count(RESIDENT_1, RESIDENT_2)\n\n\n# A tibble: 4 × 3\n                                 RESIDENT_1                                RESIDENT_2     n\n                                  <int+lbl>                                 <int+lbl> <int>\n1 11 [Visitor, slept in hh last night]      11 [Visitor, slept in hh last night]         56\n2 11 [Visitor, slept in hh last night]      22 [Usual member, slept in hh last night]    39\n3 22 [Usual member, slept in hh last night] 11 [Visitor, slept in hh last night]         17\n4 22 [Usual member, slept in hh last night] 22 [Usual member, slept in hh last night]  5855\n\nAdditionally, these reports only include women who completed (or\npartially completed) both Female Questionnaires. This information is\nreported in RESULTFQ.\nIn our “wide” extract, this information appears in\nRESULTFQ_1 and RESULTFQ_2: if you select the\n“Female Respondents” option at checkout, only women who completed (or\npartially completed) the Phase 1 Female Questionnaire will be included\nin your extract.\n\n\n\nWe’ll further restrict our sample by selecting only cases where\nRESULTFQ_2 shows that the woman also completed the Phase 2\nquestionnaire. Notice that, in addition to each of the value 1 through\n10, there are several non-response codes numbered 90\nthrough 99. You’ll see similar values repeated across all IPUMS PMA\nvariables, except that they will be left-padded to match the maximum\nwidth of a particular variable (e.g. 9999 is used for INTFQYEAR,\nwhich represents a 4-digit year for the Female Interview).\n\n\ndat %>% count(RESULTFQ_2)\n\n\n# A tibble: 11 × 2\n                                       RESULTFQ_2     n\n                                        <int+lbl> <int>\n 1  1 [Completed]                                  5491\n 2  2 [Not at home]                                  78\n 3  3 [Postponed]                                    22\n 4  4 [Refused]                                      66\n 5  5 [Partly completed]                             12\n 6  7 [Respondent moved]                             15\n 7 10 [Incapacitated]                                19\n 8 95 [Not interviewed (female questionnaire)]        4\n 9 96 [Not interviewed (household questionnaire)]   192\n10 99 [NIU (not in universe)]                       399\n11 NA                                               492\n\nPossible non-response codes include:\n95 Not interviewed (female questionnaire)\n96 Not interviewed (household questionnaire)\n97 Don’t know\n98 No response or missing\n99 NIU (not in universe)\nThe value NA in an IPUMS extract indicates that a\nparticular variable is not provided for a selected sample. In a “wide”\nLongitudinal extract, it may also signify that a\nparticular person was not included in the data from a particular phase.\nHere, an NA appearing in RESULTFQ_2 indicates\nthat a Female Respondent from Phase 1 was not found in Phase 2.\nYou can drop incomplete Phase 2 female responses as follows:\n\n\ndat_3 <- dat %>% filter(RESULTFQ_2 == 1) \n\ndat_3 %>% count(RESULTFQ_1, RESULTFQ_2)\n\n\n# A tibble: 2 × 3\n            RESULTFQ_1    RESULTFQ_2     n\n             <int+lbl>     <int+lbl> <int>\n1 1 [Completed]        1 [Completed]  5487\n2 5 [Partly completed] 1 [Completed]     4\n\nGenerally, we will combine both filtering steps together in a single\nfunction like so:\n\n\ndat <- dat %>% \n  filter(\n    RESIDENT_1 == 11 | RESIDENT_1 == 22, \n    RESIDENT_2 == 11 | RESIDENT_2 == 22,\n    RESULTFQ_2 == 1\n  ) \n\n\n\nIn upcoming posts, we’ll use the remaining cases to show how PMA\ngenerates key indicators for contraceptive use status\nand family planning intentions and outcomes. The\nsummary report for each country includes measures disaggregated by\ndemographic variables like:\nMARSTAT\n- marital status\nEDUCATT\nand EDUCATTGEN\n- highest attended level of education15\nAGE\n- age16\nWEALTHQ\nand WEALTHT\n- household wealth quintile or tertile17\nURBAN\nand SUBNATIONAL\n- geographic location18\nWe’ll be releasing a new blog post in this series every two\nweeks, but you can also get regular updates from the IPUMS Global Health Twitter page.\nJoin us again on March 15 for a full rundown of both “wide” and “long”\ndata extract options available from IPUMS PMA.\n\n\n\nDean, Natalie, and Marcello Pagano. 2015. “Evaluating Confidence Interval Methods for Binomial\nProportions in Clustered Surveys.” Journal of Survey\nStatistics and Methodology 3 (4): 484–503. https://doi.org/10.1093/jssam/smv024.\n\n\nIn addition to these three in-person\nsurveys, PMA also conducted telephone interviews with panel members\nfocused on emerging issues related to the COVID-19 pandemic in 2020.\nThese telephone surveys are already available for several countries -\nsee our series on PMA\nCOVID-19 surveys for details.↩︎\nDisplaced\nGPS coordinates for the centroid of each EA are available for most\nsamples by\nrequest from PMA. IPUMS PMA provides shapefiles for PMA countries here.↩︎\nQuestionnaires administered in each\ncountry may vary from this Core Household Questionnaire\n- click\nhere for details.↩︎\nQuestionnaires administered in each\ncountry may vary from this Core Female Questionnaire -\nclick here\nfor details.↩︎\nThe “study area” is area within which\nresident enumerators should attempt to find panel women that have moved\nout of their Phase 1 dwelling. This may extend beyond the woman’s\noriginal EA as determined by in-country administrators - see PMA Phase 2 and\nPhase 3 Survey Protocol for details.↩︎\nIn cases where no Phase 1 household\nmembers remained in the dwelling at Phase 2, women from the household\nare considered lost to follow-up (LTFU). A panel member is also\nconsidered LTFU if a Phase 2 Household Questionnaire was not completed,\nif she declined to participate, or if she was deceased or otherwise\nunavailable.↩︎\nThe srvyr package is a\ntidy implementation of\nthe popular survey package\nfor R, authored by Dr. Thomas Lumley. For thorough discussion of the\ntypes of weights available in both R and Stata, we recommend this\nblog post by Dr. Lumley.↩︎\nHQWEIGHT reflects the calculated\nselection probability for a household in an EA, normalized at the\npopulation-level. Users intending to estimate population-level\nindicators for households should restrict their sample to one\nperson per household via LINENO\n- see household\nweighting guide for details.↩︎\nFQWEIGHT adjusts\nHQWEIGHT for female non-response within the EA, normalized\nat the population-level - see female\nweighting guide for details.↩︎\nPOPWT can be used to\nestimate population-level counts - click here\nor check out this\nvideo for details.↩︎\nSee Dean & Pagano (2015) for discussion.↩︎\nSee svyciprop for a\ncomplete list of methods.↩︎\nAs we’ll see in an upcoming post,\nwomen are considered “lost to follow-up” if they moved outside the study\narea after Phase 1. Therefore, EAID_1 and\nEAID_2 are identical for all panel members: you can use\neither one to identify sample clusters.↩︎\nAs with EAID,\nyou may use either STRATA_1 or STRATA_2 if\nyour analysis is restricted to panel members.↩︎\nLevels in EDUCATT may\nvary by country; EDUCATTGEN recodes country-specific levels\nin four general categories.↩︎\nAges are frequently reported in\nfive-year groups: 15-19, 20-24, 25-29, 30-34, 35-39, 40-44, and 45-49.↩︎\nHouseholds are divided into\nquintiles/tertiles relative to the distribution of an asset SCORE\nweighted for all sampled households. For subnationally-representative\nsamples (DRC and Nigeria), separate wealth distributions are calculated\nfor each sampled region.↩︎\nSUBNATIONAL includes\nsubnational regions for all sampled countries; country-specific\nvariables are also available on the household\n- geography page.↩︎\n",
    "preview": "posts/2022-03-01-phase2-discovery/../../images/new_data.png",
    "last_modified": "2022-12-22T14:42:45-05:00",
    "input_file": {},
    "preview_width": 2555,
    "preview_height": 1437
  },
  {
    "path": "posts/2022-02-15-cei-analysis/",
    "title": "Modeling client satistifaction with both individual and facility characteristics",
    "description": "We use multilevel models to examine factors related to women's satisfaction with family planning care received from the service delivery facilities in Kenya.",
    "author": [
      {
        "name": "Jiao Yu",
        "url": "https://www.researchgate.net/profile/Jiao-Yu-6"
      },
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-02-15",
    "categories": [
      "Client Exit Interviews",
      "Data Analysis",
      "lme4",
      "Multilevel model"
    ],
    "contents": "\n\nContents\nWhy “Multilevel?”\nTheory\nStatistical rationale\n\nHow it works\nFixed effects\nVariance decomposition\nRandom intercept model\n\nSetup\nVariable recoding\nSummary table\nModels\nVisualization\n\n\nThroughout this series, we’ve been looking at PMA Client Exit Interview (CEI) surveys as a resource for understanding women’s assessments of care received from providers of family planning services. In a previous post, we explained how family planning researchers aggregate multiple dimensions of client assessment together in key indicators like the Method Information Index Plus. We’ve also shown how to incorporate CEI data together with data collected about each facilty in PMA Service Delivery Point (SDP) surveys.\nHere, we’ll wrap up this series with an example analysis that uses both cllient and facility data together while addressing the hierarchical structure of CEI sample design. Specifically, we’ll examine factors related to client satisfaction for women who received a family planning method or prescription from their provider. Our hypothesis is that the determinants of client satisfaction are multidimensional, including both individual client characteristics and certain features specific to each facility (like the range of family planning methods available).\nAs we explore this question, we’ll be building on the data cleaning steps outlined in our last post so that we can focus our attention on analytic design. As we’ll see, ordinary least squares regression may not be a good match for CEI data, which come from a convenience sample of female clients visiting a non-representative sample of facilities. Instead, we’ll model unobserved differneces between facilities as random effects in a mulitlevel model.\nWhy “Multilevel?”\nIn general, we use multilevel models when data have a nested or clustered structure - meaning that smaller levels of analysis (family planning clients) are contained within larger grouping units (facilities). Readers might recall that we’ve briefly covered multilevel modeling before, where we modeled similarities between PMA households within sample clusters as random effects. In general, multilevel models are often appropriate when data are collected in a spatial, temporal, or otherwise grouped structure. You may wonder why should we care about data structure? The short answer is that we should select an optimal statistical model based on the data we intend to analyze. But there are more factors to consider.\nTheory\nIn most social science research, model selection should be theory-driven. The best model choice is one that has a sound theoretical rationale. When thinking about social phenomena, we often ignore how social context plays a role in an individual’s life. By looking at data collected from individuals, we are focusing on the micro-level effects of specific characteristics on outcomes of interest, but these micro-level effects may vary across larger social contexts at the macro-level1.\nA frequently cited example is from education research examining children’s academic achievement. Any given child’s performance in school may primarily depend on their parents’ education and socioeconomic background. But teacher characteristics and the abilities of other children in their classroom are also likely to influence the child’s performance. Because of these classroom effects, we would expect that a child’s test score is the result of both their individual characteristics and the features of their classroom, which are shared amongst their classmates. In a study where multpile students from the same classroom are sampled, we would need a statistical approach that explicitly address both individual and classroom effects.\nStatistical rationale\nMore importantly, the reason we choose multilevel models over ordinary least squares (OLS) is that failing to recognize a multilevel data structure may violate key assumptions in the OLS approach. One of these assumptions is the independence of observations. This assumption posits that observations in a regression should be independent of one another.\nWhen individuals are sampled within groups, individuals from the same group may be more alike than individuals selected from different groups. This is especially true in cases where physical proximity is a strong predictor of group membership: we’ve shown in a previous post that sampled women in CEI surveys mainly visit facilities that are close to their homes, and that civic unrest may disrupt transportation and access to those facilities. As a result, similarities between clients sampled at the same facility may be attributed to more than the facility itself - it could be that those women face similar access issues, live in similar neighborhoods, or share similar personal and occupational characteristics that we can’t observe directly. If we ignore the spatial organization of our data, we risk underestimating the standard errors of our model (Gelman and Hill 2006).\nFortunately, multilevel modeling gives us a way to simultaneously analyze data collected about both individual clients and the facilities where they were interviewed. In general, this approach enables us to link individuals to their social contexts and estimate the extent of group effects on individual outcomes. Moreover, it handles differences in number of women sampled at each facility - an important feature given that CEI data only include family planning clients who happened to visit each facility during a two day observation period (McElreath 2020).\n\nMultilevel models go by many different names. The most common synonyms for multilevel models are hierarchical linear models, mixed effects models, and random effects models. People may use them all interchangeably.\nHow it works\nBefore we dive in, let’s revisit the simpler OLS appraoch, where all clients would be modeled with a single linear function. Consider a model where we estimate only the intercept:\n\\[\ny_i = \\beta_0 + e_i \n\\] Here, \\(y_i\\) represents an outcome: in our case, this will be a particular client’s satisfaction with family planning services after receiving a family planning method or prescription. \\(\\beta_0\\) is the regression intercept - it is the mean satisfaction score for all clients in the sample of all facilities. \\(e_i\\) is the “error” term - also called the “residual” - and it measures the difference between an individual’s actual satisfaction score and the score predicted for them by our model. Let’s take a look at a hypothetical sample.\n\n\n\nThis plot demonstrates an OLS regression line for client satisfaction with no predictors. The horizontal line corresponds to the overall mean satisfaction, which is also the intercept \\(\\beta_0\\)=4.5. The distance from Ann’s score to the mean is the level-1 (individual level) residual \\(e_i\\)=3.5. Ann’s evaluation of services can be calculated as the sum of two parts: the overall mean and her residual, i.e. 4.5+3.5=8.\nAs we have mentioned, the OLS regression model only captures average relationships in the data and it can not address variations in the relationship between variables across units or groups. The average score of satisfaction across all facilities is 4.5, whereas the effect that any particular facility has on the client satisfaction is unknown. It is possible that Facility A’s rating is way better than the rating of other facilities, but that pattern would be totally ignored under the OLS framework. Fortunately, we have other options.\nFixed effects\nInstead of employing a simple OLS regression, we could address differences between facilities via a fixed effects approach, where we create dummy variables for each facility identified by FACILITYID within the same OLS framework. Suppose we have 200 facilities in our sample. We choose one facility as the reference and include indicators for the remaining 199 facilities as dummy variables. This approach is advantageous if you intend to compare service qualities across different facilities. Yet, the limitation is obvious: when the number of facilities is is too large compared to the number of clients, we experience a high risk of overfitting our model to the particular facilities we happend to sample. Another drawback in this approach is that it does not allow models to include facility-level explanatory variables - like the number of family planning methods available - since facility-level variables will have the same value for each dummy variable.\nVariance decomposition\nNow, let’s move on to the multilevel model. Again, we consider an intercept-only model. We will rewrite our model as:\n\\[\ny_{ij} = \\beta_0 + u_j+e_{ij} \n\\] Compare this to the OLS regression equation. First, we include a subscript \\(j\\) to represent the facility identification. Now \\(y_{ij}\\) represents the satisfaction score of woman \\(i\\) who receives services from facility \\(j\\). Second, a new term \\(u_j\\) is included in the model, which represents the difference between a facility’s mean score and the overall mean. \\(\\beta_0\\) is again the average satisfaction and \\(e_{ij}\\) is individual \\(i\\)’s deviation to the mean satisfaction score of her facility.\nLet’s turn to our hypothetical data. We found Ann receives family planning services from Facility A and her rating of services is based on her experiences at that facility. Of course, our sample includes several women that also visited Facility A: we’ll use the color red to mark these women on our plot. We can easily calculate the mean satisfaction score for Facility A by averaging the values of the red points. This facility mean is represented by a horizontal red line. Now, the distance of Ann’s score to the overall mean score is decomposed into two parts (or in statistical terms, two variance components): one is the distance from the facility mean to the overall mean. This corresponds to \\(u_j\\). The other is the distance from her score to the facility’s mean score, \\(e_{ij}\\). To calculate Ann’s satisfaction, we sum up the overall mean (intercept), the group level deviation, and the individual residual, 4.5+2.5+1=8. Technically, We can repeat this process to find out all facility means, the group-level residuals (\\(u_{j, \\ where \\ j=1, 2…n}\\)), and individual-level residuals (\\(e_{ij,\\ where \\ i=1, 2…k, \\ j=1, 2… n}\\)).\n\n\n\nIf there are 200 facilities in our sample, we can draw 200 regression lines for each of the facilities. Unlike the fixed overall mean \\(\\beta_0\\), these group-level means (group-level intercepts) vary across facilities. That is to say, each facility has its own intercept and the distance from the intercepts to the overall mean is represented by \\(u_j\\). Statistically, to gauge these variations, we’ve assumed that group-level residuals follow a normal distribution in order to estimate their variance after fitting the model. Intuitively, the estimated variance of \\(u_j\\) indicates the extent to which the group-level intercept, on average, varies by facilities/groups/units. Similarly, the estimated variance \\(e_{ij}\\) represents the variance of individual scores around their affiliated group-level average (the group-level intercept).\n\nThe term fixed effects are not used in a consistent way. Fixed effects can be defined as varying coefficients that are not themselves modeled, such as dummy variables. It also refers to the coefficients that do not vary by group, just as the overall mean score in our example. See Gelman and Hill (2006) for a discussion.\nThe varying coefficients in a multilevel model are called random effects. The term fixed effects refers to coefficients that do not vary by group. In our case, the fixed effect is the estimated coefficient of the overall mean satisfaction score (\\(\\beta_0\\)). The random effects are the coefficients of group-level residuals (\\(u_j\\)) and individual-level residuals (\\(e_{ij}\\)).\nRandom intercept model\nA basic multilevel model is a random intercept model. Random intercept models estimate unique lines for each group, where each line is parallel to the overall average line (just as we have shown in our intercept-only model above). Facility A’s regression line is parallel to the horizontal line of the mean satisfaction scores. The regression line for Facility B will be parallel to the line of the overall mean as well. When adding an explanatory variable to the model, we would be able to estimate the slope of the explanatory variable \\(\\beta_1\\). The parallel property remains the same, even as we add multiple dimensions to our model from multiple facility-level and client-level variables. The reason we call this a random intercept model is because the regression lines for any two facilities will always be parallel: the difference between facilities is captured by a unique intercept term.\n\nIt’s worth noting that the terminology in statistical literature is confusing and inconsistent in terms of random intercept. Sometimes \\(\\beta_0+u_j\\) is called the random intercept while other people regard \\(u_i\\) as the random intercept.\nAs we’ll see, multilevel model interpretation will be familiar to those who are already familiar with ordinary least squares. \\(\\beta_0\\) is the average of the outcome when all \\(x\\) variables are equal to zero. \\(\\beta_1\\) is the increase in the outcome for one unit increase in \\(x\\). The main differnece is that we’ll also need to interpret a random effects term: this will be the estimated variance (or standard deviation) of \\(u_j\\) and \\(e_{ij}\\). These represent the unexplained dispersion of client satistifaction scores at the facility level and at the individual level, respectively.\n\nThe random intercept model assumes that the strength of the relationship between \\(x\\) and \\(y\\) is the same across groups. Other multilevel models - like the random slope model - are preferred when the effect of \\(x\\) on \\(y\\) varies by group.\nSetup\nLet’s now turn to a specific example using CEI and SDP data from the 2019 sample from Kenya. To keep setup simple, we’ll restrict our analysis to a number of variables we’ve covered in previous posts in this series - there’s a lot more that you might include in your own analysis! Specifically, we’ll need these variables from the 2019 Kenya CEI survey:\nThree measures of client satisfaction that we’ll index as our dependent variable\nFPGETDESIREDTODAY: obtained her preferred family planning method\nRETURNFAC: would return to the same provider again\nREFERFAC: would recommend the provider to a friend or relative\n\nDemographic variables for each client\nAGE: age in years\nMARSTAT: marital status\nEDUCATTGEN: education (4 categories)\nBIRTHEVENT: number of birth events\n\nVariables describing the quality of information provided about the method each client received, which we’ll again index as Method Information Index Plus (MII+). They ask the client to recall whether their provider mentioned:\nDISCOTHFP: other family planning methods they might use\nTELLSIDEEFF: side effects or problems they might have with the method\nTELLSEPROB: what to do about those side effects or problems\nTELLSWITCH: that they could switch methods in the future\n\nAdditionally, we’ll merge several facility variables from the 2019 Kenya SDP survey. For the sake of simplicity, we’ll consider variables indicating whether a facility provides a specific family planning method (variables with names ending with PROV, e.g. IUDPROV). See this post for tips when working with several method-specific variables generated from the same multiple response question. We’ll simply count the total number of methods provided at each facility.\nYou’ll need to create separate data extracts for the CEI and SDP surveys. Once you’ve downloaded them, load each into R along with the tidyverse and ipumsr packages as follows:\n\n\n\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\n\ncei <- read_ipums_micro(\n  ddi = \"data/pma_00001.xml\",\n  data = \"data/pma_00001.dat.gz\"\n) \n\nsdp <- read_ipums_micro(\n  ddi = \"data/pma_0002.xml\",\n  data = \"data/pma_0002.dat.gz\"\n)\n\n\n\n\n\n\nAs we’ve discussed, it’s often useful to filter CEI data using FPINFOYN: clients who received neither family planning information nor a method were not given further questions, so they’ll appear as NIU (not in universe) in most variables. Dropping these cases will eliminate most of the values we’d otherwise label NA below.\n\n\ncei <- cei %>% filter(FPINFOYN == 1)\n\n\n\nNext, we’ll link women from the cei data extract together with data from the corresponding facility in the sdp data extract. We’ll use left_join, thereby preserving all rows in cei while duplicating rows from sdp to match every woman sampled at a particular facility (this also drops any facility where no client exit interviews were conducted).\n\n\ndat <- left_join(\n  cei, \n  sdp, \n  by = \"FACILITYID\", \n  suffix = c(\"_CEI\", \"_SDP\")\n) \n\n\n\nVariable recoding\nThe service quality measure MII+ discussed in our previous post describes the depth of information given by a provider to a woman who received a family planning method or prescription during her visit. If a woman did not receive a method or prescription - or if she did not respond to one of the component questions of MII+ - we’ll want to exclude her from our analysis. Similarly, we’ll drop cases where FPGETDESIREDTODAY shows that the woman obtained no method because she was only seeking follow-up care. Finally, we’ll exclude any woman who declined to answer or responded “don’t know” to any of our key questions of interest.\nWe’ll mark all of these cases NA so that they’ll be dropped automatically from our analysis.\n\n\ndat <- dat %>% \n  select(\n    FACILITYID, AGE, BIRTHEVENT,\n    REFERFAC, RETURNFAC, \n    FPGETDESIREDTODAY, \n    TELLSWITCH, DISCOTHFP, TELLSIDEEFF, TELLSEPROB, \n    EDUCATTGEN, MARSTAT,\n    ends_with(\"PROV\")\n  ) %>% \n  mutate(across(\n    everything(), \n    ~.x %>% \n      lbl_na_if(~.lbl %in% c(\n        \"Don't know\", \n        \"No response or missing\",\n        \"NIU (not in universe)\",\n        \"Neither, did not obtain\"\n      )) %>% \n      zap_labels()\n  )) \n\n\n\nNext, we’ll recode every binary variable as a logical taking the value TRUE for affirmative responses, and FALSE for negative responses (all other values are coded NA). As in our last post, this will include binary recodings for EDUCATTGEN and MARSTAT as EDUCAT2 (more than primary/middle school education) and MARSTAT2 (either married or living with a partner).\n\n\ndat <- dat %>% \n  mutate(\n    EDUCAT2 = EDUCATTGEN > 2,\n    MARSTAT2 = MARSTAT == 21 | MARSTAT == 22,\n    across(-c(FACILITYID, AGE, BIRTHEVENT), as.logical)\n  ) %>% \n  select(-c(EDUCATTGEN, MARSTAT))\n\n\n\nLastly, we’ll create three aggregate measures to summarise most of the logical variables we’ve just created.\nSATIS, our dependent variable, will be the sum of TRUE values in FPGETDESIREDTODAY, RETURNFAC, and REFERFAC\nNUM_METHODS_PROV will count the number of methods provided at each client’s facility (variables ending with PROV)\nMIIplus will be TRUE if all four components of MII+ are TRUE\nWe’ll use transmute here to build all three while dropping each of their component variables. We also preserve FACILITYID, AGE, BIRTHEVENT, EDUCAT2, and MARSTAT2 by including them as-is. Finally, we’ll use drop_na to drop any cases with NA values in any of our variables of interest.\n\n\n\n\n\ndat <- dat %>%\n  rowwise() %>% \n  transmute(\n    FACILITYID, AGE, BIRTHEVENT, EDUCAT2, MARSTAT2,\n    SATIS = sum(REFERFAC, RETURNFAC, FPGETDESIREDTODAY, na.rm = TRUE),\n    NUM_METHODS_PROV = sum(c_across(ends_with(\"PROV\")), na.rm = TRUE),\n    MIIplus = if_all(c(TELLSWITCH, DISCOTHFP, TELLSEPROB, TELLSIDEEFF))\n  ) %>% \n  ungroup()\n\n\n\nAs a last step, we’ll create new variable labels for each measure that we’ll use in all figures that follow.\n\n\ndat <- dat %>% \n  labelled::set_variable_labels(\n    SATIS = \"Client satisfaction index\",\n    MIIplus = \"Method Information Index PLUS (MII+)\",\n    NUM_METHODS_PROV = \"Number of methods provided by facility\",\n    BIRTHEVENT = \"Birth count\",\n    EDUCAT2 = \"Education: more than primary/middle school\",\n    MARSTAT2 = \"Married or living with partner\",\n    AGE = \"Age\"\n  )\n\n\n\nSummary table\nNow that we’ve finished data cleaning, let’s take a look at the distribution of these variables in a gtsummary table. When creating the table, we’ll specify a specific summary statistic for FACILITYID so that the total number of sampled facilities is shown via n_distinct; we’ll use the default summary statistics for all other variables.\n\n\nlibrary(gtsummary)\n\ndat %>% \n  tbl_summary(\n    digits = list(everything() ~ 0),       \n    missing = \"no\",\n    statistic = list(FACILITYID ~ \"{n_distinct}\"),\n    label = list(FACILITYID ~ \"Number of sampled facilities\")\n  ) %>% \n  modify_table_body(\n    ~.x %>% \n      mutate(variable = variable %>% fct_relevel(\n        \"AGE\", \"BIRTHEVENT\", \"EDUCAT2\", \"MARSTAT2\", \"MIIplus\", \"FACILITYID\", \n        \"NUM_METHODS_PROV\", \"SATIS\"\n      )) %>% \n      arrange(variable)\n  ) %>% \n  modify_spanning_header(everything() ~ \"# Descriptive Statistics\") %>% \n  modify_header(update = list(label ~ \" \")) %>% \n  italicize_labels() \n\n\n\n\n        Descriptive Statistics\n\n      \n    \n      N = 3,7491\n    Age\n27 (23, 32)Birth count\n2 (1, 4)Education: more than primary/middle school\n2,053 (55%)Married or living with partner\n3,176 (85%)Method Information Index PLUS (MII+)\n2,127 (57%)Number of sampled facilities\n438Number of methods provided by facility\n7 (6, 8)Client satisfaction index\n0\n3 (0%)1\n21 (1%)2\n338 (9%)3\n3,387 (90%)\n        \n          1\n          \n           \n          n_distinct; Median (IQR); n (%)\n          \n      \n    \n\nAt the bottom of this table, we display the frequency and percentage of scores on our dependent variable, SATIS. As you can see, a strong majority (90%) of sampled clients provided affirmative responses for all three component survey questions captured by this “client satisfaction index.” Among the remaining cases, only about 1% provided affirmative responses to fewer than two questions.\nOur integer independent variables are summarised by median (and IQR), while our logical (binary) independent variables are summarised by frequency (and percent). Notably: only a slim majority of clients receiving a family planning method met the criteria for MII+ (57%). Meanwhile, we see that 50% of sampled facilities provide between 6 and 8 different family planning methods (among 13 methods listed on the SDP questionnaire). Our final sample includes 3,749 clients sampled at 438 facilities.\nModels\nMultilevel models can easily be estimated in R using the package lme4. Because the lme4 package does not include p values by default, we also load the lmerTest to generate significance levels for each of our coefficients. Finally, we’ll need broom.mixed to import tidy methods used to display model output.\n\n\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(broom.mixed)\n\n\n\nAs you can see in the code chunk below, the code for a multilevel model is similar to an OLS model. The only difference is an additional group component or facility effect. The (1 | FACILITYID) is included at the end of the model, which means that we allow the intercept, represented by 1, to vary by facilities. Let’s first estimate an intercept-only model without including any explanatory variables; we’ll call this model m1, and we’ll display the results in a gtsummary table.\n\n\n# Model\nm1 <- lmer(SATIS ~ 1 + (1 | FACILITYID), data = dat) \n\n# Table \nm1 %>% \n  gtsummary::tbl_regression(\n    conf.int = TRUE, \n    intercept = TRUE,\n    tidy_fun = broom.mixed::tidy,\n    label = list(\n      `(Intercept)` = \"Intercept\",\n      `FACILITYID.sd__(Intercept)` = \"Random Effects: facility (SD)\",\n      `Residual.sd__Observation` = \"Random Effects: client residual (SD)\"\n    )\n  ) %>% \n  modify_spanning_header(everything() ~ \"# Model 1: Intercept-only Model\") %>% \n  modify_header(update = list(label ~ \" \")) %>% \n  add_significance_stars()\n\n\n\n\n        Model 1: Intercept-only Model\n\n      \n    \n      Beta1\n      SE2\n    Intercept\n2.9***\n0.009Random Effects: facility (SD)\n0.14\nRandom Effects: client residual (SD)\n0.30\n\n        \n          1\n          \n           \n          *p<0.05; **p<0.01; ***p<0.001\n          \n        \n          2\n          \n           \n          SE = Standard Error\n          \n      \n    \n\nNotice that there are three estimated terms here (we’ve customized their labels to make the output easier to read). The overall Intercept is listed first: it stands for average satisfaction score for all women in the sample. It represents the mean satisfaction score in the complete Kenya 2019 sample (if you recall the plot, the intercept corresponds to the horizontal line \\(\\beta_0\\)):\n\n\ndat %>% summarise(mean_SATIS = mean(SATIS) %>% round(1))\n\n\n# A tibble: 1 × 1\n  mean_SATIS\n       <dbl>\n1        2.9\n\nThere are also two terms for this model’s random effects. The first shows the estimated standard deviation of facility intercepts. If needed, you can find the intercepts generated for each sampled facility with the coef function like so:\n\n\nm1_coef <- coef(m1)$FACILITYID %>% \n  rownames_to_column(\"FACILITYID\") %>% \n  tibble() \n\nm1_coef\n\n\n# A tibble: 438 × 2\n   FACILITYID `(Intercept)`\n   <chr>              <dbl>\n 1 404111001           2.85\n 2 404111003           2.82\n 3 404111004           2.96\n 4 404111005           2.95\n 5 404111006           2.96\n 6 404111007           2.98\n 7 404111011           2.72\n 8 404111012           2.96\n 9 404111013           2.78\n10 404111015           2.90\n# … with 428 more rows\n\nThe final term is the estimated standard deviation for individual clients (SD\\(e_{ij}\\)). Predicted values for clients can be obtained with the predict function and attached to dat for comparison with each individual’s actual SATIS score:\n\n\npredict(m1) %>% \n  tibble() %>% \n  bind_cols(dat) %>% \n  select(SATIS, PREDICTED = \".\")\n\n\n# A tibble: 3,749 × 2\n   SATIS PREDICTED\n   <dbl>     <dbl>\n 1     2      2.82\n 2     3      2.82\n 3     3      2.82\n 4     3      2.82\n 5     3      2.82\n 6     3      2.82\n 7     3      2.85\n 8     3      2.85\n 9     2      2.82\n10     3      2.82\n# … with 3,739 more rows\n\nNext, we’ll include all of our explanatory variables in a second model and save the model estimates to m2\n\n\nm2 <- lmer(\n  SATIS ~ MIIplus + NUM_METHODS_PROV + AGE +\n    BIRTHEVENT + EDUCAT2 + MARSTAT2 + (1 | FACILITYID), \n  data = dat\n) \n\nm2 %>% \n  gtsummary::tbl_regression(\n    conf.int = TRUE, \n    show_single_row = where(is.logical),\n    tidy_fun = broom.mixed::tidy,\n    label = list(\n      `FACILITYID.sd__(Intercept)` = \"Random Effects: facility (SD)\",\n      `Residual.sd__Observation` = \"Random Effects: client residual (SD)\"\n    )\n  ) %>% \n  modify_spanning_header(everything() ~ \"# Model 2: Mixed Effects Model\") %>% \n  modify_header(update = list(label ~ \" \")) %>% \n  add_significance_stars()\n\n\n\n\n        Model 2: Mixed Effects Model\n\n      \n    \n      Beta1\n      SE2\n    Method Information Index PLUS (MII+)\n0.05***\n0.012Number of methods provided by facility\n0.00\n0.006Age\n0.00\n0.001Birth count\n0.00\n0.004Education: more than primary/middle school\n-0.02\n0.012Married or living with partner\n0.02\n0.015Random Effects: facility (SD)\n0.13\nRandom Effects: client residual (SD)\n0.30\n\n        \n          1\n          \n           \n          *p<0.05; **p<0.01; ***p<0.001\n          \n        \n          2\n          \n           \n          SE = Standard Error\n          \n      \n    \n\nThe predicted standard deviation for both random effects is nearly unchanged, but the model now includes coefficient estimates for each explanatory variable - our fixed effects. The interpretation for fixed effects is similar to the interpretation for the results of an OLS model; for example, clients who meet the criteria for MII+ are estimated to score 0.05 points higher on our satisfaction index compared to those who do not (although this effect is quite small, it is significant at p < 0.001). None of the other effects are statistically significant.\nSuppose you wanted to review the estimated slopes for each facility with coef as we did above. The key difference between random effects and fixed effects is that the estimated slope for every fixed effect is the same for every facility; only the random effects will vary.\n\n\nm2_coef <- coef(m2)$FACILITYID %>% \n  rownames_to_column(\"FACILITYID\") %>% \n  tibble()\n\nm2_coef\n\n\n# A tibble: 438 × 8\n   FACILITYID `(Intercept)` MIIplusTRUE NUM_METHODS_PROV     AGE\n   <chr>              <dbl>       <dbl>            <dbl>   <dbl>\n 1 404111001           2.75      0.0478          0.00463 0.00105\n 2 404111003           2.71      0.0478          0.00463 0.00105\n 3 404111004           2.87      0.0478          0.00463 0.00105\n 4 404111005           2.86      0.0478          0.00463 0.00105\n 5 404111006           2.86      0.0478          0.00463 0.00105\n 6 404111007           2.87      0.0478          0.00463 0.00105\n 7 404111011           2.65      0.0478          0.00463 0.00105\n 8 404111012           2.89      0.0478          0.00463 0.00105\n 9 404111013           2.72      0.0478          0.00463 0.00105\n10 404111015           2.81      0.0478          0.00463 0.00105\n# … with 428 more rows, and 3 more variables: BIRTHEVENT <dbl>,\n#   EDUCAT2TRUE <dbl>, MARSTAT2TRUE <dbl>\n\nVisualization\nIn previous posts, we’ve explored faceted graphics as a way to compare descriptive statistics across samples or countries - in fact, they’re also a handy way to visualize mixed effect models.\nConsider, for example, a simple version of our model with only one fixed effect: we’ll use AGE here.\n\n\nm3 <- lmer(SATIS ~ AGE + (1 | FACILITYID), data = dat)\n\n\n\nIn a faceted display, we could compare the different regression models produced by facility-specific random effects: let’s look at the facilities with the 3 highest and 3 lowest intercept terms.\n\n\nm3_coefs <- coef(m3)$FACILITYID %>% \n  rownames_to_column(\"FACILITYID\") %>% \n  tibble() \n\nm3_coefs <- bind_rows(\n  slice_max(m3_coefs, `(Intercept)`, n = 3),\n  slice_min(m3_coefs, `(Intercept)`, n = 3)\n)\n\nm3_coefs \n\n\n# A tibble: 6 × 3\n  FACILITYID `(Intercept)`     AGE\n  <chr>              <dbl>   <dbl>\n1 404171022           2.95 0.00118\n2 404111027           2.95 0.00118\n3 404191017           2.95 0.00118\n4 404131020           2.22 0.00118\n5 404131059           2.31 0.00118\n6 404131010           2.38 0.00118\n\nFirst, let’s plot the AGE and SATIS reported for each client in these facilities. We’ll filter our data to include only women who visited one of the facilities in m3_coefs, and we’ll arrange FACILITYID as a factor with levels sorted from the lowest to highest mean satisfaction score.\n\n\ndat_m3 <- dat %>%\n  filter(FACILITYID %in% m3_coefs$FACILITYID) %>% \n  group_by(FACILITYID) %>% \n  mutate(FACSAT = mean(SATIS)) %>% \n  ungroup() %>% \n  mutate(FACILITYID = FACILITYID %>% as_factor %>% fct_reorder(FACSAT))\n\n\n\nNext, we’ll plot actual AGE and SATIS for each client. We’ll use FACILITYID to place responses from clients at the lowest ranking facilities in the top row, whereas clients at the highest ranking facilities will be in the bottom row. Notice that the mode in the top row is 2, while facilities in the bottom row unanimously received perfect 3 rankings.\n\n\n# graphics theme\nsource(\"theme_pma.R\")\n\nplot_m3 <- dat_m3 %>% \n  ggplot(aes(x = AGE, y = SATIS)) + \n  geom_point() + \n  theme_pma(\n    \"Client Satisfaction by Age and Facility\",\n    \"The three lowest and highest rated facilities in Kenya 2019 are shown\"\n  ) + \n  labs(\n    x = \"Age\",\n    y = \"Satisfaction Score\"\n  ) + \n  facet_wrap(vars(FACILITYID), dir = \"h\", ncol = 3)\n\n\n\n\nThe function theme_pma is defined in sourced script you’ll find in the folder for this post on GitHub. Learn more about custom ggplot2 themes here.\n\n\nplot_m3\n\n\n\n\nFinally, we’ll plot the predicted linear model with unique intercepts for each facility.\n\n\nm3_coefs %>% \n  rename(INT = `(Intercept)`, SLOPE = AGE) %>% \n  left_join(dat_m3, by = \"FACILITYID\") %>% \n  group_by(FACILITYID) %>% \n  mutate(FACSAT = mean(SATIS)) %>% \n  ungroup() %>% \n  mutate(FACILITYID = FACILITYID %>% as_factor %>% fct_reorder(FACSAT)) %>% \n  ggplot(aes(x = AGE, y = SATIS)) + \n  geom_point() + \n  geom_abline(aes(intercept = INT, slope = SLOPE)) +\n  theme_pma(\n    \"Client Satisfaction by Age with Facility Random Effects\",\n    \"The three lowest and highest rated facilities in Kenya 2019 are shown\"\n  ) + \n  labs(\n    x = \"Age\",\n    y = \"Satisfaction Score\"\n  ) + \n  facet_wrap(vars(FACILITYID), dir = \"h\", ncol = 3) \n\n\n\n\nHere, we can see the idea of “random intercepts” more clearly. While the slope of all 6 lines is identical (and very nearly zero), each facility has a unique intercept on the y-axis. This reflects the higher client satisfaction in the bottom three facilities compared to those in the top row. Taken together, the effect of age client satisfaction with family planning services is trivial, although the significance is borderline. Results from model m2 indicate a more prominent effect of MIIplus on client satisfaction (this suggests that facility features matter!)\nThis post is also an introduction to the motivation, application, and interpretation of basic multilevel models. We’ve focused on the random intercept model, which is applied to achieve better estimates of baseline differences when we intend to analyze hierarchical data. It is advantageous compared to regular OLS regression because it simultaneously models group-level variation and individual-level differences. For PMA Client Exit Interview data - where clients are sampled at facilities participating on a contemporaneous Serivice Delivery Point survey - multilevel models are a great way to incorporate both facility and client characteristics into your analysis.\n\n\n\nGelman, Andrew, and Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel/Hierarchical Models. 1st edition. Cambridge ; New York: Cambridge University Press.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and STAN. 2nd edition. Boca Raton: Chapman; Hall/CRC.\n\n\nWe recommend readers to check out Karen Robson and David Pevalin (2016) book, Multilevel modeling in plain language for a thorough discussion of the theoretical rationale of multilevel modeling↩︎\n",
    "preview": "posts/2022-02-15-cei-analysis/cei-analysis_files/figure-html5/unnamed-chunk-25-1.png",
    "last_modified": "2022-04-13T13:11:20-04:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 960
  },
  {
    "path": "posts/2022-02-01-cei-fp/",
    "title": "Comparing client experiences with family planning service providers",
    "description": "Service quality questions are included in both Client Exit Interview and Family Planning surveys from PMA. We show how to match similar questions across surveys and compare the results with faceted graphics.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-02-01",
    "categories": [
      "Client Exit Interviews",
      "Data Analysis",
      "Bar Charts",
      "srvyr",
      "ggplot2"
    ],
    "contents": "\n\nContents\nComparable survey questions\nFamily planning clients\nMerge CEI and FP data\nSurvey Design Elements\nVariable Recoding\nGraphics theme\nDemographics\nFaceted bar blot\n\nService Experience\nMethod Information\nClient autonomy\nClient Satisfaction\n\nWrap-up\n\n\n\n\nClient Exit Interview (CEI) surveys from PMA capture the service experience of female family planning clients immediately following a visit to a health facility sampled in a contemporaneous Service Delivery Point (SDP) survey. In previous posts, we’ve explained that CEI surveys use non-random convenience sampling to select reproductive aged women visiting a facility during a particular two-day observation period.\nThis type of sampling is useful because it maximizes the number of available CEI survey participants within a set time frame, but it also introduces potential sources of sample bias against the broader population of female family planning clients in each country or region (both the observation period and the underlying SDP sampling frame are non-random). CEI surveys offer a snapshot of client perspectives at a certain time and place, but they are not intended for population-level inference.\nIn contrast to CEI surveys, PMA Family Planning (FP) surveys are randomly sampled, and there are a number of questions about family planning service quality that are common to both. In FP surveys, women who were currently using a modern family planning method - or had used one in the past 12 months - were asked about their service experience with the provider where they obtained the method (regardless of whether the provider was a facility sampled in an SDP survey). These questions are nearly identical to some of the questions you’ll find in a CEI survey collected in the same time and place, except that women in the FP survey were asked to recall family planning visits that happened potentially several months in the past.\n\nIn this context, a “modern method” refers to any of these methods other than LAM, withdrawal, rhythm, or “other traditional” methods.\nIn this post, we’ll guide you through all of the variables you’ll find in contemporaneous FP and CEI surveys. We’ll also compare descriptive statistics for each CEI sample with population-level estimates derived from a corresponding FP survey. This will give us some sense of how CEI samples compare with a broader population of female family planning clients in each country or region. As of this writing, IPUMS PMA offers FP surveys from the following places that were collected contemporaneously with CEI surveys (these FP surveys are nationally representative, or regionally representative as noted):\nBurkina Faso\nKenya\nDRC - Kongo Central\nDRC - Kinshasa\nNigeria - Lagos\nNigeria - Kano\nTo follow along, you’ll need to create two separate data extracts from the IPUMS PMA website containing these samples - one for the Client Exit Interview unit of analysis, and another for the Family Planning unit of analysis.\n\n\n\nTo switch from one unit of analysis to the other, click the CHANGE button at the top of your screen:\n\n\n\nComparable survey questions\nLet’s take a look at the questions you’ll find repeated in both the CEI and FP surveys. While a particular question may be identical - or nearly identical - on both surveys, you may find it listed under different variable names. The table below shows all of the questions that appear on both surveys (excluding automatically generated technical and geographic variables), and it gives the variable name you’ll need to include in each of your data extracts.\nFor this post, we’ll also include GEOCD and GEONG (survey regions for DRC and Nigeria), as well as FQWEIGHT (the FP sampling weight - no such weight is available for CEI surveys).\n\n\n\nClient Exit Interview\n\n\nFamily Planning Survey\n\n\nDescription\n\n\nAGE\n\n\nAGE\n\n\nRespondent’s age\n\n\nEDUCATT\n\n\nEDUCATT\n\n\nRespondent’s education level\n\n\nEDUCATTGEN\n\n\nEDUCATTGEN\n\n\nRespondent’s education level (general)\n\n\nMARSTAT\n\n\nMARSTAT\n\n\nRespondent’s marital status\n\n\nBIRTHEVENT\n\n\nBIRTHEVENT\n\n\nCount of respondent’s birth events\n\n\nFACILITYTYPE\n\n\nFPPROVIDER\n\n\nFaciliy type (detailed)\n\n\nFACILITYTYPEGEN\n\n\nFPPROVIDER\n\n\nFacility type (general)\n\n\nAUTHORITY\n\n\nFPPROVIDERGEN\n\n\nFacility managing authority\n\n\nREFERFAC\n\n\nFPPROVIDEREFER\n\n\nRespondent would refer a relative/friend to facility\n\n\nRETURNFAC\n\n\nFPPROVIDERETURN\n\n\nRespondent would return to facility\n\n\nFPGETDESIREDTODAY\n\n\nFPGETDESIRED\n\n\nRespondent received preferred FP method\n\n\nFPGETWHYTODAY\n\n\nFPGETDESIREDWHY\n\n\nReason respondent did not receive preferred FP method\n\n\nFPDECIDEMETHOD\n\n\nFPDECIDEMETHOD\n\n\nPerson who decided which FP method the respondent received\n\n\nTELLSWITCH\n\n\nFPTOLDSWITCH\n\n\nProvider told respondent she could switch FP methods in the future\n\n\nDISCOTHFP\n\n\nFPCUROM\n\n\nProvider told respondent about other FP methods she could use\n\n\nTELLSIDEEFF\n\n\nFPCUREFF\n\n\nProvider told respondent about potential side effects / problems\n\n\nTELLSEPROB\n\n\nFPCURDEAL\n\n\nProvider told respondent what to do about side effects / problems\n\n\nINTFQMON\n\n\nINTFQMON\n\n\nInterview month\n\n\nINTFQYEAR\n\n\nINTFQYEAR\n\n\nInterview year\n\n\nGEOCD\n\n\nGEOCD\n\n\nProvince - DRC\n\n\nGEONG\n\n\nGEONG\n\n\nState - Nigeria\n\n\n–\n\n\nFQWEIGHT\n\n\nFemale questionnaire weight (not available for CEI)\n\n\n\nOnce you’ve downloaded both extracts, place them into the “data” folder in your working directory. Load them into R as separate data frames for the moment - we’ll call ours cei and fp.\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\n\ncei <- read_ipums_micro(\n  ddi = \"data/pma_00001.xml\",\n  data = \"data/pma_00001.dat.gz\"\n) \n\nfp <- read_ipums_micro(\n  ddi = \"data/pma_00002.xml\",\n  data = \"data/pma_00002.dat.gz\"\n)\n\n\n\n\n\n\n\n© IPUMS (MPL 2.0)\nFamily planning clients\nWe’ll only be examining a subset of the respondents from both surveys in this post. From the CEI survey, we’ll restrict our analysis to women who received family planning information or a family planning method during their visit (most of the questions on the CEI survey were skipped otherwise). You’ll find this information in the variable FPINFOYN.\n\n\ncei <- cei %>% filter(FPINFOYN == 1)\n\n\n\nFrom the FP survey, we’ll only include those women who were asked questions about a recent family planning visit. If a woman in the FP sample did not answer these questions (either because she had not recently used a modern method, or because she obtained it from somewhere other than a health provider) her response to those questions will be coded 99 for NIU (not in universe). We’ll drop those cases using the variable FPPROVIDERETURN:\n\n\nfp <- fp %>% filter(FPPROVIDERETURN < 99)\n\n\n\nMerge CEI and FP data\nNow that both of our data frames only contain records for women who recently experienced a family planning visit with their provider, we’ll want to merge them together into a single data frame. First, we’ll create a new variable SURVEY indicating whether a particular record originated in the cei or fp data extract, and we’ll then change variable names as needed in fp to match the corresponding variable in cei (use the above table for reference).\n\n\ncei <- cei %>% \n  mutate(SURVEY = \"CEI\")\n\nfp <- fp %>% \n  mutate(SURVEY = \"FP\") %>% \n  rename(\n    FACILITYTYPE = FPPROVIDER,\n    FACILITYTYPEGEN = FPPROVIDER,\n    AUTHORITY = FPPROVIDERGEN,\n    REFERFAC = FPPROVIDEREFER,\n    RETURNFAC = FPPROVIDERETURN,\n    FPGETDESIREDTODAY = FPGETDESIRED,\n    FPGETWHYTODAY = FPGETDESIREDWHY,\n    FPDECIDEMETHOD = FPDECIDEMETHOD,\n    TELLSWITCH = FPTOLDSWITCH,\n    DISCOTHFP = FPCUROM,\n    TELLSIDEEFF = FPCUREFF,\n    TELLSEPROB = FPCURDEAL\n  )\n\n\n\nFinally, we’ll use bind_rows to create a single data frame called dat. All of the variables appearing under the same name in both cei and fp will be merged together automatically. Variables that only appear in one of the original data frames will be preserved as-is, except that rows from the opposite data frame will be automatically populated with the value NA.\n\n\ndat <- bind_rows(cei, fp)\n\n\n\nFor example, INTFQMON and INTFQYEAR appeared in both cei and fp - they describe the month and year in which the interview was conducted. If we now group_by the SURVEY variable we created, we’ll see that that this information has been merged into a single set of variables.\n\n\ndat %>% \n  group_by(SURVEY) %>% \n  count(INTFQMON, INTFQYEAR)\n\n\n# A tibble: 7 × 4\n# Groups:   SURVEY [2]\n  SURVEY      INTFQMON INTFQYEAR     n\n  <chr>      <int+lbl> <int+lbl> <int>\n1 CEI     1 [January]       2020  1056\n2 CEI     2 [February]      2020   603\n3 CEI    12 [December]      2019  4267\n4 FP      1 [January]       2020  2471\n5 FP      2 [February]      2020   294\n6 FP     11 [November]      2019  2630\n7 FP     12 [December]      2019  2159\n\n\nInterviews for this round of CEI surveys were completed between December 2019 and February 2020. Interviews for these FP surveys were completed as part of a new PMA panel study at the same time: between November 2019 and February 2020.\nOn the other hand, variables like FPINFOYN appear only on the CEI survey. If we group by SURVEY and count FPINFOYN cases, we’ll see that all women interviewed for the FP survey are coded NA.\n\n\ndat %>% \n  group_by(SURVEY) %>% \n  count(FPINFOYN)\n\n\n# A tibble: 2 × 3\n# Groups:   SURVEY [2]\n  SURVEY  FPINFOYN     n\n  <chr>  <int+lbl> <int>\n1 CEI      1 [Yes]  5926\n2 FP      NA        7554\n\nSurvey Design Elements\nLike FPINFOYN, the variable representing FP sampling weights FQWEIGHT takes the value NA for all of CEI records in our merged dataset.\n\n\ndat %>% \n  group_by(SURVEY) %>% \n  count(is.na(FQWEIGHT))\n\n\n# A tibble: 2 × 3\n# Groups:   SURVEY [2]\n  SURVEY `is.na(FQWEIGHT)`     n\n  <chr>  <lgl>             <int>\n1 CEI    TRUE               5926\n2 FP     FALSE              7554\n\nBecause we want to derive population-level estimates from the FP survey, we’ll need to specify FQWEIGHT as a weight with help from the srvyr package we’ve used elsewhere on this blog. This would be simple if we only included cases from the FP survey. For example, to compare the mean AGE of family planning clients in the FP sample to the estimated mean AGE of family planning clients in the population for each COUNTRY:\n\n\nlibrary(srvyr)\n\n# `FQWEIGHT` is the sampling weight for the FP survey\ndat %>% \n  filter(SURVEY == \"FP\") %>% \n  as_survey_design(weights = FQWEIGHT) %>% \n  group_by(SURVEY, COUNTRY) %>% \n  summarise(\n    sample_mean = mean(AGE, na.rm = TRUE),\n    pop_mean = survey_mean(AGE, na.rm = TRUE, vartype = NULL)\n  )\n\n\n# A tibble: 4 × 4\n# Groups:   SURVEY [1]\n  SURVEY                        COUNTRY sample_mean pop_mean\n  <chr>                       <int+lbl>       <dbl>    <dbl>\n1 FP     1 [Burkina Faso]                      29.6     30.3\n2 FP     2 [Congo, Democratic Republic]        28.8     29.1\n3 FP     7 [Kenya]                             30.9     30.9\n4 FP     9 [Nigeria]                           32.4     32.5\n\n\n\n\n\n© Greg Freedman Ellis et al. (GPL 2 | GPL 3)\nUnfortunately, this same code produces an error if we try to include all of the CEI cases as well. The problem here is that our weights argument cannot include NA values:\n\n\n# `FQWEIGHT` is `NA` for CEI records\ndat %>% \n  as_survey_design(weights = FQWEIGHT) %>% \n  group_by(SURVEY, COUNTRY) %>% \n  summarise(\n    sample_mean = mean(AGE, na.rm = TRUE),\n    pop_mean = survey_mean(AGE, na.rm = TRUE, vartype = NULL)\n  )\n\n\nError in (function (object, ...) : missing values in `weights'\n\nTo solve this problem, we’ll create a copy of FQWEIGHT called DATWEIGHT, except that DATWEIGHT will take the value 1 for all CEI records. As a result, population estimates derived from functions like survey_mean will be identical to the sample statistics for CEI surveys.\n\n\ndat <- dat %>% mutate(DATWEIGHT = if_else(SURVEY == \"FP\", FQWEIGHT, 1))\n\n# `sample_mean` == `pop_mean` for CEI, but not for FP\ndat %>% \n  as_survey_design(weights = DATWEIGHT) %>% \n  group_by(SURVEY, COUNTRY) %>% \n  summarise(\n    sample_mean = mean(AGE, na.rm = TRUE),\n    pop_mean = survey_mean(AGE, na.rm = TRUE, vartype = NULL)\n  )\n\n\n# A tibble: 8 × 4\n# Groups:   SURVEY [2]\n  SURVEY                        COUNTRY sample_mean pop_mean\n  <chr>                       <int+lbl>       <dbl>    <dbl>\n1 CEI    1 [Burkina Faso]                      28.4     28.4\n2 CEI    2 [Congo, Democratic Republic]        30.5     30.5\n3 CEI    7 [Kenya]                             28.3     28.3\n4 CEI    9 [Nigeria]                           31.3     31.3\n5 FP     1 [Burkina Faso]                      29.6     30.3\n6 FP     2 [Congo, Democratic Republic]        28.8     29.1\n7 FP     7 [Kenya]                             30.9     30.9\n8 FP     9 [Nigeria]                           32.4     32.5\n\nYou might also recall from previous posts that FP surveys are sampled within geographic clusters identified by the variable EAID. When we report population-level estimates from the FP survey, we’ll want to generate cluster-robust standard errors represented in 95% confidence intervals for each point estimate. Sample clusters can be specified with the id argument in as_survey_design like so:\n\n\n# Use `id = EAID` for cluster-robust standard errors \ndat %>% \n  as_survey_design(weights = DATWEIGHT, id = EAID) %>% \n  group_by(SURVEY, COUNTRY) %>% \n  summarise(\n    sample_mean = mean(AGE, na.rm = TRUE),\n    pop_mean = survey_mean(\n      AGE, \n      na.rm = TRUE, \n      vartype = \"ci\" # produces 95% confidence interval be default\n    )\n  )\n\n\n# A tibble: 8 × 6\n# Groups:   SURVEY [2]\n  SURVEY        COUNTRY sample_mean pop_mean pop_mean_low pop_mean_upp\n  <chr>       <int+lbl>       <dbl>    <dbl>        <dbl>        <dbl>\n1 CEI    1 [Burkina Fa…        28.4     28.4         27.9         28.9\n2 CEI    2 [Congo, Dem…        30.5     30.5         29.3         31.6\n3 CEI    7 [Kenya]             28.3     28.3         28.0         28.6\n4 CEI    9 [Nigeria]           31.3     31.3         30.3         32.3\n5 FP     1 [Burkina Fa…        29.6     30.3         29.6         30.9\n6 FP     2 [Congo, Dem…        28.8     29.1         28.4         29.7\n7 FP     7 [Kenya]             30.9     30.9         30.6         31.2\n8 FP     9 [Nigeria]           32.4     32.5         31.5         33.4\n\nNote: because we’re only reporting sample statistics for the non-representative CEI surveys, we’ll need to manually suppress CEI confidence intervals in our tables and figures. More on that in a moment.\nVariable Recoding\nAll of the binary variables in our dataset should be recoded as logicals, and all categorical variables with more than two responses should be recoded as factors (we recommend creating levels for each factor that look exactly as you want them to appear in final tables and figures).\nAs a first step, we’ll want to recode all of the IPUMS PMA top-codes for different types of non-response. We’ll use across to replace codes for the following value labels with NA in all variables.\n\n\ndat <- dat %>% \n  mutate(across(everything(), ~lbl_na_if(.x, ~.lbl %in% c(\n    \"Don't know\", \n    \"No response\",\n    \"Logical edit - missing\",\n    \"No response or missing\",\n    \"NIU (not in universe)\",\n    # Special codes for `FPGETDESIREDTODAY`\n    \"Neither, follow-up visit only\",\n    \"Did not have a preference\",\n    \"Neither, did not obtain\"\n  )))) \n\n\n\nFPGETDESIREDTODAY is a binary indicator with additional response options describing reasons why the client did not obtain her desired family planning method: she may have had no preference, or she may not have obtained a new method during a follow-up visit. We’ll code these responses NA (as if they were NIU).\nThere are three variables that require additional recoding. First, we’ll want to replace the existing SAMPLE variable with a factor containing concise, readable labels. We’ll also use GEOCD and GEONG to parse the regional sampling frames used for DRC and Nigeria.\n\n\ndat <- dat %>% \n  mutate(\n    COUNTRY = COUNTRY %>% \n      as_factor() %>% \n      fct_recode(\"DRC\" = \"Congo, Democratic Republic\") %>% \n      as.character(),\n    GEO = case_when(\n       !is.na(GEOCD) ~ GEOCD %>% as_factor() %>% as.character(),\n       !is.na(GEONG) ~ GEONG %>% as_factor() %>% as.character()\n    ),\n    SAMPLE = if_else(!is.na(GEO), paste0(COUNTRY, \" - \", GEO), COUNTRY),\n    SAMPLE = as_factor(SAMPLE)\n  ) \n\n\n\nAs a result, our new SAMPLE variable looks exactly as we’ll want it to appear on the page:\n\n\ndat %>% count(SURVEY, SAMPLE)\n\n\n# A tibble: 12 × 3\n   SURVEY SAMPLE                  n\n   <chr>  <fct>               <int>\n 1 CEI    Burkina Faso          845\n 2 CEI    DRC - Kinshasa         96\n 3 CEI    DRC - Kongo Central    76\n 4 CEI    Kenya                3901\n 5 CEI    Nigeria - Lagos       460\n 6 CEI    Nigeria - Kano        548\n 7 FP     Burkina Faso         2037\n 8 FP     DRC - Kinshasa        583\n 9 FP     DRC - Kongo Central   474\n10 FP     Kenya                4000\n11 FP     Nigeria - Lagos       356\n12 FP     Nigeria - Kano        104\n\nWe’ll also collapse categories in EDUCATTGEN and MARSTAT, creating new binary logicals EDUCAT2 (more than primary/middle school education) and MARSTAT2 (either married or living with a partner).\n\n\ndat <- dat %>% \n  mutate(\n    EDUCAT2 = EDUCATTGEN > 2,\n    MARSTAT2 = MARSTAT == 21 | MARSTAT == 22\n  )\n\n# Compare `EDUCAT2` with `EDUCATTGEN`\ndat %>% count(EDUCAT2, EDUCATTGEN)\n\n\n# A tibble: 5 × 3\n  EDUCAT2                   EDUCATTGEN     n\n  <lgl>                      <int+lbl> <int>\n1 FALSE    1 [Never attended]           1575\n2 FALSE    2 [Primary/Middle school]    4646\n3 TRUE     3 [Secondary/post-primary]   5207\n4 TRUE     4 [Tertiary/post-secondary]  2047\n5 NA      NA                               5\n\n# Compare `MARSTAT2` with `MARSTAT`\ndat %>% count(MARSTAT2, MARSTAT)\n\n\n# A tibble: 6 × 3\n  MARSTAT2                            MARSTAT     n\n  <lgl>                             <int+lbl> <int>\n1 FALSE    10 [Never married]                  1887\n2 FALSE    31 [Divorced or separated]           609\n3 FALSE    32 [Widow or widower]                164\n4 TRUE     21 [Currently married]              9498\n5 TRUE     22 [Currently living with partner]  1319\n6 NA       NA                                     3\n\nFinally, we’ll recode all of the remaining binary variables as logicals and all of the categorical variables as factors (using the existing IPUMS PMA value labels as levels).\n\n\ndat <- dat %>% \n  mutate(\n    # Create Logicals: `TRUE` if the original variable equals `1`\n    across(\n      c(FPGETDESIREDTODAY, REFERFAC, RETURNFAC, FPGETDESIREDTODAY,\n        TELLSWITCH, DISCOTHFP, TELLSIDEEFF, TELLSEPROB),\n      ~.x == 1\n    ),\n    # Create Factors: each level is an IPUMS value label\n    across(c(FPGETWHYTODAY, FPDECIDEMETHOD), as_factor)\n  ) \n\n\n\nGraphics theme\nOne last setup item: we’ll specify a custom theme for figures made with ggplot2. This allows us to generally specify the font, legend, and colors used in all of the graphics created below. We’ll create a function called theme_pma that applies those formatting options, and we’ll also give it two arguments for a plot title and (optionally) a subtitle.\n\nYou’ll find more details about creating custom themes in this post, or on this documentation page.\n\n\nlibrary(sysfonts)\nlibrary(showtext)\n\nsysfonts::font_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext::showtext_auto()\noptions(tibble.print_min = 20)\n\ntheme_pma <- theme_pma <- function(\n  title, \n  subtitle = NULL\n){\n  components <- list(\n    theme_minimal() %+replace% \n      theme(\n        text = element_text(family = \"cabrito\", size = 13),\n        plot.title = element_text(\n          size = 22, color = \"#00263A\", hjust = 0, margin = margin(b = 5)\n        ),\n        plot.subtitle = element_text(\n          size = 16, hjust = 0, margin = margin(b = 10)\n        ),\n        legend.position = \"bottom\",\n        strip.background = element_blank(),\n        strip.text.y = element_text(size = 16, angle = 0),\n        panel.spacing = unit(1, \"lines\"),\n        axis.text.y = element_blank()\n      ),\n    guides(fill = guide_legend(reverse = TRUE)),\n    scale_fill_manual(values = list(\"#00263AD9\", \"#98579BD9\")),\n    labs(\n      title = title,\n      subtitle = subtitle,\n      x = NULL,\n      y = NULL,\n      fill = NULL\n    )\n  )\n}\n\n\n\n\n\n\n\n© RStudio (CC0 1.0)\nDemographics\n\n\n\nWe’re now ready to see how CEI samples compare with population estimates derived from representative FP surveys. First, we’ll consider the demographic composition of our samples. There are four main demographic variables appearing in both the CEI and FP surveys. They represent the woman’s\nage (in years)\nmarital status (recoded as MARSTAT2 above)\neducation level (recoded as EDUCAT2 above)\nnumber of live birth events (excluding stillbirths)\nWe’ll use summarise to calculate summary demographic statistics for each SAMPLE separately for the CEI and FP SURVEY, and we’ll store the result in a table called demographics. You can use survey_mean for all four variables here: we’ll calculate a simple average for both AGE and BIRTHEVENT, and we’ll use the optional argument proportion = TRUE to calculate proportions for MARSTAT2 and EDUCAT2 (multiplying by 100 creates percentages).\n\nThe argument proportion = TRUE ensures the the standard error estimates for MARSTAT2 and EDUCAT2 are within the range 0 to 1 (see also prop_method).\n\n\ndemographics <- dat %>% \n  as_survey_design(weights = DATWEIGHT, id = EAID) %>% \n  group_by(SURVEY, SAMPLE) %>% \n  summarise(\n    across(\n      c(AGE, BIRTHEVENT),\n      ~survey_mean(.x, na.rm = TRUE, vartype = \"ci\"),\n      .names = \"{.col}_est\"\n    ),\n    across(\n      c(EDUCAT2, MARSTAT2),\n      ~100 * survey_mean(.x, na.rm = TRUE, vartype = \"ci\", proportion = TRUE),\n      .names = \"{.col}_est\"\n    )\n  ) \n\ndemographics\n\n\n# A tibble: 12 × 14\n# Groups:   SURVEY [2]\n   SURVEY SAMPLE        AGE_est AGE_est_low AGE_est_upp BIRTHEVENT_est\n   <chr>  <fct>           <dbl>       <dbl>       <dbl>          <dbl>\n 1 CEI    Burkina Faso     28.4        27.9        28.9           2.85\n 2 CEI    DRC - Kinsha…    30.3        28.8        31.9           3.02\n 3 CEI    DRC - Kongo …    30.6        29.0        32.3           3.14\n 4 CEI    Kenya            28.3        28.0        28.6           2.70\n 5 CEI    Nigeria - La…    33.9        33.2        34.7           2.95\n 6 CEI    Nigeria - Ka…    29.1        28.3        29.8           4.41\n 7 FP     Burkina Faso     30.3        29.6        30.9           3.60\n 8 FP     DRC - Kinsha…    29.0        28.0        29.9           2.23\n 9 FP     DRC - Kongo …    29.2        28.3        30.1           2.94\n10 FP     Kenya            30.9        30.6        31.2           3.04\n11 FP     Nigeria - La…    32.6        31.4        33.7           2.34\n12 FP     Nigeria - Ka…    32.0        30.5        33.4           5.33\n# … with 8 more variables: BIRTHEVENT_est_low <dbl>,\n#   BIRTHEVENT_est_upp <dbl>, EDUCAT2_est <dbl>,\n#   EDUCAT2_est_low <dbl>, EDUCAT2_est_upp <dbl>, MARSTAT2_est <dbl>,\n#   MARSTAT2_est_low <dbl>, MARSTAT2_est_upp <dbl>\n\n\nThe .names argument in across allows you to use the pronoun {.col} together with a suffix like _est that you’ll like to append to each of the original column names. We do this so we can easily organize the point estimates separately from confidence intervals in pivot_longer below.\nThe results here are awkwardly shaped. Because we specified vartype = \"ci\", we’ve created three columns for each variable: the suffix _est shows the point-estimate, while _est_upp and _est_low respectively show the upper and lower bounds of a 95% confidence interval.\nLet’s reshape demographics so that we see only one point-estimate and confidence interval per row. This will slim-down our table to just six columns:\nSURVEY\nSAMPLE\nVAR - the name of the demographic variable\nEST - the point estimate calculated by survey_mean\nLOW - the 95% confidence interval lower limit\nUPP - the 95% confidence interval upper limit\n\n\ndemographics <- demographics %>% \n  rename_with(~str_remove(.x, \"_est\"), matches(\"low|upp\")) %>% \n  pivot_longer(\n    -c(SAMPLE, SURVEY),\n    names_sep = \"_\",\n    names_to = c(\"VAR\", \"STAT\"),\n    values_to = \"VALUE\"\n  ) %>% \n  pivot_wider(names_from = STAT, values_from = VALUE) %>% \n  rename_with(toupper, everything())\n\ndemographics\n\n\n# A tibble: 48 × 6\n# Groups:   SURVEY [2]\n   SURVEY SAMPLE              VAR          EST   LOW   UPP\n   <chr>  <fct>               <chr>      <dbl> <dbl> <dbl>\n 1 CEI    Burkina Faso        AGE        28.4  27.9  28.9 \n 2 CEI    Burkina Faso        BIRTHEVENT  2.85  2.71  2.98\n 3 CEI    Burkina Faso        EDUCAT2    36.2  31.8  40.8 \n 4 CEI    Burkina Faso        MARSTAT2   89.3  86.9  91.4 \n 5 CEI    DRC - Kinshasa      AGE        30.3  28.8  31.9 \n 6 CEI    DRC - Kinshasa      BIRTHEVENT  3.02  2.58  3.46\n 7 CEI    DRC - Kinshasa      EDUCAT2    94.8  85.8  98.2 \n 8 CEI    DRC - Kinshasa      MARSTAT2   63.5  45.5  78.4 \n 9 CEI    DRC - Kongo Central AGE        30.6  29.0  32.3 \n10 CEI    DRC - Kongo Central BIRTHEVENT  3.14  2.77  3.52\n# … with 38 more rows\n\nRemember that we purposefully coded DATWEIGHT == 1 for CEI records above so that survey_mean would only produce sample means for those surveys. As a result, the confidence intervals you see for CEI statistics here are not valid. We’ll only want to keep the values in LOW and UP if the value in SURVEY is “FP”.\n\n\ndemographics <- demographics %>% \n  mutate(across(c(LOW, UPP), ~case_when(SURVEY == \"FP\" ~ .x)))\n\n# `LOW` and `UPP` are now `NA` if `SURVEY == \"CEI\"`\ndemographics %>% arrange(VAR, SAMPLE)\n\n\n# A tibble: 48 × 6\n# Groups:   SURVEY [2]\n   SURVEY SAMPLE              VAR     EST   LOW   UPP\n   <chr>  <fct>               <chr> <dbl> <dbl> <dbl>\n 1 CEI    Burkina Faso        AGE    28.4  NA    NA  \n 2 FP     Burkina Faso        AGE    30.3  29.6  30.9\n 3 CEI    DRC - Kinshasa      AGE    30.3  NA    NA  \n 4 FP     DRC - Kinshasa      AGE    29.0  28.0  29.9\n 5 CEI    DRC - Kongo Central AGE    30.6  NA    NA  \n 6 FP     DRC - Kongo Central AGE    29.2  28.3  30.1\n 7 CEI    Kenya               AGE    28.3  NA    NA  \n 8 FP     Kenya               AGE    30.9  30.6  31.2\n 9 CEI    Nigeria - Lagos     AGE    33.9  NA    NA  \n10 FP     Nigeria - Lagos     AGE    32.6  31.4  33.7\n# … with 38 more rows\n\nFinally, we also recommend creating two more columns containing labels for variables (VARLBL) and each survey (SURVLBL) that look exactly as you’d like them to appear on your plot.\n\n\ndemographics <- demographics %>% \n  mutate(\n    VARLBL = case_when(\n      VAR == \"EDUCAT2\" ~ \"More than primary education (%)\",\n      VAR == \"AGE\" ~ \"Mean age\",\n      VAR == \"BIRTHEVENT\" ~ \"Mean birth count\",\n      VAR == \"MARSTAT2\" ~ \"Married or living with partner (%)\"\n    ),\n    SURVLBL = case_when(\n      SURVEY == \"FP\" ~ \"FP Population Estimate (95% CI)\",\n      SURVEY == \"CEI\" ~ \"CEI Sample\"\n    )\n  )  \n\n\n\nFaceted bar blot\nLet’s plot the results! Because we want to compare CEI sample statistics directly with population estimates derived from the FP survey, grouped bar charts are a nice choice here. We’ll align two bars (one for each survey), and we’ll use UPP and LOW to plot confidence intervals for the FP population estimates (NA values for the CEI surveys will simply be ignored).\nFirst, consider a layout for just one sample (Kenya) and one variable (AGE). We’ll plot EST on the x-axis, and we’ll plot SURVEY on the y-axis. We’ll assign each of the colors specified by theme_pma (created above) with fill = SURVLBL - this also generates a legend with the survey labels we created. Finally, we’ll plot the upper and lower bounds of our population confidence interval with xmin = LOW and xmax = UPP.\n\n\ndemographics %>% \n  filter(SAMPLE == \"Kenya\", VAR == \"AGE\") %>% \n  ggplot(aes(y = SURVEY, x = EST, fill = SURVLBL, xmin = LOW, xmax = UPP)) + \n  geom_bar(stat = \"identity\") + \n  geom_errorbar(width = 0.4, color = \"#00263A\") +\n  theme_pma(\n    \"Mean Age of Family Planning Clients in Kenya\",\n    \"CEI survey vs population estimated from a contemporaneous FP survey\"\n  ) \n\n\n\n\nIf we arrange one pair of bar charts for each sample in a column, we’ll be able to simultaneously compare the differences across surveys and samples. We’ll use facet_grid to plot one SAMPLE per row.\n\n\ndemographics %>% \n  filter(VAR == \"AGE\") %>% \n  ggplot(aes(y = SURVEY, x = EST, fill = SURVLBL, xmin = LOW, xmax = UPP)) + \n  geom_bar(stat = \"identity\") + \n  facet_grid(rows = vars(SAMPLE)) + # plot one `SAMPLE` per row \n  geom_errorbar(width = 0.4, color = \"#00263A\") +\n  theme_pma(\n    \"Mean Age of Family Planning Clients\",\n    \"CEI surveys vs population estimates from contemporaneous FP surveys\"\n  )\n\n\n\n\nWe can also combine all four demographic variables into a single figure if we plot each VARLBL in a separate column (and allow the x-axis to vary based in the range of each VAR with scales = \"free\").\n\n\ndemographics %>% \n  ggplot(aes(y = SURVEY, x = EST, fill = SURVLBL, xmin = LOW, xmax = UPP)) + \n  geom_bar(stat = \"identity\") + \n  facet_grid(\n    rows = vars(SAMPLE), # plot one `SAMPLE` per row \n    cols = vars(VARLBL), # plot one `VARLBL` per column\n    scales = \"free\"      # fit one x-axis range per `VAR`\n  ) + \n  geom_errorbar(width = 0.4, color = \"#00263A\") +\n  theme_pma(\n    \"Family Planning Client Demographics\",\n    \"CEI surveys vs population estimates from contemporaneous FP surveys\"\n  ) \n\n\n\n\nWhat do we learn from this graphic? For the most part, CEI samples share a similar demographic profile with the broader population of female family planning clients in each place. In most cases, the mean age and birth count of women in a particular CEI sample falls within - or very close to - the range we’d expect to see in the population. Similarly, the percentage of partnered women and women with more than primary education in the CEI sample mirrors the population very closely. Let’s see if these similarities extend beyond demographics into variables that directly measure family planning service experience.\nService Experience\nWe’ll recycle this same workflow as we explore additional variables related to the quality of service experienced by women in each survey. These variables describe three general aspects of service experience, and we’ll make one plot for each:\nMethod information\nClient autonomy\nClient satisfaction\nMethod Information\nCEI and FP surveys each contain four common questions related to the quality of information about family planning methods provided to clients during their visit. They ask the respondent to recall whether their provider mentioned:\n\nother family planning methods they might use\nside effects or problems they might have with the method\nwhat to do about those side effects or problems\nthat they could switch methods in the future\nThese questions are regularly included in global health surveys, and you’ll often find them indexed together as the Method Information Index PLUS (MII+). This index is simple to calculate, so we’ll demonstrate it here: a client meets the criteria for MII+ if she responds positively to all four component questions.\n\n\nYou’ll find questions 1-3 included many global health surveys, including IPUMS DHS samples dating back to 1997. They constitute the original Method Information Index (MII). The fourth question was added to create MII+ more recently. Learn more here.\n\n\ndat <- dat %>% \n  mutate(MIIplus = if_all(c(TELLSWITCH, DISCOTHFP, TELLSEPROB, TELLSIDEEFF)))\n\n\n\nAs shown above, we’ll again create summary proportions for the four source variables along with our new variable MIIplus. The only difference here is that we’ll create VARLBL as a factor with levels sorted in the order we want them to appear on our plot (the index MII+ should appear last).\n\n\nmeth_info <- dat %>% \n  mutate(MIIplus = if_all(c(TELLSWITCH, DISCOTHFP, TELLSEPROB, TELLSIDEEFF))) %>%\n  as_survey_design(weights = DATWEIGHT, id = EAID) %>% \n  group_by(SURVEY, SAMPLE) %>% \n  summarise(across(\n    c(TELLSWITCH, DISCOTHFP, TELLSEPROB, TELLSIDEEFF, MIIplus),\n    ~100 * survey_mean(.x, na.rm = TRUE, vartype = \"ci\", proportion = TRUE),\n    .names = \"{.col}_est\"\n  )) %>% \n  rename_with(~str_remove(.x, \"_est\"), matches(\"low|upp\")) %>% \n  pivot_longer(\n    -c(SAMPLE, SURVEY),\n    names_sep = \"_\",\n    names_to = c(\"VAR\", \"STAT\"),\n    values_to = \"VALUE\"\n  ) %>% \n  pivot_wider(names_from = STAT, values_from = VALUE) %>% \n  rename_with(toupper, everything()) %>% \n  mutate(\n    across(c(LOW, UPP), ~case_when(SURVEY == \"FP\" ~ .x)),\n    VARLBL = VAR %>% \n      fct_relevel(\"DISCOTHFP\", \"TELLSWITCH\", \"TELLSIDEEFF\", \"TELLSEPROB\") %>% \n      fct_recode(\n        \"about other methods \\nshe could use?\" = \"DISCOTHFP\",\n        \"that she could switch \\nmethods in the future?\" = \"TELLSWITCH\",\n        \"aobut any side effects or \\nproblems she might have?\" = \"TELLSIDEEFF\", \n        \"what to do about side \\neffects or problems?\" = \"TELLSEPROB\",\n        \"All of the above \\n (MII+)\" = \"MIIplus\"\n      ),\n    SURVLBL = case_when(\n      SURVEY == \"FP\" ~ \"FP Population Estimate (95% CI)\",\n      SURVEY == \"CEI\" ~ \"CEI Sample\"\n    )\n  ) \n\n\n\nOur plotting function is also nearly identical to the one we used above, except that we’ll use scales = \"fixed\" to assign the same x-axis range to each column.\n\n\nmeth_info %>% \n  ggplot(aes(y = SURVEY, x = EST, fill = SURVLBL, xmin = LOW, xmax = UPP)) + \n  geom_bar(stat = \"identity\") + \n  facet_grid(\n    rows = vars(SAMPLE),  # plot one `SAMPLE` per row \n    cols = vars(VARLBL),  # plot one `VARLBL` per column\n    scales = \"fixed\"      # fit one x-axis range per `VAR`\n  ) + \n  geom_errorbar(width = 0.4, color = \"#00263A\") +\n  theme_pma(\n    \"Componenents of Method Information Index PLUS\",\n    paste(\n      \"During her family planning visit, did the client's provider tell her...\"\n    )\n  ) \n\n\n\n\nGiven that CEI sample participants provided responses immediately following a family planning visit, while FP participants were asked to reflect on these matters potentially several months after theirs, you might expect to find some artifact of recency bias at work in the way that provider conversations are remembered over time.\nIn fact, we don’t see consistent evidence of recency bias in these results. For example, the proportion of women in the Burkina Faso CEI sample responding positively to each component of MII+ is significantly lower than the percentage we’d expect to see in the population. The opposite is true for the Lagos and Konga Central CEI samples, where the proportion of women responding positively to each MII+ component is higher (or statistically the same) compared to the population. In our simple analysis, it seems that differences across countries and regions tell a more consistent story than differences in the recency of the family planning visit - but there’s certainly more to explore here!\nClient autonomy\nA second aspect of service experience covered in both surveys describes whether the client autonomously decided which family planning method she received during her visit, or whether that decision was made with or by someone else.\nThis time, we’re only working with one variable, FPDECIDEMETHOD, so there’s no need to use across in our summary function. We won’t need to plot multiple questions in columns, either; instead, we’ll use columns to show the proportion associated with each response.\n\n\ndecider <- dat %>% \n  as_survey_design(weights = DATWEIGHT, id = EAID) %>% \n  filter(!is.na(FPDECIDEMETHOD)) %>% \n  group_by(SURVEY, SAMPLE, FPDECIDEMETHOD) %>% \n  summarise(FPDECIDEMETHOD_EST = 100*survey_mean(vartype = \"ci\", propo = T)) %>% \n  rename(EST = matches(\"est$\"), LOW = matches(\"low\"), UPP = matches(\"upp\")) %>% \n  mutate(\n    across(matches(\"low|upp\"), ~case_when(SURVEY == \"FP\" ~ .x)),\n    SURVLBL = case_when(\n      SURVEY == \"FP\" ~ \"FP Population Estimate (95% CI)\",\n      SURVEY == \"CEI\" ~ \"CEI Sample\"\n    ),\n    FPDECIDEMETHOD = FPDECIDEMETHOD %>% \n      str_replace(\"and\", \"&\\n\") %>% \n      fct_relevel(\n        \"Respondent alone\", \"Respondent &\\n provider\", \"Respondent &\\n partner\",  \n        \"Provider\", \"Partner\", \"Other\"                                    \n      )\n  ) \n\ndecider %>% \n  ggplot(aes(y = SURVEY, x = EST, fill = SURVLBL, xmin = LOW, xmax = UPP)) + \n  geom_bar(stat = \"identity\", position = \"dodge\") + \n  facet_grid(\n    rows = vars(SAMPLE),  \n    cols = vars(FPDECIDEMETHOD),  # this time, response options in columns\n    scales = \"fixed\"      \n  ) + \n  geom_errorbar(width = 0.4, color = \"#00263A\") +\n  theme_pma(\n    \"Who made the ultimate decision about which method the client received?\",\n    \"CEI surveys vs population estimates from contemporaneous FP surveys\"\n  )\n\n\n\n\nOverall, a plurality of women in every survey indicated that they alone made the ultimate decision about the method they received (this includes a majority of cases in every CEI sample, except for those collected in Nigeria). Partners also contributed to the decision in many cases, but the decision was more commonly shared than made by the partner alone. The proportion for each response in the CEI survey falls within - or very close to - the 95% confidence interval for nearly every population.\nClient Satisfaction\nThe final aspect of service experience you’ll find covered in both CEI and FP surveys deals with the client’s satisfaction with her provider. These questions indicate whether the client:\nobtained her preferred family planning method (if she was seeking one and had a preference)\nwould return to the same provider again\nwould recommend the provider to a friend or relative\nBecause all three variables are binary, we’ll again calculate summary proportions representing positive responses to each.\n\n\nsatisf <- dat %>% \n  as_survey_design(weights = DATWEIGHT, id = EAID) %>% \n  group_by(SURVEY, SAMPLE) %>%\n  summarise(across(\n    c(REFERFAC, RETURNFAC, FPGETDESIREDTODAY),\n    ~100 * survey_mean(.x, na.rm = TRUE, vartype = \"ci\", proportion = TRUE),\n    .names = \"{.col}_est\"\n  )) %>% \n  rename_with(~str_remove(.x, \"_est\"), matches(\"low|upp\")) %>% \n  pivot_longer(\n    -c(SAMPLE, SURVEY),\n    names_sep = \"_\",\n    names_to = c(\"VAR\", \"STAT\"),\n    values_to = \"VALUE\"\n  ) %>% \n  pivot_wider(names_from = STAT, values_from = VALUE) %>% \n  rename_with(toupper, everything()) %>% \n  mutate(\n    across(c(LOW, UPP), ~case_when(SURVEY == \"FP\" ~ .x)),\n    VARLBL = VAR %>% \n      fct_relevel(\"FPGETDESIREDTODAY\", \"RETURNFAC\", \"REFERFAC\") %>% \n      fct_recode(\n        \"Obtained her preferred method\" = \"FPGETDESIREDTODAY\",\n        \"Would return to this provider\" = \"RETURNFAC\",\n        \"Would refer this provider \\n to a friend or relative\" = \"REFERFAC\"\n      ),\n    SURVLBL = case_when(\n      SURVEY == \"FP\" ~ \"FP Population Estimate (95% CI)\",\n      SURVEY == \"CEI\" ~ \"CEI Sample\"\n    )\n  )\n\nsatisf %>% \n  ggplot(aes(y = SURVEY, x = EST, fill = SURVLBL, xmin = LOW, xmax = UPP)) + \n  geom_bar(stat = \"identity\") + \n  facet_grid(\n    rows = vars(SAMPLE),  # plot one `SAMPLE` per row \n    cols = vars(VARLBL),  # plot one `VARLBL` per column\n    scales = \"fixed\"      # fit one x-axis range per `VAR`\n  ) + \n  geom_errorbar(width = 0.4, color = \"#00263A\") +\n  theme_pma(\n    \"Family Planning Client Satisfaction\",\n    \"CEI surveys vs population estimates from contemporaneous FP surveys\"\n  ) \n\n\n\n\nAll three measures of client satisfaction were positively rated by nearly all women in every sample, with the curious exception of the two FP surveys fielded in DRC (both DRC CEI samples resemble samples from other places more closely than they resemble DRC FP samples - we’re not sure why this might be!) Otherwise, we see no major differences across samples or surveys; there are several instances where the proportion of women in a CEI sample who said they would “return to this provider” or “refer this provider to a friend or relative” is higher than the upper-limit of a 95% confidence interval for the corresponding population. However, we hesitate to suggest that this is a “statistically significant” difference: because no more than 100% of the population can answer affirmatively, these confidence intervals may be distorted slightly downward (and subject to methodological choices - see survey_mean for details).\nWrap-up\nThere’s no way to concisely describe the relationship between Client Exit Interview samples and population estimates we’ve derived from contemporaneous Family Planning samples. With respect the age, education level, marital status, and the birth history of respondents, CEI samples don’t look very different from larger populations of family planning clients. Likewise, we’ve seen that women in both surveys consistently report high-levels of autonomy when choosing a family planning method, and high-levels of satisfaction with their provider. However, we saw mixed results regarding the quality of information provided about family planning methods (indexed as MII+).\nThese findings are expected, of course, because CEI surveys aren’t designed to represent larger populations of family planning clients - they reflect client perspectives collected only in a specific place and time. Still, we hope it’s helpful to have a general sense of the way that specific variables from CEI surveys resemble similar variables in FP surveys that are randomly sampled.\n\n\n\n",
    "preview": "posts/2022-02-01-cei-fp/cei-fp_files/figure-html5/unnamed-chunk-35-1.png",
    "last_modified": "2022-04-13T13:11:20-04:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1536
  },
  {
    "path": "posts/2022-01-15-cei-sdp/",
    "title": "Building many similar models: easy variable substitution with 'pack' and 'across'",
    "description": "SDP surveys include data on the availability, cost, and demand for up to 13 family planning methods at each facility. Use one generic formula to explore independent models for client counseling on each method.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2022-01-15",
    "categories": [
      "Client Exit Interviews",
      "Service Delivery Points",
      "Data Manipulation",
      "across",
      "pack",
      "glm"
    ],
    "contents": "\n\nContents\nSetup: join CEI and SDP data\nA conventional workflow\nIntroducing pack\nUsing across with packs\nModeling with packs\nThe parent data frame\nUnpacking\n\nJust the code, please\nConventional workflow\nPacked workflow\n\n\n\n\n\nIf you’ve visited this blog before, you’ll know that we’re huge fans of the across function form dplyr - that’s because PMA surveys feature a lot of “select all that apply” style questions where each response option gets formatted as a separate binary variable in the IPUMS PMA data extract system. Because we often work with several variables from the same original question, we usually want to apply the same transformations or summary procedures to a group of variables, and across gives us a powerful way to do that.\nSometimes, we might want to use across in the modeling phase of a particular research project. This happens whenever we want to run a batch of similar models with identical controls, but with different dependent variables or key independent variables of interest. Ideally, we’d like to build one generic model formula and use across to substitute key variables in each iteration.\nConsider, for example, the kind of research question you might explore with the new PMA Client Exit Interview (CEI) survey from Kenya, where women were asked whether they received counseling on several family planning methods immediately following a visit with their healthcare provider. The IPUMS PMA extract system contains one binary variable for each of these response options:\n\nCheck out our CEI Data Discovery post for an overview of the topics included in the CEI survey.\nLCL_201. Which methods were you counselled on during this visit today?\nSelect all methods mentioned. Be sure to scroll to bottom to see all choices.\nYou cannot select 'No response' with other options\n\n[] Female sterilization\n[] Male sterilization\n[] Implant\n[] IUD\n[] Injectables\n[] Pill\n[] Emergency contraception\n[] Male condom\n[] Female condom\n[] Diaphragm\n[] Foam/Jelly\n[] Standard days / cycle beads\n[] LAM\n[] Rhythm method\n[] Withdrawal\n[] None of the above\n[] No response\nYou could imagine a situation where a researcher might want to model the odds that a woman received counseling on each one of these methods in turn. You would probably want to control for a number of individual factors like the woman’s age, whether she is married or partnered, and her birth history. These variables would appear in the formula for every model. On the other hand, you might also want to substitute independent variables having to do with the availability, cost, or overall demand for a particular family planning method at the facility she visited. Is there some way we could iterate through all of the family planning methods in this list, substituting both dependent and independent variables relevant to a particular method?\nIn this post, we’ll showcase an approach to this problem that combines across with pack, a little-known function from the tidyr package that will help us pre-select variables that “go together” in each model. If you visit the documentation page for pack, you’ll see that it’s marked with a blue “maturing” lifecycle tag - this generally means that a particular function is in a stable development stage, but that the package authors are still exploring how it might be used in practice. We think pack offers an excellent way to exploit data masking in certain contexts without need for more advanced tidy-evaluation operators (see rlang). And, because tidyr is part of the “tidyverse”, you’ll be able to load pack and across together in one step:\n\n\n\n\n© RStudio (CC0 1.0)\n\n\nlibrary(tidyverse)\n\n\n\nSetup: join CEI and SDP data\nBefore we dive in, lets take a look at the complete list variables describing availability, cost, and demand for specific family planning methods at sampled facilities in the most recent round of PMA Service Delivery Point (SDP) surveys. Keep in mind: women were interviewed for CEI surveys at a sampled SDP if that facility had an average daily client volume of at least three family planning clients per day. Any of these SDP variables could be predictors in a model for the likelihood that a client received counseling on a particular method:\n\n\n\nMethod\n\n\nProvides\n\n\nCurrent stock\n\n\nDuration current stockout\n\n\nRecent Stockout (3 mo)\n\n\nCharges for\n\n\nFee (local currency)\n\n\nTotal client visits this month\n\n\nNew client visits this month\n\n\nUnits sold this month\n\n\nExpect next shipment (unit)\n\n\nExpect next shipment (value)\n\n\nMale condoms\n\n\nCONPROV\n\n\nCONOBS\n\n\nCONOUTDAY\n\n\nCONOUT3MO\n\n\nCONCHARGE\n\n\nCONFEE\n\n\nCONVNUMMO\n\n\nCONNVNUMMO\n\n\nCONSOLDMO\n\n\nMCUNIT\n\n\nMCVAL\n\n\nStd. Days/Cycle beads\n\n\nCYCBPROV\n\n\nCYCBOBS\n\n\nCYCBOUTDAY\n\n\nCYCBOUT3MO\n\n\nCYCBCHARGE\n\n\nCYCBFEE\n\n\nCYCBVNUMMO\n\n\nCYCBNVNUMMO\n\n\nCYCBSOLDMO\n\n\nBEADSUNIT\n\n\nBEADSVAL\n\n\nDiaphragm\n\n\nDIAPROV\n\n\nDIAOBS\n\n\nDIAOUTDAY\n\n\nDIAOUT3MO\n\n\nDIACHARGE\n\n\nDIAFEE\n\n\nDIAVNUMMO\n\n\nDIANVNUMMO\n\n\nDIASOLDMO\n\n\nDIAUNIT\n\n\nDIAVAL\n\n\nEmergency contraception\n\n\nEMRGPROV\n\n\nEMRGOBS\n\n\nEMRGOUTDAY\n\n\nEMRGOUT3MO\n\n\nEMRGCHARGE\n\n\nEMRGFEE\n\n\nEMRGVNUMMO\n\n\nEMRGNVNUMMO\n\n\nEMRGSOLDMO\n\n\nECUNIT\n\n\nECVAL\n\n\nFemale condom\n\n\nFCPROV\n\n\nFCOBS\n\n\nFCOUTDAY\n\n\nFCOUT3MO\n\n\nFCCHARGE\n\n\nFCFEE\n\n\nFCVNUMMO\n\n\nFCNNUMMO\n\n\nFCSOLDMO\n\n\nFCUNIT\n\n\nFCVAL\n\n\nFoam/Jelly\n\n\nFJPROV\n\n\nFJOBS\n\n\nFJOUTDAY\n\n\nFJOUT3MO\n\n\nFJCHARGE\n\n\nFJFEE\n\n\nFJVNUMMO\n\n\nFJNVNUMMO\n\n\nFJSOLDMO\n\n\nFOAMUNIT\n\n\nFOAMVAL\n\n\nImplant\n\n\nIMPPROV\n\n\nIMPOBS\n\n\nIMPOUTDAY\n\n\nIMPOUT3MO\n\n\nIMPCHARGE\n\n\nIMPFEE\n\n\nIMPVNUMMO\n\n\nIMPNVNUMMO\n\n\nIMPSOLDMO\n\n\nIMPUNIT\n\n\nIMPVAL\n\n\nIUD\n\n\nIUDPROV\n\n\nIUDOBS\n\n\nIUDOUTDAY\n\n\nIUDOUT3MO\n\n\nIUDCHARGE\n\n\nIUDFEE\n\n\nIUDVNUMMO\n\n\nIUDNVNUMMO\n\n\nIUDSOLDMO\n\n\nIUDUNIT\n\n\nIUDVAL\n\n\nPill\n\n\nPILLPROV\n\n\nPILLOBS\n\n\nPILLOUTDAY\n\n\nPILLOUT3MO\n\n\nPILLCHARGE\n\n\nPILLFEE\n\n\nPILLVNUMMO\n\n\nPILLNVNUMMO\n\n\nPILLSOLDMO\n\n\nPILLSUNIT\n\n\nPILLSVAL\n\n\nInjectables - Depo Provera\n\n\nDEPOPROV\n\n\nDEPOOBS\n\n\nDEPOOUTDAY\n\n\nDEPOOUT3MO\n\n\nDEPOCHARGE\n\n\nDEPOFEE\n\n\nDEPOVNUMMO\n\n\nDEPONNUMMO\n\n\nDEPOSOLDMO\n\n\nDEPOUNIT\n\n\nDEPOVAL\n\n\nInjectables - Sayana Press\n\n\nSAYPROV\n\n\nSAYOBS\n\n\nSAYOUTDAY\n\n\nSAYOUT3MO\n\n\nSAYCHARGE\n\n\nSAYFEE\n\n\nSAYVNUMMO\n\n\nSAYNNUMMO\n\n\nSAYSOLDMO\n\n\nINJSPUNIT\n\n\nINJSPVAL\n\n\nFemale sterilization\n\n\nFSTPROV\n\n\n–\n\n\n–\n\n\n–\n\n\nFSTCHARGE\n\n\nFSTFEE\n\n\nFSTVNUMMO\n\n\n–\n\n\n–\n\n\n–\n\n\n–\n\n\nMale sterilization\n\n\nMSTPROV\n\n\n–\n\n\n–\n\n\n–\n\n\nMSTCHARGE\n\n\nMSTFEE\n\n\nMSTVNUMMO\n\n\n–\n\n\n–\n\n\n–\n\n\n–\n\n\n\nThere are only 11 base questions associated with the variables in this table, but each question gets repeated once for up to 13 family planning methods included in the SDP survey. You’ll notice that every variable from a particular question shares the same suffix; for example, every variable indicating whether the facility “provides” a method shares the suffix PROV (like CONPROV, CYCBPROV, DIAPROV, etc).\nTo start, we’ll need to download a data extract containing these variables. In this example, we’ll use an extract that includes only “Facility Respondents” from the Kenya 2019 sample and save it into the “data” folder of our working directory. Load it into R with with ipumsr package like so:\n\n2019-2020 SDP samples for Burkina Faso, DRC, and Nigeria are also currently available from IPUMS PMA. More CEI and SDP samples will be released in early 2022!\n\n\nlibrary(ipumsr)\n\nsdp <- read_ipums_micro(\n  ddi = \"data/pma_00001.xml\",\n  data = \"data/pma_00001.dat.gz\"\n)\n\n\n\nYou’ll then need to download a second data extract containing only “Female Respondents” to the 2019 CEI sample from Kenya.\n\n\ncei <- read_ipums_micro(\n  ddi = \"data/pma_00002.xml\",\n  data = \"data/pma_00002.dat.gz\"\n)\n\n\n\nIn order to link women from the CEI data extract to the correct facility in the SDP data extract, you’ll need to join records by FACILITYID. Here, we will left_join cei with sdp, which means 1) all of the rows in cei will be preserved, and 2) sdp variables for each facility will be copied once for every woman interviewed at that facility. We’ll call the resulting data frame dat.\n\n\ndat <- left_join(\n  cei, \n  sdp, \n  by = \"FACILITYID\", \n  suffix = c(\"_CEI\", \"_SDP\")\n) \n\n\n\n\nThe suffix argument is used to identify the source for any variables that were included in both surveys (e.g. COUNTRY, EAID, FACILITYTYPEGEN).\nWe mentioned in our CEI Data Discovery post that almost all of the questions on the CEI survey were given only to women who received family planning information or a family planning method during their visit to the facility. You’ll find this information recorded in the variable FPINFOYN, so we’ll drop any case where FPINFOYN == 0, indicating that the woman answered no further questions about family planning services.\n\n\ndat <- dat %>% filter(FPINFOYN == 1) \n\n\n\nA conventional workflow\nTo keep this example simple, let’s focus our research question on variables related to the availability of a method at the facility where a CEI respondent was interviewed. Specifically, we want to know: are women less likely to receive counseling on a given family planning method if that method is not reliably available from their provider?\nStrictly speaking, you don’t need to organize variables into packs to examine this problem. Doing so just makes it easier to manipulate and analyze all of the variables related to a particular family planning method. To see how, let’s lay out a workflow for just one of the family planning methods: we’ll pick IUDs to start.\nThe CEI variable METHCOUNIUD will be our dependent variable in this example. It indicates whether the woman received any counseling about IUDs during her visit.\n\n\ndat %>% count(METHCOUNIUD)\n\n\n# A tibble: 2 × 2\n  METHCOUNIUD     n\n    <int+lbl> <int>\n1     0 [No]   2779\n2     1 [Yes]  1122\n\nOur key independent variable should indicate whether the method is “reliably available” at the facility the woman visited. For this example, let’s say that a method is “reliably available” if it was continuously in-stock for three months prior to the SDP interview. You might expect this information to appear in the SDP variable IUDOUT3MO, but look closely at the text from that variable’s universe tab:\n\n\n\n\nIn other words, this question was skipped if 1) a facility that normally provides IUDs was out of stock on the day of the interview, or 2) a facility doesn’t provide the method at all. These cases are marked 99 and labeled NIU (not in universe):\n\n\ndat %>% count(IUDOUT3MO)\n\n\n# A tibble: 3 × 2\n                   IUDOUT3MO     n\n                   <int+lbl> <int>\n1  0 [No]                     2980\n2  1 [Yes]                     204\n3 99 [NIU (not in universe)]   717\n\nWe can’t distinguish facilities with temporary stockouts from those that never provide IUDs at all, so we’ll want to combine the information in IUDOUT3MO with another variable. Here, we’ll use IUDOBS, which indicates whether the facility had IUDs in-stock on the day of the SDP interview (and whether that stock was observed directly by the interviewer). In this case, the universe includes all facilities that normally provide IUDs.\n\n\n\n\n\n\ndat %>% count(IUDOUT3MO, IUDOBS)\n\n\n# A tibble: 6 × 3\n                   IUDOUT3MO                         IUDOBS     n\n                   <int+lbl>                      <int+lbl> <int>\n1  0 [No]                     1 [In-stock and observed]      2725\n2  0 [No]                     2 [In-stock but not observed]   255\n3  1 [Yes]                    1 [In-stock and observed]       159\n4  1 [Yes]                    2 [In-stock but not observed]    45\n5 99 [NIU (not in universe)]  3 [Out of stock]                190\n6 99 [NIU (not in universe)] 99 [NIU (not in universe)]       527\n\nOnly 190 of the 717 facilities that were NIU (not in universe) for IUDOUT3MO were excluded because of a current stockout. The remaining 527 facilities don’t provide IUDs at all.\nSuppose that you were going to combine these variables to build a factor we’ll call IUDAVAIL with 3 levels: facilities where IUDs are “reliably available”, those with a “current or recent stockout”, and those where IUDs are “not provided”. Alone, this task is not too difficult with help from case_when:\n\n\ndat %>% \n  mutate(IUDAVAIL = case_when(\n   IUDOBS == 99 ~ \"not provided\",\n   IUDOBS == 3 | IUDOUT3MO == 1 ~ \"cur/rec stockout\",\n   IUDOUT3MO == 0 ~ \"reliably avail\"\n  )) %>% \n  count(IUDOBS, IUDOUT3MO, IUDAVAIL)\n\n\n# A tibble: 6 × 4\n                          IUDOBS          IUDOUT3MO IUDAVAIL         n\n                       <int+lbl>          <int+lbl> <chr>        <int>\n1  1 [In-stock and observed]      0 [No]            reliably av…  2725\n2  1 [In-stock and observed]      1 [Yes]           cur/rec sto…   159\n3  2 [In-stock but not observed]  0 [No]            reliably av…   255\n4  2 [In-stock but not observed]  1 [Yes]           cur/rec sto…    45\n5  3 [Out of stock]              99 [NIU (not in u… cur/rec sto…   190\n6 99 [NIU (not in universe)]     99 [NIU (not in u… not provided   527\n\nBut what should you do if you want to build a similar variable for each of the nine relevant family planning methods? With the approach we’ve used so far, you’d need to write a separate case_when function for every family planning method. Each would look nearly identical to the last, except that you’d use the relevant OBS and OUT3MO variable for each method. Before we explore an approach with pack, take a look at the code we’re hoping to avoid:\n\n\ndat <- dat %>% \n  mutate(\n    IUDAVAIL = case_when(\n      IUDOBS == 99 ~ \"not provided\",\n      IUDOBS == 3 | IUDOUT3MO == 1 ~ \"cur/rec stockout\",\n      IUDOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    CONAVAIL = case_when(\n      CONOBS == 99 ~ \"not provided\",\n      CONOBS == 3 | CONOUT3MO == 1 ~ \"cur/rec stockout\",\n      CONOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    BEADSAVAIL = case_when(\n      CYCBOBS == 99 ~ \"not provided\",\n      CYCBOBS == 3 | CYCBOUT3MO == 1 ~ \"cur/rec stockout\",\n      CYCBOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    DIAAVAIL = case_when(\n      DIAOBS == 99 ~ \"not provided\",\n      DIAOBS == 3 | DIAOUT3MO == 1 ~ \"cur/rec stockout\",\n      DIAOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    EMRGAVAIL = case_when(\n      EMRGOBS == 99 ~ \"not provided\",\n      EMRGOBS == 3 | EMRGOUT3MO == 1 ~ \"cur/rec stockout\",\n      EMRGOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    FCAVAIL = case_when(\n      FCOBS == 99 ~ \"not provided\",\n      FCOBS == 3 | FCOUT3MO == 1 ~ \"cur/rec stockout\",\n      FCOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    FJAVAIL = case_when(\n      FJOBS == 99 ~ \"not provided\",\n      FJOBS == 3 | FJOUT3MO == 1 ~ \"cur/rec stockout\",\n      FJOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    IMPAVAIL = case_when(\n      IMPOBS == 99 ~ \"not provided\",\n      IMPOBS == 3 | IMPOUT3MO == 1 ~ \"cur/rec stockout\",\n      IMPOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    PILLAVAIL = case_when(\n      PILLOBS == 99 ~ \"not provided\",\n      PILLOBS == 3 | PILLOUT3MO == 1 ~ \"cur/rec stockout\",\n      PILLOUT3MO == 0 ~ \"reliably avail\"\n    )\n  )\n\n\n\nThat’s a lot of repeated effort, and a lot places where you might make a simple copy / paste error. And then, imagine repeating this entire process to include the SDP variables related to cost and demand for different methods - you’d have to do another set of nine case_when functions for every variable you wanted to create!\nIntroducing pack\nThe difference with pack is that we’ll pre-select all of the variables that we ultimately want to substitute into a method-specific model. In other words, we’ll be manually identifying all of the dependent and key independent variables that “go together” in one step at the beginning of our workflow.\n\nYou can include a variable in more than one pack - this will create independent copies of the duplicated variable.\n\n\ndat_packed <- dat %>% \n  pack(\n    BEADS = c(METHCOUNBEADS, CYCBOBS, CYCBOUT3MO),\n    CON = c(METHCOUNMC, CONOBS, CONOUT3MO),\n    DIA = c(METHCOUNDIA, DIAOBS, DIAOUT3MO),\n    EMRG = c(METHCOUNEC, EMRGOBS, DIAOUT3MO),\n    FC = c(METHCOUNFC, FCOBS, FCOUT3MO),\n    FOAM = c(METHCOUNFOAM, FJOBS, FJOUT3MO),\n    IMP = c(METHCOUNIMP, IMPOBS, IMPOUT3MO),\n    IUD = c(METHCOUNIUD, IUDOBS, IUDOUT3MO),\n    PILL = c(METHCOUNPILL, PILLOBS, PILLOUT3MO)\n  ) \n\n\n\n\n\n\n\n© RStudio (CC0 1.0)\nWhen we do this, we create one tidy data frame - a tibble - for all of the variables dealing with a particular family planning method. Each one of these smaller data frames is “packed” into a single column in the larger parent data frame we’ve called dat_packed. This parent also contains all of the original dat variables that we didn’t happen to include in a pack.\nYou can call any one of these smaller packs using the same $ operator you’d use to call any other variable.\n\n\ndat_packed$IUD\n\n\n# A tibble: 3,901 × 3\n   METHCOUNIUD                    IUDOBS IUDOUT3MO\n     <int+lbl>                 <int+lbl> <int+lbl>\n 1      0 [No] 1 [In-stock and observed]   0 [No] \n 2      0 [No] 1 [In-stock and observed]   0 [No] \n 3      0 [No] 1 [In-stock and observed]   1 [Yes]\n 4      0 [No] 1 [In-stock and observed]   0 [No] \n 5      0 [No] 1 [In-stock and observed]   0 [No] \n 6      0 [No] 1 [In-stock and observed]   0 [No] \n 7      0 [No] 1 [In-stock and observed]   0 [No] \n 8      0 [No] 1 [In-stock and observed]   0 [No] \n 9      0 [No] 1 [In-stock and observed]   1 [Yes]\n10      0 [No] 1 [In-stock and observed]   1 [Yes]\n# … with 3,891 more rows\n\nIf you call one of these packs in the larger context of its parent data frame, you’ll notice something strange about the output. Let’s call the IUD pack together with FACILITYID:\n\n\ndat_packed %>% select(FACILITYID, IUD)\n\n\n# A tibble: 3,901 × 2\n   FACILITYID IUD$METHCOUNIUD                   $IUDOBS $IUDOUT3MO\n    <dbl+lbl>       <int+lbl>                 <int+lbl>  <int+lbl>\n 1  404111003          0 [No] 1 [In-stock and observed]    0 [No] \n 2  404111003          0 [No] 1 [In-stock and observed]    0 [No] \n 3  404111001          0 [No] 1 [In-stock and observed]    1 [Yes]\n 4  404111003          0 [No] 1 [In-stock and observed]    0 [No] \n 5  404111003          0 [No] 1 [In-stock and observed]    0 [No] \n 6  404111003          0 [No] 1 [In-stock and observed]    0 [No] \n 7  404111003          0 [No] 1 [In-stock and observed]    0 [No] \n 8  404111003          0 [No] 1 [In-stock and observed]    0 [No] \n 9  404111001          0 [No] 1 [In-stock and observed]    1 [Yes]\n10  404111001          0 [No] 1 [In-stock and observed]    1 [Yes]\n# … with 3,891 more rows\n\nThe tibble header tells us we’ve printed a tibble with 3,901 rows and 2 columns, but we actually see 4 columns - FACILITYID and each of the 3 variables in our IUD pack. Moreover, the pack name IUD appears as a prefix only on the first column IUD$METHCOUNIUD; the others use $ as shorthand to show that they’re members of the same pack.\nIn practice, you’ll rarely want to select individual packs by name - it’s much more useful to select and then mutate or summarize all packs at once. You can do this by selecting all variables that are members of the tibble class with where(is_tibble):\n\n\ndat_packed %>% select(where(is_tibble))\n\n\n# A tibble: 3,901 × 9\n   BEADS$METHCOUNBEADS   $CYCBOBS  $CYCBOUT3MO CON$METHCOUNMC  $CONOBS\n             <int+lbl>  <int+lbl>    <int+lbl>      <int+lbl> <int+lb>\n 1              0 [No] 99 [NIU (… 99 [NIU (no…         0 [No] 1 [In-s…\n 2              0 [No] 99 [NIU (… 99 [NIU (no…         0 [No] 1 [In-s…\n 3              0 [No] 99 [NIU (… 99 [NIU (no…         0 [No] 1 [In-s…\n 4              0 [No] 99 [NIU (… 99 [NIU (no…         0 [No] 1 [In-s…\n 5              0 [No] 99 [NIU (… 99 [NIU (no…         0 [No] 1 [In-s…\n 6              0 [No] 99 [NIU (… 99 [NIU (no…         0 [No] 1 [In-s…\n 7              0 [No] 99 [NIU (… 99 [NIU (no…         0 [No] 1 [In-s…\n 8              0 [No] 99 [NIU (… 99 [NIU (no…         0 [No] 1 [In-s…\n 9              0 [No] 99 [NIU (… 99 [NIU (no…         0 [No] 1 [In-s…\n10              0 [No] 99 [NIU (… 99 [NIU (no…         0 [No] 1 [In-s…\n# … with 3,891 more rows, and 7 more variables: DIA <tibble[,3]>,\n#   EMRG <tibble[,3]>, FC <tibble[,3]>, FOAM <tibble[,3]>,\n#   IMP <tibble[,3]>, IUD <tibble[,3]>, PILL <tibble[,3]>\n\nUsing across with packs\nOnce you’re able to create and select packs, the next step is to repeat the same changes or analytic functions within each pack using across. First, we’ll strip all references to each family planning method from the variable names in each pack with rename. You don’t have to worry about creating duplicate names (e.g. nine variables named OBS) as long as they’re organized in packs (BEADS$OBS, DIA$OBS, EMRG$OBS, etc). In fact, this is exactly what we want!\n\n\ndat_packed <- dat_packed %>% \n  mutate(across(\n    where(is_tibble),\n    ~.x %>% \n      rename(\n        COUNSEL = contains(\"METHCOUN\"),\n        OBS = contains(\"OBS\"),\n        OUT3MO = contains(\"OUT3MO\")\n      )\n  ))\n\n# Within each pack, you'll now find 3 variables of the same name\ndat_packed %>% select(where(is_tibble))\n\n\n# A tibble: 3,901 × 9\n   BEADS$COUNSEL        $OBS     $OUT3MO CON$COUNSEL      $OBS $OUT3MO\n       <int+lbl>   <int+lbl>   <int+lbl>   <int+lbl> <int+lbl> <int+l>\n 1        0 [No] 99 [NIU (n… 99 [NIU (n…      0 [No] 1 [In-st…  0 [No]\n 2        0 [No] 99 [NIU (n… 99 [NIU (n…      0 [No] 1 [In-st…  0 [No]\n 3        0 [No] 99 [NIU (n… 99 [NIU (n…      0 [No] 1 [In-st…  0 [No]\n 4        0 [No] 99 [NIU (n… 99 [NIU (n…      0 [No] 1 [In-st…  0 [No]\n 5        0 [No] 99 [NIU (n… 99 [NIU (n…      0 [No] 1 [In-st…  0 [No]\n 6        0 [No] 99 [NIU (n… 99 [NIU (n…      0 [No] 1 [In-st…  0 [No]\n 7        0 [No] 99 [NIU (n… 99 [NIU (n…      0 [No] 1 [In-st…  0 [No]\n 8        0 [No] 99 [NIU (n… 99 [NIU (n…      0 [No] 1 [In-st…  0 [No]\n 9        0 [No] 99 [NIU (n… 99 [NIU (n…      0 [No] 1 [In-st…  0 [No]\n10        0 [No] 99 [NIU (n… 99 [NIU (n…      0 [No] 1 [In-st…  0 [No]\n# … with 3,891 more rows, and 7 more variables: DIA <tibble[,3]>,\n#   EMRG <tibble[,3]>, FC <tibble[,3]>, FOAM <tibble[,3]>,\n#   IMP <tibble[,3]>, IUD <tibble[,3]>, PILL <tibble[,3]>\n\n\n\n\n\n© RStudio (CC0 1.0)\nThis makes it easy to apply the same case_when function to each pack.\n\n\ndat_packed <- dat_packed %>% \n  mutate(across(\n    where(is_tibble),\n    ~.x %>% \n      mutate(\n        AVAIL = fct_relevel(\n          case_when(\n            OBS == 99 ~ \"not provided\",\n            OBS == 3 | OUT3MO == 1 ~ \"cur/rec stockout\",\n            OUT3MO == 0 ~ \"reliably avail\" \n          ),\n          \"reliably avail\" # set reference group\n        ) \n      )\n  ))\n\n# One `AVAIL` variable was added to each pack\ndat_packed %>% select(where(is_tibble))\n\n\n# A tibble: 3,901 × 9\n   BEADS$COUNSEL      $OBS  $OUT3MO $AVAIL CON$COUNSEL    $OBS $OUT3MO\n       <int+lbl> <int+lbl> <int+lb> <fct>    <int+lbl> <int+l> <int+l>\n 1        0 [No] 99 [NIU … 99 [NIU… not p…      0 [No] 1 [In-…  0 [No]\n 2        0 [No] 99 [NIU … 99 [NIU… not p…      0 [No] 1 [In-…  0 [No]\n 3        0 [No] 99 [NIU … 99 [NIU… not p…      0 [No] 1 [In-…  0 [No]\n 4        0 [No] 99 [NIU … 99 [NIU… not p…      0 [No] 1 [In-…  0 [No]\n 5        0 [No] 99 [NIU … 99 [NIU… not p…      0 [No] 1 [In-…  0 [No]\n 6        0 [No] 99 [NIU … 99 [NIU… not p…      0 [No] 1 [In-…  0 [No]\n 7        0 [No] 99 [NIU … 99 [NIU… not p…      0 [No] 1 [In-…  0 [No]\n 8        0 [No] 99 [NIU … 99 [NIU… not p…      0 [No] 1 [In-…  0 [No]\n 9        0 [No] 99 [NIU … 99 [NIU… not p…      0 [No] 1 [In-…  0 [No]\n10        0 [No] 99 [NIU … 99 [NIU… not p…      0 [No] 1 [In-…  0 [No]\n# … with 3,891 more rows, and 7 more variables: DIA <tibble[,4]>,\n#   EMRG <tibble[,4]>, FC <tibble[,4]>, FOAM <tibble[,4]>,\n#   IMP <tibble[,4]>, IUD <tibble[,4]>, PILL <tibble[,4]>\n\nModeling with packs\nHere’s the real payoff: once you’ve assigned the same name to all of the variables repeated across packs, it’s particularly easy to build parallel model formulas without needing to reference each family planning method by name.\nLet’s now use the AVAIL variable for each method to predict the likelihood that a woman would have received counseling on that method in COUNSEL. In other words, we want to build nine logistic regression models using the appropriate pair of method-specific variables.\nBefore we get to the “packed” approach, again consider a conventional approach where you’d substitute the relevant variables for each family planning method by hand. Have you ever written something that looks like this?\n\n\n\n\n\ndat %>% \n  mutate(across(\n    ends_with(\"AVAIL\") & where(is.character),\n    ~.x %>% fct_relevel(\"reliably avail\") # set reference group\n  )) %>% \n  summarise(\n    # We want to avoid writing a unique formula for each model if possible:\n    BEADS = glm(METHCOUNBEADS ~ BEADSAVAIL, \"binomial\", cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    CON = glm(METHCOUNMC ~ CONAVAIL, \"binomial\", cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    DIA = glm(METHCOUNDIA ~ DIAAVAIL, \"binomial\", cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    EMRG = glm(METHCOUNEC ~ EMRGAVAIL, \"binomial\", cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    FC = glm(METHCOUNFC ~ FCAVAIL, \"binomial\", cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    FOAM = glm(METHCOUNFOAM ~ FJAVAIL, \"binomial\", cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    IMP = glm(METHCOUNIMP ~ IMPAVAIL, \"binomial\", cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    IUD = glm(METHCOUNIUD ~ IUDAVAIL, \"binomial\", cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    PILL = glm(METHCOUNPILL ~ PILLAVAIL, \"binomial\", cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list()\n  ) %>% \n  pivot_longer(everything(), names_to = \"COUNSELED\") %>% \n  unnest(value) %>% \n  mutate(across(where(is.double), ~round(.x, 2)))\n\n\n# A tibble: 26 × 6\n   COUNSELED term                 estimate std.error statistic p.value\n   <chr>     <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 BEADS     (Intercept)           1   e-2      0.23    -19.0     0   \n 2 BEADS     BEADSAVAILcur/rec …   2.14e+0      0.42      1.8     0.07\n 3 BEADS     BEADSAVAILnot prov…   2.16e+0      0.26      2.97    0   \n 4 CON       (Intercept)           2.1 e-1      0.05    -34.3     0   \n 5 CON       CONAVAILcur/rec st…   1.25e+0      0.12      1.85    0.06\n 6 CON       CONAVAILnot provid…   0          280.       -0.05    0.96\n 7 DIA       (Intercept)           0          822.       -0.02    0.98\n 8 DIA       DIAAVAILcur/rec st…   1   e+0   1615.        0       1   \n 9 DIA       DIAAVAILnot provid…   1.72e+6    822.        0.02    0.99\n10 EMRG      (Intercept)           6   e-2      0.09    -29.3     0   \n# … with 16 more rows\n\nAgain - there’s nothing wrong this output. But, with the packed approach we’ll be able to 1) easily substitute method-specific variables in each model without repeating ourselves, and 2) we can use pack names for each model in the COUNSELED column while removing extra text from the term column.\n\n\ndat_packed %>%\n  summarise(across(\n    where(is_tibble),\n    ~glm(COUNSEL ~ AVAIL, \"binomial\", .x) %>%\n      broom::tidy(exp = TRUE) %>%\n      list()\n  )) %>%\n  pivot_longer(everything(), names_to = \"COUNSELED\") %>%\n  unnest(value) %>%\n  mutate(across(where(is.double), ~round(.x, 2))) %>%\n  mutate(term = term %>% str_remove(\"AVAIL\"))\n\n\n# A tibble: 26 × 6\n   COUNSELED term               estimate std.error statistic p.value\n   <chr>     <chr>                 <dbl>     <dbl>     <dbl>   <dbl>\n 1 BEADS     (Intercept)            0.01      0.23    -19.0     0   \n 2 BEADS     cur/rec stockout       2.14      0.42      1.8     0.07\n 3 BEADS     not provided           2.16      0.26      2.97    0   \n 4 CON       (Intercept)            0.21      0.05    -34.3     0   \n 5 CON       cur/rec stockout       1.25      0.12      1.85    0.06\n 6 CON       not provided           0       280.       -0.05    0.96\n 7 DIA       (Intercept)            0       822.       -0.02    0.98\n 8 DIA       cur/rec stockout       1      1615.        0       1   \n 9 DIA       not provided     1722429.      822.        0.02    0.99\n10 EMRG      (Intercept)            0.13      0.48     -4.26    0   \n# … with 16 more rows\n\nWhat happened here? In summary, we created one pack of variables for each family planning method. We then made all variable names identical across packs so that every pack contains a pair of variables called COUNSEL and AVAIL. Finally, we used across to iterate over every pack via where(is_tibble): we applied the same general glm call to every pack, referenced in the context of a particular iteration with the pronoun .x.\nThe parent data frame\nNow suppose we wanted to introduce a common set of controls with each model. We mentioned at the beginning of this post that we might want to control for certain individual factors like like the woman’s age (AGE), whether she is married or partnered (MARSTAT, recoded here as PARTNERED), and her birth history (BIRTHEVENT).\nRemember that these variables were not included in the packed data frames we created above. Instead, they’re located in a parent data frame together with all of our packs. When we iterate through each pack with across, R searches for variables called COUNSEL and AVAIL in one particular pack, masking those in the other packs - this is what allows us to reuse the same variable names for each family planning method. Because each iteration focuses on the contents of one pack, you might expect to get an error if you reference variables outside of that pack.\nFortunately, this is not the case! You can simply add the variables AGE, PARTNERED, and BIRTHEVENT to the formula applied to each pack. R won’t find those variables within the current pack, but it will find them in the parent data frame in which the pack is a member:\n\n\ndat_packed %>%\n  mutate(PARTNERED = MARSTAT %in% 21:22) %>%\n  summarise(across(\n    where(is_tibble),\n    # You can select variables both within and outside of each pack \n    ~glm(COUNSEL ~ AVAIL + AGE + PARTNERED + BIRTHEVENT, \"binomial\", .x) %>%\n      broom::tidy(exp = TRUE) %>%\n      list()\n  )) %>%\n  pivot_longer(everything(), names_to = \"COUNSELED\") %>%\n  unnest(value) %>%\n  mutate(across(where(is.double), ~round(.x, 2))) %>%\n  mutate(term = term %>% str_remove(\"AVAIL\") %>% str_remove(\"TRUE\"))\n\n\n# A tibble: 53 × 6\n   COUNSELED term             estimate std.error statistic p.value\n   <chr>     <chr>               <dbl>     <dbl>     <dbl>   <dbl>\n 1 BEADS     (Intercept)          0.02      0.56     -7.5     0   \n 2 BEADS     cur/rec stockout     2.17      0.42      1.82    0.07\n 3 BEADS     not provided         2.22      0.26      3.07    0   \n 4 BEADS     AGE                  1.01      0.02      0.32    0.75\n 5 BEADS     PARTNERED            1.34      0.31      0.93    0.35\n 6 BEADS     BIRTHEVENT           0.8       0.09     -2.51    0.01\n 7 CON       (Intercept)          0.4       0.2      -4.7     0   \n 8 CON       cur/rec stockout     1.25      0.12      1.85    0.06\n 9 CON       not provided         0       279.       -0.05    0.96\n10 CON       AGE                  0.99      0.01     -1.48    0.14\n# … with 43 more rows\n\nUnpacking\nOccasionally, you may want to unpack variables and return your data frame to its original shape. If you’ve duplicated variable names across packs as we’ve done above, you’ll get an error if you unpack without specifying some way to maintain unique names in the reshaped data frame:\n\n\ndat_packed %>% unpack(where(is_tibble))\n\n\nError: Names must be unique.\nx These names are duplicated:\n  * \"COUNSEL\" at locations 411, 415, 419, 423, 427, etc.\n  * \"OBS\" at locations 412, 416, 420, 424, 428, etc.\n  * \"OUT3MO\" at locations 413, 417, 421, 425, 429, etc.\n  * \"AVAIL\" at locations 414, 418, 422, 426, 430, etc.\nℹ Use argument `names_repair` to specify repair strategy.\n\nIn our case, we’ll use the pack name as a prefix for each new variable name. We’ll use names_sep = \"_\" to separate each prefix with an underscore:\n\n\ndat_packed %>%\n  select(where(is_tibble)) %>%\n  unpack(where(is_tibble), names_sep = \"_\")\n\n\n# A tibble: 3,901 × 36\n   BEADS_COUNSEL     BEADS_OBS    BEADS_OUT3MO BEADS_AVAIL CON_COUNSEL\n       <int+lbl>     <int+lbl>       <int+lbl> <fct>         <int+lbl>\n 1        0 [No] 99 [NIU (not… 99 [NIU (not i… not provid…      0 [No]\n 2        0 [No] 99 [NIU (not… 99 [NIU (not i… not provid…      0 [No]\n 3        0 [No] 99 [NIU (not… 99 [NIU (not i… not provid…      0 [No]\n 4        0 [No] 99 [NIU (not… 99 [NIU (not i… not provid…      0 [No]\n 5        0 [No] 99 [NIU (not… 99 [NIU (not i… not provid…      0 [No]\n 6        0 [No] 99 [NIU (not… 99 [NIU (not i… not provid…      0 [No]\n 7        0 [No] 99 [NIU (not… 99 [NIU (not i… not provid…      0 [No]\n 8        0 [No] 99 [NIU (not… 99 [NIU (not i… not provid…      0 [No]\n 9        0 [No] 99 [NIU (not… 99 [NIU (not i… not provid…      0 [No]\n10        0 [No] 99 [NIU (not… 99 [NIU (not i… not provid…      0 [No]\n# … with 3,891 more rows, and 31 more variables: CON_OBS <int+lbl>,\n#   CON_OUT3MO <int+lbl>, CON_AVAIL <fct>, DIA_COUNSEL <int+lbl>,\n#   DIA_OBS <int+lbl>, DIA_OUT3MO <int+lbl>, DIA_AVAIL <fct>,\n#   EMRG_COUNSEL <int+lbl>, EMRG_OBS <int+lbl>,\n#   EMRG_OUT3MO <int+lbl>, EMRG_AVAIL <fct>, FC_COUNSEL <int+lbl>,\n#   FC_OBS <int+lbl>, FC_OUT3MO <int+lbl>, FC_AVAIL <fct>,\n#   FOAM_COUNSEL <int+lbl>, FOAM_OBS <int+lbl>, …\n\nJust the code, please\nIn case the benefits we gained with pack aren’t quite clear, let’s take a look at the complete workflow in one big code chunk. For comparison’s sake, this is life without pack:\nConventional workflow\n\n\n\n\n\ndat %>% \n  mutate(\n    # The \"availability\" of every family planning method is coded separately \n    IUDAVAIL = case_when(\n      IUDOBS == 99 ~ \"not provided\",\n      IUDOBS == 3 | IUDOUT3MO == 1 ~ \"cur/rec stockout\",\n      IUDOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    CONAVAIL = case_when(\n      CONOBS == 99 ~ \"not provided\",\n      CONOBS == 3 | CONOUT3MO == 1 ~ \"cur/rec stockout\",\n      CONOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    BEADSAVAIL = case_when(\n      CYCBOBS == 99 ~ \"not provided\",\n      CYCBOBS == 3 | CYCBOUT3MO == 1 ~ \"cur/rec stockout\",\n      CYCBOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    DIAAVAIL = case_when(\n      DIAOBS == 99 ~ \"not provided\",\n      DIAOBS == 3 | DIAOUT3MO == 1 ~ \"cur/rec stockout\",\n      DIAOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    EMRGAVAIL = case_when(\n      EMRGOBS == 99 ~ \"not provided\",\n      EMRGOBS == 3 | EMRGOUT3MO == 1 ~ \"cur/rec stockout\",\n      EMRGOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    FCAVAIL = case_when(\n      FCOBS == 99 ~ \"not provided\",\n      FCOBS == 3 | FCOUT3MO == 1 ~ \"cur/rec stockout\",\n      FCOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    FJAVAIL = case_when(\n      FJOBS == 99 ~ \"not provided\",\n      FJOBS == 3 | FJOUT3MO == 1 ~ \"cur/rec stockout\",\n      FJOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    IMPAVAIL = case_when(\n      IMPOBS == 99 ~ \"not provided\",\n      IMPOBS == 3 | IMPOUT3MO == 1 ~ \"cur/rec stockout\",\n      IMPOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    PILLAVAIL = case_when(\n      PILLOBS == 99 ~ \"not provided\",\n      PILLOBS == 3 | PILLOUT3MO == 1 ~ \"cur/rec stockout\",\n      PILLOUT3MO == 0 ~ \"reliably avail\"\n    ),\n    across(\n      ends_with(\"AVAIL\") & where(is.character),\n      ~.x %>% fct_relevel(\"reliably avail\") # set reference group\n    ),\n    PARTNERED = MARSTAT %in% 21:22\n  ) %>% \n  # Variables for every family planning method are substituted manually \n  summarise(\n    BEADS = glm(\n      METHCOUNBEADS ~ BEADSAVAIL + AGE + PARTNERED + BIRTHEVENT, \n      \"binomial\", \n      cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    CON = glm(\n      METHCOUNMC ~ CONAVAIL + AGE + PARTNERED + BIRTHEVENT, \n      \"binomial\", \n      cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    DIA = glm(\n      METHCOUNDIA ~ DIAAVAIL + AGE + PARTNERED + BIRTHEVENT, \n      \"binomial\", \n      cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    EMRG = glm(\n      METHCOUNEC ~ EMRGAVAIL + AGE + PARTNERED + BIRTHEVENT, \n      \"binomial\", \n      cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    FC = glm(\n      METHCOUNFC ~ FCAVAIL + AGE + PARTNERED + BIRTHEVENT, \n      \"binomial\", \n      cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    FOAM = glm(\n      METHCOUNFOAM ~ FJAVAIL + AGE + PARTNERED + BIRTHEVENT, \n      \"binomial\", \n      cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    IMP = glm(\n      METHCOUNIMP ~ IMPAVAIL + AGE + PARTNERED + BIRTHEVENT, \n      \"binomial\", \n      cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    IUD = glm(\n      METHCOUNIUD ~ IUDAVAIL + AGE + PARTNERED + BIRTHEVENT, \n      \"binomial\", \n      cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list(),\n    PILL = glm(\n      METHCOUNPILL ~ PILLAVAIL + AGE + PARTNERED + BIRTHEVENT, \n      \"binomial\", \n      cur_data()) %>% \n      broom::tidy(exp = TRUE) %>% \n      list()\n  ) %>% \n  pivot_longer(everything(), names_to = \"COUNSELED\") %>% \n  unnest(value) %>% \n  mutate(across(where(is.double), ~round(.x, 2)))\n\n\n\nPacked workflow\nWith pack you only need to specify variables the “go together” once at the beginning. The results are identical, but compared to a conventional workflow, this saves you the trouble of manually substituting variables into code you’d otherwise need repeat.\n\n\ndat %>% \n  pack(\n    BEADS = c(METHCOUNBEADS, CYCBOBS, CYCBOUT3MO),\n    CON = c(METHCOUNMC, CONOBS, CONOUT3MO),\n    DIA = c(METHCOUNDIA, DIAOBS, DIAOUT3MO),\n    EMRG = c(METHCOUNEC, EMRGOBS, DIAOUT3MO),\n    FC = c(METHCOUNFC, FCOBS, FCOUT3MO),\n    FOAM = c(METHCOUNFOAM, FJOBS, FJOUT3MO),\n    IMP = c(METHCOUNIMP, IMPOBS, IMPOUT3MO),\n    IUD = c(METHCOUNIUD, IUDOBS, IUDOUT3MO),\n    PILL = c(METHCOUNPILL, PILLOBS, PILLOUT3MO)\n  ) %>% \n  # The same generic \"availability\" coding is applied to every pack \n  mutate(\n    across(\n      where(is_tibble),\n      ~.x %>% \n        rename(\n          COUNSEL = contains(\"METHCOUN\"),\n          OBS = contains(\"OBS\"),\n          OUT3MO = contains(\"OUT3MO\")\n        ) %>% \n        mutate(AVAIL = fct_relevel(\n          case_when(\n            OBS == 99 ~ \"not provided\",\n            OBS == 3 | OUT3MO == 1 ~ \"cur/rec stockout\",\n            OUT3MO == 0 ~ \"reliably avail\" \n          ),\n          \"reliably avail\" # set reference group\n        ) \n        )\n    ),\n    PARTNERED = MARSTAT %in% 21:22\n  ) %>% \n  # The same generic model formula is applied to every pack\n  summarise(across(\n    where(is_tibble),\n    ~glm(COUNSEL ~ AVAIL + AGE + PARTNERED + BIRTHEVENT, \"binomial\", .x) %>%\n      broom::tidy(exp = TRUE) %>%\n      list()\n  )) %>%\n  pivot_longer(everything(), names_to = \"COUNSELED\") %>%\n  unnest(value) %>%\n  mutate(across(where(is.double), ~round(.x, 2))) %>%\n  mutate(term = term %>% str_remove(\"AVAIL\") %>% str_remove(\"TRUE\"))\n\n\n\n\n\n\n",
    "preview": "posts/2022-01-15-cei-sdp/images/tbl_regression.png",
    "last_modified": "2022-04-13T13:11:20-04:00",
    "input_file": {},
    "preview_width": 1528,
    "preview_height": 1128
  },
  {
    "path": "posts/2021-12-15-cei-conflict/",
    "title": "How to integrate ACLED conflict data with PMA Client Exit Interview data",
    "description": "Conflict data provides important context for access to family planning services.",
    "author": [
      {
        "name": "Maya Luetke",
        "url": "https://www.linkedin.com/in/maya-luetke-12425829/"
      },
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-12-15",
    "categories": [
      "Client Exit Interviews",
      "Armed Conflict",
      "ACLED",
      "Mapping",
      "Animation",
      "sf",
      "ggspatial",
      "gganimate"
    ],
    "contents": "\n\nContents\nSetup\nArmed conflict data\nShapefile\nFacility GPS coordinates\n\nMapping conflict in Uganda\nAnimation\n\nMerge with CEI data\nResults\n\nWhen we introduced the new PMA Client Exit Interview (CEI) surveys in our last post, we mentioned several variables that describe some of the barriers that women face when accessing care at a particular facility. Some of these deal with transportation, in particular:\nFACNEAREST indicates whether the woman visited the facility nearest to her home today.\nFor women who did not visit the nearest facility, NOTNEARESTWHY explains why.\nFACTRAVELHR and FACTRAVELMIN describe the total amount of time required to reach the facility.\nTRANSPORT describes the mode of transportation she used to get to the facility\nClient Exit Interview (CEI) surveys are a convenience sample of women receiving family planning services at a facility included in a contemporaneous Service Delivery Point (SDP) survey.\nTransportation challenges can make it difficult or impossible for women to access family planning services, and they can be rooted in multiple intersecting factors that may not be visible without additional context. In some places, for example, the presence of nearby or recent armed conflict can disrupt public transportation, cause destruction to transportation infrastructure (e.g., roads, bridges), make certain types of travel unsafe, or even discourage movement altogether. In this post, we will show you how to download, aggregate, and match externally sourced conflict data with a 2020 CEI survey from Uganda. We’ll see how the proximity and timing of armed conflict influences CEI transportation measures, and we’ll demonstrate how to map monthly conflict statistics with an animated plot built with the gganimate package.\nSetup\nLet’s begin by downloading a CEI data extract from the IPUMS PMA website. We’ll select the Uganda 2020 sample and the five variables listed above; a number of pre-selected variables will also be included automatically.\nWe’ve downloaded our data extract and saved it in the “data” subfolder of our working directory. We’ll load it here, along with a few key packages:\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\n\ncei <- read_ipums_micro(\n  ddi = \"data/pma_00058.xml\",\n  data = \"data/pma_00058.dat.gz\"\n) \n\n\n\nThe variables FACNEAREST, NOTNEARESTWHY, and TRANSPORT are labelled integers, but we’ll change them into factors in order to make our summary tables easier to read. In the process, we’ll also replace the top-code “NIU (not in universe)” with the label NA and drop any zero-frequency response options.\n\n\ncei <- cei %>% \n  mutate(across(\n    c(COUNTRY, FACNEAREST, TRANSPORT, NOTNEARESTWHY, FACILITYTYPEGEN), \n    ~.x %>% \n      lbl_na_if(~.lbl == \"NIU (not in universe)\") %>%\n      as_factor() %>% \n      fct_drop()\n  ))\n\n\n\nNext, we’ll want to combine FACTRAVELHR and FACTRAVELMIN together. These variables come from a combined question intended to solicit both hours and minutes:\n109. How much time did it take you to travel here today?\nEnter -88 for do not know in both, -99 for no response in both.\nMinutes ___\nPlease verify the time entered\n\nHours ___\nPlease verify the time entered\nNotably, however, some respondents appear to have provided the same time in both hours and minutes (e.g. 3 hours and 180 minutes). While you might decide to use these responses in your own analysis, we’ll exercise an abundance of caution here: we’ll drop any responses where FACTRAVELHR > 0, but the number of minutes in FACTRAVELMIN is longer than one hour. We’ll also drop cases where the number of hours in FACTRAVELHR exceeds one full day (24 hours). With the remaining cases, we’ll calculate FACTRAVEL as the sum of FACTRAVELMIN and 60 * FACTRAVELHR.\n\n\ncei <- cei %>% \n  filter(FACTRAVELHR < 24 & (FACTRAVELHR == 0 | FACTRAVELMIN < 60)) %>% \n  mutate(FACTRAVEL = 60*FACTRAVELHR + FACTRAVELMIN)\n\n\n\nNow that we’ve finished processing the CEI data extract, let’s take a look at a gtsummary table containing our key transportation variables.\n\n\nlibrary(gtsummary)\n\ncei %>% \n  select(FACNEAREST, NOTNEARESTWHY, TRANSPORT, FACTRAVEL) %>% \n  tbl_summary(\n    label = list(\n      FACNEAREST ~ \"Facility is nearest to residence\",\n      NOTNEARESTWHY ~ \"Reason for not visiting nearest facility\",\n      TRANSPORT ~ \"Mode of transportation taken to facility\",\n      FACTRAVEL ~ \"Total travel time to facility (minutes)\"),\n    statistic = list(\n      all_continuous() ~ \"{median} ({p25}, {p75})\", \n      all_categorical() ~ \"{n} ({p}%)\"\n    ),\n    digits = list(everything() ~ 0),       \n    missing = \"no\"\n  ) %>% \n  modify_spanning_header(\n    everything() ~ \"# Client Exit Interview Transportation Summary\"\n  ) %>% \n  modify_header(update = list(label ~ \" \")) %>% \n  bold_labels() %>%\n  italicize_labels() \n\n\n\n\n        Client Exit Interview Transportation Summary\n\n      \n    \n      N = 2,3491\n    Facility is nearest to residence\n1,878 (80%)Reason for not visiting nearest facility\nNo family planning services\n64 (14%)Inconvenient operating hours\n20 (4%)Bad reputation / Bad prior experience\n35 (7%)Do not like personnel\n17 (4%)No medicine\n35 (7%)Prefers to remain anonymous\n16 (3%)It is more expensive than other options\n129 (27%)Was referred\n23 (5%)Less convenient location\n13 (3%)Absence of provider\n20 (4%)Other\n99 (21%)Mode of transportation taken to facility\nMotor vehicle (car, motorcycle, bus)\n868 (37%)Bicycle / pedicab\n96 (4%)Walking\n1,382 (59%)Boat\n1 (0%)Other\n2 (0%)Total travel time to facility (minutes)\n30 (20, 60)\n        \n          1\n          \n           \n          n (%); Median (IQR)\n          \n      \n    \n\n\n\n\n\nWhile 80% of sampled women visited the facility nearest to their home, 20% went elsewhere. For the latter group, a plurality of women visited a different facility because of cost (27%), while the second most important reason is “other” (21%). A majority of women (59%) traveled to the facility on foot (“Walking”), and the median travel time for all women is half an hour (the IQR shows that 50% of women spent between 20 and 60 minutes traveling).\nBefore we dig into these variables a bit more, consider how each of these might be impacted by armed conflict. It may prevent women from visiting the nearest healthcare facility, particularly if there is localized violent conflict occurring between their home and the facility, and thus also increase travel times to facilities to avoid conflict-ridden areas. It may also increase wait times at the facilities and limit the stocks of available medicines, contraceptives, and other medical supplies at facilities if supply-chains are interrupted by violence. To test these effects, we’ll need to choose and download a dataset describing the location and timing of armed conflict events in Uganda.\nArmed conflict data\nThere are several sources of publicly available conflict data. Two notable and frequently used databases are The Armed Conflict Location & Event Data Project (ACLED) and Uppsala Conflict Data Program (UCDP). Some researchers also argue for the integration of such databases into a more comprehensive dataset. If you are interested in learning more about this technique, please refer to the R package, meltt. However, for the sake of this blog post, we will use the ACLED dataset.\nIn order to get access to the ACLED data and be able to download an extract of the data, you must first register for an account on the ACLED website.\n\n\n\nFigure 1: Image from https://acleddata.com/#/dashboard\n\n\n\nAfter verifying your email by clicking the link in the email sent to you from ACLED, you must agree to ACLED’s Terms of Use in the dashboard of your account. Next, you must request an “access key” (a string of upper and lower case letters and numbers) by clicking the “Add new key” button in the dashboard of your account.\n\n\n\nFigure 2: Image from https://developer.acleddata.com/dashboard/main/\n\n\n\nBe sure to copy and save this access key as you will need it later and will not be able to view it again (though you can revoke the key and request another one if you do misplace it).\nAfter these steps, you can use the access key to request data through the ACLED’s Data Export Tool. To request the dataset, enter the access key, dates of interest, and country or region of interest. We’ll examine one year (September 1, 2019 to August 31, 2020) of conflict data prior to the beginning of CEI data collection in Uganda in September 2020.\n\n\n\nFigure 3: Image from https://acleddata.com/data-export-tool/\n\n\n\nThe ACLED dataset you’ll receive is a simple CSV file with 31 columns: we’ll select a handful that we’ll need in our analysis.\n\n\nconflict <- read_csv(\"data/2019-09-01-2020-08-31-Uganda.csv\") %>% \n  select(\n    event_id_cnty, event_type, sub_event_type, event_date, \n    time_precision, latitude, longitude, admin2, geo_precision\n  )\n\nconflict\n\n\n# A tibble: 515 × 9\n   event_id_cnty event_type  sub_event_type  event_date time_precision\n   <chr>         <chr>       <chr>           <chr>               <dbl>\n 1 UGA6189       Protests    Protest with i… 31 August…              1\n 2 UGA6188       Riots       Mob violence    30 August…              1\n 3 UGA6187       Strategic … Looting/proper… 30 August…              1\n 4 UGA6186       Riots       Mob violence    29 August…              1\n 5 UGA6185       Riots       Mob violence    29 August…              1\n 6 UGA6183       Battles     Armed clash     27 August…              1\n 7 UGA6181       Riots       Mob violence    26 August…              1\n 8 UGA6182       Riots       Violent demons… 26 August…              1\n 9 UGA6180       Violence a… Attack          25 August…              1\n10 UGA6179       Protests    Excessive forc… 23 August…              1\n# … with 505 more rows, and 4 more variables: latitude <dbl>,\n#   longitude <dbl>, admin2 <chr>, geo_precision <dbl>\n\nYou’ll notice that there are 515 rows in our conflict dataset - each representing a specific event with a unique event_id_cnty number. The variables event_type and sub_event_type describe different types of recorded events. We’ll use the kableExtra package to create an easy-to-read table showing the frequency of each event type.\n\n\nlibrary(kableExtra)\n\nconflict %>% \n  count(event_type, sub_event_type) %>% \n  mutate(pct = 100*prop.table(n) %>% round(3)) %>% \n  kbl() \n\n\n\nevent_type\n\n\nsub_event_type\n\n\nn\n\n\npct\n\n\nBattles\n\n\nArmed clash\n\n\n67\n\n\n13.0\n\n\nExplosions/Remote violence\n\n\nRemote explosive/landmine/IED\n\n\n1\n\n\n0.2\n\n\nProtests\n\n\nExcessive force against protesters\n\n\n5\n\n\n1.0\n\n\nProtests\n\n\nPeaceful protest\n\n\n65\n\n\n12.6\n\n\nProtests\n\n\nProtest with intervention\n\n\n53\n\n\n10.3\n\n\nRiots\n\n\nMob violence\n\n\n112\n\n\n21.7\n\n\nRiots\n\n\nViolent demonstration\n\n\n57\n\n\n11.1\n\n\nStrategic developments\n\n\nArrests\n\n\n2\n\n\n0.4\n\n\nStrategic developments\n\n\nChange to group/activity\n\n\n1\n\n\n0.2\n\n\nStrategic developments\n\n\nDisrupted weapons use\n\n\n1\n\n\n0.2\n\n\nStrategic developments\n\n\nLooting/property destruction\n\n\n2\n\n\n0.4\n\n\nStrategic developments\n\n\nOther\n\n\n2\n\n\n0.4\n\n\nViolence against civilians\n\n\nAbduction/forced disappearance\n\n\n5\n\n\n1.0\n\n\nViolence against civilians\n\n\nAttack\n\n\n136\n\n\n26.4\n\n\nViolence against civilians\n\n\nSexual violence\n\n\n6\n\n\n1.2\n\n\n\n\n\n\nAs you can see from the table above, there are a number of different types and subtypes of events in the ACLED dataset. In this analysis, we’re interested in events that may cause transportation disruptions or otherwise impede access to health facilities, so we’ll exclude events in the category Strategic developments. Events in the categories Protests and Riots are not necessarily “armed conflict”, but we’ll retain them in our analysis because of their potential to impede access to facilities.\n\n\nconflict <- conflict %>% filter(event_type != \"Strategic developments\")\n\n\n\nEach event is associated with a particular event_date and a set of latitude and longitude coordinates. These are subject to different degrees of precision represented in time_precision and geo_precision, respectively, on a scale ranging from 1 (most precise) to 3 (least precise). The specific meaning for each value is described in the ACLED codebook, but we’ll summarize here.\nThe degrees of time_precision are:\nThe listed event_date matches the date of the event\nThe listed event_date is the middle date of an event that happened during a specified week or weekend\nThe listed event_date is the middle date of an event that happened during a specified month\n\n\nconflict %>% \n  count(time_precision) %>%\n  kbl()\n\n\n\ntime_precision\n\n\nn\n\n\n1\n\n\n420\n\n\n2\n\n\n79\n\n\n3\n\n\n8\n\n\nTo keep things simple, we’ll recode event_date to the least precise level in time_precision - the month and year in which an event happened. We’ll use the lubridate package to create a century month code (cmc) for each month, and we’ll then recode event_date as a string containing the month and year for each event.\n\n\nlibrary(lubridate)\n\nconflict <-conflict %>% \n  mutate(\n    event_date = event_date %>% as_date(format = '%d %B %Y'),\n    event_month = month(event_date),\n    event_year = year(event_date),\n    event_cmc = 12*(event_year - 1900) + event_month\n  ) %>% \n  arrange(event_cmc) %>% \n  mutate(\n    event_date = month(event_month, label = TRUE) %>% \n      paste(event_year) %>% \n      as_factor()\n  )\n\n\n\n\n\n\n\nThe degrees of geo_precision are:\nThe listed coordinates are the centroid of a town where the event happened\nThe listed coordinates are the centroid of a town in the district in which the event happened (the nearest town is used if possible)\nThe listed coordinates are represent a natural location (e.g. “border area”, “forest”, or “sea”) or a provincial capital located in a “larger region” in which the event happened\nMost locations are specifically geo-referenced within a particular town (geo_precision == 1), but we’ll need to decide how to handle those locations that are less precise:\n\n\nconflict %>% \n  count(geo_precision) %>%\n  kbl()\n\n\n\ngeo_precision\n\n\nn\n\n\n1\n\n\n300\n\n\n2\n\n\n195\n\n\n3\n\n\n12\n\n\nBecause all but 12 events are geo-referenced to towns within the same district, we’ll drop events where geo-precision == 3 and aggregate the others by districts represented in the variable admin2 (admin level 2).\n\n\nconflict <- conflict %>% filter(geo_precision < 3)\n\n\n\nDoing so will allow us to build a cloropleth map showing the number of conflicts in each district in each month. But first, we’ll need to locate an appropriate shapefile.\nShapefile\nIPUMS PMA offers shapefiles for each sampled country at the same administrative level shown in the variable SUBNATIONAL. For Uganda, the boundaries of 10 regions are included (admin level 1).\nAs we’ve seen, the ACLED conflict data are more precise: all of the events remaining in conflict are geo-referenced to the nearest town within the same district, which is recorded in the column admin2 (admin level 2).\n\n\nconflict %>% count(admin2)\n\n\n# A tibble: 94 × 2\n   admin2       n\n   <chr>    <int>\n 1 Abim         6\n 2 Adjumani     3\n 3 Agago       10\n 4 Amolatar     1\n 5 Amuru       14\n 6 Apac         4\n 7 Arua        14\n 8 Budaka       3\n 9 Bududa       1\n10 Bugiri       1\n# … with 84 more rows\n\nIn order to map these events, we’ll need to locate a shapefile from a different source that contains boundaries for all of the districts in Uganda. We’ll find the shapefile we need from The Humanitarian Data Exchange and save it in the “data” subfolder of our working directory. We’ll load it into R with the sf package and, for the sake of improved processing speed, we’ll apply a small amount of smoothing to the boundaries with st_simplify.\n\n\nlibrary(sf)\n\nshapefile <- st_read(\"data/uga_admbnda_ubos_20200824_shp\") %>% \n  rename(admin2 = ADM2_EN) %>% \n  count(admin2) %>% \n  select(-n) %>% \n  st_make_valid() %>% \n  st_simplify(dTolerance = 1000) \n\n\n\n\n\n\n\n\n\nshapefile\n\n\nSimple feature collection with 135 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29.57268 ymin: -1.479916 xmax: 34.99451 ymax: 4.231367\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     admin2                       geometry\n1      Abim MULTIPOLYGON (((33.59604 3....\n2  Adjumani MULTIPOLYGON (((32.05573 3....\n3     Agago MULTIPOLYGON (((33.4717 3.2...\n4  Alebtong MULTIPOLYGON (((33.03664 2....\n5  Amolatar MULTIPOLYGON (((32.95499 1....\n6    Amudat MULTIPOLYGON (((34.92851 2....\n7    Amuria MULTIPOLYGON (((33.47753 2....\n8     Amuru MULTIPOLYGON (((32.0598 3.5...\n9      Apac MULTIPOLYGON (((32.57423 2....\n10     Arua MULTIPOLYGON (((31.16639 3....\n\nFacility GPS coordinates\nThe final source of data we’ll use in this post are the displaced GPS coordinates for each of the enumeration areas used to select facilities for the CEI sample. IPUMS PMA does not disseminate these coordinates, so you’ll need to apply to download them directly from our partners at PMA. Once approved, you’ll receive a CSV file - we’ve saved a copy of this file into the “data” subfolder of our working directory.\n\n\ngps <- read_csv(\"data/PMA_UG_GPS_v1_19May2021.csv\") %>%\n  select(EAID = EA_ID, GPSLONG, GPSLAT, DATUM) %>%\n  st_as_sf(\n    coords = c(\"GPSLONG\", \"GPSLAT\"), \n    crs = 4326\n  )\n\ngps\n\n\nSimple feature collection with 122 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 29.65181 ymin: -1.311755 xmax: 34.94487 ymax: 3.450838\nGeodetic CRS:  WGS 84\n# A tibble: 122 × 3\n        EAID DATUM              geometry\n *     <dbl> <chr>           <POINT [°]>\n 1 800221003 WGS84  (32.33993 0.2208572)\n 2 800191002 WGS84   (29.9435 -1.157961)\n 3 800121008 WGS84 (30.19217 -0.5432807)\n 4 800151006 WGS84   (33.29807 0.688975)\n 5 800171005 WGS84  (32.62457 0.3097168)\n 6 800221009 WGS84  (32.54551 0.1381675)\n 7 800241002 WGS84   (30.66916 0.771588)\n 8 800141003 WGS84   (31.52249 1.627066)\n 9 800151008 WGS84  (33.45034 0.5236081)\n10 800241004 WGS84 (29.73013 0.03855568)\n# … with 112 more rows\n\nMapping conflict in Uganda\nNext, we’ll want to think about the best way to visualize monthly changes in the amount of conflict in each district. Previously, we’ve shown how to create a faceted plot, where you might arrange maps for each month in a grid. This works well in some cases, but here - where we’ll build one map for each of 12 months - this would easily overwhelm the available space on our page. Instead, we’ll create an animated image - specifically, a gif - that cycles through each month in sequence.\nTo get started, we’ll first need to count the monthly total number of events in each district. We’ll do this simply by counting the number of distinct event_id_cnty codes for each district in each month. We’ll call this summary table conflict_summary.\n\n\nconflict_summary <- conflict %>% \n  group_by(admin2, event_date) %>% \n  summarise(events = n_distinct(event_id_cnty), .groups = \"keep\") %>% \n  ungroup() \n\nconflict_summary\n\n\n# A tibble: 284 × 3\n   admin2   event_date events\n   <chr>    <fct>       <int>\n 1 Abim     Jan 2020        2\n 2 Abim     Feb 2020        1\n 3 Abim     Mar 2020        1\n 4 Abim     May 2020        1\n 5 Abim     Jun 2020        1\n 6 Adjumani Oct 2019        1\n 7 Adjumani Dec 2019        2\n 8 Agago    Apr 2020        3\n 9 Agago    May 2020        1\n10 Agago    Jun 2020        2\n# … with 274 more rows\n\nNotice the first district, Abim, has recorded events in only 5 of the 12 months in our timeline; in each of the remaining 7 months, there were no reported events in the database. We’ll want to fill these gaps with 0, and the easiest way to do this is to pivot_wider, placing each of the 12 months into a separate column. Any district with no recorded events in a particular month will show NA in that column.\n\n\n\n\n\n\nconflict_summary <- conflict_summary %>% \n  arrange(event_date) %>% \n  pivot_wider(\n    admin2,\n    names_from = event_date,\n    values_from = events\n  ) %>% \n  arrange(admin2)\n\nconflict_summary\n\n\n# A tibble: 94 × 13\n   admin2   `Sep 2019` `Oct 2019` `Nov 2019` `Dec 2019` `Jan 2020`\n   <chr>         <int>      <int>      <int>      <int>      <int>\n 1 Abim             NA         NA         NA         NA          2\n 2 Adjumani         NA          1         NA          2         NA\n 3 Agago            NA         NA         NA         NA         NA\n 4 Amolatar          1         NA         NA         NA         NA\n 5 Amuru            NA         NA         NA          1         NA\n 6 Apac             NA         NA         NA         NA         NA\n 7 Arua             NA         NA         NA         NA         NA\n 8 Budaka           NA          1         NA         NA         NA\n 9 Bududa           NA         NA         NA         NA          1\n10 Bugiri           NA         NA         NA         NA         NA\n# … with 84 more rows, and 7 more variables: Feb 2020 <int>,\n#   Mar 2020 <int>, Apr 2020 <int>, May 2020 <int>, Jun 2020 <int>,\n#   Jul 2020 <int>, Aug 2020 <int>\n\nNow, the complete monthly event totals for each district are stored in a single row. At this point, we’ll want to merge conflict_summary with our shapefile.\n\n\nconflict_summary <- shapefile %>% full_join(conflict_summary, by = \"admin2\")\n\n\n\nFinally, we’ll pivot_longer so that each row contains one month again, except that missing months will be represented with the value NA. We’ll replace these values with 0. (We’ll also need to transform event_date back into a factor with levels set in chronological order - these were removed when the dates were used as column names above).\n\n\nconflict_summary <- conflict_summary %>% \n  pivot_longer(\n    cols = contains(\" \"), \n    names_to = \"event_date\",\n    values_to = \"events\"\n  ) %>% \n  mutate(event_date = factor(\n    event_date, \n    levels = levels(conflict$event_date)\n  )) %>% \n  select(admin2, events, event_date) %>% \n  mutate(events = ifelse(is.na(events), 0, events))\n\nconflict_summary\n\n\nSimple feature collection with 1620 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29.57268 ymin: -1.479916 xmax: 34.99451 ymax: 4.231367\nGeodetic CRS:  WGS 84\n# A tibble: 1,620 × 4\n   admin2 events event_date                                   geometry\n * <chr>   <dbl> <fct>                              <MULTIPOLYGON [°]>\n 1 Abim        0 Sep 2019   (((33.59604 3.140113, 33.56416 3.148248, …\n 2 Abim        0 Oct 2019   (((33.59604 3.140113, 33.56416 3.148248, …\n 3 Abim        0 Nov 2019   (((33.59604 3.140113, 33.56416 3.148248, …\n 4 Abim        0 Dec 2019   (((33.59604 3.140113, 33.56416 3.148248, …\n 5 Abim        2 Jan 2020   (((33.59604 3.140113, 33.56416 3.148248, …\n 6 Abim        1 Feb 2020   (((33.59604 3.140113, 33.56416 3.148248, …\n 7 Abim        1 Mar 2020   (((33.59604 3.140113, 33.56416 3.148248, …\n 8 Abim        0 Apr 2020   (((33.59604 3.140113, 33.56416 3.148248, …\n 9 Abim        1 May 2020   (((33.59604 3.140113, 33.56416 3.148248, …\n10 Abim        1 Jun 2020   (((33.59604 3.140113, 33.56416 3.148248, …\n# … with 1,610 more rows\n\nYou could now easily build a static map for any single month. We’ll build an example for August 2020 with our favorite ggplot-aligned package for spatial data, ggspatial.\n\n\nlibrary(ggspatial)\n\nggplot() + \n  layer_spatial(\n    conflict_summary %>% filter(event_date == \"Aug 2020\"), \n    aes(fill = events)\n  ) + \n  layer_spatial(gps, aes(shape = \"Enumeration Area Centroid\")) + \n  theme_minimal() + \n  theme(\n    text = element_text(family = \"cabrito\", size = 12, color = \"#00263A\"),\n    plot.title = element_text(size = 24),\n    legend.direction = \"horizontal\"\n  ) + \n  annotation_scale(aes(style = \"ticks\", location = \"br\")) +\n  scale_fill_gradient(low = \"#FFFFFF\", high = \"#7F0000\") + \n  guides(\n    shape = guide_legend(title = element_blank()),\n    fill = guide_colorbar(title = element_blank())\n  ) + \n  labs(\n    title = \"Incidents of armed conflict and civil unrest: August 2020\", \n    caption = \"Data source: ACLED (https://acleddata.com/)\"\n  ) \n\n\n\n\nAnimation\nTo build an animated version of this map that shows the number of armed conflicts for each month in sequence, we’ll use the gganimate package. This code will look almost exactly like the code we used to create a static map for August 2020, except that we’ll use the function transition_states to cycle through each event_date, and animate to render the animation over a 24 second period (two seconds per month). Also notice the title, where we use the variable {closest_state} to import the correct event_date for each month.\n\n\n\n\n\n\nlibrary(gganimate) \n\ndynamic_map <- ggplot() + \n  layer_spatial(conflict_summary, aes(fill = events)) + \n  layer_spatial(gps, aes(shape = \"Enumeration Area Centroid\")) + \n  theme_minimal() + \n  theme(\n    text = element_text(size = 12, color = \"#00263A\"),\n    plot.title = element_text(size = 24),\n    legend.direction = \"horizontal\"\n  ) + \n  annotation_scale(aes(style = \"ticks\", location = \"br\")) +\n  scale_fill_gradient(low = \"#FFFFFF\", high = \"#7F0000\") + \n  guides(\n    shape = guide_legend(title = element_blank()),\n    fill = guide_colorbar(title = element_blank())\n  ) + \n  labs(\n    title = \"Incidents of armed conflict and civil unrest: {closest_state}\", \n    caption = \"Data source: ACLED (https://acleddata.com/)\"\n  ) + \n  transition_states(event_date, transition_length = 0, state_length = 1)\n\nanimate(\n  dynamic_map, \n  width = 1200, \n  height = 800,\n  duration = 24 # 2 seconds per month (12 months)\n)\n\n\n\n\n\n\nMerge with CEI data\nAs a final processing step, we’ll now use conflict_summary to find the number of recent distict-level conflicts for each facility in the CEI survey. We’ll focus here on the 3 months prior to the first month of CEI data collection: June, July, and August 2020.\nFor comparison’s sake, let’s divide the 135 districts into two groups: “low” and “high” levels of recent conflict. We’ll define HIGH_CONFLICT districts as those with a three-month event total in the upper-most tertile relative to all district totals.\n\n\nconflict_summary <- conflict_summary %>% \n  group_by(admin2) %>% \n  slice(10:12) %>% # most recent 3 months\n  summarise(conflict_events_3mo = sum(events)) %>% \n  ungroup() %>% \n  transmute(HIGH_CONFLICT = ntile(conflict_events_3mo, 3) > 2) \n\nconflict_summary\n\n\nSimple feature collection with 135 features and 1 field\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 29.57268 ymin: -1.479916 xmax: 34.99451 ymax: 4.231367\nGeodetic CRS:  WGS 84\n# A tibble: 135 × 2\n   HIGH_CONFLICT                                              geometry\n * <lgl>                                                <GEOMETRY [°]>\n 1 FALSE         POLYGON ((33.59604 3.140113, 33.56416 3.148248, 33.5…\n 2 FALSE         POLYGON ((32.05573 3.58631, 31.96306 3.56222, 31.933…\n 3 TRUE          MULTIPOLYGON (((33.4717 3.297044, 33.40285 3.303162,…\n 4 FALSE         POLYGON ((33.03664 2.500747, 33.01045 2.496633, 33.0…\n 5 FALSE         POLYGON ((32.95499 1.807919, 32.86451 1.814944, 32.8…\n 6 FALSE         POLYGON ((34.92851 2.283174, 34.88737 2.269499, 34.8…\n 7 FALSE         POLYGON ((33.47753 2.23472, 33.44095 2.239425, 33.47…\n 8 TRUE          POLYGON ((32.0598 3.576683, 32.05748 3.413509, 32.01…\n 9 FALSE         POLYGON ((32.57423 2.218455, 32.53095 2.13281, 32.52…\n10 TRUE          POLYGON ((31.16639 3.006533, 31.18047 3.062847, 31.2…\n# … with 125 more rows\n\nNow, we’ll need to identify the correct district for every enumeration area. The GPS coordinates for each enumeration area are stored in gps, so we’ll use st_intersection to place them within the district boundaries shown in conflict_summary. In the rare event that the gps coordinates sit directly on a district boundary, we’ll label the enumeration area “high” conflict if either one of the districts is labelled “high”.\n\n\nconflict_summary <- gps %>% \n  st_intersection(conflict_summary) %>% \n  st_drop_geometry() %>% \n  group_by(EAID) %>% \n  summarise(HIGH_CONFLICT = any(HIGH_CONFLICT))\n\nconflict_summary\n\n\n# A tibble: 122 × 2\n        EAID HIGH_CONFLICT\n       <dbl> <lgl>        \n 1 800111001 TRUE         \n 2 800111002 TRUE         \n 3 800111003 TRUE         \n 4 800111004 TRUE         \n 5 800111005 TRUE         \n 6 800111006 TRUE         \n 7 800121001 TRUE         \n 8 800121002 FALSE        \n 9 800121003 FALSE        \n10 800121004 FALSE        \n# … with 112 more rows\n\nFinally, we’ll attach conflict_summary to the original cei data extract by EAID.\n\n\ncei <- cei %>% left_join(conflict_summary, by = \"EAID\")\n\n\n\nResults\nNow we will look at the variables in the CEI data that we think might be impacted by localized conflict. We mentioned these at the beginning of this post but to remind you, they are:\nFACNEAREST\nTRANSPORT\nFACTRAVELHR and FACTRAVELMIN\nNOTNEARESTWHY\nTo examine these variables and their relationship to conflict, we will again build a gtsummary table, but this time we will stratify this table by HIGH_CONFLICT.\n\n\ncei %>% \n  select(HIGH_CONFLICT, FACNEAREST, NOTNEARESTWHY, TRANSPORT, FACTRAVEL) %>%\n  tbl_summary(\n    by = HIGH_CONFLICT, \n    label = list(\n      FACNEAREST ~ \"Facility is nearest to residence\",\n      NOTNEARESTWHY ~ \"Reason for not visiting nearest facility\",\n      TRANSPORT ~ \"Mode of transportation taken to facility\",\n      FACTRAVEL ~ \"Total travel time to facility (minutes)\"\n    ),\n    statistic = list(\n      all_continuous() ~ \"{median} ({p25}, {p75})\", \n      all_categorical() ~ \"{n} ({p}%)\"\n    ),\n    digits = list(everything() ~ 0),       \n    missing = \"no\"\n  ) %>% \n  add_p(test = list(\n    all_continuous() ~ \"t.test\", \n    c(\"TRANSPORT\",\"NOTNEARESTWHY\") ~ \"fisher.test\",\n    c(\"FACNEAREST\") ~ \"chisq.test\"\n  )) %>% \n  bold_p() %>%\n  modify_spanning_header(update = list(\n   everything() ~ \"# **Client Exit Interview Transportation Summary**\"\n  )) %>%\n  modify_header(update = list(\n    label ~ \" \",\n    stat_1 ~ \"**Low/Moderate Conflict** <br> N = {n}\",\n    stat_2 ~ \"**High Conflict** <br> N = {n}\",\n    p.value ~ \"**p-value**\"\n  )) %>%\n  bold_labels() %>% \n  italicize_labels() \n\n\n\n\n        Client Exit Interview Transportation Summary\n\n      \n    \n      Low/Moderate Conflict  N = 9301\n      High Conflict  N = 14191\n      p-value2\n    Facility is nearest to residence\n777 (84%)\n1,101 (78%)\nReason for not visiting nearest facility\n\n\nNo family planning services\n28 (18%)\n36 (11%)\nInconvenient operating hours\n6 (4%)\n14 (4%)\nBad reputation / Bad prior experience\n9 (6%)\n26 (8%)\nDo not like personnel\n5 (3%)\n12 (4%)\nNo medicine\n15 (10%)\n20 (6%)\nPrefers to remain anonymous\n3 (2%)\n13 (4%)\nIt is more expensive than other options\n31 (20%)\n98 (31%)\nWas referred\n9 (6%)\n14 (4%)\nLess convenient location\n3 (2%)\n10 (3%)\nAbsence of provider\n8 (5%)\n12 (4%)\nOther\n36 (24%)\n63 (20%)\nMode of transportation taken to facility\n\n\nMotor vehicle (car, motorcycle, bus)\n292 (31%)\n576 (41%)\nBicycle / pedicab\n49 (5%)\n47 (3%)\nWalking\n589 (63%)\n793 (56%)\nBoat\n0 (0%)\n1 (0%)\nOther\n0 (0%)\n2 (0%)\nTotal travel time to facility (minutes)\n40 (20, 65)\n30 (15, 60)\n\n        \n          1\n          \n           \n          n (%); Median (IQR)\n          \n        \n          2\n          \n           \n          Pearson's Chi-squared test; Fisher's exact test; Welch Two Sample t-test\n          \n      \n    \n\nAs you can see in the table above, there are some significant differences between the respondents that have experienced High conflict in their area compared to those that experienced Low/Moderate conflict. More respondents in the high conflict areas did not visit the facility nearest to their residence compared to those in the low/moderate conflict areas. Overall, there were no significant differences in the reasons for not visiting the nearest facility. However, it may be notable that there are no possible responses that inquire about conflict as a possible reason and the closest one that might estimate this is less convenient location, which is demonstrably more prevalent among the High conflict group compared to the Low/Moderate group. We also see significant differences in the mode of transportation between the two groups, with less respondents in the High conflict area walking and biking to the clinic/facility and more taking a motor vehicle compared to respondents in the Low/Moderate area. Finally, the travel time to facility is also significantly different between respondents living in High conflict versus Low/Moderate conflict areas. The trend appears to be in an unexpected direction, with those in Low/Moderate conflict settings having greater travel times compared to those in High conflict settings. A possible explanation for this trend may be that women in the Low/Moderate conflict group are more likely to walk or bicycle to the facility and less likely to use motor vehicle transport compared to the women in the High conflict group.\nTaken together, the results of this analysis seem to indicate that conflict does indeed impact women’s ability to access family planning services. Importantly, it may be more expensive or even unaffordable for women to obtain a motor vehicle ride to a healthcare facility. Since the CEI data were collected from women at healthcare facilities, we do not know the magnitude of women who were unable to visit a healthcare facility due to the direct threat of localized violence or indirect cost of longer travel or the necessity of a motor vehicle in order to visit a healthcare facility and avoid local conflict.\n\n\n\n",
    "preview": "posts/2021-12-15-cei-conflict/cei-conflict_files/figure-html5/unnamed-chunk-28-1.png",
    "last_modified": "2022-04-13T13:10:48-04:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1536
  },
  {
    "path": "posts/2021-12-01-cei-discovery/",
    "title": "Introducing Client Exit Interviews",
    "description": "Women receiving family planning services assess their care in a new data series from PMA.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-12-01",
    "categories": [
      "Data Discovery",
      "New Data",
      "Client Exit Interviews",
      "Service Delivery Points"
    ],
    "contents": "\n\nContents\nSample Design\nMissing data\nSample weights\n\nTopics\nTechnical Variables\nInterview Location\nBackground\nServices & Information\nAssessment\n\nNext Steps\n\nThis fall, IPUMS PMA released baseline data from a new study examining women’s assessment of care received from providers of family planning services. Previously, we’ve seen how PMA service delivery point (SDP) surveys can be combined with surveys of households and women sampled within the same geographically defined enumeration areas. These new Client Exit Interview (CEI) surveys represent women who have received care from a specific provider included in a contemporaneous SDP sample.\nInterviews for samples included in this release were conducted between December 2019 and November 2020. Women aged 15-49 receiving services at a participating SDP were approached by interviewers and asked to reflect on their visit. As we’ll see, most questions were given only to women who received or discussed a family planning method with their provider. Questions address whether the woman received her preferred method, whether the advantages or disadvantages of certain methods were discussed, and how she felt about the overall experience.\n\nA convenience sample of women leaving a facility that participated in the SDP survey\nWomen who completed the baseline interview were invited to participate in a follow-up telephone interview six months afterward, but these follow-ups were canceled in most PMA countries because of disruptions caused by COVID-19. Coming this spring, IPUMS PMA plans to release data from a second round of baseline CEI interviews collected one year after the first round; from then onward, we expect to release six month follow-up interviews following each baseline survey.\nToday, we’re launching a new series devoted to showcasing the first round of CEI baseline surveys. Let’s see what’s included in the release!\nSample Design\nCEI surveys are currently available from six PMA countries (more countries will be included in the second round planned for release in 2022):\nBurkina Faso\nDemocratic Republic of Congo (DRC) - Kinshasa and Kongo Central only\nIndia - Rajasthan only\nKenya\nNigeria - Kano and Lagos only\nUganda\nAs we’ve discussed elsewhere, up to three public-sector and three private-sector facilities are sampled for each enumeration area in a given SDP survey. Sampled SDPs were eligible to host client exit interviews only if their daily client volume was three or more. (We’ll show how to link SDP and CEI data together in an upcoming post.)\nCEI interviewers were present at eligible SDPs for two business days during which family planning services were offered to clients. They invited all female clients to participate in the survey; participants are those who agreed and affirmed that their age was between 15 and 49. Interviewers then asked participants whether they received or discussed a family planning method with their provider; this information is reported in the variable FPINFOYN:\n\nFamily planning clients aged 15-49\n100. Did you receive any family planning information or a method during your \nvisit today?\n\nIf no, thank her for her time and end the interview.\n\n[] Yes\n[] No\n[] No response\nMissing data\nWomen who indicated that they did not receive or discuss a method in FPINFOYN were asked no further questions, but you’ll find that these cases are included in all CEI data extracts. For all other variables derived from the CEI questionnaire (except for those that describe the facility and the woman’s age), these cases will be labelled NIU (not in universe).\n\nPMA allows respondents to skip questions if they are deemed irrelevant based on answers to a previous question. Those cases will be marked NIU (not in universe) as well.\nA small number of women declined consent to be interviewed. These cases are labelled Not interviewed (female questionnaire), and they may be automatically excluded from your data extract by selecting “Female Respondents” rather than “All cases (Respondents and Non-respondents)” at checkout.\nIf a woman declined to answer a particular question - but otherwise consented to the interview - her response will be labelled No response or missing.\nIn many cases, you’ll want to consolidate all types of “missing data” by marking them NA with help from the ipumsr package. For example, let’s say you’ve downloaded the following data extract and placed it in the data folder of your working directory.\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00054.xml\",\n  data = \"data/pma_00054.dat.gz\"\n)\n\n\n\nVariables that you’d expect to be binary - with response options for “yes” or “no” - will have additional top codes for the three types of missing responses we’ve discussed. For example DISCFPTODAY indicates whether the woman discussed family planning with her provider today:\n\n\ndat %>% count(DISCFPTODAY)\n\n\n# A tibble: 5 × 2\n                                  DISCFPTODAY     n\n                                    <int+lbl> <int>\n1  0 [No]                                       735\n2  1 [Yes]                                     5428\n3 95 [Not interviewed (female questionnaire)]     5\n4 98 [No response or missing]                     2\n5 99 [NIU (not in universe)]                   2838\n\nNotice that the top codes for missing data are numeric: 95, 98, and 99. These codes will will be the same for all binary variables, but not necessarily for continuous variables or variables with many response categories. For example, look at FPMETHGIVEN, which describes the method or prescription given to the woman by her provider during the visit:\n\n\ndat %>% count(FPMETHGIVEN)\n\n\n# A tibble: 22 × 2\n                                    FPMETHGIVEN     n\n                                      <int+lbl> <int>\n 1 101 [Female Sterilization]                     111\n 2 102 [Male Sterilization]                         1\n 3 111 [Implants]                                2229\n 4 112 [IUD]                                      347\n 5 113 [Post-partum IUD]                           89\n 6 114 [Post-abortion IUD]                          1\n 7 120 [Injectables]                             3704\n 8 123 [Injectables (Depo Provera)]               268\n 9 124 [Injectables (Sayana Press)]               163\n10 131 [Pill]                                     946\n11 132 [Emergency Contraception]                   47\n12 141 [Male condom]                              117\n13 142 [Female condom]                              6\n14 151 [Diaphragm]                                  2\n15 160 [Standard Days/Cycle Beads Method]           8\n16 170 [Lactational amenorrhea method (LAM)]        2\n17 210 [Rhythm]                                     1\n18 220 [Withdrawal]                                 2\n19 900 [None of the above]                          4\n20 995 [Not interviewed (female questionnaire)]     5\n21 998 [No response or missing]                     2\n22 999 [NIU (not in universe)]                    953\n\nHere, the top codes are left-padded to match the number of digits required for all of the response categories. They are now 995, 998, and 999.\nYou’ll find the value NA in some variables, but only if the associated question was excluded from one or more of the samples in your data extract. For instance, GEOCD indicates whether respondents to the DRC sample were interviewed in Kinshasa or Konga Central; it’s not included in the samples from other countries:\n\n\ndat %>% count(COUNTRY, GEOCD)\n\n\n# A tibble: 7 × 3\n                          COUNTRY              GEOCD     n\n                        <int+lbl>          <int+lbl> <int>\n1  1 [Burkina Faso]               NA                   946\n2  2 [Congo, Democratic Republic]  1 [Kinshasa]         96\n3  2 [Congo, Democratic Republic]  2 [Kongo Central]    76\n4  6 [India]                      NA                   532\n5  7 [Kenya]                      NA                  3935\n6  9 [Nigeria]                    NA                  1016\n7 10 [Uganda]                     NA                  2407\n\nIf you want to mark all top codes as NA, the easiest way to do so is to reference the labels rather than the numeric codes. We’ll provide them to the ipumsr function lbl_na_if applied to all variables in our extract:\n\n\ndat <- dat %>% \n  mutate(across(everything(), ~lbl_na_if(.x,\n    ~.lbl %in% c(\n        \"Not interviewed (female questionnaire)\",\n        \"No response or missing\",\n        \"NIU (not in universe)\"\n      )\n  )))\n\n\n\n\nThe value NA may be useful if, for example, you don’t want to create dummy variables for missing values in an analytic model. R will usually drop NA cases by default.\nNow, missing responses for DISCFPTODAY and FPMETHGIVEN are simply NA.\n\n\ndat %>% count(DISCFPTODAY)\n\n\n# A tibble: 3 × 2\n  DISCFPTODAY     n\n    <int+lbl> <int>\n1     0 [No]    735\n2     1 [Yes]  5428\n3    NA        2845\n\ndat %>% count(FPMETHGIVEN)\n\n\n# A tibble: 20 × 2\n                                 FPMETHGIVEN     n\n                                   <int+lbl> <int>\n 1 101 [Female Sterilization]                  111\n 2 102 [Male Sterilization]                      1\n 3 111 [Implants]                             2229\n 4 112 [IUD]                                   347\n 5 113 [Post-partum IUD]                        89\n 6 114 [Post-abortion IUD]                       1\n 7 120 [Injectables]                          3704\n 8 123 [Injectables (Depo Provera)]            268\n 9 124 [Injectables (Sayana Press)]            163\n10 131 [Pill]                                  946\n11 132 [Emergency Contraception]                47\n12 141 [Male condom]                           117\n13 142 [Female condom]                           6\n14 151 [Diaphragm]                               2\n15 160 [Standard Days/Cycle Beads Method]        8\n16 170 [Lactational amenorrhea method (LAM)]     2\n17 210 [Rhythm]                                  1\n18 220 [Withdrawal]                              2\n19 900 [None of the above]                       4\n20  NA                                         960\n\nWe encourage you to use caution when labelling values NA. You may find it useful to mark other values NA (e.g. “None of the above” or “Don’t know”), but doing so may have unintended consequences for your analysis!\nSample weights\nNotably, no sample weights are available for CEI surveys: as we’ve discussed, PMA constructed a convenience sample of women visiting eligible facilities over a two day period. Those facilities are, themselves, selected to reflect the service environment experienced by women in the household and female sample - neither CEI nor SDP samples are designed to be nationally or subnationally representative.\nTopics\nYou can browse an English version of the common CEI questionnaire here, or you can find country-specific variations in both English and French (where appropriate) along with PMA dataset notes on this page.\nIPUMS PMA harmonizes variables from all PMA samples to ensure that the same variable names, labels, and response options are used wherever possible. In this case, all six of the CEI samples are highly comparable, except that some variables are not available for all samples.\nYou’ll find CEI data on the IPUMS PMA website under the new “Client Exit Interview” unit of analysis.\n\n\n\nVariables are arranged by topic, but you may also browse them alphabetically or search for a particular variable by name, label, value label, or description. We’ll give a broad overview here.\nTechnical Variables\nAs with all IPUMS PMA data, you’ll find several preselected variables included automatically with your extract. The include “technical variables” reporting the SAMPLE, COUNTRY, YEAR, and ROUND (all samples included in this release are “round 1”; data from “round 2” will be available next spring).\nAdditionally, you’ll find several unique identification numbers:\nEAID identifies each enumeration area\nFACILITYID identifies each facility\nENUMID identifies each enumerator (interviewer)\nINTFQMON identifies the month of the interview\nINTFQYEAR identifies the year of the interview\nThe variable CONSENTFQ indicates whether the woman provided informed consent to participate in the interview, and RESULTCQ provides details about whether the interview was completed.\nInterview Location\nAs we’ve mentioned, CEI baseline interviews took place at facilities sampled in a contemporaneous SDP survey. In an upcoming post, we’ll show how to use FACILITYID to obtain detailed information about each facility and attach it to a CEI data extract. However, CEI extracts do contain some basic information about the facility:\nFACILITYTYPE and FACILITYTYPEGEN describe the facility type (hospital, health clinic, pharmacy, etc.)\nFACILITYADV indicates whether the service delivery point is an “advanced facility.” Generally speaking, advanced facilities include hospitals, health centers, and clinics, whereas pharmacies and drug shops are not considered advanced facilities. This definition varies across countries.\nAUTHORITY indicates whether the managing authority for the facility is government, private, an NGO, a faith-based organization, or “other”.\nURBAN indicates whether the facility is located in an urban enumeration area (not available for DRC, Nigeria, or Kenya).\nSUBNATIONAL identifies the subnational region in which the facility is located - variables starting with the prefix GEO provide the same information, but are country-specific.\nBackground\nAll women who received family planning information or a family planning method during their visit (see FPINFOYN) are asked to provide their AGE, but women whose age is younger than 15 or older the 49 are excluded from the data file. All remaining women are asked to provide their:\neducation level EDUCATT and EDUCATTGEN\nmarital status MARSTAT\nnumber of times given birth BIRTHEVENT\nOther important background information concerns each woman’s experience using family planning before the visit. PREVMETH indicates whether the woman ever used any family planning method before; if so, PREVMETHDUR and PREVMETHDURVAL indicate how long she’s been using her most recent method. For any woman who received a method today, FPUSEPREV indicates whether she had previously used it; if so, PREVMETHYR indicates whether she’d used it in the previous 12 months.\nServices & Information\nVISITREASON gives the main reason for the woman’s visit, and VISITFPTODAY indicates whether the main reason included family planning. The availability of most other variables depends on whether the woman received a method or prescription FPVISITGIVEN, or whether she discussed family planning during the visit DISCFPTODAY .\nFor women who received a method or prescription, FPMETHGIVEN describes the method that was given (if the method was injectable, FPINJTYPETODAY gives the injectable type). You’ll also find variables explaining the woman’s expectations prior to the visit, and whether the method she was given met those expectations. These describe:\nwhich method she initially wanted FP1STMETHWANT\nwhether she obtained the method she initially wanted FPGETDESIREDTODAY\nthe reason why she didn’t receive the method she initially wanted FPGETWHYTODAY\nwho made the final decision about the method she ultimately received FPDECIDEMETHOD\nSeveral variables describe what the provider told her about the method she was given. Specifically, did the provider:\nexplain how to use the method TELLMETHUSE\nexplain possible side effects TELLSIDEEFF\ntell her what to do if she experienced problems TELLSEPROB\ntell her when to return for follow-up TELLWHENRETURN\ntell her about methods other than the one she was given DISCOTHFP\ntalk about methods that protect against HIV/AIDs and STIs DISCSTIPROTECT\nask about her preferred method ASKFPPREF\ntell her she could switch methods in the future TELLSWITCH\nWhether a woman received a method or only discussed family planning, the variable DISCMETHPROCON indicates whether the advantages and disadvantages of a particular method were discussed. If so, the woman was asked to report whether the discussion covered any of the following advantages:\ndiscrete METHPRODISCRETE\neasy to use METHPROEASY\neffective METHPROEFFECT\nreturn to fertility METHPROFERT\nfew side effects METHPROFEWSE\nless bleeding METHPROLESSBLD\nmore regular bleeding METHPROMOREBLD\nno hormones METHPRONOHORMONE\nlong term protection METHPROLONG\nother advantages METHPROOTH\nLikewise, she was asked to report whether the discussion covered any of the following disadvantages:\ndifficult to use METHCONDIFF\nineffective METHCONNOTEFF\nmore bleeding METHCONMOREBLD\nirregular bleeding METHCONIRRBLD\ncramping METHCONCRAMP\nheadache METHCONHEADACHE\nfew / no periods METHCONLESSPRD\nnausea METHCONNAUS\nweight gain METHCONWTGAIN\nother METHCONOTH\nFinally, women in the Kenya sample were also asked whether this discussion included any of the following methods, in particular:\nstandard days / cycle beads METHCOUNBEADS\ndiaphragm METHCOUNDIA\nemergency contraception METHCOUNEC\nfemale condoms METHCOUNFC\nfoam / jelly METHCOUNFOAM\nfemale sterilization METHCOUNFSTER\nimplants METHCOUNIMP\ninjectables METHCOUNINJ\nIUD METHCOUNIUD\nLAM METHCOUNLAM\nmale condom METHCOUNMC\nmale sterilization METHCOUNMSTER\npill METHCOUNPILL\nrhythm method METHCOUNRHY\nwithdrawal METHCOUNWD\nnone of the above METHCOUNNONE\nAssessment\nWomen give an overall rating (5 point scale) of their satisfaction with services received during their visit SERVSATIS, the overall clarity of the information they received FPINFOCLARITY, and the politeness of staff at the facility POLITESTAFF. They’re also asked to report whether they:\nwould return to the facility RETURNFAC\nwould refer the facility to a friend or relative REFERFAC\nwere given a change to ask questions PROVLETQUESTION\nfelt the provider answers all questions clearly CLEARANSWERS\nOther variables concern strains on the woman’s time or financial resources. FPPAYTODAY indicates whether she paid for family planning services received during the visit (some samples include FPINSTODAY indicating whether those services were covered by insurance). FACTRAVELHR and FACTRAVELMIN describe the total travel time needed to reach the facility, while TRANSPORT gives the mode of transportation; the related variable FACNEAREST indicates whether this facility was the option nearest to the woman’s home, and - if not - NOTNEARESTWHY explains why she did not visit the nearest facility. Finally, TODAYWAITHR together with TODAYWAITMIN gives the total wait time the woman experienced before seeing her provider during the visit.\nNext Steps\nOver the coming weeks, we’ll be exploring some of the exciting research questions you might explore with CEI surveys (particularly when combined with SDP surveys and external spatial data). In the meantime, reach out to us on Twitter and let us know what excites you most about this incredible new data series from PMA.\n\n\n\n",
    "preview": "posts/2021-12-01-cei-discovery/../../images/new_data.png",
    "last_modified": "2022-04-13T13:10:48-04:00",
    "input_file": {},
    "preview_width": 2555,
    "preview_height": 1437
  },
  {
    "path": "posts/2021-11-15-find-an-example/",
    "title": "2021 Blog Round-Up",
    "description": "Where to find example code for all of the key concepts we've covered so far.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-11-15",
    "categories": [
      "R Tips",
      "R packages"
    ],
    "contents": "\n\nContents\nIntroduction Course\nData Discovery\nData Manipulation\nIPUMS labelled data\nIteration with columns\nIteration with rows\nJoining and Reshaping\nVisualization\nSpatial data\n\nData Analysis\nPlans for 2022\n\nWe launched the IPUMS PMA Data Analysis Hub one year\nago this week, and we’ve covered a lot since then! As we’re\ngearing up for new series exploring Client Exit\nInterviews and longitudinal analysis with Round 2 Panel\nData in the coming months, we thought it might be a nice time to\npause and take inventory of the important concepts we’ve covered in our\nfirst year.\nIntroduction Course\nLooking for a place to start learning about IPUMS PMA data with\ncoding examples in your preferred programming language? Check out our\nnew online introduction course!\nThis course is free and open to all registered IPUMS PMA data users.\nYou’ll learn all about PMA surveys, the IPUMS data extract system, and\nbasic analysis tools for R or Stata.\nData Discovery\nOur Data\nDiscovery posts are where you’ll find announcements about new data releases and\ndeep-dives into available data for a featured topic. So far, we’ve\nexplored:\nService Delivery Point (SDP)\nsurveys\nCOVID-19 surveys\nNutrition surveys\nfor women and young children\nMigration history\ndata\nExternal sources for climate, population\ndensity, and infrastructure\ndata that complement PMA surveys\n\n\n\nData Discovery posts help you navigate the IPUMS PMA website to find the most\nimportant variables related to a particular topic.\nData Manipulation\nA Data\nManipulation post typically showcases tips for recoding, reshaping,\ndescribing, or visualizing variables included in an IPUMS PMA data\nextract. Often, we’ll feature tools from one or two of our favorite R\npackages; while we always recommend visiting package documentation\nwebsites, our goal here is to show why these tools are important\nspecifically for working with data from IPUMS PMA.\nIPUMS labelled data\n\nAlmost every post uses the ipumsr package to import an\nIPUMS PMA data extract into R. Once loaded, you’ll find that many IPUMS\nPMA variables are labelled;\nthe ipumsr package contains functions for exploring and\nmanipulating those labels. We’ve shown how to:\nload an IPUMS PMA data\nextract into R\nrecode\nor label NA values for a particular variable\nconvert\nlabelled variables into factors for tables and figures\n\n\n\n\n\n\n\n\n© IPUMS (MPL\n2.0)\n\nThe ipumsr package\nprovides tools to access and manipulate labels.\nIteration with columns\nWhen you want to apply changes to several IPUMS PMA\nvariables, it’s usually most efficient to leverage the across function from dplyr. We use\nacross all the time, but some of our best examples show how\nto:\nuse tidy\nselection to identify variables by location or a naming pattern\nrecode\nor label NA values for several variables with tools from\nipumsr\ncheck conditions for multiple variables with if_any\nand if_all\nIteration with rows\n\nMany functions in R are vectorized:\nwhen you apply them to a column in your data frame, you typically get\none result for each row.\nNon-vectorized functions instead return one\nresult summarizing the entire column. For instance, the\nfunction mean gives you one mean value derived from all\nrows in a given column. Tools from dplyr like rowwise\nand group_by\nallow us to apply non-vectorized functions to individual rows or groups\nof rows. We’ve used these functions to:\nsummarize variables within\ngroups\nsummarize variables within\nthe same row with c_across\niterate through groups with help from cur_group\n\n\n\n\n\n© RStudio (CC0 1.0)\nJoining and Reshaping\n\nAll of the IPUMS PMA data extracts we’ve examined so far are\nrectangular in shape: each row represents one person or\nfacility. Sometimes, it’s necessary to change this structure: we might\nwant to spread multiple observations of the same individual into\nseparate rows, or we might want to leverage\nhierarchical data to situate a person within some\nlarger context (like a household, a region, or a country). With help\nfrom data-structuring packages like tidyr, we’ve shown how to:\nmerge summary SDP\ndata to records for individual women\nmerge\nbaseline and COVID-19 follow up surveys for women in a panel\nstudy\npivot event-history data from a wide to long format and back\nagain\nuse nested\ndata structures for individuals grouped by household\n\n\n\n\n\n© RStudio (CC0 1.0)\nVisualization\n\nWhenever we summarize variables or model output on this blog, we like\nto make figures with ggplot2 and tables\nwith gtsummary.\nFor maps, we’ve focused on ggspatial\n- an extension of ggplot2 that supports raster data from\nboth the raster package\nand the terra\npackage. Topics include:\ndesigning a\ntheme for ggplot2 (custom fonts, colors, and\nlayout)\nbasic bar\ncharts\ngrouped bar\ncharts\ndivergent\nstacked bar charts\nfaceted\nbar charts\nlollipop\ncharts\nradar\ncharts\nalluvial\ncharts\ndot\nand whisker charts\nerror bars and text\nannotation\nmaps\nwith ggspatial\ndescriptive\ntables and model summary\ntables with gtsummary\n\n\n\n\n\n© RStudio (CC0 1.0)\n\n\n\nData Manipulation posts include tips for data\nwrangling, exploration, and presentation.\nSpatial data\n\nLastly, we’ve devoted several Data Manipulation posts to exploring\nexternal sources for spatial data. If you’re new to spatial data - or if\nyou’re an ArcGIS user interested in learning more about R - we recommend\nchecking out the free, open-source text Geocomputation with R.\nYou’ll be introduced to both of the major packages we use on this blog:\nsf for vector\ndata and terra\nfor raster data. We’re planning to cover much more spatial\ncontent in the coming months, but so far we’ve explained how to:\nfind and use PMA\nGPS coordinates\nfind and use IPUMS\nPMA shapefiles\ncreate enumeration area buffer\nzones\nunderstand and manipulate coordinate\nreference systems\nmerge external vector\ndata with the sf package\nmerge external raster data with both the raster\npackage and the newer terra\npackage\n\n\n\n\n\n© Edzer Pebesma (GPLv2)\n\n\n\n\n© Robert J. Hijmans et al. (GPLv3)\nData Analysis\nWe like to end every series with a Data Analysis post.\nHere, we use what we’ve learned in earlier posts to build a model and\ndiscuss important findings. Often, we’ll use this as an opportunity to\nshowcase new and exciting published research\nfrom authors working with PMA data. These posts discuss:\n\ndesign\nelements for the household and female surveys like sample weights\nand information about cluster sampling\ndesign\nelements for COVID-19 follow up surveys\nordinary\nleast squares regression\nbinary\nlogistic regression\nmultinomial\nmodels\nmulti-level\nmixed effect models\nsurvival analysis\ncluster\nrobust standard error estimation\nbootstrapped\nstandard error estimation\n\n\n\n\n\n© Greg Freedman Ellis et al. (GPL\n2 | GPL 3)\n\n\n\n\nWe walk through source code from recent publications with PMA data in a\nData Analysis post.\nPlans for 2022\nWe’ve been trilled to connect with so many of you - more than 2,000\nreaders in over 100 countries - in our first year! Coming in the months\nahead, we’ll continue providing bi-weekly blog posts covering the latest\nIPUMS PMA data releases as they become available. We’ve mentioned\nupcoming series planned for Client Exit Interviews and\nRound 2 Panel Data, and we’ll also return to the\nrelationship between COVID-19 and family planning in\nnew samples. We plan to continue emphasizing spatial\nanalysis made possible with external data sources, and we’d\nlove to expand our coverage of PMA publications in\ncollaboration with researchers using IPUMS PMA data in their own work.\nWe’re also planning a new course on longitudinal\nanalysis using the first two rounds of PMA panel data; look for\nnew announcements on this in the early spring. And, as always, we’ll\ncontinue exploring free and powerful tools for working with\nsurvey data in R that we hope will make IPUMS PMA accessible to\nmore researchers than ever before.\nSpecial thanks to all of our outstanding partners at the Bill & Melinda Gates\nFoundation, Johns Hopkins\nUniversity, and here at IPUMS\nfor tremendous support as we launched this new project in 2021!\nThis blog would not be possible without brilliant insight and\nongoing encouragement from the whole team at IPUMS PMA: professors\nKathryn Grace, Elizabeth Heger Boyle, and Nina Brooks; project director\nDevon Kristiansen; post-doctoral associates Maya Luetke and Jiao Yu; and\ngraduate research assistants Shelby Rutzick, Saeun Park, and Tayler\nNelson who contributed posts this year - thanks to each of you!\n\n\n\n",
    "preview": "posts/2021-11-15-find-an-example/../../images/logo-navy.png",
    "last_modified": "2022-07-01T15:03:35-04:00",
    "input_file": {},
    "preview_width": 1113,
    "preview_height": 312
  },
  {
    "path": "posts/2021-11-01-nutrition-analysis/",
    "title": "Measuring agricultural conditions and their relationship with infant nutrition in Burkina Faso",
    "description": "We've learned how to build key indicators with spatially referenced nutrition data from PMA. Now let's see how researchers have used them.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-11-05",
    "categories": [
      "Nutrition",
      "Climate",
      "Data Analysis",
      "Mixed Effects",
      "PMA Publications",
      "terra",
      "sf",
      "lme4",
      "gtsummary"
    ],
    "contents": "\n\nContents\nPMA Nutrition Data\nLivelihood Zones\nWRSI\nMulti-level Mixed Effects Models\nModeling MUAC\nModeling MDD and MMF\n\nWrap-up\n\nWe’re wrapping up our series on PMA nutrition surveys this week with an exciting new paper published in the journal Environmental Research Communications. Authors Jessie Pinchoff, William Turner, and Kathryn Grace look at the relationship between agricultural conditions and infant malnutrition in Burkina Faso, so their work mobilizes many of the tools we’ve demonstrated in this series so far. If you’ve been reading along, you’ll already know how to:\nfind harmonized nutrition data for infants,\nfind and summarize data collected from mothers of sampled infants,\nbuild key nutrition indicators, and\nexplore climate data together with PMA nutrition surveys\nIn this post, we’ll see how Pinchoff et al. put these pieces together to build a multi-level mixed effects logistic regression model for each of three nutrition outcomes for infants aged 6-23 months. Their results suggest that - in Burkina Faso, where many households rely on rainfed, subsistence agriculture - the quality of a particular growing season has a statistically significant impact on infant nutrition and growth.\nAs always in a PMA Publications post, we’ll share R code and discuss decisions about measurement and analysis as we review the author’s approach. Our hope is that you’ll find something useful for your own project linking climate and nutrition data! For background information on the prevalence of rainfed food systems and infant malnutrition in Burkina Faso - or for a discussion of the implications of these findings for policy and further research - we encourage you to check out the published paper.\n\nBig thanks to Jessie Pinchoff for sharing Stata source code for this paper! We’ve adapted it for R and used IPUMS PMA variables where available.\nPMA Nutrition Data\nThe authors derive three dependent variables from the 2017 Burkina Faso nutrition sample. We’ve already demonstrated how to make two of these - Minimum Dietary Diversity MDD and Minimum Meal Frequency MMF - in an earlier post. Both MDD and MMF are defined by World Health Organization (WHO) recommendations for Infant and Young Child Feeding (IYCF) practices necessary for healthy growth and development in children during the first two years of life.\n\nBe sure to check out our post discussing WHO guidelines for MDD and MMF in much greater detail.\nThe third dependent variable is an anthropometric measurement of each infant’s physical development. IPUMS PMA nutrition surveys include INFARMCIRCVAL, a measure of the infant’s mid-upper arm circumference (MUAC) taken by the interviewer on the day of the interview. According to WHO guidelines, MUAC measurements below 11.5 centimeters indicate acute malnutrition in children aged 6-23 months, and measurements between 11.5 and 12.5 centimeters indicate risk of malnutrition. Pinchoff et al. point to a range of studies suggesting that these thresholds may be too low to properly identify malnourishment, and they note that PMA surveys were conducted largely in June or July - early months of the Burkina Faso “hunger season” before food shortages were likely to manifest in anthropometric measures. To address these issues, the authors build a binary threshold for MUAC measures below 13.5 centimeters that we’ll call MUAC_LOW.\nWe’ll construct one model for each of these three outcomes with a range of independent variables recoded from IPUMS PMA variables and two external data sources (more on these in a moment). We’ll be using harmonized IPUMS PMA data where possible, but we’ll mention here that the authors used source data downloaded directly from PMA before harmonized data from IPUMS PMA became available; these differences will not change our main findings, but they did impact certain design choices. For example, the authors were not able to control for the SEX of each infant, as this information was collected on the household screening questionnaire but not on the child nutrition questionnaire; IPUMS PMA has matched records from the two questionnaires together, so you might choose to include this information in your own work.\nNotably absent from IPUMS PMA data are 1) the infant’s precise age in months, and 2) several variables related to perceived food insecurity in the infant’s household. The authors obtained this information directly from PMA source data (although it may be available from IPUMS PMA soon). We’ve previously shown how to use currently available IPUMS PMA data to accurately estimate each infant’s age within one month, but we’ll use the precise age of the infant on the day of the interview here. We’ve also pre-constructed a measure of household food insecurity HHFOODINSEC from source data: food insecurity is ranked “Severe” if 6 or more of the following statements were true, “Moderate” if 4-5 were true, and “Low/None” otherwise.\n\n\n\nWe’ve also recoded some existing IPUMS PMA variables beforehand, and we’ve located information about each child’s mother (including her own MUAC measurements) using a procedure described here. We removed all cases from the file except for infants aged 6-23 months without missing responses, and then saved this “cleaned” dataset as an R data file. We’ll use read_rds to load it into R now:\n\n\nlibrary(tidyverse)\n\ndat <- read_rds(\"data/dat_clean.rds\")\n\n\n\nWe’ll use our favorite table-making package, gtsummary, to preview all of the PMA nutrition variables we’ve made.\n\n\nlibrary(gtsummary)\n\ndat %>% \n  select(\n    INFAGE_3, INFDIAR, MOMAGE_4, MOMEDUC, MOMMUAC_3,\n    HHKIDS_4, HHFOODINSEC, MAD, MDD, MMF, MUAC_LOW\n  ) %>% \n  tbl_summary() %>% \n  modify_spanning_header(everything() ~ \"# PMA Nutrition Variables\") %>% \n  modify_header(update = list(label ~ \" \")) %>% \n  italicize_labels() %>% \n  as_gt() %>% \n  gt::tab_options(table.width = gt::pct(75))\n\n\n\n\n        PMA Nutrition Variables\n\n      \n    \n      N = 1,7221\n    Infant's age\n6-11\n638 (37%)12-17\n586 (34%)18-23\n498 (29%)Infant diarrhea last 2 wks\n580 (34%)Mother's age\n35+\n336 (20%)25-34\n809 (47%)20-24\n431 (25%)<20\n146 (8.5%)Mother ever attended school\n632 (37%)Mother's MUAC (cm)\nNormal (>25 cm)\n1,270 (74%)Risk (22.1-25 cm)\n412 (24%)Acute (22 cm or less)\n40 (2.3%)Household total kids under 5\n1\n646 (38%)2\n457 (27%)3\n291 (17%)4+\n328 (19%)Household food insecurity\nLow/None\n1,012 (59%)Moderate\n314 (18%)Severe\n396 (23%)Minimum Acceptable Diet (MAD)\n178 (10%)Minimum Dietary Diversity (MDD)\n265 (15%)Minimum Meal Frequency (MMF)\n910 (53%)MUAC 13.5 cm or less\n568 (33%)\n        \n          1\n          \n           \n          n (%)\n          \n      \n    \n\nThe authors derive two additional independent variables - including their key predictor of interest - from external datasets distributed by the Famine Early Warning Systems Network (FEWSNET).\nLivelihood Zones\nThe first external data source concerns livelihood zones for the enumeration areas used to identify households in the PMA nutrition sample. Livelihood zones describe the main ways that workers in a particular area earn income and procure food, and they are used widely in climate-health research. You can download a shapefile from FEWSNET describing nine distinct livelihood zones for Burkina Faso here.\nWe’ve downloaded the shapefile BF_LHZ_2014 and saved it in the “data” folder of our working directory. Let’s load it into R with the sf package and call the resulting object lhz.\n\n\nlibrary(sf)\n\nlhz <- st_read(\"data/BF_LHZ_2014\") %>% \n  st_transform(crs = 4326) %>%                 # Set to WGS 84\n  mutate(label = paste(LZCODE, LZNAMEEN))      # Label for our map below\n\n\n\nWe’ll want to find a livelihood zone classification for each PMA enumeration area, so we’ll also need to obtain their displaced GPS coordinates from PMA. In our last post, we described steps for creating buffer zones containing the actual centroid location for each enumeration area, subject to certain rules:\nurban centroids are displaced up to 2 kilometers in any direction\n99% of rural centroids are displaced up to 5 kilometers in any direction\n1% of rural centroids are displaced up to 10 kilometers in any direction\ndisplacement across administrative boundaries is not permitted\nWe’ve downloaded 1) a CSV file containing the displaced GPS coordinates, and 2) a shapefile containing administrative boundaries for Burkina Faso. Both are saved in the “data” folder of our working directory. We’ll load both into R and create gps_buf to represent the buffer zones for each enumeration area.\n\nMake sure to review our last post, where we describe these steps in detail.\n\n\n# Displaced gps coordinates \ngps <- read_csv(\"data/gps_bf.csv\") %>% \n  select(EAID = EA_ID, GPSLONG, GPSLAT) %>% \n  st_as_sf(coords = c(\"GPSLONG\", \"GPSLAT\"), crs = 4326) %>% \n  left_join(\n    by = \"EAID\",\n    dat %>% select(EAID, URBAN) %>% distinct()\n  )\n\n# Shapefile \nshape <- st_read(\"data/shape_bf\") %>% select(ADMIN_NAME)\n\n# Project `gps` and `shape` to meters \ngps <- gps %>% st_transform(crs = 32630)\nshape <- shape %>% st_transform(crs = 32630)\n\n# Create buffers\ngps_buf <- gps %>% \n  st_buffer(if_else(.$URBAN, 2000, 5000)) %>% \n  st_intersection(shape) %>% \n  st_filter(gps)\n\n# Revert to WGS84\ngps <- gps %>% st_transform(crs = 4326)\nshape <- shape %>% st_transform(crs = 4326)\ngps_buf <- gps_buf %>% st_transform(crs = 4326)\n\n\n\nNow, let’s plot the nine FEWNET livelihood zones in lhz with ggspatial.\n\n\nlibrary(ggspatial)\nsource(\"make_theme.R\")\n\nggplot() + \n  layer_spatial(lhz, aes(fill = label)) + \n  theme_pma(\n    title = \"FEWSNET Livelihood Zones for Burkina Faso\",\n    caption = paste0(\n      \"https://fews.net/west-africa/burkina-faso/\",\n      \"livelihood-zone-map/november-2009\"\n    )\n  ) + \n  scale_fill_manual(\n    name = NULL,\n    values = c(\"#7B4D30\", \"#0E440F\", \"#29682C\", \"#7E9C32\", \"#587211\",\n      \"#D20501\", \"#B5D55A\", \"#4FA252\", \"#5C2D0F\")\n  ) \n\n\n\n\nWe’ve defined theme_pma in a source script called make_theme.R. If you’re curious, you can find it on our GitHub page here.\n\n\n\nTo simplify things a bit, the authors collapse these nine zones into three major categories: urban (Ouaga), agricultural, and pastoral (or agropastoral). We’ll do the same here, and then map the result.\n\n\nlhz <- lhz %>% \n  mutate(LIVZ_3 = case_when(\n    LZCODE == \"BF06\" ~ \"Ouaga/Urban\",\n    LZCODE %in% c(\"BF07\", \"BF08\", \"BF09\") ~ \"Pastoral\",\n    T ~ \"Agricultural\"\n  ))\n\nggplot() + \n  layer_spatial(\n    lhz %>% count(LIVZ_3) %>% st_make_valid() , \n    aes(fill = LIVZ_3)\n  ) + \n  layer_spatial(gps_buf, color = \"#00263A\", alpha = 0) + \n  theme_pma(\n    title = \"Distribution of PMA Enumeration Areas within Major Livelihood Zones\",\n    show_eas = TRUE\n  ) + \n  scale_fill_manual(\n    name = NULL,\n    values = c( \"#899DA4\", \"#C93311\", \"#DC863B\")\n  ) \n\n\n\n\nWe’ll now assign each enumeration area one of those three categories in dat. In the rare case where a buffer overlaps with a boundary between livelihood zones, we’ll use whichever livelihood zone contains the centroid. As we’ll see, a majority of the sampled infants reside in “agricultural” areas (54%) or “pastoral” areas (30%). Only a small minority reside in the Ouaga “urban” area (16%).\n\n\ndat <- lhz %>%\n  mutate(LIVZ_3 = case_when(\n    LZCODE == \"BF06\" ~ \"Ouaga/Urban\",\n    LZCODE %in% c(\"BF07\", \"BF08\", \"BF09\") ~ \"Pastoral\",\n    T ~ \"Agricultural\"\n  )) %>%\n  st_intersection(gps_buf) %>%      # find the intersection with EA buffers\n  st_filter(gps) %>%                # keep only if it contains the centroid\n  tibble() %>%\n  select(EAID, LIVZ_3) %>%\n  right_join(dat, by = \"EAID\")\n\n\n\n\n\ndat %>% \n  select(LIVZ_3) %>% \n  tbl_summary() %>% \n  modify_spanning_header(\n    everything() ~ \"# Recoded FEWSNET Livelihood Zones\"\n  ) %>% \n  modify_header(update = list(label ~ \" \")) %>% \n  italicize_labels() %>% \n  as_gt() %>% \n  gt::tab_options(table.width = gt::pct(75))\n\n\n\n\n        Recoded FEWSNET Livelihood Zones\n\n      \n    \n      N = 1,7221\n    Livelihood zone\nAgricultural\n924 (54%)Pastoral\n517 (30%)Ouaga/Urban\n281 (16%)\n        \n          1\n          \n           \n          n (%)\n          \n      \n    \n\nWRSI\nThe final data source concerns the authors’ main predictor of interest: agricultural conditions in the infant’s enumeration area that may influence the abundance and variety of available food, or the livelihoods of families involved with agricultural work.\nHere, the authors use a crop-specific Water Requirement Satisfaction Index (WRSI) - also developed by FEWSNET - to model precipitation relative to other meteorological factors that drive evaporation and transpiration (e.g. solar radiation, air temperature, humidity, and wind). Rainfall, alone, can sometimes serve as a good proxy for agricultural conditions, but not if the water evaporates before it becomes available for plants. WRSI also models the growing season for a selected reference crop - in this case, millet - to test whether rainfall occurs during the most crucial stages of plant development.\nTo see why all of this matters, let’s take a look at a simple rainfall total for the 2017 growing season. Following the steps outlined in our last post, we’ve download a dataset from the Climate Hazards center InfraRed Precipitation with Station (CHIRPS) series spanning the years 1981 (the first year of data collection) through 2017. We calculated a simple terra::sum for each year’s growing season (approximated as June 1 to Oct 1) and saved the result in a raster with one layer for each year’s total seasonal accumulation (in millimeters).\n\n\nlibrary(terra)\n\nyr_sums <- rast(\"data/chirps_sums.tif\")\n\nyr_sums\n\n\nclass       : SpatRaster \ndimensions  : 115, 159, 37  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : -5.549997, 2.400003, 9.349999, 15.1  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : chirps_sums.tif \nnames       :      1981,      1982,      1983,      1984,      1985,      1986, ... \nmin values  : 156.65630, 170.00345, 139.44662,  63.97786, 121.26834, 171.29820, ... \nmax values  :  985.3304,  834.6878,  862.3036, 1024.9135, 1053.9604, 1017.6069, ... \n\nSuppose we simply wanted to gauge whether 2017 was especially wetter or drier than average in a particular place. We could calculate a simple z-score and map the result:\n\n\nz_scores <- (yr_sums$`2017` - mean(yr_sums)) / stdev(yr_sums)\n\nggplot() + \n  layer_spatial(mask(z_scores, vect(shape), touches = FALSE)) +\n  layer_spatial(lhz %>% count(LIVZ_3) %>% st_make_valid(), alpha = 0) +\n  layer_spatial(gps_buf, color = \"#00263A\", alpha = 0) +\n  theme_pma(\n    title = \"2017 Rainfall Accumulation: June 1 - Oct 1\",\n    subtitle = \"Z-scores relative to mean seasonal accumuation 1981-2017\",\n    caption = \"https://www.chc.ucsb.edu/data/chirps\",\n    show_eas = TRUE\n  ) + \n  scale_fill_gradient2(\n    name = \"Z-score\",\n    limits = c(-2.3, 2.3),\n    low = \"#FAEFD1\", \n    high = \"#00263A\", \n    na.value = \"transparent\"\n  ) \n\n\n\n\nAs you can see, there’s a good deal of spatial variation in the Burkina Faso rainfall totals for 2017. In our map, the z-score “0” indicates a perfectly average year, whereas z-scores “1” and “-1” indicate rainfall totals exactly 1 standard deviation above or below average, respectively. Enumeration areas located in the northern and eastern regions experienced more rainfall than normal in 2017, while those in the south and west experienced less.\nWe’ll assign one z-score to each enumeration area by taking a weighted average of the pixels that overlap with each buffer: the extract function will produce a “weight” equal to the proportion of each pixel included within the boundaries of a given buffer. Finally we’ll match these z-scores to each of the infants in dat.\n\nCheck out this post explaining why we take a weighted mean of the pixels in each buffer.\n\n\ndat <- z_scores %>%\n  extract(gps_buf %>% vect(), weights = TRUE) %>%\n  tibble() %>%\n  right_join(gps_buf %>% rowid_to_column(\"ID\"), by = \"ID\") %>%\n  group_by(EAID) %>%\n  summarise(CHIRPS_Z = weighted.mean(`2017`, weight)) %>%\n  full_join(dat, by = \"EAID\")\n\n\n\nNow, let’s compare these relative rainfall totals to WRSI scores obtained for each enumeration area. FEWSNET provides free software called GeoWRSI that you can use to specify a reference crop, source data, and other parameters used to calculate WRSI. The authors used CHIRPS data combined with NOAA ESRL PSD Global Reference Evapotranspiration for the FEWS NET Science Community (RefET) to calculate WRSI scores for millet. They’ve shared the program output with us as WRSI.dta, so we’ll simply attach the WRSI score for each EA to dat.\n\n\ndat <- haven::read_dta(\"data/WRSI.dta\") %>%\n  select(EAID = EA_ID, WRSI_17 = eos_wrsi_anomaly_2017) %>%\n  right_join(dat, by = \"EAID\")\n\n\n\nBecause CHIRPS precipitation totals were used to derive WRSI, you might expect to see a strong correlation between the two measures. We should see this if we create a scatterplot for each of the enumeration areas in dat:\n\n\ndat %>% \n  ggplot(aes(x = CHIRPS_Z, y = WRSI_17)) + \n  geom_point() + \n  geom_abline() + \n  theme_minimal() + \n  xlim(-2, 2) + \n  ylim(-20, 20)\n\n\n\n\nIn fact, the correlation between rainfall and WRSI is positive, but somewhat weak. Here, a negative value for WRSI indicates poor growing conditions for millet. There are a handful of enumeration areas where conditions were wetter than normal (CHIRPS_Z > 0), but overall conditions for growing millet were poor (WRSI < 0). This can happen if, for example, if conditions in 2017 were also hotter than normal (driving evaporation), or if rainfall occurred at the wrong stage of plant development. Overall, most enumeration areas were located in areas that experienced less rainfall than normal (CHIRPS_Z < 0), but only a few of these experienced exceptionally poor growing conditions for millet.\nFor these reasons, the authors use WRSI rather than the simpler CHIRPS z-scores we’ve derived. As we’ll see, they find that - controlling for all of the other independent variables we’ve discussed so far - there is a statistically significant relationship between “good agricultural conditions” and positive nutritional outcomes for infants.\n\n\ndat %>% \n  select(WRSI_17, CHIRPS_Z) %>% \n  tbl_summary(label = list(\n    WRSI_17 = \"WRSI Anomaly\",\n    CHIRPS_Z = \"CHIRPS Z-score\"\n  )) %>% \n  modify_spanning_header(\n    everything() ~ \"# 2017 Agricultural Conditions\"\n  ) %>% \n  modify_header(update = list(label ~ \" \")) %>% \n  italicize_labels() %>% \n  as_gt() %>% \n  gt::tab_options(table.width = gt::pct(75))\n\n\n\n\n        2017 Agricultural Conditions\n\n      \n    \n      N = 1,7221\n    WRSI Anomaly\n0.0 (-4.0, 1.0)CHIRPS Z-score\n-0.54 (-0.92, -0.18)\n        \n          1\n          \n           \n          Median (IQR)\n          \n      \n    \n\nMulti-level Mixed Effects Models\nIf you’re a regular reader of this blog, you might remember that we’ve previously shown how to model binary outcomes like unmet need for family planning and current contraceptive use with cluster-robust standard error estimation via the survey package. When we do so, we address the likelihood that neighboring households - those in the same enumeration area - probably share many common features. While the point-estimate for each predictor is identical to the estimate you’d obtain from logistic regression, the estimated standard error for each predictor is typically larger. Practically speaking, we make it harder for each predictor to pass the same test for statistical significance (e.g. “p < .05”) because we suspect that the clustered sample design produces artificial agreement between respondents.\nPinchoff et al. use a different approach to solve the same problem, except that their multi-level mixed effects model incorporates variation within and between enumeration areas into the estimate associated with each predictor. As a result, both the point-estimate and the standard error associated with each is different compared to what you’d obtain from logistic regression.\nYou might imagine this approach in contrast to a naive fixed effects model where we simply plugged in EAID as an independent variable. Because EAID is categorical, we’d effectively create one “dummy variable” for every enumeration area (categorical variables like LIVZ_3 or MOMEDUC are handled this way). The estimates for all of our other independent variables would be “controlled for” variation between enumeration areas.\nWhen we treat enumeration areas as random effects, we explicitly incorporate this sort of variation into our model. Compared with the fixed effects approach - where each “dummy variable” is defined by infants from the same enumeration area - the random effects approach combines what we know about one enumeration area with information about how it compares with the others. The result is an improved estimation for every “dummy variable,” because each incorporates information from the full sample. More importantly, this generally reduces the standard error for each predictor. Let’s see how the authors implemented this approach to model MUAC_LOW, MDD, and MFF.\nModeling MUAC\nMost of the functions we use for multi-level modeling come from the lme4 package. We’ll need an analogue to the glm function that allows us to specify a “binomial” link function and a formula that specifies EAID as a random effect.\n\n\nlibrary(lme4)\n\n\n\nHere, we use glmer to build three models: one that controls for MDD, one that controls for MMF, and one that controls for neither. The notation (1|EAID) signals that we’ll be fitting 1 intercept for each enumeration area (note, however, that these intercepts are not reported in the model output; instead, we’ll see a standard deviation summarizing the dispersion between these intercepts).\n\n\nMUAC1 <- glmer(\n  data = dat,\n  family = \"binomial\",\n  formula = MUAC_LOW ~ WRSI_17 + LIVZ_3 + MOMAGE_4 + MOMMUAC_3 + \n    INFDIAR + MOMEDUC + HHKIDS_4 + INFAGE_3 + (1|EAID)\n)\n\nMUAC2 <- glmer(\n  data = dat,\n  family = \"binomial\",\n  formula = MUAC_LOW ~ WRSI_17 + MDD + LIVZ_3 + MOMAGE_4 + MOMMUAC_3 + \n    INFDIAR + MOMEDUC + HHKIDS_4 + INFAGE_3 + (1|EAID)\n)\n\nMUAC3 <- glmer(\n  data = dat,\n  family = \"binomial\",\n  formula = MUAC_LOW ~ WRSI_17 + MMF + LIVZ_3 + MOMAGE_4 + MOMMUAC_3 + \n    INFDIAR + MOMEDUC + HHKIDS_4 + INFAGE_3 + (1|EAID)\n)\n\n\n\nThe next step looks messy, but it’s mostly just formatting the output to fit in a gtsummary table. Basically, we’ll use purrr::map to create one table for each model, and then store them in a list. Then we use gtsummary::tbl_merge to merge them together. The rest is just creating labels, moving rows, and setting the overall look of the table on this page:\n\n\nlist(MUAC1, MUAC2, MUAC3) %>% \n  map(\n    ~.x %>%   \n      tbl_regression(\n        exp = TRUE, \n        conf.int = TRUE, \n        show_single_row = where(is.logical),\n        tidy_fun = broom.mixed::tidy, \n        label = list(\n          `EAID.sd__(Intercept)` = \"Random Effects: EAID (standard deviation)\"\n        )\n      ) %>% \n      add_significance_stars() \n  ) %>% \n  tbl_merge() %>%  \n  italicize_labels() %>% \n  modify_header(update = list(label ~ \" \")) %>% \n  modify_spanning_header(update = list(\n    estimate_1 ~ \"**Model 1**\",\n    std.error_1 ~ \"**Model 1**\",\n    estimate_2 ~ \"**Model 2**\",\n    std.error_2 ~ \"**Model 2**\",\n    estimate_3 ~ \"**Model 3**\",\n    std.error_3 ~ \"**Model 3**\"\n  )) %>% \n  modify_table_body(\n    ~.x %>% \n      mutate(variable = variable %>% fct_relevel(c(\n        \"WRSI_17\", \"MDD\", \"MMF\", \"LIVZ_3\", \"MOMAGE_4\", \"MOMMUAC_3\",\n        \"INFDIAR\", \"MOMEDUC\", \"HHKIDS_4\", \"INFAGE_3\", \"EAID.sd__(Intercept)\"\n      ))) %>% \n      arrange(variable)\n  ) %>% \n  as_gt() %>% \n  gt::tab_options(table.width = gt::pct(100)) %>% \n  gt::tab_header(\n    gt::md(\"# Factors Associated with <br> MUAC <= 13.5 cm\")\n  )\n\n\n\nFactors Associated with  MUAC <= 13.5 cm\n\n    \n      \n        Model 1\n      \n      \n        Model 2\n      \n      \n        Model 3\n      \n    OR1,2\n      SE2\n      OR1,2\n      SE2\n      OR1,2\n      SE2\n    WRSI anomaly 2017\n0.97*\n0.016\n0.97*\n0.016\n0.97*\n0.016Minimum Dietary Diversity (MDD)\n\n\n0.67*\n0.115\n\nMinimum Meal Frequency (MMF)\n\n\n\n\n1.03\n0.118Livelihood zone\n\n\n\n\n\nAgricultural\n—\n—\n—\n—\n—\n—Pastoral\n1.20\n0.220\n1.19\n0.214\n1.20\n0.220Ouaga/Urban\n1.09\n0.254\n1.08\n0.249\n1.09\n0.254Mother's age\n\n\n\n\n\n35+\n—\n—\n—\n—\n—\n—25-34\n0.96\n0.141\n0.97\n0.142\n0.96\n0.14120-24\n0.93\n0.156\n0.92\n0.155\n0.93\n0.156<20\n1.17\n0.260\n1.16\n0.260\n1.17\n0.261Mother's MUAC (cm)\n\n\n\n\n\nNormal (>25 cm)\n—\n—\n—\n—\n—\n—Risk (22.1-25 cm)\n1.64***\n0.208\n1.65***\n0.210\n1.64***\n0.209Acute (22 cm or less)\n2.71**\n0.937\n2.71**\n0.935\n2.71**\n0.937Infant diarrhea last 2 wks\n1.22\n0.143\n1.20\n0.141\n1.22\n0.144Mother ever attended school\n0.71**\n0.092\n0.73*\n0.094\n0.71**\n0.092Household total kids under 5\n\n\n\n\n\n1\n—\n—\n—\n—\n—\n—2\n1.17\n0.164\n1.17\n0.164\n1.17\n0.1643\n1.13\n0.186\n1.13\n0.186\n1.13\n0.1874+\n1.21\n0.196\n1.20\n0.194\n1.21\n0.196Infant's age\n\n\n\n\n\n6-11\n—\n—\n—\n—\n—\n—12-17\n0.80\n0.104\n0.84\n0.109\n0.80\n0.10418-23\n0.81\n0.110\n0.83\n0.113\n0.81\n0.110Random Effects: EAID (standard deviation)\n0.48\n\n0.46\n\n0.48\n\n        \n          1\n          \n           \n          *p<0.05; **p<0.01; ***p<0.001\n          \n        \n          2\n          \n           \n          OR = Odds Ratio, SE = Standard Error\n          \n      \n    \n\nGenerally speaking, all three of these models suggest that improved agricultural conditions in the enumeration area (measured by WRSI) are associated with lower odds of infant malnourishment (measured by a MUAC 13.5 cm or lower). This effect is roughly the same whether we control for IYCF practices (MDD and MMF) or not. The authors note that “for some children who are near the margin or threshold for intervention, seasonal variation in agricultural yield could therefore play an important role in shifting them from (or into) different risk categories.”\nControlling for WRSI, infants who consume a diverse diet (measured by MDD) appear significantly less likely to have MUAC measurements below 13.5 cm. However, meal frequency (measured by MMF) had no statistically significant effect. Other significant factors are related to the mother’s nutritional status and her education level.\nModeling MDD and MMF\nWe’ll use the same appraoch to recreate the authors models for MDD and MMF:\n\n\nMDD <- glmer(\n  data = dat,\n  family = \"binomial\",\n  formula = MDD ~ WRSI_17 + LIVZ_3 + MOMAGE_4 + HHFOODINSEC + MOMEDUC + \n    HHKIDS_4 + INFAGE_3 + (1|EAID)\n) \n\nMMF <- glmer(\n  data = dat,\n  family = \"binomial\",\n  formula = MMF ~ WRSI_17 + LIVZ_3 + MOMAGE_4 + HHFOODINSEC + MOMEDUC + \n    HHKIDS_4 + INFAGE_3 + (1|EAID)\n) \n\nlist(MMF, MDD) %>% \n  map(\n    ~.x %>%   \n      tbl_regression(\n        exp = TRUE, \n        conf.int = TRUE, \n        show_single_row = where(is.logical),\n        tidy_fun = broom.mixed::tidy, \n        label = list(\n          `EAID.sd__(Intercept)` = \"Random Effects: EAID (standard deviation)\"\n        )\n      ) %>% \n      add_significance_stars()\n  ) %>% \n  tbl_merge() %>%  \n  italicize_labels() %>% \n  modify_header(update = list(label ~ \" \")) %>% \n  modify_spanning_header(update = list(\n    estimate_1 ~ \"**Minimum Meal Frequency (MMF)**\",\n    std.error_1 ~ \"**Minimum Meal Frequency (MMF)**\",\n    estimate_2 ~ \"**Minimum Dietary Diversity (MDD)**\",\n    std.error_2 ~ \"**Minimum Dietary Diversity (MDD)**\"\n  )) %>% \n  modify_table_body(\n    ~.x %>% \n      mutate(variable = variable %>% fct_relevel(c(\n        \"WRSI_17\", \"LIVZ_3\", \"HHFOODINSEC\", \"MOMAGE_4\", \"MOMEDUC\",\n        \"HHKIDS_4\", \"INFAGE_3\", \"EAID.sd__(Intercept)\"\n      ))) %>% \n      arrange(variable)\n  ) %>% \n  as_gt() %>% \n  gt::tab_options(table.width = gt::pct(100)) %>% \n  gt::tab_header(\n    gt::md(\"# Factors Associated with <br> Recommended IYCF Practices\") \n  )\n\n\n\nFactors Associated with  Recommended IYCF Practices\n\n    \n      \n        Minimum Meal Frequency (MMF)\n      \n      \n        Minimum Dietary Diversity (MDD)\n      \n    OR1,2\n      SE2\n      OR1,2\n      SE2\n    WRSI anomaly 2017\n1.02\n0.025\n1.07*\n0.034Livelihood zone\n\n\n\nAgricultural\n—\n—\n—\n—Pastoral\n1.48\n0.390\n0.83\n0.276Ouaga/Urban\n1.46\n0.450\n0.87\n0.331Household food insecurity\n\n\n\nLow/None\n—\n—\n—\n—Moderate\n0.86\n0.129\n0.77\n0.166Severe\n0.91\n0.139\n0.58*\n0.128Mother's age\n\n\n\n35+\n—\n—\n—\n—25-34\n1.04\n0.151\n1.13\n0.22720-24\n0.85\n0.141\n0.81\n0.190<20\n0.61*\n0.138\n0.90\n0.289Mother ever attended school\n1.10\n0.143\n1.75***\n0.297Household total kids under 5\n\n\n\n1\n—\n—\n—\n—2\n1.09\n0.150\n0.93\n0.1723\n0.81\n0.133\n0.89\n0.2034+\n1.07\n0.174\n0.76\n0.184Infant's age\n\n\n\n6-11\n—\n—\n—\n—12-17\n1.38*\n0.176\n2.78***\n0.52018-23\n1.96***\n0.263\n2.18***\n0.422Random Effects: EAID (standard deviation)\n0.83\n\n0.99\n\n        \n          1\n          \n           \n          *p<0.05; **p<0.01; ***p<0.001\n          \n        \n          2\n          \n           \n          OR = Odds Ratio, SE = Standard Error\n          \n      \n    \n\nHere, improved agricultural conditions in the enumeration area are again broadly associated with improved nutritional outcomes, but only MDD is shown to be significantly improved by higher WRSI scores. Infants whose mother perceived “severe” food insecurity in their household (answering 6 or more questions positively) were significantly less likely to achieve MDD, but the effect on infant MMF was ambiguous.\nWhat do we make of the difference between dietary diversity and meal frequency? The authors suggest that it might be easier for respondents to recall types of foods compared to the frequency of food consumption if, for example, mothers were not present for every meal (or if small meals are not recalled, if meal times are inconsistent, etc). Similarly, they may be more sensitive to changes in the composition of their family’s diet, whereas meal timing / occurrence may be less connected with an individual’s perception of food security.\nWrap-up\nThe kinds of dietary recall questions you’ll find in PMA nutrition surveys are common, but they’re rarely accompanied by the kind of spatial data Pinchoff et al. bring to this analysis. If you’re working on a research project that uses spatially referenced nutrition data - or if you’re using remotely sensed climate data together with other global health surveys - we’d love to hear from you. As always, you can reach us in the comments below or on Twitter.\nComing up later this month: we’ll be diving into the brand new SDP client exit interview data available from IPUMS PMA. As we’ll see, there are plenty of exciting ways to explore spatial dynamics of service delivery, as well.\nSpecial thanks to Greg Husak at the the Climate Hazards Center, and Jiao Yu at the University of Minnesota for excellent help with this post!\n\n\n\n“Indicators for Assessing Infant and Young Child Feeding Practices: Definitions and Measurement Methods.” 2021. World Health Organization; the United Nations Children’s Fund (UNICEF). https://apps.who.int/iris/bitstream/handle/10665/340706/9789240018389-eng.pdf?sequence=1.\n\n\nPinchoff, Jessie, William Turner, and Kathryn Grace. 2021. “The Association Between Agricultural Conditions and Multiple Dimensions of Undernutrition in Children 6-23 Months of Age in Burkina Faso.” Environmental Research Communications 3 (6): 065004. https://iopscience.iop.org/article/10.1088/2515-7620/ac07f5/meta.\n\n\n\n\n",
    "preview": "posts/2021-11-01-nutrition-analysis/nutrition-analysis_files/figure-html5/unnamed-chunk-12-1.png",
    "last_modified": "2022-04-13T13:10:48-04:00",
    "input_file": {},
    "preview_width": 2304,
    "preview_height": 1536
  },
  {
    "path": "posts/2021-10-15-nutrition-climate/",
    "title": "How to use CHIRPS Climate Data with PMA Nutrition Surveys",
    "description": "Remotely sensed daily precipitation data is an incredible resource for understanding rainfed food systems.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-10-15",
    "categories": [
      "Nutrition",
      "CHIRPS",
      "Precipitation",
      "Climate",
      "Agriculture",
      "terra",
      "sf",
      "ggspatial"
    ],
    "contents": "\n\nContents\nSetup\nSimple features objects\nPlot theme\n\nEnumeration Area Buffers\nCHIRPS data\nRaster data with terra\nRaster layers\n\nRainfall within Enumeration Areas\n\nIf you’ve been following along with this series, you already know that PMA nutrition surveys offer researchers a unique opportunity to connect nutrition data for women and young children with data about their local health and nutrition services environment. PMA promotes this type of contextual research by cluster sampling both households and service delivery points within the same geographically-defined enumeration areas.\nIn this post, we’ll take a look at another approach to studying contextual factors that impact nutrition. Specifically, we’ll be laying the groundwork for our next post, where we’ll dive into a recent paper published in Environmental Research Communications that explores the impact of climate change on rainfed agriculture in Burkina Faso. As we’ll see, the authors use PMA nutrition data together with local precipitation measures from the Climate Hazards center InfraRed Precipitation with Station dataset (CHIRPS) to show how spatial patterns of growing season quality impact the quality and variety of foods available for women and young children.\nResearch like this is made possible when we know the approximate centroid location for enumeration areas used in PMA nutrition surveys. PMA offers displaced GPS coordinates for all of its nutrition surveys here. In preparation for our next post, we’ll show how to combine these GPS coordinates with an IPUMS PMA data extract and precipitation raster data downloaded from CHIRPS.\nSetup\nTo get started, we’ll download a 2017 Burkina Faso nutrition data extract from IPUMS PMA and load it into R. We’ve selected responses only for “Females and Children with Nutrition Information” (all other household members have been omitted). As usual, we’ll save the “dat” file together with the “xml” codebook in our working directory, and we’ll then load both into R with the tidyverse and ipumsr packages.\n\n\nlibrary(tidyverse)\nlibrary(ipumsr)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00002.xml\",\n  data = \"data/pma_00002.dat.gz\"\n)\n\n\n\nNotably, IPUMS PMA does not disseminate the GPS coordinates we’ll be using in this post. Instead, you’ll need to apply to download them directly from our partners at PMA. Once approved, you’ll receive a CSV file containing the displaced centroid for every enumeration area represented in our data extract dat. You’ll also receive complete documentation detailing the procedure PMA used to displace each centroid from its original location.\nIf you’re new to spatial analysis in R, you might expect to begin by loading the CSV into R the usual way:\n\n\ngps <- read_csv(\"data/gps_bf.csv\") %>% \n  select(EA_ID, GPSLONG, GPSLAT, DATUM)\ngps \n\n\n# A tibble: 83 × 4\n   EA_ID GPSLONG GPSLAT DATUM\n   <dbl>   <dbl>  <dbl> <chr>\n 1  7610  -1.07    12.9 WGS84\n 2  7820  -4.07    12.7 WGS84\n 3  7271  -1.58    12.4 WGS84\n 4  7799  -1.54    12.4 WGS84\n 5  7243   0.380   12.1 WGS84\n 6  7026  -2.37    12.3 WGS84\n 7  7859  -1.57    12.3 WGS84\n 8  7725  -1.55    12.3 WGS84\n 9  7390  -2.21    12.1 WGS84\n10  7104  -1.91    12.8 WGS84\n# … with 73 more rows\n\nHere, we see one row for each of the 83 enumeration areas included in the 2017 Burkina Faso sample. The column EA_ID corresponds to the variable EAID, and the displaced latitude and longitude points are displayed in GPSLAT and GPSLONG, respectively. The column DATUM shows the coordinate reference system for those points: “WGS84” for the World Geodetic System 1984.\nIn order to perform geometrical operations with these gps coordinates, we’ll need to load the sf package designed for manipulating simple features used by geographic information systems. We’ve covered the basics of this package in previous posts here and here, so we’ll skip over some of the introductory details this time; however, it’s crucial to know that sf requires three operating system dependencies:\nGEOS for geometrical operations on projected coordinates\nPRØJ for coordinate reference system conversion and transformation\nGDAL for driver options\nMake sure to follow these instructions for installing GEOS, PRØJ, and GDAL on your operating system. You may also need to update R, and then run install.packages(\"sf\").\nSimple features objects\nOnce you’ve installed sf, load it into R and use st_as_sf to coerce gps into the “simple features” object class. We’ll tell sf that the coordinates data are stored in GPSLONG and GPSLAT, and that the points are modeled with the coordinate reference system (crs) 4326 (this is the EPSG code corresponding to the World Geodetic System 1984).\n\n\n\n\n© (GPLv2)\n\n\nlibrary(sf)\ngps <- gps %>% \n  st_as_sf(\n    coords = c(\"GPSLONG\", \"GPSLAT\"), \n    crs = 4326\n  )\ngps \n\n\nSimple feature collection with 83 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -5.18865 ymin: 9.883331 xmax: 1.634087 ymax: 14.39679\nGeodetic CRS:  WGS 84\n# A tibble: 83 × 3\n   EA_ID DATUM             geometry\n * <dbl> <chr>          <POINT [°]>\n 1  7610 WGS84 (-1.065238 12.93839)\n 2  7820 WGS84 (-4.065366 12.72985)\n 3  7271 WGS84 (-1.583361 12.37884)\n 4  7799 WGS84 (-1.540024 12.40452)\n 5  7243 WGS84 (0.3797186 12.07097)\n 6  7026 WGS84 (-2.366313 12.26087)\n 7  7859 WGS84 (-1.570808 12.33761)\n 8  7725 WGS84 (-1.552744 12.33411)\n 9  7390 WGS84 (-2.211783 12.09784)\n10  7104 WGS84 (-1.909244 12.76427)\n# … with 73 more rows\n\nThe result of this transformation looks something like a tibble, except that it contains a header describing a simple feature collection with 83 “features” (one per enumeration area) and 2 “fields” (EA_ID and DATUM). The new column geometry replaces GPSLONG and GPSLAT, and it contains the latitude / longitude for each displaced centroid.\nThere are several graphics packages available for mapping simple feature collections, but we’ll focus here on ggspatial - an extension of the ggplot2 package we’ve introduced elsewhere on this blog. For example, we can now easily lay out the displaced centroid for each EAID as a point on a grid like so:\n\nIn this post, we’ll be plotting SpatRaster objects from the terra package. Support for terra objects is provided in ggspatial version 1.1.5.9000 (currently available on GitHub).\n\n\nlibrary(ggspatial)\nggplot() + layer_spatial(gps)\n\n\n\n\nThe ggspatial package comes with several base-map options, accessible via annotation_map_tile. However, we’ll use a shapefile we’ve downloaded from IPUMS PMA and saved in the “data” folder of our working directory. We’ll use sf::st_read to load it as another simple feature collection (we’ll also drop some columns that we won’t be using in this post).\n\n\nshape <- st_read(\"data/shape_bf\") %>% select(ADMIN_NAME)\n\n\nReading layer `geobf' from data source \n  `/Users/Matt/R/pma-data-hub/_posts/2021-10-15-nutrition-climate/data/shape_bf' \n  using driver `ESRI Shapefile'\nSimple feature collection with 13 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -5.521112 ymin: 9.393889 xmax: 2.404293 ymax: 15.08511\nGeodetic CRS:  WGS 84\n\nshape\n\n\nSimple feature collection with 13 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -5.521112 ymin: 9.393889 xmax: 2.404293 ymax: 15.08511\nGeodetic CRS:  WGS 84\nFirst 10 features:\n          ADMIN_NAME                       geometry\n1  Boucle du Mouhoun MULTIPOLYGON (((-3.206306 1...\n2           Cascades MULTIPOLYGON (((-5.388849 1...\n3             Centre MULTIPOLYGON (((-1.565052 1...\n4         Centre-Est MULTIPOLYGON (((-0.2517975 ...\n5        Centre-Nord MULTIPOLYGON (((-0.6722373 ...\n6       Centre-Ouest MULTIPOLYGON (((-2.547486 1...\n7         Centre-Sud MULTIPOLYGON (((-1.470801 1...\n8                Est MULTIPOLYGON (((0.06834642 ...\n9      Hauts-Bassins MULTIPOLYGON (((-4.483203 1...\n10              Nord MULTIPOLYGON (((-2.952616 1...\n\nWith ggspatial, you can layer different simple feature collections together, much like you would layer multiple geometries on a bar chart or any other figure in ggplot2. We’ll build a transparent layer for shape (by setting alpha = 0), and then we’ll build a layer for gps.\n\n\nggplot() + \n  layer_spatial(shape, alpha = 0) + # `alpha = 0` makes the shapes transparent\n  layer_spatial(gps) \n\n\n\n\nPlot theme\nIn previous posts, we’ve shown how to make a custom theme for plots made with ggplot2. Because ggspatial is a spatial extension of ggplot2, we’ll do so again here to create theme_pma_rainfall. This theme builds on theme_minimal by specifying a font, several label and color options, a few custom mapping options:\ntitle gives us a quick way to provide a title for our map\nsubtitle provides an optional subtitle\nshow_legend allows us to show or hide a pre-designed legend describing the shapes we’ll use to show urban and rural enumeration areas\nmanual_grid describes the coordinates of one particular enumeration area we’ll be focusing on in an example below\n\n\nsysfonts::font_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext::showtext_auto()\n\ntheme_pma_rainfall <- function(\n  title, \n  subtitle = NULL, \n  show_legend = TRUE,\n  manual_grid = FALSE\n){\n  components <- list(\n    theme_minimal() %+replace% \n      theme(\n        text = element_text(family = \"cabrito\", size = 10), \n        plot.title = element_text(\n          hjust = 0,\n          size = 18, \n          color = \"#00263A\", # IPUMS navy\n          margin = margin(b = 5)\n        ), \n        plot.subtitle = element_text(\n          size = 12, \n          hjust = 0,\n          margin = margin(b = 10)\n        )\n      ),\n    labs(\n      title = title, \n      subtitle = subtitle,\n      fill = \"Rainfall total (mm)\",\n      size = \"EA displacement buffer\",\n      x = NULL,\n      y = NULL\n    ),\n    guides(size = guide_legend(override.aes = list(alpha = 1))),\n    annotation_scale(aes(style = \"ticks\", location = \"br\")),\n    if(show_legend){c(\n      geom_point(\n        mapping = aes(size = URBAN + 1, x = 0, y = 14),\n        data = gps,\n        alpha = 0, \n        shape = 21, \n        fill = \"white\"\n      ),\n      scale_size(\n        breaks = c(1, 2), \n        range = c(.75, 3), \n        labels = c(\"Urban (2 km)\", \"Rural (5 km)\")\n      )\n    )},\n    if(manual_grid){c(\n      scale_x_continuous(breaks = seq(from = -0.4, to = -0.2, by = 0.025)),\n      scale_y_continuous(breaks = seq(from = 13.4, to = 13.6, by = 0.025)),\n      scale_fill_gradient2(high = \"#BEC4CB\")\n    )}\n  )\n}\n\n\n\nWe’ll be layering theme_pma_rainfall onto our ggspatial maps like so:\n\n\nggplot() + \n  layer_spatial(shape, alpha = 0) + \n  layer_spatial(gps) + \n  theme_pma_rainfall(\n    title = \"2017 Burkina Faso Nutrition Survey Enumeration Areas\",\n    subtitle = \"Displaced centroid location for household sample clusters\",\n    show_legend = FALSE\n  )\n\n\n\n\nEnumeration Area Buffers\nWe mentioned above that the gps coordinates downloaded from PMA are not the actual centroid locations for each EA. These coordinates are randomly displaced from the actual centroid, subject to certain rules:\nurban EAs were displaced up to 2 kilometers in any direction\n99% of rural EAs were displaced up to 5 kilometers in any direction\n1% of rural EAs were discplaced up to 10 kilometers in any direction\ndisplaced coordinates could not cross one of the administrative boundaries shown in our shape file\n\n\n\nFigure 1: Image courtesy https://pmadata.org\n\n\n\nIn order to better represent the actual centroid location for each EA, we’ll use sf::st_buffer to create an appropriately sized buffer zone around the displaced gps coordinates for urban and rural areas. First, we’ll need to project both gps and shape with a coordinate reference system that uses meters rather than degrees of latitude / longitude. We’ll use EPSG code 32630 to select an appropriate projection for Burkina Faso. Notice that the geometry column for each now describes a point in meters:\n\n\n# Project `gps` to meters \ngps <- gps %>% st_transform(crs = 32630)\ngps\n\n\nSimple feature collection with 83 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 261303.6 ymin: 1092514 xmax: 1005762 ymax: 1593223\nProjected CRS: WGS 84 / UTM zone 30N\n# A tibble: 83 × 3\n   EA_ID DATUM           geometry\n * <dbl> <chr>        <POINT [m]>\n 1  7610 WGS84 (709895.9 1431117)\n 2  7820 WGS84 (384340.5 1407498)\n 3  7271 WGS84 (654009.7 1368854)\n 4  7799 WGS84 (658706.4 1371720)\n 5  7243 WGS84 (868012.7 1336673)\n 6  7026 WGS84 (568916.8 1355481)\n 7  7859 WGS84   (655399 1364301)\n 8  7725 WGS84 (657365.6 1363924)\n 9  7390 WGS84   (585776 1337496)\n10  7104 WGS84 (618400.2 1411317)\n# … with 73 more rows\n\n# Project `shape` to meters \nshape <- shape %>% st_transform(crs = 32630)\nshape\n\n\nSimple feature collection with 13 features and 1 field\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 223985.4 ymin: 1038409 xmax: 1089380 ymax: 1669244\nProjected CRS: WGS 84 / UTM zone 30N\nFirst 10 features:\n          ADMIN_NAME                       geometry\n1  Boucle du Mouhoun MULTIPOLYGON (((477692.2 15...\n2           Cascades MULTIPOLYGON (((238964.1 12...\n3             Centre MULTIPOLYGON (((655859.9 13...\n4         Centre-Est MULTIPOLYGON (((798642.2 13...\n5        Centre-Nord MULTIPOLYGON (((751439.8 15...\n6       Centre-Ouest MULTIPOLYGON (((549102.6 14...\n7         Centre-Sud MULTIPOLYGON (((666365.7 13...\n8                Est MULTIPOLYGON (((832139.5 14...\n9      Hauts-Bassins MULTIPOLYGON (((338580.2 13...\n10              Nord MULTIPOLYGON (((505125.2 15...\n\nNext, we’ll need to identify which of the EAs in gps are located in urban areas. To do so, we’ll use the URBAN indicator for each EAID in our data extract dat.\n\n\ngps <- dat %>% \n  count(EAID, URBAN) %>% \n  select(EAID, URBAN) %>% \n  mutate(URBAN = if_else(URBAN == 1, TRUE, FALSE)) %>% \n  full_join(gps %>% rename(EAID = EA_ID), ., by = \"EAID\")\ngps\n\n\nSimple feature collection with 83 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 261303.6 ymin: 1092514 xmax: 1005762 ymax: 1593223\nProjected CRS: WGS 84 / UTM zone 30N\n# A tibble: 83 × 4\n    EAID DATUM           geometry URBAN\n   <dbl> <chr>        <POINT [m]> <lgl>\n 1  7610 WGS84 (709895.9 1431117) FALSE\n 2  7820 WGS84 (384340.5 1407498) FALSE\n 3  7271 WGS84 (654009.7 1368854) TRUE \n 4  7799 WGS84 (658706.4 1371720) TRUE \n 5  7243 WGS84 (868012.7 1336673) TRUE \n 6  7026 WGS84 (568916.8 1355481) TRUE \n 7  7859 WGS84   (655399 1364301) TRUE \n 8  7725 WGS84 (657365.6 1363924) TRUE \n 9  7390 WGS84   (585776 1337496) FALSE\n10  7104 WGS84 (618400.2 1411317) FALSE\n# … with 73 more rows\n\nThe function st_buffer will draw a circle around each centroid. We’ll specify that the radius of our circle should be 2000 meters if a particular EA is URBAN, and 5000 meters otherwise. We’ll then bisect each circle with st_intersection if it crosses an administrative boundary in shape, and we’ll use st_filter to discard any resulting section that does not contain one of the original centroids in gps.\n\nWe use a 5 km buffer for all rural EAs in our maps, but remember that an unknown 1% of rural EAs were actually displaced 10 km.\n\n\ngps <- gps %>% \n  st_buffer(if_else(.$URBAN, 2000, 5000)) %>% \n  st_intersection(shape) %>% \n  st_filter(gps) \ngps \n\n\nSimple feature collection with 83 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 257997.5 ymin: 1090514 xmax: 1010762 ymax: 1598223\nProjected CRS: WGS 84 / UTM zone 30N\n# A tibble: 83 × 5\n    EAID DATUM URBAN ADMIN_NAME                               geometry\n * <dbl> <chr> <lgl> <chr>                               <POLYGON [m]>\n 1  7820 WGS84 FALSE Boucle du Mouhoun ((389340.5 1407498, 389333.6 1…\n 2  7139 WGS84 TRUE  Boucle du Mouhoun ((452887.2 1376644, 452884.4 1…\n 3  7869 WGS84 FALSE Boucle du Mouhoun ((524026.7 1425830, 524019.9 1…\n 4  7602 WGS84 FALSE Boucle du Mouhoun ((473865.1 1373194, 473858.3 1…\n 5  7185 WGS84 TRUE  Boucle du Mouhoun ((383533.7 1346964, 383531 134…\n 6  7016 WGS84 FALSE Boucle du Mouhoun ((359037.3 1313005, 359030.4 1…\n 7  7212 WGS84 FALSE Boucle du Mouhoun ((531483.7 1275510, 531476.8 1…\n 8  7813 WGS84 FALSE Cascades          ((412468.5 1144108, 412461.6 1…\n 9  7521 WGS84 FALSE Cascades          ((289412.7 1156524, 289405.9 1…\n10  7335 WGS84 TRUE  Cascades          ((307168.9 1176806, 307166.1 1…\n# … with 73 more rows\n\nNotice that the geometry column now describes a “polygon” rather than a “point”. This polygon is defined by a series of latitude / longitude pairs that form the circumference of a buffer zone.\nWe’re finished measuring distance in meters, so we’ll revert back to degrees of latitude / longitude and plot the result. (This time, we’ll use the argument show_legend = TRUE to adopt the custom legend we designed for theme_pma_rainfall).\n\n\ngps <- gps %>% st_transform(crs = 4326)\nshape <- shape %>% st_transform(crs = 4326)\n\nggplot() + \n  layer_spatial(shape, alpha = 0) + \n  layer_spatial(gps, alpha = 0) + \n  theme_pma_rainfall(\n    title = \"2017 Burkina Faso Nutrition Survey Enumeration Areas\",\n    subtitle = \"Displaced centroid location for household sample clusters\",\n    show_legend = TRUE\n  )\n\n\n\n\nNow that we’ve identified the buffer zone for each cluster of sampled households, we’re ready to calculate a measure of local precipitation for each household with data from CHIRPS.\nCHIRPS data\nThe complete CHIRPS precipitation data series can be downloaded directly from the UCSB Climate Hazards Center, but we imagine most users will want to select an area of interest through the CHIRPS API provider, ClimateServ. If you’re familiar with tools for downloading and saving raster files, you can submit a request to ClimateServ directly from R via the chirps R package. Or, if you’re more comfortable using a graphic user interface, you can simply navigate to the ClimateServ homepage in your browser:\n\n\n\nThe ClimateServ website allows us to simply select the country boundaries for Burkina Faso. We’ll select “download raw data” to download daily rainfall totals for a roughly 30 year period from June 1, 2017 (nutrition interviews were conducted between June and August).\n\n\n\nOnce your request has been processed, you’ll receive a compressed folder containing one “tif” image for each day in the 30 year timespan: that’s 10,959 files containing comprising potentially several gigabytes of raster data. We’ve previously shown how to use the raster package to handle this type of data, but we’ll now introduce the terra package as a newer, faster alternative.\nRaster data with terra\nIf you’ve installed all of the dependencies needed for sf above, you’ll be able to install terra with install.packages(\"terra\") and then load it into R.\n\n\nlibrary(terra)\n\n\n\nThe magic behind terra is that it avoids reading every image into R at once. Instead, it reads metadata about each image - information about its spatial extent, coordinate reference system, and pixel count. Let’s take a look at the metadata for the image associated with a particularly rainy day in 1997:\n\n\nday1 <- rast(\"data/chirps_bf/19970301.tif\")\nday1\n\n\nclass       : SpatRaster \ndimensions  : 115, 159, 1  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : -5.549997, 2.400003, 9.349999, 15.1  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : 19970301.tif \nname        : 19970301 \nmin value   :        0 \nmax value   : 8.319133 \n\n\n\n\n\n© (GPLv3)\nAs you can see, this image contains 115 rows and 159 columns of pixels. The value in each pixel represents the rainfall - in millimeters - for an area 0.05 degrees longitude by 0.05 degrees latitutde (shown in the “resolution” field). If you just want to preview the values associated with each pixel, we recommend coercing the default matrix as a tibble:\n\n\nday1_vals <- values(day1, dataframe = TRUE) %>% tibble()\nday1_vals\n\n\n# A tibble: 18,285 × 1\n   X19970301\n       <dbl>\n 1         0\n 2         0\n 3         0\n 4         0\n 5         0\n 6         0\n 7         0\n 8         0\n 9         0\n10         0\n# … with 18,275 more rows\n\nThe result is a single column with precipitation totals for 18,285 pixels. This is the CHIRPS data we’ve obtained for a single day in our 30-year timespan. Alone, it’s not a lot of data:\n\n\nobject.size(day1_vals) %>% format(\"Mb\")\n\n\n[1] \"0.1 Mb\"\n\nIf you’d like, you can plot the rainfall pixels from March 1, 1997 with the same ggspatial tools shown above. We’ll also ensure that all pixels representing “0” rainfall are transparent (revealing the underlying coordinate grid).\n\n\nggplot() +\n  layer_spatial(\n    day1,\n    alpha = if_else(values(day1) == 0, 0, 1) # makes 0 values transparent\n  ) +\n  layer_spatial(shape, alpha = 0) +\n  layer_spatial(gps,  alpha = 0) +\n  theme_pma_rainfall(\n    title = \"Burkina Faso Rainfall Totals: March 1, 1997\",\n    subtitle = paste(\n      \"National precipitation with displaced centroid locations for 2017 PMA\",\n      \"Nutrition Survey enumeration areas\"\n    )\n  ) +    \n  scale_fill_gradient2(\n    low = \"#000000\",   # white\n    high = \"#00263A\"  # IPUMS navy\n  )\n\n\n\n\nRaster layers\nNow, imagine working with data for each of the 10,959 days in our data series. Whereas the total size of the dataset from a single day was small - only about 0.1 megabytes - the amount of data required to represent 18,285 pixels from daily collection over a 30-year period could easily overwhelm the amount of memory available to R. Instead, we’ll only read metadata for each image into a large list with purrr::map:\n\n\nchirps <- list.files(\"data/chirps\", full.names = TRUE) %>%\n  map(~rast(.x))\n\n\n\nWe can now “stack” all of the list-items in chirps as “layers” in a single metadata object:\n\n\nchirps <- rast(chirps)\nchirps\n\n\nclass       : SpatRaster \ndimensions  : 115, 159, 14031  (nrow, ncol, nlyr)\nresolution  : 0.05, 0.05  (x, y)\nextent      : -5.549997, 2.400003, 9.349999, 15.1  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsources     : 19810101.tif  \n              19810102.tif  \n              19810103.tif  \n              ... and 14028 more source(s)\nnames       : 19810101, 19810102, 19810103, 19810104, 19810105, 19810106, ... \n\nNotice that the amount of data actually loaded into R is only about one kilobyte:\n\n\nobject.size(chirps) %>% format(\"Kb\")\n\n\n[1] \"1.3 Kb\"\n\nThe terra package contains several summary methods you can use to quickly explore summary statistics over all of the layers included in our 30-year timespan. For example, terra::mean computes the mean value for each pixel across every layer of chirps. This can be particularly helpful if you want to create a map showing the 30-year average rainfall for selected enumeration areas relative to neighboring areas:\n\n\nbf_means <- terra::mean(chirps) \n\n\n\nWhen we build a map for bf_means we’ll use mask simply to hide any pixels outside the boundaries of our shape file:\n\n\nggplot() +\n  layer_spatial(mask(bf_means, vect(shape), touches = FALSE)) + \n  layer_spatial(shape, alpha = 0) +\n  layer_spatial(gps,  alpha = 0) +\n  theme_pma_rainfall(\n    title = \"Burkina Faso 30-year Average Daily Rainfall\",\n    subtitle = paste(\n      \"National precipitation with displaced centroid locations for 2017 PMA\",\n      \"Nutrition Survey enumeration areas\"\n    )\n  ) +\n  scale_fill_continuous(\n    low = \"#FAEFD1BB\", high = \"#00263ABB\", na.value = \"transparent\"\n  ) + \n  labs(caption = paste(\n    sep = \"\\n\",\n    \"Climate Hazards Center InfraRed Precipitation with Station data (CHIRPS)\",\n    \"06-01-1987 to 06-01-2017\"\n  ))\n\n\n\n\nFor most analytic purposes, you’ll want to do more than simply layer summary data beneath a map of the PMA enumeration areas. Instead, we’ll want to extract the pixels associated with the area covered by the buffer zones we created above.\nRainfall within Enumeration Areas\nLet’s start by zooming-in one of the enumeration areas listed in our gps dataset. This rural EA is located near the eastern border in the Boucle du Mouhoun region, so you’ll notice that its 5 kilometer buffer zone is cropped by an administrative boundary.\n\n\nggplot() + \n  layer_spatial(gps %>% filter(EAID == 7003), alpha = 0) +\n  theme_pma_rainfall(\n    \"Enumeration Area 7003\", \n    \"A rural sample cluster in the Boucle du Mouhoun region\",\n    show_legend = FALSE,\n    manual_grid = TRUE\n  )   \n\n\n\n\nIn our single-day map above, we plotted national rainfall totals for March 1, 1997. We’ll plot rainfall from this date again, but this time we’ll use the crop function to focus only on pixels in the immediate vicinity of EAID == 7003.\n\n\nday1_7003 <- crop(\n  day1, \n  gps %>% filter(EAID == 7003), \n  snap = \"out\"\n)\n\nggplot() + \n  layer_spatial(day1_7003) + \n  layer_spatial(gps %>% filter(EAID == 7003), alpha = 0) + \n  theme_pma_rainfall(\n    title = \"Rural EA Rainfall Total: March 1, 1997\", \n    subtitle = \"One daily total is reported for every 0.05 arc-degrees\",\n    show_legend = FALSE, \n    manual_grid = TRUE\n  ) \n\n\n\n\nInterestingly, we see a range of rainfall totals across the 9 pixels in this area: trace amounts of rain were detected in the 6 western-most pixels, but not in the 3 pixels on the eastern side. How should we summarise the rainfall experienced by a household in this enumeration area, given that its centroid might be located any one of several different pixels?\nYou might consider taking the mean daily total for all 9 pixels, but 2 pixels (top-right and bottom-right) are not included in the buffer zone at all. Most of the remaining pixels only partially overlap with the buffer zone - you might reasonably conclude the centroid is more likely to fall within the bottom 2 rows of pixels than in the top row.\nFortunately, the terra function extract gives both the rainfall total and the proportion of each pixel overlapping with buffer zone if we specify weights = TRUE. We’ll need to use vect to coerce the gps object into the SpatVector class used by most terra functions.\n\n\nday1_7003 <- extract(\n  day1_7003, \n  gps %>% filter(EAID == 7003) %>% vect(), \n  weights = TRUE\n)\n\nday1_7003 \n\n\n  ID  19970301 weight\n1  1 1.2160333   0.01\n2  1 0.8472163   0.13\n3  1 1.6922826   0.49\n4  1 1.4724811   1.00\n5  1 0.0000000   0.22\n6  1 1.3903536   0.26\n7  1 1.3996017   0.64\n\nThe result is a data.frame containing one row for each pixel that overlaps with our buffer (the top-right and bottom-right pixels are omitted). The column 19970301 gives the rainfall for each pixel, and the column weight shows the proportion of each pixel that falls within the buffer. We can think of these weight values as probabilities representing the likelihood that each pixel contains the real centroid location for EA == 7003. Let’s calculate a weighted.mean using the probabilities represented by weight:\n\n\nday1_7003 %>% \n  summarise(\n    EAID = 7003,\n    wtd_mean = weighted.mean(`19970301`, weight)\n  )\n\n\n  EAID wtd_mean\n1 7003 1.338631\n\nThis represents the approximate single-day rainfall total for March 1, 1997 spatially averaged for all pixels overlapping with the buffer for EA == 7003. In order to produce the 30-year average daily rainfall for this buffer, we’ll simply repeat the same process for each day between June 1, 1987 and June 1, 2017 (the entire stack represented by chirps). We’ll arrange the results in a tibble, and we’ll replace the default ID column with the unique identifier for each pixel shown above.\n\n\nchirps30_7003 <- extract(\n  chirps,\n  gps %>% filter(EAID == 7003) %>% vect(),\n  weights = TRUE\n)\n\nchirps30_7003 <- chirps30_7003 %>%\n  tibble() %>%\n  dplyr::select(-ID) %>%\n  rowid_to_column(\"pixel\") %>%\n  relocate(weight, .after = pixel)\n\nchirps30_7003\n\n\n\n\n# A tibble: 7 × 10,961\n  pixel weight `19870601` `19870602` `19870603` `19870604` `19870605`\n  <int>  <dbl>      <dbl>      <dbl>      <dbl>      <dbl>      <dbl>\n1     1   0.01       8.81          0       2.94       5.87          0\n2     2   0.13       8.43          0       2.81       5.62          0\n3     3   0.49       9.46          0       3.15       6.31          0\n4     4   1.00       9.10          0       3.03       6.07          0\n5     5   0.22       9.23          0       3.08       6.16          0\n6     6   0.26       9.99          0       3.33       6.66          0\n7     7   0.64       9.45          0       3.15       6.30          0\n# … with 10,954 more variables: 19870606 <dbl>, 19870607 <dbl>,\n#   19870608 <dbl>, 19870609 <dbl>, 19870610 <dbl>, 19870611 <dbl>,\n#   19870612 <dbl>, 19870613 <dbl>, 19870614 <dbl>, 19870615 <dbl>,\n#   19870616 <dbl>, 19870617 <dbl>, 19870618 <dbl>, 19870619 <dbl>,\n#   19870620 <dbl>, 19870621 <dbl>, 19870622 <dbl>, 19870623 <dbl>,\n#   19870624 <dbl>, 19870625 <dbl>, 19870626 <dbl>, 19870627 <dbl>,\n#   19870628 <dbl>, 19870629 <dbl>, 19870630 <dbl>, 19870701 <dbl>, …\n\nThe rainfall total for each day is stored in one of 10,959 columns to the right of pixel and weight. We’ll use pivot_longer to rearrange these data in rows, and then we’ll calculate a simple weighted.mean to obtain the 30-year average daily rainfall.\n\n\nchirps30_7003 <- chirps30_7003 %>% pivot_longer(-c(pixel, weight)) \nchirps30_7003   \n\n\n# A tibble: 76,713 × 4\n   pixel weight name     value\n   <int>  <dbl> <chr>    <dbl>\n 1     1   0.01 19870601  8.81\n 2     1   0.01 19870602  0   \n 3     1   0.01 19870603  2.94\n 4     1   0.01 19870604  5.87\n 5     1   0.01 19870605  0   \n 6     1   0.01 19870606 30.6 \n 7     1   0.01 19870607  3.39\n 8     1   0.01 19870608  0   \n 9     1   0.01 19870609  0   \n10     1   0.01 19870610  0   \n# … with 76,703 more rows\n\nchirps30_7003 %>% \n  summarise(\n    EAID = 7003,\n    MEAN_20YR = weighted.mean(value, weight)\n  )\n\n\n# A tibble: 1 × 2\n   EAID MEAN_20YR\n  <dbl>     <dbl>\n1  7003      1.50\n\nNow that we’ve developed a strategy for summarising all of the rainfall pixels for a single enumeration area, we’ll see that it’s easy to generalize our approach to all of the enumeration areas associated with the 2017 Burkina Faso sample. Although we’ll save a great deal of time by focusing only on the CHIRPS pixels that fall within each of our 83 buffer zones, the extract procedure below will still require a few minutes of patience:\n\n\nchirps30_all <- chirps %>%\n  extract(gps %>% vect(), weights = TRUE) %>%\n  as.data.frame() %>%\n  tibble()\nchirps30_all\n\n\n\n\n# A tibble: 416 × 10,961\n      ID `19870601` `19870602` `19870603` `19870604` `19870605`\n   <dbl>      <dbl>      <dbl>      <dbl>      <dbl>      <dbl>\n 1     1          0       5.91       5.91       11.8       5.91\n 2     1          0       5.76       5.76       11.5       5.76\n 3     1          0       5.73       5.73       11.5       5.73\n 4     1          0       6.56       6.56       13.1       0   \n 5     1          0       6.14       6.14       12.3       6.14\n 6     1          0       6.15       6.15       12.3       6.15\n 7     1          0       6.80       0          13.6       0   \n 8     1          0       6.83       0          13.7       0   \n 9     2          0       5.95       0          17.9       5.95\n10     2          0       6.07       0          18.2       6.07\n# … with 406 more rows, and 10,955 more variables: 19870606 <dbl>,\n#   19870607 <dbl>, 19870608 <dbl>, 19870609 <dbl>, 19870610 <dbl>,\n#   19870611 <dbl>, 19870612 <dbl>, 19870613 <dbl>, 19870614 <dbl>,\n#   19870615 <dbl>, 19870616 <dbl>, 19870617 <dbl>, 19870618 <dbl>,\n#   19870619 <dbl>, 19870620 <dbl>, 19870621 <dbl>, 19870622 <dbl>,\n#   19870623 <dbl>, 19870624 <dbl>, 19870625 <dbl>, 19870626 <dbl>,\n#   19870627 <dbl>, 19870628 <dbl>, 19870629 <dbl>, 19870630 <dbl>, …\n\nThe only difference here is that ID represents an index number for each of the 83 enumeration areas, and each enumeration area may include anywhere between 1 and 9 pixels. We haven’t bothered assigning numbers to each pixel, but we’ll need to find the correct EAID for each ID.\n\n\nchirps30_all <- gps %>% \n  rowid_to_column(\"ID\") %>% \n  tibble() %>% \n  dplyr::select(ID, EAID) %>% \n  full_join(chirps30_all, by = \"ID\")\nchirps30_all\n\n\n# A tibble: 416 × 10,962\n      ID  EAID `19870601` `19870602` `19870603` `19870604` `19870605`\n   <dbl> <dbl>      <dbl>      <dbl>      <dbl>      <dbl>      <dbl>\n 1     1  7820          0       5.91       5.91       11.8       5.91\n 2     1  7820          0       5.76       5.76       11.5       5.76\n 3     1  7820          0       5.73       5.73       11.5       5.73\n 4     1  7820          0       6.56       6.56       13.1       0   \n 5     1  7820          0       6.14       6.14       12.3       6.14\n 6     1  7820          0       6.15       6.15       12.3       6.15\n 7     1  7820          0       6.80       0          13.6       0   \n 8     1  7820          0       6.83       0          13.7       0   \n 9     2  7139          0       5.95       0          17.9       5.95\n10     2  7139          0       6.07       0          18.2       6.07\n# … with 406 more rows, and 10,955 more variables: 19870606 <dbl>,\n#   19870607 <dbl>, 19870608 <dbl>, 19870609 <dbl>, 19870610 <dbl>,\n#   19870611 <dbl>, 19870612 <dbl>, 19870613 <dbl>, 19870614 <dbl>,\n#   19870615 <dbl>, 19870616 <dbl>, 19870617 <dbl>, 19870618 <dbl>,\n#   19870619 <dbl>, 19870620 <dbl>, 19870621 <dbl>, 19870622 <dbl>,\n#   19870623 <dbl>, 19870624 <dbl>, 19870625 <dbl>, 19870626 <dbl>,\n#   19870627 <dbl>, 19870628 <dbl>, 19870629 <dbl>, 19870630 <dbl>, …\n\nFinally, we’ll pivot_longer and calculate a separate weighted.mean for each EAID. The result can be merged directly to gps if we’d like to create a map:\n\n\ngps <- chirps30_all %>% \n  pivot_longer(-c(ID, EAID, weight)) %>% \n  group_by(EAID) %>% \n  summarise(CHIRPS_30 = weighted.mean(value, weight)) %>% \n  full_join(gps, by = \"EAID\")\n\nggplot() + \n  layer_spatial(shape, alpha = 0) + \n  layer_spatial(gps, aes(fill = CHIRPS_30, stroke = 0)) + \n  theme_pma_rainfall(\n    title = \"Burkina Faso 30-year Average Daily Rainfall\", \n    subtitle = \"PMA 2017 Nutrition Survey enumeration area centroid locations\"\n  ) + \n  scale_fill_steps(low = \"#FAEFD1\", high = \"#00263A\") +\n  labs(caption = paste(sep = \"\\n\",\n    \"Climate Hazards Center InfraRed Precipitation with Station data (CHIRPS)\",\n    \"06-01-1987 to 06-01-2017\"\n  ))\n\n\n\n\nWe can also attach these local rainfall totals to the records for individual women and children in the 2017 Burkina Faso nutrition dataset dat. At this point, the simple features collection class is no longer necessary; we can simply join CHIRPS_30 directly to dat.\n\n\ngps %>% \n  select(EAID, CHIRPS_30) %>% \n  full_join(dat, by = \"EAID\") \n\n\n# A tibble: 8,305 × 978\n    EAID CHIRPS_30         SAMPLE COUNTRY  YEAR ROUND HHID   PERSONID \n   <dbl>     <dbl>      <int+lbl> <int+l> <int> <dbl> <chr>  <chr>    \n 1  7003      1.50 85406 [Burkin… 1 [Bur…  2017     1 07003… 07003000…\n 2  7003      1.50 85406 [Burkin… 1 [Bur…  2017     1 07003… 07003000…\n 3  7003      1.50 85406 [Burkin… 1 [Bur…  2017     1 07003… 07003000…\n 4  7003      1.50 85406 [Burkin… 1 [Bur…  2017     1 07003… 07003000…\n 5  7003      1.50 85406 [Burkin… 1 [Bur…  2017     1 07003… 07003000…\n 6  7003      1.50 85406 [Burkin… 1 [Bur…  2017     1 07003… 07003000…\n 7  7003      1.50 85406 [Burkin… 1 [Bur…  2017     1 07003… 07003000…\n 8  7003      1.50 85406 [Burkin… 1 [Bur…  2017     1 07003… 07003000…\n 9  7003      1.50 85406 [Burkin… 1 [Bur…  2017     1 07003… 07003000…\n10  7003      1.50 85406 [Burkin… 1 [Bur…  2017     1 07003… 07003000…\n# … with 8,295 more rows, and 970 more variables:\n#   RESPONDENT <int+lbl>, LINENO <int>, ENUMID <dbl+lbl>,\n#   CONSENTHQ <int+lbl>, AVAILABLEHQ <int+lbl>, VISITNUMHQ <int+lbl>,\n#   PREVINTERVIEWHQ <int+lbl>, RESULTHQ <int+lbl>,\n#   ELIGIBLEHH <int+lbl>, RESULTFCQ <int+lbl>, HHIDORIG <chr>,\n#   ELIGTYPE <int+lbl>, ELIGIBLEFC <int+lbl>, ELIGIBLESEL <int+lbl>,\n#   ELIGIBLEKID <int+lbl>, ELIGIBLEHHKID <int+lbl>, …\n\nIn our next post, we’ll learn much more about the relationship between CHIRPS precipitation data and nutritional outcomes for the women and young children in this survey. Stay tuned!\n\n\n\n",
    "preview": "posts/2021-10-15-nutrition-climate/nutrition-climate_files/figure-html5/unnamed-chunk-32-1.png",
    "last_modified": "2022-04-13T13:10:47-04:00",
    "input_file": {},
    "preview_width": 1536,
    "preview_height": 1536
  },
  {
    "path": "posts/2021-10-01-nutrition-indicators/",
    "title": "Infant and Young Child Feeding (IYCF) Indicators for PMA Nutrition Data",
    "description": "Use WHO guidelines to calculate Minimum Dietary Diversity (MDD), Minimum Meal Frequency (MMF), and Minimum Acceptable Diet (MAD).",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-10-01",
    "categories": [
      "Nutrition",
      "IYCF",
      "Indicators",
      "Data Manipulation"
    ],
    "contents": "\n\nContents\nSetup\nMinimum Age with Century Month Codes\nMDD: Minimum Dietary Diversity\nMMF: Minimum Meal Frequency\nMAD: Minimum Acceptable Diet\nNext Steps\n\nGlobal indicators for Infant and Young Child Feeding (IYCF) practices have been used in large-scale nutrition surveys like the Demographic and Health Surveys (DHS) and Multiple Indicator Cluster Surveys (MICS) since 2008. These indicators provide benchmark dietary standards necessary for healthy growth and development in children during the first two years of life.\nIn 2017 and 2018 - the same years that PMA nutrition surveys were fielded in Burkina Faso and Kenya - the World Health Organization (WHO), UNICEF, and other international aid organizations convened an inter-agency review of IYCF guidelines. Their findings included recommendations for revised measures outlined here.\nIn this post, we’ll highlight three of the most commonly used IYCF indicators for children age 6-23 months, and we’ll show to calculate them with dietary recall data from the 2017 PMA nutrition survey from Burkina Faso. We’ll use the revised WHO definitions for:\nMDD: Minimum Dietary Diversity\nMMF: Minimum Meal Frequency\nMAD: Minimum Acceptable Diet\nSetup\nWhile you’ll be able to use the code in this post for any of the four PMA nutrition samples, we’ll focus on a data extract containing only the Burkina Faso 2017 sample. We’ve selected cases marked “Females and Children with Nutrition Information,” dropping all other household members from the file.\nWe’ll load the data extract into R with the packages ipumsr and tidyverse.\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00002.xml\",\n  data = \"data/pma_00002.dat.gz\"\n)\n\n\n\nFor all graphs in this post, we’ll use a custom ggplot2 theme we’ll call theme_pma. Check out this post for more information about how to develop and use a graphics theme like this one:\n\n\nsysfonts::font_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext::showtext_auto()\n\ntheme_pma <- function(title, subtitle){\n  components <- list(\n    theme_minimal() %+replace% \n      theme(\n        text = element_text(family = \"cabrito\", size = 10), \n        plot.title = element_text(\n          size = 18, color = \"#00263A\", margin = margin(b = 10)\n        ), \n        plot.subtitle = element_text(size = 12, margin = margin(b = 10)),\n        legend.title = element_blank(),        \n        panel.grid.minor = element_blank(),     \n        axis.ticks = element_blank(),          \n        legend.position = \"bottom\",\n        panel.spacing = unit(4, \"lines\"), \n        strip.text = element_blank()\n      ),\n    scale_fill_manual(\n      values = alpha(\n        alpha = .85,\n        colour = c(\n          \"#98579B\",   # PMA Pink\n          \"#00263A\",  # IPUMS Navy\n          \"#81A88D\"   # Green\n        )\n      )\n    ),\n    labs(\n      title = toupper(title),\n      subtitle = subtitle,\n      x = NULL,\n      y = NULL,\n      fill = NULL\n    ),\n    ylim(0, 100)\n  )\n}\n\n\n\nMinimum Age with Century Month Codes\nThe IYCF indicators we’ll calculate below only apply to infants who were between 6 and 23 months of age on the day of the nutrition interview. We know the birth month KIDBIRTHMO and year KIDBIRTHYR for each sampled child, but the interview month INTFCQMON and year INTFCQYEAR are only reported on the record for the woman who responded on their behalf (usually the child’s mother). In order to calculate each child’s age, we’ll need to use the procedure outlined in our last post to identify the mother for each child living in a household where nutrition surveys were administered in more than one month.\nTo make this calculation easier, we’ll combine each month and year into a single century month code (CMC). Dates reported as a CMC reflect the number of months since January 1900:\n\\[CMC = 12*(Year – 1900) + Month\\]\nYou’ll find CMC dates in many demographic surveys because they make it easy to measure the minimum passage of time between two events (particularly when the exact day is unknown). In our case, we’ll subtract the CMC code for each child’s birthdate KIDBIRTHCMC from the CMC code for the nutrition interview INTFCQCMC; we’ll then subtract one additional month to account for births that happened nearer to the end of the birth month than the date of the interview was to the end of the interview month.\nFor example, imagine a child born on January 1, 2017 and whose nutrition interview happened on February 1, 2017. The CMC code for their birthdate would be calculated as:\n\\[\\begin{eqnarray} \nKIDBIRTHCMC &=& 12*(2017 – 1900) + 1 \\\\ \n&=& 1405\n\\end{eqnarray}\\]\nAnd the CMC code for their interview date would be:\n\\[\\begin{eqnarray} \nINTFCQCMC &=& 12*(2017 – 1900) + 2 \\\\\n&=& 1406\n\\end{eqnarray}\\]\nSuppose we calculate each child’s age in months KIDAGEMO by subtracting KIDBIRTHCMC from INTFCQCMC:\n\\[\\begin{eqnarray} \nKIDAGEMO &=& INTFCQCMC - KIDBIRTHCMC \\\\\n&=& 1406 - 1405 \\\\ \n&=& 1\n\\end{eqnarray}\\]\nThis particular child aged one complete month between January 1 and February 1, so our calculation for KIDAGEMO works out. Unfortunately, this creates incorrect calculations for all of the children born after January 1, since they won’t have aged one complete month by February 1. In practice, we don’t know the precise day of either event; this is why we subtract an additional month in our calculation for KIDAGEMO, which reports each child’s minimum age in months.\n\\[\\begin{eqnarray} \nKIDAGEMO &=& INTFCQCMC - KIDBIRTHCMC - 1\\\\\n&=& 1406 - 1405 -1 \\\\ \n&=& 0\n\\end{eqnarray}\\]\nNote that all of the date variables contain special top-codes designating missing values; we’ll use dplyr::case_when to calculate CMC codes only for non-missing dates (all other cases will be marked NA automatically).\n\n\ndat <- dat %>% \n  mutate(\n    KIDBIRTHCMC = case_when(\n      KIDBIRTHMO <= 12 & KIDBIRTHYR <= 2017 ~ \n        12*(KIDBIRTHYR - 1900) + KIDBIRTHMO\n    ),\n    INTFCQCMC = case_when(\n      INTFCQMON <= 12 & INTFCQYEAR <= 2017 ~ \n        12*(INTFCQYEAR - 1900) + INTFCQMON\n    )\n  )\n\n\n\nAs we mentioned, the interview date is only located on the record for the woman in each household who provided nutrition information for herself and on behalf of each sampled child. As a result, INTFCQCMC is currently NA for each child.\n\n\ndat %>% count(ELIGTYPE, INTFCQCMC)\n\n\n# A tibble: 7 × 3\n                             ELIGTYPE INTFCQCMC     n\n                            <int+lbl>     <dbl> <int>\n1 11 [Infant under age 2 (INF)]              NA  2436\n2 12 [Youngest aged 2-5 (YK)]                NA   343\n3 13 [Older aged 2-5 (OTK)]                  NA  1032\n4 20 [Selected women aged 10-49 (WN)]      1410  3008\n5 20 [Selected women aged 10-49 (WN)]      1411  1231\n6 20 [Selected women aged 10-49 (WN)]      1412   253\n7 20 [Selected women aged 10-49 (WN)]      1413     2\n\nBefore we can calculate the age of each child KIDAGEMO, we need to match each child to the correct woman who provided responses on their behalf (usually their mother). Following the steps outlined in our last post, we’ll group the data by household HHID and then perform a rowwise search for each person in the sample. If that person is a woman aged 10-49 (ELIGTYPE == 20), we’ll leave INTFCQCMC as-is; otherwise, we’ll use these criteria to determine INTFCQCMC:\nIf all nutrition questionnaires administered in the household happened in the same month (or if only one nutrition questionnaire was administered), report the only INTFCQCMC available.\nIf women in the household received the nutrition questionnaire in different months, locate the woman in the household whose AGE and education level EDUCATT match the available information about each child’s mother in AGEMOM and EDUCATTMOM. Report the value in INTFCQCMC for the woman matched as the child’s mother.\nIf multiple women in the child’s household share the same AGE and education level EDUCATT, return NA. In this case, the interview date for the child cannot be determined.\n\n\ndat <- dat %>%  \n  select(\n    HHID, \n    PERSONID,\n    ELIGTYPE, \n    AGE, \n    AGEMOM,\n    EDUCATT, \n    EDUCATTMOM, \n    INTFCQCMC\n  ) %>% \n  group_by(HHID) %>% \n  mutate(HH_DATA = list(cur_data())) %>%\n  ungroup()  %>% \n  rowwise() %>% \n  mutate(INTFCQCMC = ifelse(ELIGTYPE == 20, INTFCQCMC, {\n    unique_dates <- HH_DATA %>% \n      filter(!is.na(INTFCQCMC)) %>% \n      distinct(INTFCQCMC) %>% \n      pull(INTFCQCMC)\n    ifelse(length(unique_dates) == 1, unique_dates, {\n      agemom <- AGEMOM\n      educattmom <- EDUCATTMOM\n      moms <- HH_DATA %>%\n        filter(AGE == agemom, EDUCATT == educattmom) %>%\n        pull(INTFCQCMC)\n      ifelse(length(moms) == 1, moms, NA)\n    })\n  })) %>% \n  ungroup() %>% \n  select(PERSONID, INTFCQCMC) %>% \n  right_join(dat %>% select(!INTFCQCMC), by = \"PERSONID\")\n\n\n\nLet’s now check to see whether an interview date INTFCQCMC was determined for every child:\n\n\ndat %>% count(ELIGTYPE, INTFCQCMC)\n\n\n# A tibble: 14 × 3\n                              ELIGTYPE INTFCQCMC     n\n                             <int+lbl>     <dbl> <int>\n 1 11 [Infant under age 2 (INF)]            1410  1663\n 2 11 [Infant under age 2 (INF)]            1411   648\n 3 11 [Infant under age 2 (INF)]            1412   124\n 4 11 [Infant under age 2 (INF)]            1413     1\n 5 12 [Youngest aged 2-5 (YK)]              1410   236\n 6 12 [Youngest aged 2-5 (YK)]              1411    99\n 7 12 [Youngest aged 2-5 (YK)]              1412     8\n 8 13 [Older aged 2-5 (OTK)]                1410   746\n 9 13 [Older aged 2-5 (OTK)]                1411   231\n10 13 [Older aged 2-5 (OTK)]                1412    55\n11 20 [Selected women aged 10-49 (WN)]      1410  3008\n12 20 [Selected women aged 10-49 (WN)]      1411  1231\n13 20 [Selected women aged 10-49 (WN)]      1412   253\n14 20 [Selected women aged 10-49 (WN)]      1413     2\n\nSuccess! Now, we can calculate the minimum age of every sampled child as KIDAGEMO.\n\n\ndat <- dat %>% mutate(KIDAGEMO = INTFCQCMC - KIDBIRTHCMC - 1)\n\n\n\nFor the remainder of the post, we’ll focus on children who were at least 6 months of age defined by KIDAGEMO. Unfortunately, because precise ages are suppressed in the public IPUMS PMA dataset, we’ve rounded down and likely excluded some children who are, in reality, exactly 6 months of age. On the other hand, we’ll keep all children where INFCHECK indicates that the respondent confirmed that the child was under 24 months of age (regardless of their recorded birthdate).\n\nThe official PMA summary report, which uses precise ages, shows a sample of 1732 children aged 6-23 months. Our approximation yields a smaller sample with 1706 children aged 6-23 months, a difference of 26 children.\n\n\ndat <- dat %>% filter(KIDAGEMO >= 6 & INFCHECK == 1)\n\n\n\nFor convenience, we’ll also create a factor KIDAGEMO_3 that aggregates children into three groups:\n\n\ndat <- dat %>% \n  mutate(KIDAGEMO_3 = case_when(\n    KIDAGEMO < 12 ~ \"6-11 months\",\n    KIDAGEMO < 18 ~ \"12-17 months\",\n    KIDAGEMO >= 18 ~ \"18-23 months\"\n  ) %>% \n    factor(levels = c(\"6-11 months\", \"12-17 months\", \"18-23 months\"))\n  ) \n\n\n\n\n\n\nMDD: Minimum Dietary Diversity\nWHO guidelines define Minimum Dietary Diversity (MDD) for children aged 6-23 months as consumption of food or beverages from at least 5 out of 8 defined food groups during the previous day. The PMA nutrition questionnaire for infants includes the following recall questions designed to meet the criteria for calculating MDD.\nAre you currently breastfeeding ${under_2yr_child_name}?\n\n[] Yes\n[] No\n\n\nNow I will ask you about liquids that ${under_2yr_child_name} had \nyesterday during the day or at night. I am interested in whether your child had \nthe item I mention even if it was combined with other foods.\n\nProceed to the next screen when ready.\n\nDid ${under_2yr_child_name} eat or drink:\n\n[] Plain water\n[] Juice or juice base\n[] Soup\n[] Milk such as canned milk, powder or fresh animal milk\n[] Primary milk / infant formula or marketed infant formula (Breastmilk \n   substitute: NAN, Nativa, Guigoz, etc.)\n[] Sweet drinks (sodas, zom-koom, bissap, ginger juice)\n[] Other liquids\n[] Yogurt\n[] A commercially prepared baby formula, such as Cerelac, vitacasui, vitaline\n[] Porridge\n\n\nNow I would like to ask you about foods that ${under_2yr_child_name} had \nyesterday during the day or at night. I am interested in whether your child had \nthe item I mention even if it was combined with other foods.\n\nProceed to the next screen when ready.\n\nDid ${under_2yr_child_name} eat or drink:\n\n[] Any fortified food like Cerelac?\n[] Maize, rice, wheat, thick porridge, sorghum, bread, or other foods made from \n   grains?\n[] Pumpkin, carrots, squash or yellow sweet potatoes that are yellow or orange \n   inside\n[] Irish potatoes, yams, cassava, white sweet potatoes, or any other foods made \n   from roots?\n[] Sukumu wiki or any dark green, leafy vegetables?\n[] Ripe mangoes, pawpaw and fruits that are orange or yellow inside?\n[] Any other fruits or vegetables?\n[] Liver, kidney, heart or other organ meats?\n[] Any meat, such as beef, pork, lamb, goat, chicken, duck?\n[] Eggs?\n[] Fresh or dried fish or shellfish?\n[] Any foods made from beans, peas, lentils, or nuts?\n[] Cheese or other food made from milk?\n[] Sugary foods, jiggery (sukari nguru), mandaazi, donuts, cake, sweet biscuits \n   or candies?\n[] Savory snacks like fried chips, crisps, samosas, or other fried foods?\n[] Any other solid, semi-solid or soft food?\nIPUMS PMA provides harmonized indicators for each of the response options shown. We’ll group the relevant options into each of the 8 food groups defined in WHO guidelines for MDD.\nBreast Milk\nINFBFNOW\n\nGrains, Roots, or Tubers\nINFYESTFORM\nINFYESTPORR\nINFYESTGRAIN\nINFYESTWHTVEG\nINFYESTFORT\n\nLegumes or Nuts\nINFYESTBEAN\n\nDairy\nINFYESTMILK\nINFYESTYOG\nINFYESTFORMP\nINFYESTDAIRY\n\nFlesh Foods\nINFYESTFISH\nINFYESTMEAT\nINFYESTORG\n\nEggs\nINFYESTEGG\n\nVitamin A-rich Fruits and Vegetables\nINFYESTYLWVEG\nINFYESTGRNVEG\nINFYESTYLWFRT\n\nOther Fruits and Vegetables\nINFYESTOTHFRTVEG\n\nFor each variable, the response code 1 indicates that the infant consumed the food yesterday (in INFBFNOW, it indicates that the child is currently being breastfed, so we assume that they were breastfed yesterday); we’ll label these responses TRUE. Because we removed all non-infant cases from our extract, we can safely collapse all of the remaining responses together as FALSE (the only remaining cases that are “NIU (not in universe)” are infants in INFBFNOW who were never breastfed).\nWe’ll create one “group” variable with the prefix GRP_ for each food group. In cases where more than one harmonized variable is used, we’ll use dplyr::if_any to indicate whether any of the constituent foods was eaten yesterday.\n\n\ndat <- dat %>% \n  mutate(\n    GRP_BF = INFBFNOW == 1,\n    GRP_NUT = INFYESTBEAN == 1,\n    GRP_EGG = INFYESTEGG == 1,\n    GRP_OTH = INFYESTOTHFRTVEG == 1,\n    GRP_GRAIN = if_any(\n      c(INFYESTFORM, INFYESTPORR, INFYESTGRAIN, INFYESTWHTVEG, INFYESTFORT),\n      ~.x == 1\n    ),\n    GRP_DAIRY = if_any(\n      c(INFYESTMILK, INFYESTYOG, INFYESTFORMP, INFYESTDAIRY),\n      ~.x == 1\n    ),\n    GRP_FLESH = if_any(\n      c(INFYESTFISH, INFYESTMEAT, INFYESTORG),\n      ~.x == 1\n    ),\n    GRP_VITA = if_any(\n      c(INFYESTYLWVEG, INFYESTGRNVEG, INFYESTYLWFRT),\n      ~.x == 1\n    )\n  ) \n\n\n\nLet’s preview the proportion of infants in each age range from KIDAGEMO_3 who consumed foods from each of the 8 food groups yesterday. First, we’ll make a summary table with dplyr::summarise showing the proportion of children in each age range that consumed foods from each group:\n\n\ngrp_summary <- dat %>% \n  group_by(KIDAGEMO_3) %>% \n  summarise(across(starts_with(\"GRP\"), ~100*mean(.x))) \n\ngrp_summary\n\n\n# A tibble: 3 × 9\n  KIDAGEMO_3   GRP_BF GRP_NUT GRP_EGG GRP_OTH GRP_GRAIN GRP_DAIRY\n  <fct>         <dbl>   <dbl>   <dbl>   <dbl>     <dbl>     <dbl>\n1 6-11 months    94.6    6.95    4.90    5.69      83.6      20.2\n2 12-17 months   95.5    8.80   11.3     8.47      90.5      26.2\n3 18-23 months   70.1   14.0    11.0    11.3       94.7      24.6\n# … with 2 more variables: GRP_FLESH <dbl>, GRP_VITA <dbl>\n\nWe’ll use tidyr::pivot_longer to create a long version of the table containing labels for each food group written exactly as we want them to appear on a ggplot.\n\n\ngrp_summary <- grp_summary %>% \n  pivot_longer(\n    !KIDAGEMO_3,\n    names_pattern = \"GRP_(.*)\",\n    names_to = c(\"group\")\n  ) %>% \n  mutate(\n    group = group %>% \n      as_factor() %>% \n      fct_relevel(\"GRAIN\", \"NUT\", \"FLESH\", \"EGG\", \"VITA\", \"OTH\", \"DAIRY\") %>% \n      fct_recode(\n        `Grains, roots, \\n tubers` = \"GRAIN\",\n        `Legumes and nuts` = \"NUT\",\n        `Flesh foods \\n (meat, fish, poultry)` = \"FLESH\",\n        `Eggs` = \"EGG\",\n        `Vitamin A-rich \\n fruits / veg` = \"VITA\",\n        `Other \\n fruits / veg` = \"OTH\",\n        `Dairy` = \"DAIRY\",\n        `Breastmilk` = \"BF\"\n      )\n  )\n\ngrp_summary\n\n\n# A tibble: 24 × 3\n   KIDAGEMO_3   group                                  value\n   <fct>        <fct>                                  <dbl>\n 1 6-11 months  \"Breastmilk\"                           94.6 \n 2 6-11 months  \"Legumes and nuts\"                      6.95\n 3 6-11 months  \"Eggs\"                                  4.90\n 4 6-11 months  \"Other \\n fruits / veg\"                 5.69\n 5 6-11 months  \"Grains, roots, \\n tubers\"             83.6 \n 6 6-11 months  \"Dairy\"                                20.2 \n 7 6-11 months  \"Flesh foods \\n (meat, fish, poultry)\" 25.6 \n 8 6-11 months  \"Vitamin A-rich \\n fruits / veg\"       49.1 \n 9 12-17 months \"Breastmilk\"                           95.5 \n10 12-17 months \"Legumes and nuts\"                      8.80\n# … with 14 more rows\n\nNow, we’ll create a grouped bar chart using the custom theme_pma created above.\n\n\ngrp_summary %>% \n  ggplot(aes(fill = KIDAGEMO_3, x = group, y = value)) + \n  geom_bar(width = .6, position = position_dodge(0.6), stat = \"identity\") + \n  theme_pma(\n    title = \"Infant consumption of MDD food groups\",\n    subtitle = \"Consumption of foods from 5 of 8 groups is required for MDD\"\n  )\n\n\n\n\nFinally, we’ll calculate MDD. Because MDD combines indicators from multiple columns, we’ll use dplyr::c_across. If the total sum of values in all columns with the prefix GRP is at least 5, the child will meet the WHO criteria for “Minimum Dietary Diversity.”\n\n\ndat <- dat %>% \n  rowwise() %>% \n  mutate(MDD = sum(c_across(starts_with(\"GRP\"))) >= 5) %>% \n  ungroup() \n\n\n\nWe’ll add MDD as a facet to the plot we made above.\n\n\ndat %>% \n  group_by(KIDAGEMO_3) %>% \n  summarise(group = \"MDD\", value = 100*mean(MDD), aside = TRUE) %>% \n  bind_rows(grp_summary %>% mutate(aside = FALSE)) %>% \n  ggplot(aes(fill = KIDAGEMO_3, x = group, y = value)) + \n  geom_bar(width = 0.8, position = position_dodge(0.8), stat = \"identity\") + \n  facet_grid(\n    cols = vars(aside), \n    scales = \"free_x\", \n    space = \"free_x\",\n  ) + \n  theme_pma(\n    title = \"Minimum Dietary Diversity (MDD) in Infants 6-23 Months\",\n    subtitle = \"Consumption of foods from 5 of 8 groups is required for MDD\"\n  ) \n\n\n\n\nMMF: Minimum Meal Frequency\nIn order to achieve Minimum Meal Frequency (MMF), WHO guidelines recommend that an infant should receive solid, semi-solid, or soft foods multiple times during the previous day. The precise quantity of meals depends on the child’s age and whether they are breastfed:\nBreastfed infants aged 6-8 months should receive two feedings of solid, semi-solid or soft foods\nBreastfed infants aged 9-23 months should receive three feedings of of solid, semi-solid or soft foods\nNon-breastfed infants aged 6-23 months should receive four feedings of solid, semi-solid or soft foods or milk feeds, provided that at least one of the feedings includes solid, semi-solid or soft foods\nHere, a “feeding” includes both meals and snacks, and “milk feeds” include “any formula (e.g. infant formula, follow-on formula, “toddler milk”) or any animal milk other than human breast milk, (e.g. cow milk, goat milk, evaporated milk or reconstituted powdered milk) as well as semi-solid and fluid/drinkable yogurt and other fluid/drinkable fermented products made with animal milk\".1\nFollowing this definition, we’ll first calculate the combined total number of MILKFEEDS from INFMILKNUM, INFYOGNUM, and INFFORMNUM; then, we’ll combine MILKFEEDS with INFFOODNUM appropriately for each child to create MMF.\nFor each NUM variable, we should be careful to note the reason why cases may appear “NIU (not in universe)”: these are children whose mother answered in a previous question that they did not consume the food yesterday. We’ll re-code these NIU cases as 0, rather than treat them as “missing.” On the other hand, we’ll assign the value NA to any child whose mother “did not know” whether they received the food yesterday.\n\n\ndat <- dat %>% \n  mutate(\n    across(\n      c(INFMILKNUM, INFYOGNUM, INFFORMNUM, INFFOODNUM), \n      ~case_when(.x < 90 ~ as.integer(.x))\n    ),\n    INFMILKNUM = ifelse(INFYESTMILK == 0, 0, INFMILKNUM),\n    INFYOGNUM = ifelse(INFYESTYOG == 0, 0, INFYOGNUM),\n    INFFORMNUM = ifelse(INFYESTFORMP == 0, 0, INFFORMNUM), \n    INFFOODNUM = ifelse(INFFOODYEST == 0, 0, INFFOODNUM),\n  )  \n\n\n\nNow, we’ll calculate MILKFEEDS as a sum of the three constituent NUM variables for dairy products (unless all are NA, in which case we’ll return NA).\n\n\ndat <- dat %>% \n  rowwise() %>% \n  mutate(MILKFEEDS = case_when(\n    !if_all(c(INFMILKNUM, INFYOGNUM, INFFORMNUM), is.na) ~ \n      sum(c_across(c(INFMILKNUM, INFYOGNUM, INFFORMNUM)), na.rm = TRUE)\n  )) %>% \n  ungroup()\n\n\n\nFinally, we’ll use case_when to apply separate calculations of MMF depending on whether the child is under 9 months, and whether they are breastfeeding.\n\n\ndat <- dat %>% \n  mutate(MMF = case_when(\n    KIDAGEMO < 9 & GRP_BF ~ INFFOODNUM >= 2,\n    KIDAGEMO >= 9 & GRP_BF ~ INFFOODNUM >= 3,\n    !GRP_BF ~ INFFOODNUM + MILKFEEDS >= 4 & INFFOODNUM >= 1\n  ))\n\n\n\nLet’s compare the percentage of children who achieved MMF to the percentage who achieved MDD as shown above.\n\n\ndat %>% \n  group_by(KIDAGEMO_3) %>%\n  summarise(MDD = 100*mean(MDD), MMF = 100*mean(MMF, na.rm = T)) %>% \n  pivot_longer(!KIDAGEMO_3) %>% \n  mutate(name = factor(name, levels = c(\"MDD\", \"MMF\"))) %>% \n  ggplot(aes(fill = KIDAGEMO_3, x = name, y = value)) + \n  geom_bar(width = 0.6, position = position_dodge(0.6), stat = \"identity\") + \n  geom_text(\n    aes(label = round(value, 1)), \n    position = position_dodge(0.6),\n    vjust = -0.5\n  ) +\n  theme_pma(\n    title = \"Key IYCF Indicators for Infants Age 6-23 Months\",\n    subtitle = paste(\n      \"Minimum Dietary Diversity (MDD)\",\n      \"and Minimum Meal Frequency (MMF)\"\n    )\n  ) \n\n\n\n\nMAD: Minimum Acceptable Diet\nLastly, the WHO definition for Minimum Acceptable Diet (MAD) combines the two measures we’ve calculated above. MAD uses separate crieteria for breastfed and non-breastfed children:\nBreastfed children should achieve both MDD and MMF - as appropriately defined for their age - during the previous day\nNon-breastfed children should achieve both MDD and MMF - as appropriately defined for their age - during the previous day and also receive at least two milk feeds.\nWe’ve already defined all of the intermediate variables needed to calculate MAD, so we’ll simply combine them as appropriate for breastfed and non-breastfed children with one final case_when function:\n\n\ndat <- dat %>% \n  mutate(MAD = case_when(\n    GRP_BF ~ MMF & MDD,\n    !GRP_BF ~ MMF & MDD & MILKFEEDS >= 2\n  )) \n\n\n\nTo wrap up, we’ll add MAD to the chart we made comparing MDD and MMF.\n\n\ndat %>% \n  group_by(KIDAGEMO_3) %>%\n  summarise(\n    MDD = 100*mean(MDD), \n    MMF = 100*mean(MMF, na.rm = T),\n    MAD = 100*mean(MAD, na.rm = T)\n  ) %>% \n  pivot_longer(!KIDAGEMO_3) %>% \n  mutate(name = factor(name, levels = c(\"MDD\", \"MMF\", \"MAD\"))) %>% \n  ggplot(aes(fill = KIDAGEMO_3, x = name, y = value)) + \n  geom_bar(width = 0.6, position = position_dodge(0.6), stat = \"identity\") + \n  geom_text(\n    aes(label = round(value, 1)), \n    position = position_dodge(0.6),\n    vjust = -0.5\n  ) +\n  theme_pma(\n    title = \"IYCF Indicators for Infants Age 6-23 Months\",\n    subtitle = paste(\n      \"Minimum Dietary Diversity (MDD),\",\n      \"Minimum Meal Frequency (MMF), \\n\",\n      \"and Minimum Acceptable Diet (MAD)\"\n    )\n  ) \n\n\n\n\nNext Steps\nIn the coming weeks, we’ll show how researchers have used the IYCF indicators we’ve created to learn more about environmental and household factors that contribute to child malnutrition. We’ll also dig into supplementary data sources that connect food security outcomes with local agricultural conditions. In the meantime, make sure to connect with us on Twitter and let us know how you’re using PMA Nutrition data.\n\n\n\n“Indicators for Assessing Infant and Young Child Feeding Practices: Definitions and Measurement Methods.” 2021. World Health Organization; the United Nations Children’s Fund (UNICEF). https://apps.who.int/iris/bitstream/handle/10665/340706/9789240018389-eng.pdf?sequence=1.\n\n\nPinchoff, Jessie, William Turner, and Kathryn Grace. 2021. “The Association Between Agricultural Conditions and Multiple Dimensions of Undernutrition in Children 6-23 Months of Age in Burkina Faso.” Environmental Research Communications 3 (6): 065004. https://iopscience.iop.org/article/10.1088/2515-7620/ac07f5/meta.\n\n\n“Pma2020 Nutrition Survey - Burkina Faso: Key Results | September 2017.” 2017. Performance Monitoring for Action. https://www.pmadata.org/sites/default/files/data_product_results/PMA2020-Burkina-R1-Nutrition-Brief-EN.pdf.\n\n\nsee page 10, “Indicators for Assessing Infant and Young Child Feeding Practices: Definitions and Measurement Methods” (2021)↩︎\n",
    "preview": "posts/2021-10-01-nutrition-indicators/nutrition-indicators_files/figure-html5/unnamed-chunk-22-1.png",
    "last_modified": "2022-04-13T13:10:47-04:00",
    "input_file": {},
    "preview_width": 1920,
    "preview_height": 1152
  },
  {
    "path": "posts/2021-09-15-nutrition-linking/",
    "title": "Update: Matching Records in 2018 Nutrition Surveys",
    "description": "It's now much easier to perform row-wise operations with pre-grouped data!",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-09-15",
    "categories": [
      "Nutrition",
      "Data Manipulation",
      "rowwise",
      "group_by",
      "cur_data",
      "pmap"
    ],
    "contents": "\n\nContents\nSetup\nMatching with multiple varialbes\nIdentifying the “current group”\nRow-wise search within groups\nExpanded search\nNew research questions\n\nWhen IPUMS PMA first released harmonized 2018 nutrition surveys from households in Burkina Faso and Kenya, we published a user note describing how to match children and mothers in the same household with pmap - a function designed to iterate over several variables simultaneously.\nOur challenge was this: IPUMS PMA nutrition data are actually a harmonized version of three separate surveys. When you download and open a nutrition data extract, any given row may contain variables associated with:\na household screening questionnaire,\na nutrition questionnaire for all children under age 5, and\na nutrition questionnaire for selected women aged 10-49\nAs we mentioned in our last post, all children under age 5 living in one of the screened households were sampled in the subsequent child nutrition survey. However, women aged 10-49 were only selected for the female nutrition survey from a random sub-sample of screened households (45% of sampled households in Burkina Faso, 25% in Kenya).\nWe imagine that many users will want to link children to mothers where possible, particularly because the female nutrition survey includes questions about antenatal care and nutrtion support the mother received during her most recent pregnancy. Our user note offered code you could use to, at minimum, link sampled mothers to their youngest sampled child.\nIn this post, we’d like to offer an updated version of this code that uses the rowwise function released with dplyr 1.0.0 last year. Both approaches work great! But, we believe that the rowwise approach is a quite bit easier to read and understand.\nSetup\nTo keep things simple, we’ll use a data extract from Burkina Faso 2018 that contains only household members who participated in either the child nutrition survey or the female nutrition survey (you can request a file with all household members if you select “All Cases” at checkout). We’ll use the tidyverse and ipumsr packages to load our data into R.\n\n\nlibrary(tidyverse)\nlibrary(ipumsr)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00002.xml\",\n  data = \"data/pma_00002.dat.gz\"\n)\n\n\n\n\n\n\n\n© 2017 (MPL 2.0)\nFor the purposes of this post, we’ll be working with only a small subset of variables (feel free to include any number of variables when you create your own extract). Also: in order to make our coding examples a bit more readable, we’ll take an extra step of reassigning shorter identification numbers to each household and person - this is not recommended practice in general and we do so only to reduce the number of characters in HHID (20) and PERSONID (22) to 4.\n\n\ndat <- dat %>% \n  select(\n    HHID,\n    ELIGTYPE,\n    AGEHQ,\n    RELATEKID,\n    KIDBIRTHYR,\n    KIDBIRTHMO,\n    LASTBIRTHYR,\n    LASTBIRTHMO,\n    KIDARMCIRCVAL,\n    RPANCPREGMO\n  ) %>% \n  arrange(HHID, ELIGTYPE) %>% \n  rowid_to_column(var = \"PERSONID\") %>% \n  group_by(HHID) %>% \n  mutate(HHID = cur_group_id()) %>% \n  ungroup()\n\n\n\n\n\n\n\n© 2018 RStudio (CC0 1.0)\nMatching with multiple varialbes\nFor any given household in our dataset, there should always be at least one child under age 5 who participated in the child nutrition survey. We also expect roughly 45% of households should also include at least one woman aged 10-49 who particpated in the female nutrition survey.\nA typical household might look something like this:\n\n\n\nHHID\n\n\nPERSONID\n\n\nAGEHQ\n\n\nELIGTYPE\n\n\nKIDBIRTHMO\n\n\nKIDBIRTHYR\n\n\nLASTBIRTHMO\n\n\nLASTBIRTHYR\n\n\n1598\n\n\n3521\n\n\n0\n\n\n11 - Infant under age 2 (INF)\n\n\nDecember\n\n\n2017\n\n\nNA\n\n\nNA\n\n\n1598\n\n\n3522\n\n\n0\n\n\n11 - Infant under age 2 (INF)\n\n\nJuly\n\n\n2017\n\n\nNA\n\n\nNA\n\n\n1598\n\n\n3523\n\n\n0\n\n\n11 - Infant under age 2 (INF)\n\n\nApril\n\n\n2018\n\n\nNA\n\n\nNA\n\n\n1598\n\n\n3524\n\n\n4\n\n\n14 - Aged 2-5 (K)\n\n\nJuly\n\n\n2013\n\n\nNA\n\n\nNA\n\n\n1598\n\n\n3525\n\n\n20\n\n\n20 - Selected women aged 10-49 (WN)\n\n\nNA\n\n\nNA\n\n\nApril\n\n\n2018\n\n\n1598\n\n\n3526\n\n\n25\n\n\n20 - Selected women aged 10-49 (WN)\n\n\nNA\n\n\nNA\n\n\nDecember\n\n\n2017\n\n\n1598\n\n\n3527\n\n\n45\n\n\n20 - Selected women aged 10-49 (WN)\n\n\nNA\n\n\nNA\n\n\nJuly\n\n\n2017\n\n\n\nAll members of the household share the same household ID in HHID. Each person has a unique PERSONID, while AGEHQ gives their age (when the household questionnaire was completed) and ELIGTYPE describes their eligibility for sub-modules on either the child or female nutrition questionnaire (both the numeric code and label are shown).\nIn this household, it’s easy to spot the mother for each infant: each infant’s birth month KIDBIRTHMO and year KIDBIRTHYR match the month and year of one woman’s most recent delivery shown in LASTBIRTHMO and LASTBIRTHYR. Unfortunately, it’s not possible to match the 4 year-old child to a mother (women were only asked about the date of their most recent birth).\nOnce the matches are identified by both month and year, we could attach any number of variables from the mother’s record onto the record for the child. For demonstration purposes, we’ll just attach her PERSONID as a new variable called MOMID. If the child’s mother cannot be determined - or if a particular row contains data from a mother, rather than a child - we’ll assign the value NA to MOMID.\nIdentifying the “current group”\nImagine dividing our search in two basic steps: first, we’ll want to group our data into households. Then, we’ll iterate through person in the dataset: if that person is a child, we’ll search the members of their group for a woman with a matching birth month and year.\nLet’s focus on the first step for a moment. A simple way to minimize the number of records involved with the search for each child’s mother is to group_by HHID, and then create a unique subset of the larger dataset for each child. After we’ve grouped the data, we’ll use cur_data to return the current data for each group. For convenience, you might save this miniature dataset as a column in dat - we’ll call ours HH_DATA:\n\n\ndat <- dat %>% \n  group_by(HHID) %>% \n  mutate(HH_DATA = list(cur_data())) %>% \n  ungroup()\n\n\n\n\nFor grouped data, cur_data() returns a dataset with one row for each member of the group.\nIf you now look at dat, you’ll see we’ve stored one table in HH_DATA for each person. If you opened one of those tables, you’d see:\none row for each person living in the individual’s household\nall columns from dat except for the grouping column HHID (10 in total)\n\n\ndat %>% select(PERSONID, HHID, HH_DATA)\n\n\n# A tibble: 5,267 × 3\n   PERSONID  HHID HH_DATA          \n      <int> <int> <list>           \n 1        1     1 <tibble [3 × 10]>\n 2        2     1 <tibble [3 × 10]>\n 3        3     1 <tibble [3 × 10]>\n 4        4     2 <tibble [2 × 10]>\n 5        5     2 <tibble [2 × 10]>\n 6        6     3 <tibble [2 × 10]>\n 7        7     3 <tibble [2 × 10]>\n 8        8     4 <tibble [1 × 10]>\n 9        9     5 <tibble [5 × 10]>\n10       10     5 <tibble [5 × 10]>\n# … with 5,257 more rows\n\nLet’s pull HH_DATA for the first four individuals in dat (essentially printing the contents of the list):\n\n\ndat %>% \n  slice(1:4) %>% \n  pull(HH_DATA)\n\n\n[[1]]\n# A tibble: 3 × 10\n  PERSONID  ELIGTYPE AGEHQ RELATEKID KIDBIRTHYR KIDBIRTHMO LASTBIRTHYR\n     <int> <int+lbl> <int> <int+lbl>      <dbl>  <int+lbl>   <int+lbl>\n1        1 14 [Aged…     4 1 [Mothe…       2014  6 [June]  9999 [NIU …\n2        2 14 [Aged…     2 1 [Mothe…       2016  3 [March] 9999 [NIU …\n3        3 14 [Aged…     2 2 [Fathe…       2016  5 [May]   9999 [NIU …\n# … with 3 more variables: LASTBIRTHMO <int+lbl>,\n#   KIDARMCIRCVAL <dbl+lbl>, RPANCPREGMO <int+lbl>\n\n[[2]]\n# A tibble: 3 × 10\n  PERSONID  ELIGTYPE AGEHQ RELATEKID KIDBIRTHYR KIDBIRTHMO LASTBIRTHYR\n     <int> <int+lbl> <int> <int+lbl>      <dbl>  <int+lbl>   <int+lbl>\n1        1 14 [Aged…     4 1 [Mothe…       2014  6 [June]  9999 [NIU …\n2        2 14 [Aged…     2 1 [Mothe…       2016  3 [March] 9999 [NIU …\n3        3 14 [Aged…     2 2 [Fathe…       2016  5 [May]   9999 [NIU …\n# … with 3 more variables: LASTBIRTHMO <int+lbl>,\n#   KIDARMCIRCVAL <dbl+lbl>, RPANCPREGMO <int+lbl>\n\n[[3]]\n# A tibble: 3 × 10\n  PERSONID  ELIGTYPE AGEHQ RELATEKID KIDBIRTHYR KIDBIRTHMO LASTBIRTHYR\n     <int> <int+lbl> <int> <int+lbl>      <dbl>  <int+lbl>   <int+lbl>\n1        1 14 [Aged…     4 1 [Mothe…       2014  6 [June]  9999 [NIU …\n2        2 14 [Aged…     2 1 [Mothe…       2016  3 [March] 9999 [NIU …\n3        3 14 [Aged…     2 2 [Fathe…       2016  5 [May]   9999 [NIU …\n# … with 3 more variables: LASTBIRTHMO <int+lbl>,\n#   KIDARMCIRCVAL <dbl+lbl>, RPANCPREGMO <int+lbl>\n\n[[4]]\n# A tibble: 2 × 10\n  PERSONID  ELIGTYPE AGEHQ RELATEKID KIDBIRTHYR KIDBIRTHMO LASTBIRTHYR\n     <int> <int+lbl> <int> <int+lbl>      <dbl>  <int+lbl>   <int+lbl>\n1        4 14 [Aged…     3  1 [Moth…       2014  9 [Septe… 9999 [NIU …\n2        5 20 [Sele…    25 99 [NIU …       9999 99 [NIU (… 2014       \n# … with 3 more variables: LASTBIRTHMO <int+lbl>,\n#   KIDARMCIRCVAL <dbl+lbl>, RPANCPREGMO <int+lbl>\n\nThe first three individuals are members of the same household, so they appear in eachother’s HH_DATA. The fourth is a member of a second household, and so on.\nFor our purposes, it’s perfectly fine to leave the household datasets in a list. Once we define a search function to find each child’s mother, we’ll simply apply it to each row of HH_DATA. For example, suppose we just wanted to find the age of the oldest person in each household. We would use rowwise to iterate over each row in dat, looking for the maximum value of AGEHQ in the HH_DATA table stored in each row.\n\n\ndat %>% \n  rowwise() %>% \n  mutate(HH_AGE_OLDEST = max(HH_DATA$AGEHQ)) %>% \n  select(PERSONID, HHID, AGEHQ, HH_AGE_OLDEST)\n\n\n# A tibble: 5,267 × 4\n# Rowwise: \n   PERSONID  HHID     AGEHQ HH_AGE_OLDEST\n      <int> <int> <int+lbl>     <int+lbl>\n 1        1     1         4             4\n 2        2     1         2             4\n 3        3     1         2             4\n 4        4     2         3            25\n 5        5     2        25            25\n 6        6     3         1             4\n 7        7     3         4             4\n 8        8     4         2             2\n 9        9     5         4            27\n10       10     5         2            27\n# … with 5,257 more rows\n\nThe main difference between max and the function we’ll use for our search is that max returns the same value for every person in the household; strictly speaking, it’s not necessary to do a row-wise search through pre-grouped household data in this case. Our problem is more complex: we want to return a specific value for each person via rowwise, but we also want to restrict each person’s search to members of a pre-defined group.\nRow-wise search within groups\nNow that we’ve isolated data for each person’s household in HH_DATA, we need to write a custom function that will match birth months and years, and then return a value for MOMID only if exactly one match is found.\nTo save time, we’ll only perform our search if ELIGTYPE shows that the current row contains data for a sampled child. In other words, the value for ELIGTYPE should be less than 20.\n\n\ndat %>% count(ELIGTYPE)\n\n\n# A tibble: 3 × 2\n                             ELIGTYPE     n\n                            <int+lbl> <int>\n1 11 [Infant under age 2 (INF)]        1194\n2 14 [Aged 2-5 (K)]                    1662\n3 20 [Selected women aged 10-49 (WN)]  2411\n\nThe case_when function makes this job simple: we’ll explicitly define a function for the “case when” ELIGTYPE < 20, but we’ll not specify what to in the “case when” ELIGTYPE == 20. A nice feature of case_when is that it automatically returns the value NA for any cases that are not handled explicitly:\n\n\ndat %>% \n  count(ELIGTYPE) %>% \n  mutate(EXAMPLE = case_when(ELIGTYPE < 20 ~ TRUE))\n\n\n# A tibble: 3 × 3\n                             ELIGTYPE     n EXAMPLE\n                            <int+lbl> <int> <lgl>  \n1 11 [Infant under age 2 (INF)]        1194 TRUE   \n2 14 [Aged 2-5 (K)]                    1662 TRUE   \n3 20 [Selected women aged 10-49 (WN)]  2411 NA     \n\nAs we’ve seen, one way to identify the likely mother for each child is to match the mother’s LASTBIRTHMO and LASTBIRTHYR to the child’s KIDBIRTHMO and KIDBIRTHYR. If there is only one match in the household, we’ll return the mother’s PERSONID from HH_DATA as a new column MOMID. On the other hand, if multiple women could be the mother or if no match could be found, we’ll return the value NA.\n\n\ndat <- dat %>% \n  rowwise() %>%\n  mutate(MOMID = case_when(ELIGTYPE < 20 ~ {\n    # re-name these in order to avoid confusion with the columns in HH_DATA:\n    kid_month <- KIDBIRTHMO\n    kid_year <- KIDBIRTHYR\n    \n    # pull the PERSONID for any match\n    moms <- HH_DATA %>% \n      filter(LASTBIRTHMO == kid_month, LASTBIRTHYR == kid_year) %>% \n      pull(PERSONID)\n    \n    # if exactly one match was found, return that PERSONID\n    # otherwise, return NA\n    ifelse(length(moms) == 1, moms, NA) \n  })) %>% \n  ungroup()\n\n\n\nLet’s return to our example household:\n\n\n\nHHID\n\n\nPERSONID\n\n\nMOMID\n\n\nAGEHQ\n\n\nELIGTYPE\n\n\nKIDBIRTHMO\n\n\nKIDBIRTHYR\n\n\nLASTBIRTHMO\n\n\nLASTBIRTHYR\n\n\n1598\n\n\n3521\n\n\n3526\n\n\n0\n\n\n11 - Infant under age 2 (INF)\n\n\nDecember\n\n\n2017\n\n\nNA\n\n\nNA\n\n\n1598\n\n\n3522\n\n\n3527\n\n\n0\n\n\n11 - Infant under age 2 (INF)\n\n\nJuly\n\n\n2017\n\n\nNA\n\n\nNA\n\n\n1598\n\n\n3523\n\n\n3525\n\n\n0\n\n\n11 - Infant under age 2 (INF)\n\n\nApril\n\n\n2018\n\n\nNA\n\n\nNA\n\n\n1598\n\n\n3524\n\n\nNA\n\n\n4\n\n\n14 - Aged 2-5 (K)\n\n\nJuly\n\n\n2013\n\n\nNA\n\n\nNA\n\n\n1598\n\n\n3525\n\n\nNA\n\n\n20\n\n\n20 - Selected women aged 10-49 (WN)\n\n\nNA\n\n\nNA\n\n\nApril\n\n\n2018\n\n\n1598\n\n\n3526\n\n\nNA\n\n\n25\n\n\n20 - Selected women aged 10-49 (WN)\n\n\nNA\n\n\nNA\n\n\nDecember\n\n\n2017\n\n\n1598\n\n\n3527\n\n\nNA\n\n\n45\n\n\n20 - Selected women aged 10-49 (WN)\n\n\nNA\n\n\nNA\n\n\nJuly\n\n\n2017\n\n\n\nSuccess! MOMID shows the correct PERSONID for the mother of each infant, and it contains expected NA values as discussed above.\nBut how many children were matched to a mother, overall? Remember that a slight majority of sampled children (approximately 55%) live in households where no women were sampled for the female nutrition survey. We’ll flag the rest with an indicator WOMEN_IN_HH, then test whether each child was LINKED with a mother:\n\n\ndat %>%\n  group_by(HHID) %>% \n  mutate(WOMEN_IN_HH = any(ELIGTYPE == 20)) %>% \n  filter(ELIGTYPE < 20) %>% \n  ungroup() %>% \n  count(WOMEN_IN_HH, LINKED = !is.na(MOMID)) %>% \n  mutate(pct = 100*prop.table(n))\n\n\n# A tibble: 3 × 4\n  WOMEN_IN_HH LINKED     n   pct\n  <lgl>       <lgl>  <int> <dbl>\n1 FALSE       FALSE   1579  55.3\n2 TRUE        FALSE    481  16.8\n3 TRUE        TRUE     796  27.9\n\nSo far, we’ve managed to locate the mother for only about 28% of the children in our sample. Around 17% of the remaining children do live with a sampled woman, but could not be linked with a mother by matched birthdates.\nLet’s see if we can improve on these results.\nExpanded search\nIn our first search, our use of LASTBIRTHMO and LASTBIRTHYR ensured that only mother’s most recent child could be linked to her record. It’s possible to expand these criteria in certain circumstances using RELATEKID, which describes the relationship between each child and the person who provided responses to the interviewer on their behalf.\n\n\ndat %>% count(RELATEKID)\n\n\n# A tibble: 7 × 2\n                   RELATEKID     n\n                   <int+lbl> <int>\n1  1 [Mother]                 2646\n2  2 [Father]                   57\n3  3 [Grandmother]              94\n4  4 [Grandfather]               7\n5  5 [Sister]                    4\n6 94 [Other]                    48\n7 99 [NIU (not in universe)]  2411\n\nWhen RELATEKID == 1, this respondent is the child’s mother. So, suppose we have a household like this one:\n\n\n\nHHID\n\n\nPERSONID\n\n\nMOMID\n\n\nAGEHQ\n\n\nELIGTYPE\n\n\nRELATEKID\n\n\nKIDBIRTHMO\n\n\nKIDBIRTHYR\n\n\nLASTBIRTHMO\n\n\nLASTBIRTHYR\n\n\n61\n\n\n147\n\n\n149\n\n\n0\n\n\n11 - Infant under age 2 (INF)\n\n\nMother\n\n\nMay\n\n\n2018\n\n\nNA\n\n\nNA\n\n\n61\n\n\n148\n\n\nNA\n\n\n1\n\n\n11 - Infant under age 2 (INF)\n\n\nMother\n\n\nDecember\n\n\n2016\n\n\nNA\n\n\nNA\n\n\n61\n\n\n149\n\n\nNA\n\n\n19\n\n\n20 - Selected women aged 10-49 (WN)\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nMay\n\n\n2018\n\n\n\nWe’ve already matched the youngest child in this household with our first search, but the older child remains unlinked. Fortunately, RELATEKID tells us that the older child’s mother also lives in the household, since she provided responses on their behalf.\nBecause there is only one reproductive age woman living in this particular household, it’s reasonable to assume that the same woman is the mother for both children.\nLet’s implement these criteria in a new search, creating MOMID2.\n\n\ndat <- dat %>% \n  rowwise() %>%\n  mutate(MOMID2 = case_when(ELIGTYPE < 20 ~ {\n    # This is the same as above: if we find a match, we'll call it `mom`\n    kid_month <- KIDBIRTHMO\n    kid_year <- KIDBIRTHYR\n    moms <- HH_DATA %>%\n      filter(LASTBIRTHMO == kid_month, LASTBIRTHYR == kid_year) %>%\n      pull(PERSONID)\n    mom <- ifelse(length(moms) == 1, moms, NA)\n    \n    # Additionally, if `mom` is NA, we'll look at `RELATEKID`\n    # If the respondent was the child's mother, and only one woman in the \n    # household has ever given birth, we'll define that woman as `mom`\n    if(is.na(mom)){\n      moms <- HH_DATA %>% \n        filter(LASTBIRTHYR < 9000) %>% \n        pull(PERSONID) \n      mom <- ifelse(length(moms) == 1 & RELATEKID == 1, moms, NA)\n    }\n    mom\n  })) %>% \n  ungroup() \n\n\n\nNow, both of the children in our example household will show the same MOMID2:\n\n\n\nHHID\n\n\nPERSONID\n\n\nMOMID\n\n\nMOMID2\n\n\nAGEHQ\n\n\nELIGTYPE\n\n\nRELATEKID\n\n\nKIDBIRTHMO\n\n\nKIDBIRTHYR\n\n\nLASTBIRTHMO\n\n\nLASTBIRTHYR\n\n\n61\n\n\n147\n\n\n149\n\n\n149\n\n\n0\n\n\n11 - Infant under age 2 (INF)\n\n\nMother\n\n\nMay\n\n\n2018\n\n\nNA\n\n\nNA\n\n\n61\n\n\n148\n\n\nNA\n\n\n149\n\n\n1\n\n\n11 - Infant under age 2 (INF)\n\n\nMother\n\n\nDecember\n\n\n2016\n\n\nNA\n\n\nNA\n\n\n61\n\n\n149\n\n\nNA\n\n\nNA\n\n\n19\n\n\n20 - Selected women aged 10-49 (WN)\n\n\nNA\n\n\nNA\n\n\nNA\n\n\nMay\n\n\n2018\n\n\n\nHow much does MOMID2 improve on the results from MOMID?\n\n\ndat %>%\n  group_by(HHID) %>% \n  mutate(WOMEN_IN_HH = any(ELIGTYPE == 20)) %>% \n  filter(ELIGTYPE < 20) %>% \n  ungroup() %>% \n  count(WOMEN_IN_HH, LINKED1 = !is.na(MOMID), LINKED2 = !is.na(MOMID2)) %>% \n  mutate(pct = 100*prop.table(n))\n\n\n# A tibble: 4 × 5\n  WOMEN_IN_HH LINKED1 LINKED2     n   pct\n  <lgl>       <lgl>   <lgl>   <int> <dbl>\n1 FALSE       FALSE   FALSE    1579 55.3 \n2 TRUE        FALSE   FALSE     198  6.93\n3 TRUE        FALSE   TRUE      283  9.91\n4 TRUE        TRUE    TRUE      796 27.9 \n\nOur second search found mothers for an additional 283 children, or about 10% of the overall child nutrition sample. Setting aside the 55% of child who could not possibly be linked because of sample design restrictions, we were unable to find a mother in only 7% of cases (many of these may not live with their mother, or else we have insufficient information to identify a match).\nNew research questions\nNow that we’ve linked as many children as possible to their mother’s data, we’ll be able to explore how certain antenatal interventions might impact child growth and nutrition. Consider our first example household again:\n\n\n\nPERSONID\n\n\nMOMID\n\n\nAGEHQ\n\n\nKIDARMCIRCVAL\n\n\nRPANCPREGMO\n\n\n3521\n\n\n3526\n\n\n0\n\n\n13.3\n\n\nNA\n\n\n3522\n\n\n3527\n\n\n0\n\n\n13.6\n\n\nNA\n\n\n3523\n\n\n3525\n\n\n0\n\n\n10.9\n\n\nNA\n\n\n3524\n\n\nNA\n\n\n4\n\n\n14.1\n\n\nNA\n\n\n3525\n\n\nNA\n\n\n20\n\n\nNA\n\n\n7\n\n\n3526\n\n\nNA\n\n\n25\n\n\nNA\n\n\n3\n\n\n3527\n\n\nNA\n\n\n45\n\n\nNA\n\n\n3\n\n\n\nWe’ve added two new variables here:\nKIDARMCIRCVAL shows the Mid-Upper Arm Circumference (MUAC) for each child in centimeters. For children older than 6 months, a MUAC smaller than 11.5 centimeters is commonly used to screen for acute malnutrition.\nRPANCPREGMO reports the first month of the mother’s most recent pregnancy when she first received antenatal care.\nNow that we’ve established a link between the infants and mothers, it’s possible to investigate how infants are impacted by, for example, the timing or quality of antenatal care provided to their mother during pregnancy. In this household, the KIDARMCIRCVAL shown for the child in row 3 suggests that they may be at risk for acute malnutrition. We also observe in RPANCPREGMO that their mother received no antenatal care until the third trimester of her pregnancy (month 7). If we took the additional step of attaching the value in RPANCPREGMO to the appropriate child’s record - for example, in a variable we might call MOM_ANCPREGMO - we could then build a model examining this relationship in the larger dataset.\nIn our next post, we’ll continue our series on PMA nutrition surveys as we consider more ways to measure nutritional outcomes in children. In particular, we’ll be looking at common assessment tools for recommended infant and young child feeding practices (IYCFP) and how to create them from dietary intake data in the child nutrition survey.\n\n\n\n",
    "preview": "posts/2021-09-15-nutrition-linking/images/logos.png",
    "last_modified": "2022-04-13T13:10:47-04:00",
    "input_file": {},
    "preview_width": 960,
    "preview_height": 540
  },
  {
    "path": "posts/2021-09-01-nutrition-discovery/",
    "title": "Introducing PMA Nutrition Data",
    "description": "Nutrition surveys are available for women, young children, and health service providers in their area.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-09-01",
    "categories": [
      "Nutrition",
      "Data Discovery",
      "Service Delivery Points",
      "Infant and Young Child Feeding"
    ],
    "contents": "\n\nContents\nData Access\nHousehold Nutrition Surveys\n2017 Sample Design\n2018 Sample Design\n\nSDP Nutrition Surveys\nNext steps\n\n\n\n\nToday, we’re excited to launch a new series exploring nutrition surveys from Performance Monitoring for Action! Much like the family planning surveys we’ve discussed so far, PMA nutrition surveys feature contemporaneous samples of both households and service delivery points (SDPs). Several public use data series cover maternal and young child nutrition, but the inclusion of service delivery point data in PMA surveys gives researchers a unique opportunity to see how local service provision impacts the nutritional health of women and their households.\nPMA household nutrition surveys focus on women aged 10-49 and children up to age 5 living within geographically defined sample clusters - or enumeration areas - in Burkina Faso and Kenya. Two rounds of nationally representative, cross-sectional samples were collected from each country: one in 2017, and another in 2018.\nNutrition surveys for SDPs are designed to reflect the health service environment experienced by women and children in a corresponding household nutrition sample (SDP surveys are not nationally representative). PMA worked with officials in Burkina Faso and Kenya to obtain a census of public-sector facilities, and it sampled all public-sector facilities providing services to an enumeration area represented in the household nutrition sample. Additionally, PMA sampled up to three private-sector facilities that were located within the boundaries of any such enumeration area.\nIPUMS offers a harmonized version of all PMA nutrition surveys at no cost to registered users. At the household level, we’ve merged separate questionnaires administered to household heads, women age 10-49, and caregivers for children under age 5 in a process described here. We’ve also created integrated variable names, response codes, and documentation highlighting comparability issues between samples.\nHarmonized data from IPUMS PMA are designed to help you find and compare data from multiple PMA nutrition samples as quickly and easily as possible. In this post, we’ll guide you through some of the topics and comparability issues you’re likely to encounter. Then, in the coming weeks, we’ll take a deeper dive into analytic topics like:\nconstructing assessment indicators for infant and young child feeding (IYCF) practices\nlinking antenatal / postnatal interventions with child nutrition outcomes\ncontextualizing household nutrition with data from SDP surveys and external sources (e.g. livelihood zones and climate data)\nrecent publications featuring PMA nutrition data, and opportunities for additional analysis\nData Access\nYou’ll find nutrition data on the IPUMS PMA website by clicking on the “CHANGE” link in the box where the current unit of analysis is shown:\n\n\n\n\nAnyone can browse IPUMS PMA documentation, but you’ll need to register for a free account before you can download data.\nAs with family planning surveys, you’ll find separate units of analysis for nutrition surveys collected from households and SDPs. If you intend to use both, you will need to download two extracts: one for SDPs and one for households.\n\n\n\nThroughout this series, we’ll use tools from ipumsr and the tidyverse to work with IPUMS PMA nutrition data in R. Once you’ve downloaded extracts from one or both units of analysis, you can load them into R as follows (changing the file paths as needed):\n\n\nlibrary(tidyverse)\nlibrary(ipumsr)\n\n# we'll call data from the SDP unit of analysis `sdp`\nsdp <- read_ipums_micro(\n  ddi = \"data/pma_00001.xml\",\n  data = \"data/pma_00001.dat.gz\"\n)\n\n# we'll call data from the household unit of analysis `hh`\nhh <- read_ipums_micro(\n  ddi = \"data/pma_00002.xml\",\n  data = \"data/pma_00002.dat.gz\"\n)\n\n\n\nHousehold Nutrition Surveys\nThere are nearly 1,000 variables available from the four household nutrition samples, so navigation can seem overwhelming at first. Fortunately, a large proportion of these come from multiple response questions repeated separately for women and each sampled child.\nHarmonized variable names repeat the same stem for variables that come from the same original question, and they have a specific prefix indicating whether the question was administered to a woman or a particular child. If the question was multiple response, a unique suffix was given to the binary indicator derived from each response.\nFor example, a common question for both women and children deals with the type of foods eaten yesterday. Here is the text of the question administered to women in 2017 (both countries):\n501. Now I'd like to ask you about foods and drinks that you ate or drank\nyesterday during the day or night, whether you ate it at home or anywhere else.\n\nI am interested in whether you had the food items I will mention even if they\nwere combined with other foods. For example, if you had a soup made with\ncarrots, potatoes and meat, you should reply \"yes\" for each of these\ningredients when I read you the list. However, if you consumed only the broth\nof a soup, but not the meat or vegetable, do not say \"yes\" for the meat or\nvegetable.\n\nAs I ask you about foods and drinks, please think of foods and drinks you had\nas snacks or small meals as well as during any main meals. Please also remember\nfoods you may have eaten while preparing meals or preparing food for others.\nPlease do not include any food used in a small amount for seasoning or\ncondiments (like chilies, spices, herbs or fish powder). I will ask you about\nthose foods separately.\n\nCannot select 'no response' with other options.\n\n  [] Any foods made from grains, like maize, rice, wheat, porridge, sorghum, \n     bread\n  [] Any vegetables or roots that are orange or yellow inside like pumpkin,\n     carrots, squash or yellow sweet potatoes\n  [] Any white roots and tubers or plantains like Irish potatoes, yams, \n     cassava, white sweet potatoes\n  [] Any dark green, leafy vegetables like sukumu wiki\n  [] Any fruits that are dark yellow or orange inside like ripe mangoes, pawpaw\n  [] Any other fruits\n  [] Any other vegetables\n  [] Any meat made from animal organs like liver, kidney, heart\n  [] Any other meat, such as beef, pork, lamb, goat, chicken, duck, or dik dik\n  [] Eggs\n  [] Fresh or dried fish or shellfish\n  [] Any foods made from beans, peas, lentils\n  [] Any nuts and seeds like groundnut or groundnut paste\n  [] Any milk or milk products like cheese or mala\n  [] Any savory and fried snacks like fried chips, crisps, samosas, or other\n     fried foods\n  [] Sugary foods, jiggery (sukari nguru), mandaazi, donuts, cake, sweet\n     biscuits or candies\n  [] Any sugar-sweetened beverages like sweet fruit drinks, fizzy drinks, \n     sweet tea\n  [] Any condiments and seasonings used in small amounts for flavor, like\n     spices, herbs, fish powder, tomato paste\n  [] Other beverages and foods like unsweetened tea or coffee, clear broth, \n     alcohol\n  [] None of the above\n  [] No response\n\nThe format of questions included in each PMA household nutrition survey closely resembles nutrition questions found in other prominent global health surveys, including those you’ll find at IPUMS DHS.\nEach one of these response options is represented as a binary indicator (with top-codes for different types of non-response). For variables where this question was administered to women, each indicator received the same prefix and stem:\nWN (women) + YEST (yesterday)\nEach response is represented by the addition of a suffix like:\nWNYESTGRAIN - Woman consumed yesterday: grains\nWNYESTMEAT - Woman consumed yesterday: meats\nWNYESTFRIED - Woman consumed yesterday: savory and fried snacks\nThis question was also administered to caregivers responding on behalf of sampled children. The prefix for children can take one of several values associated with changes in sample design made between 2017 and 2018:\nINF - a child under 24 months\nYK - the caregiver’s youngest child aged 24-60 months (2017 samples only)\nOK - the caregiver’s other children aged 24-60 months (2017 samples only)\nK - any child aged 24-60 months (2018 samples only)\nKID - any child aged 0-60 months\n\nSee ELIGTYPE for more information on the use of each prefix.\nThis results in several variables for differently sampled children, for example:\nINFYESTFRIED - Infant under 2 consumed yesterday: savory/fried snacks (all samples)\nYKYESTFRIED - Youngest child aged 2-5 consumed yesterday: savory/fried snacks (2017 samples only)\nOTKYESTFRIED - Older child aged 2-5 consumed yesterday: savory/fried snacks (2017 samples only)\nKIDYESTFRIED - Child under age 5 consumed yesterday: savory/fried snacks (2018 samples only)\nBefore we continue, let’s dig a bit deeper into the changes made to sample design between the 2017 and 2018 surveys.\n2017 Sample Design\nLike all cross-sectional PMA surveys, the 2017 household nutrition survey features a multi-stage stratified cluster sample design. Officials in each country drew a sample of enumeration areas from urban/rural strata (83 enumeration areas for Burkina Faso, 151 for Kenya). Within each enumeration area, a set number of households were randomly selected for screening (89 households per enumeration area for Burkina Faso, 140 for Kenya). In preliminary screening, interviewers determined whether each household included both\n\nFull 2017 dataset notes for Burkina Faso and Kenya\nat least one woman aged 10-49 (see ELIGIBLEHHFEM), and\nat least one child under age 2 (see ELIGIBLEHHKID).\nHouseholds meeting both criteria (see ELIGIBLEHH) were given additional questions related to household food security, wealth / assets, access to water, sanitation, and so forth.\nFor example, consider the following household. In preliminary screening, the RESPONDENT provided a roster of all persons living in the household, including each person’s AGEHQ and SEX. Because the household contains both one woman aged 10-49 (row 1) and one child under age 2 (row 2), the RESPONDENT was asked to provide additional information about the household, including information used to determine WEALTHT, WATERDRINKMAIN, and more.\n\n\n\nRESPONDENT\n\n\nAGEHQ\n\n\nSEX\n\n\nWEALTHT\n\n\nWATERDRINKMAIN\n\n\nYes\n\n\n25\n\n\nFemale\n\n\nLowest tertile\n\n\nProtected spring\n\n\nNo\n\n\n0\n\n\nFemale\n\n\nLowest tertile\n\n\nProtected spring\n\n\nNo\n\n\n3\n\n\nMale\n\n\nLowest tertile\n\n\nProtected spring\n\n\nNo\n\n\n5\n\n\nMale\n\n\nLowest tertile\n\n\nProtected spring\n\n\nNo\n\n\n29\n\n\nMale\n\n\nLowest tertile\n\n\nProtected spring\n\n\n\nThe nutrition questionnaire was administered in a second stage, and only in households meeting both of the above criteria. This questionnaire was given separately to each woman age 10-49 in qualifying households:\nEach woman answered questions about her own nutritional health (prefix WN), and specific questions about nutrition during her current pregnancy (prefix CP) or recent pregnancy (prefix RP) if applicable;\nEach woman then answered questions about the youngest child in her care. Women with children under 24 months received certain questions related to infant nutrition (prefix INF). We found that, if a woman was the primary caregiver for more than one child under 24 months of age (e.g. twins), only infant feeding practices for one child were reported;\nIf the youngest child under age 5 in the woman’s care was 24 months or older, women received certain questions related to young child nutrition (prefix YK). Note: these women live with a child under 2 (see sample design), but are not the primary caretaker for that child;\nAll other children under age 5 in the woman’s care are represented by a subset of repeated questions related to young child nutrition (prefix OTK).\n\nThere are additional restrictions on children represented by YK and OTK variables: they must also be biological offspring of the responding woman. Children represented by INF variables need only be the youngest child in her care.\nEach woman aged 10-49 living in the household would have received the nutrition questionnaire; in our example household, there is only one such woman. She answered nutrition-related questions for herself, and on behalf of each of her children under age 5. You’ll see the stem for each qualifying woman and child in the variable ELIGTYPE; this will help you find the relevant nutrition variables for each person.\n\n\n\nAGEHQ\n\n\nSEX\n\n\nELIGTYPE\n\n\nWNYESTFRIED\n\n\nINFYESTFRIED\n\n\nYKYESTFRIED\n\n\nOTKYESTFRIED\n\n\nKIDYESTFRIED\n\n\n25\n\n\nFemale\n\n\nSelected women aged 10-49 (WN)\n\n\nNo\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNA\n\n\n0\n\n\nFemale\n\n\nInfant under age 2 (INF)\n\n\nNIU (not in universe)\n\n\nNo\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNA\n\n\n3\n\n\nMale\n\n\nOlder aged 2-5 (OTK)\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNo\n\n\nNA\n\n\n5\n\n\nMale\n\n\nMember of household included in nutrition sample\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNA\n\n\n29\n\n\nMale\n\n\nMember of household included in nutrition sample\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNA\n\n\n\nA few things to note here:\nELIGTYPE - Explains eligibility for nutrition questions associated with each prefix. Members of this household who were not eligible for the nutrition questionnaire are shown in rows 4 and 5 (you can exclude these cases from your extract by selecting only “Females and Children with Nutrition Information”).\nWNYESTFRIED - The 25 year old woman ate no fried food yesterday. All other household members are ineligible for this question.\nINFYESTFRIED - The newborn child (age 0) ate no friend food yesterday. All other household members are ineligible for this question.\nYKYESTFRIED - The woman’s youngest child is already represented by INFYESTFRID, so no child is eligible for questions with the stem YK. All household members are ineligible for this question\nOTKYESTFRIED - The woman has one other child under age 5. This child (age 3) ate no fried food yesterday. The final child (age 5) is too old the qualify for the nutrition questionnaire; he and all other household members are ineligible for this question.\nKIDYESTFRIED - This variable is not available for 2017 samples, so it appears as the value NA.\n2018 Sample Design\nThe 2018 household nutrition survey also features a multi-stage stratified cluster sample design. Officials in each country again drew a sample of enumeration areas from urban/rural strata (83 enumeration areas for Burkina Faso, 151 for Kenya). A set number of households were randomly selected for screening within each enumeration area (43 households per enumeration area for Burkina Faso, 56 for Kenya).\n\nFull 2018 dataset notes for Burkina Faso and Kenya\nIn contrast with the 2017 design, all screened households received questions about household food security, wealth / assets, access to water, sanitation, and so forth. Related variables are available even if no members of the household were eligible for the nutrition questionnaire (see ELIGIBLEHH).\nThe nutrition questionnaire was again administered in a second stage. This time, all children under age 5 living in screened households were selected (see ELIGIBLEKID). Because the 2017 sampling criteria were changed, 2018 samples include children under 5 in households where no women were selected. For example:\n\n\n\nAGEHQ\n\n\nSEX\n\n\nELIGTYPE\n\n\nWNYESTFRIED\n\n\nINFYESTFRIED\n\n\nYKYESTFRIED\n\n\nOTKYESTFRIED\n\n\nKIDYESTFRIED\n\n\n4\n\n\nMale\n\n\nAged 2-5 (K)\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNA\n\n\nNA\n\n\nNo\n\n\n6\n\n\nFemale\n\n\nMember of household included in nutrition sample\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNA\n\n\nNA\n\n\nNIU (not in universe)\n\n\n22\n\n\nFemale\n\n\nMember of household included in nutrition sample\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNA\n\n\nNA\n\n\nNIU (not in universe)\n\n\n39\n\n\nFemale\n\n\nMember of household included in nutrition sample\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNA\n\n\nNA\n\n\nNIU (not in universe)\n\n\n\nIn this household, only one child (age 4) was represented in the nutrition sample. The variables YKYESTFRIED and OTKYESTFRIED are only available for 2017 samples, so nutrition data for the 4 year old is recorded in KIDYESTFRIED (there is no child under 2 in the household, so no household member is eligible for INFYESTFRIED).\nNotice that there are, in fact, two women in the household aged 10-49, but they were not included in the nutrition sample. Women were selected for the 2018 nutrition survey through a separate sampling process. A given proportion of households was randomly selected to screen for eligible women (45% of sampled households in Burkina Faso, 25% in Kenya); individuals living in selected households are indicated in FQSELECTED. Any woman aged 10-49 (see ELIGIBLEFEM) residing in one of these randomly selected households would have been given questions about her own nutritional health (prefix WN), and specific questions about nutrition during her current pregnancy (prefix CP) or recent pregnancy (prefix RP) if applicable.\nIn short: it is possible - but not necessary - for sampled women and children to reside in the same household. Moreover, the respondent answering on behalf of a child may be their mother, but other caretakers could respond if the mother was not available (see RELATEKID). In an upcoming post in this series, we’ll explain how to link maternal and child records together (where possible), opening the possibility for analyses that track antenatal and postnatal interventions to child nutrition outcomes.\nSDP Nutrition Surveys\nUnlike the household nutrition surveys, you’ll find no differences in sample design between the 2017 and 2018 SDP nutrition surveys. In both rounds, PMA selected SDPs with the same set of enumeration areas used to select households (83 enumeration areas for Burkina Faso, 151 for Kenya). As mentioned above, SDP samples include:\nall public-sector facilities whose service catchment area includes a selected enumeration area\nup to three private-sector facilities located within the boundaries of a selected enumeration area\nBy design, SDP samples represent the service environment experienced by women and children in a corresponding household sample (SDP samples are not nationally representative). We anticipate that most users will want to aggregate data collected from several facilities serving the same enumeration area.\nFor example, let’s take a look at a few of the facilities surveyed in Kenya 2017:\n\n\n\n\nFACILITYID\n\n\nFACILITYTYPEGEN\n\n\nAUTHORITY\n\n\nEAID\n\n\nEASERVED1\n\n\nEASERVED2\n\n\nEASERVED3\n\n\nNUTFAC\n\n\n4047\n\n\nHospital\n\n\nGovernment\n\n\n4486\n\n\n4092\n\n\n4819\n\n\n4036\n\n\nYes\n\n\n4080\n\n\nHospital\n\n\nGovernment\n\n\n4036\n\n\n4092\n\n\n4036\n\n\nNIU (not in universe)\n\n\nYes\n\n\n4149\n\n\nPharmacy/chemist/drug shop\n\n\nPrivate\n\n\n4092\n\n\n4092\n\n\nNIU (not in universe)\n\n\nNIU (not in universe)\n\n\nNo\n\n\n\n\nAll three of these facilities provide services to the enumeration area 4092, but only one - the private-sector pharmacy - is actually located there (see EAID). The two public-sector hospitals serve multiple enumeration areas shown in variables sharing the stem EASERVED (some public-sector facilities serve up to 18 different enumeration areas listed in variables EASERVED1 to EASERVED18).\nPrivate facilities will only list one EASERVED - it will always match the facility’s EAID.\nPublic facilities may serve multiple EASERVED, usually including their own EAID.\nThe last variable NUTFAC reports whether each SDP is a “nutritional facility”, defined as a facility that “supervises, supports, or supplies community nutrition services provided either by paid staff or community health volunteers (CHVs)”. A simple way to integrate SDP data with household data from the same country-year might be to count the number of “nutritional facilities” serving each enumeration area. We recommend using pivot_longer() to create one row for each EASERVED in every facility’s catchment list:\n\n\nsdp <- sdp %>% \n  pivot_longer(\n    starts_with(\"EASERVED\"),\n    values_to = \"EASERVED\",\n    names_to = NULL\n  )\n\n\n\n\nYou’ll find “nutritional facility” defined on the NUTFAC description tab.\n\n\n\nFACILITYID\n\n\nFACILITYTYPEGEN\n\n\nAUTHORITY\n\n\nEAID\n\n\nNUTFAC\n\n\nEASERVED\n\n\n4047\n\n\nHospital\n\n\nGovernment\n\n\n4486\n\n\nYes\n\n\n4092\n\n\n4047\n\n\nHospital\n\n\nGovernment\n\n\n4486\n\n\nYes\n\n\n4819\n\n\n4047\n\n\nHospital\n\n\nGovernment\n\n\n4486\n\n\nYes\n\n\n4036\n\n\n4080\n\n\nHospital\n\n\nGovernment\n\n\n4036\n\n\nYes\n\n\n4092\n\n\n4080\n\n\nHospital\n\n\nGovernment\n\n\n4036\n\n\nYes\n\n\n4036\n\n\n4080\n\n\nHospital\n\n\nGovernment\n\n\n4036\n\n\nYes\n\n\nNIU (not in universe)\n\n\n4149\n\n\nPharmacy/chemist/drug shop\n\n\nPrivate\n\n\n4092\n\n\nNo\n\n\n4092\n\n\n4149\n\n\nPharmacy/chemist/drug shop\n\n\nPrivate\n\n\n4092\n\n\nNo\n\n\nNIU (not in universe)\n\n\n4149\n\n\nPharmacy/chemist/drug shop\n\n\nPrivate\n\n\n4092\n\n\nNo\n\n\nNIU (not in universe)\n\n\n\nEach of the three facilities in our example serves up to three enumeration areas shown in EASERVED; if a facility serves fewer than three, the remaining values are NIU (not in universe). We’re now able to count the number of “nutritional facilities” serving each enumeration area, and we can easily attach those counts to a household sample from the same year. Let’s join a count of the “nutritional facilities” N_NUTFAC with a count of sampled household members N_PERSONID living in each service area represented by our three example facilities.\n\n\nmerged <- sdp %>% \n  filter(EASERVED != \"NIU (not in universe)\") %>% \n  group_by(EASERVED) %>% \n  summarise(N_NUTFAC = sum(NUTFAC == \"Yes\")) %>%\n  left_join(hh %>% rename(EASERVED = EAID), by = \"EASERVED\") %>% \n  group_by(EASERVED, N_NUTFAC) %>% \n  summarise(\n    .groups = \"keep\",\n    N_PERSONID = n_distinct(PERSONID)\n  )\n\n\n\n\n\n\nEASERVED\n\n\nN_NUTFAC\n\n\nN_PERSONID\n\n\n4036\n\n\n2\n\n\n565\n\n\n4092\n\n\n2\n\n\n641\n\n\n4819\n\n\n1\n\n\n668\n\n\n\nCounting the number of “nutritional facilities” is only the beginning - you’ll find variables dealing with a range of service measures, like:\navailability of specific nutrition services\nmalnutrition monitoring and supplementary food assistance\nmaternal and pediatric care\nstaffing and community health workers\nmedicines\nfees\nNext steps\nIn two weeks, we’ll continue our discussion of PMA nutrition data as we dig into some of the common ways that researchers assess infant and young child feeding (IYCF) practices. Specifically, we’ll show how to construct indicators for Minimum Dietary Diversity (MDD) and Minimum Meal Frequency (MMF) used by the World Health Organization (WHO).\nIn the meantime, we hope you’ll check out PMA nutrition data on the IPUMS PMA website and begin exploring variables to use in your own analysis projects. As always, leave a comment below or reach out to us on Twitter with your questions.\n\n\n\n",
    "preview": "posts/2021-09-01-nutrition-discovery/images/unitofanalysis.png",
    "last_modified": "2022-04-13T13:10:46-04:00",
    "input_file": {},
    "preview_width": 2062,
    "preview_height": 1654
  },
  {
    "path": "posts/2021-08-15-covid-analysis/",
    "title": "Multinomial Regression with Complex Survey Design",
    "description": "The PMA COVID-19 survey is part of a broader panel study. We discuss how to merge it with the baseline survey, and how to specify sample weights and cluster information with the new svyVGAM package.",
    "author": [
      {
        "name": "Devon Kristiansen",
        "url": "https://www.linkedin.com/in/devonkristiansen"
      },
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-08-15",
    "categories": [
      "COVID-19",
      "Data Analysis",
      "svyVGAM",
      "Multinomial Logit",
      "Weights"
    ],
    "contents": "\n\nContents\nSetup\nSampling Weights\nChange in purchasing power\nMultinomial modeling\nWrap-up\n\nThroughout our discussion of the PMA COVID-19 survey this summer, we’ve mentioned that PMA COVID-19 data were collected in telephone interviews with women following a baseline survey as part of an ongoing panel study focused on family planning and reproductive health.\nWhile the scope of the COVID-19 survey is narrower than the baseline survey, it does contain several repeated questions designed to help researchers evaluate change over the first few months of the pandemic. For example, both surveys contain questions about women’s financial independence and the dynamics of household decision-making. In the baseline survey, you’ll find a variable called HHDECDAILY representing a question that asks:\nThe baseline survey was administered in-person between November 2019 and February 2020.\nThe COVID-19 follow up administered by telephone between May and August 2020.\nWho usually makes decisions about making household purchases for daily \nneeds: you, your husband/partner, you and your husband/partner jointly, \nor someone else?\n\n[] Respondent\n[] Husband/partner\n[] Respondent and husband/partner\n[] Someone else\n[] No response\nIn the covid survey, a nearly identical question asks women to reflect on changes that happened since COVID-19 restrictions began. Responses are recorded in CVBUYDECIDER:\nSince the Coronavirus (COVID-19) restrictions began, who usually makes\ndecisions about making household purchases for daily needs: you, your\nhusband/partner, you and your husband/partner jointly, or someone else?\n\n[] Respondent\n[] Husband/partner\n[] Respondent and husband/partner\n[] Someone else\n[] No response\nOne way you might model change over time with these variables is to look at women’s net change in purchasing power with a derived factor that takes the value:\n“More” if a woman has gained autonomy,\n“Less” if she has lost autonomy,\n“Same” if she experienced no change, or\nNA if either HHDECDAILY or CVBUYDECIDER is not available\nIn this post, we’ll demonstrate how to create and model this type of variable by merging the baseline and COVID-19 surveys together. We’ve modeled continuous and binary variables in previous posts, but we’ll need a different approach for a dependent variable with three outcomes: in this case, we’ll fit a multinomial logit model for the odds that a woman will experience the “Less” or “More” autonomy relative to maintaining the “Same” level of autonomy. This task is complicated by two things:\n\nIf you’d like to explore an ordered logit model for these outcomes, you can use the same tools we highlight in this post. Check out this guide for testing the “proportional odds assumption” underlying ordered logit models.\nOnly around half of the women who participated in the in-person baseline survey were reached by telephone for the COVID-19 follow up. We’ll show how changes in the sample design introduce bias to the merged data, and we’ll explain how to mitigate that bias with a sampling weight called CVQWEIGHT.\nPMA screens households for reproductive age women within geographically defined sampling clusters represented by the variable EAID. Our multinomial model should include cluster-robust standard error estimates - in other words, we want to account for correlation between neighboring women who live in the same cluster.\nUntil recently, popular R packages for multinomial regression had no built-in way to handle elements of complex survey design. Fortunately, the new svyVGAM package offers a simple interface built on the very same survey package we’ve featured throughout this blog. We’ll demonstrate fitting a multinomial model with CVQWEIGHT and EAID here, but this package also provides a general interface to any generalized linear / additive model supported by the underlying VGAM package.\nSetup\nWe’ve mentioned in previous posts that you’ll find harmonized PMA COVID-19 data if you navigate to the COVID-19 unit of analysis on the IPUMS PMA website. In this post, we’ll use an extract containing all four of the available COVID-19 samples (Female Respondents only):\nBurkina Faso 2020\nDemocratic Republic of Congo (DRC) 2020 - Kinshasa\nKenya 2020\nNigeria 2020 - Lagos and Kano\nData from the baseline surveys are located under the “Family Planning - Person” unit of analysis. Because data extracts can only contain samples with the same unit of analysis, you’ll need to create and download two separate extracts. Once you’ve downloaded an extract containing COVID-19 data, switch units of analysis by clicking the “CHANGE” link in the “Currently Browsing” window at the top of your screen:\n\n\nknitr::include_graphics(\"images/change.png\")\n\n\n\n\nThen, select the “Family Planning - Person” unit of analysis in this menu:\n\n\nknitr::include_graphics(\"images/bchoose.png\")\n\n\n\n\nYou’ll need to create an extract that contains these samples (again, Female Respondents only):\nBurkina Faso 2020\nDemocratic Republic of Congo (DRC) 2019a - Kinshasa\nKenya\nNigeria 2019a - Kano\nNigeria 2019b - Lagos\nIn the example workflow shown below, we’ve downloaded both extracts and saved them together in the “data” folder of our R working directory. We’ve also installed and loaded the following packages:\n\n\nknitr::opts_chunk$set(echo = TRUE)\noptions(tibble.print_min = 30)\n\n\n\n\n\nlibrary(tidyverse)   # 1.3.1\nlibrary(broom)       # 0.7.6\nlibrary(ipumsr)      # 0.4.5\nlibrary(srvyr)       # 1.0.1\nlibrary(svyVGAM)     # 1.0\nlibrary(kableExtra)  # 1.3.4\nlibrary(ggalluvial)  # 0.12.3\nlibrary(dotwhisker)  # 0.6.0\n\n\n\nNow, we’ll load both of our data extracts into R. We’ll create two separate dataframes named covid and baseline (we’ll also edit the variable COUNTRY in each extract for additional clarity):\n\n\ncovid <- read_ipums_micro(\n  ddi = \"data/pma_00032.xml\",\n  data_file = \"data/pma_00032.dat.gz\"\n) %>% \n  mutate(COUNTRY = as_factor(COUNTRY %>% lbl_relabel(\n    lbl(2, \"DRC (Kinshasa)\") ~ .val == 2, \n    lbl(9, \"Nigeria (Lagos/Kano)\") ~ .val == 9\n  )))  \n\nbaseline <- read_ipums_micro(\n  ddi = \"data/pma_00039.xml\",\n  data_file = \"data/pma_00039.dat.gz\"\n) %>% \n  mutate(COUNTRY = as_factor(COUNTRY %>% lbl_relabel(\n    lbl(2, \"DRC (Kinshasa)\") ~ .val == 2, \n    lbl(9, \"Nigeria (Lagos/Kano)\") ~ .val == 9\n  )))  \n\n\n\nOne last thing here: we’ll be making several graphs to help illustrate our workflow in this post. We’ll create a custom theme theme_pma() for those graphs so that the fonts, colors, and other design elements match the overall look of this blog.\n\n\nlibrary(showtext)\nfont_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext_auto()\n\ntheme_pma <- function(title, subtitle = NULL, x = NULL, legend.position){\n  components <- list(\n    theme_minimal() %+replace% \n      theme(\n        text = element_text(family = \"cabrito\", size = 14), \n        plot.title = element_text(\n          size = 18, color = \"#00263A\", margin = margin(b = 10)\n        ), \n        plot.subtitle = element_text(\n          size = 16, color = \"#00263A\", margin = margin(b = 5)\n        ),\n        legend.title = element_blank(),        \n        legend.position = legend.position,\n        strip.text.y = element_text(size = 12, angle = 0),\n        panel.spacing = unit(2, \"lines\")\n      ),\n    scale_fill_manual(\n      values = alpha(\n        colour =  c(\n          \"#00263A\",   # IPUMS Navy\n          \"#7A99AC\",   # IPUMS Blue Grey\n          \"#BDD2DE\",   # IPUMS Medium Grey\n          \"#98579B\",   # PMA Pink\n          \"#CCBA72\",   # Tan\n          \"#81A88D\"    # Green\n        )\n      ),\n      na.value = \"#F0E6F0\"\n    ),\n    scale_color_manual(\n      values = alpha(\n        alpha = .85,   # .85 creates bars that are 15% transparent\n        colour = c(\n          \"#98579B\",   # PMA Pink\n          \"#00263A\"    # IPUMS Navy\n        )\n      )\n    ),\n    labs(\n      title = toupper(title), \n      subtitle = subtitle, \n      x = x, \n      y = NULL, \n      fill = NULL\n    ),\n    guides(fill = guide_legend(reverse = TRUE, byrow = TRUE))\n  )\n}\n\n\n\n\nWe discuss custom themes in detail here\nSampling Weights\nRemember that interviews for the baseline survey were administered in-person, but the covid interviews were administered via telephone. Suppose we ignored the sampling weight CVQWEIGHT completely: how might the requirement of access to a telephone bias the combined sample of women who participated in both surveys?\nLet’s take a look at a few of the demographic variables that appear in both baseline and covid. We’ll use imap_dfr() build a data frame by iterating over both of the data extracts, and we’ll use summarise() to create the following summary statistics:\nRESPONDENTS - the total number of women in the sample\nMEAN AGE - the mean age of women in the sample\nPCT URBAN - the percentage of sampled women living in “urban” areas\nPCT NO SCHOOL - the percentage of sampled women who “never attended” school\nPCT MARRIED - the percentage of sampled women who are currently married\n\n\nsamples_tbl <- list(baseline, covid) %>% \n  imap_dfr(\n    ~.x %>% \n      group_by(COUNTRY) %>%\n      summarise(\n        SAMPLE = if_else(.y == 1, \"baseline\", \"covid\"),\n        RESPONDENTS = n(),\n        `MEAN AGE` = mean(AGE),\n        `PCT URBAN` = 100 * mean(URBAN), \n        `PCT NO SCHOOL` = 100 * mean(EDUCATTGEN <= 2), \n        `PCT MARRIED` = 100 * mean(MARSTAT == 21) \n      ) \n  ) %>% \n  arrange(COUNTRY)\n\n\n\n\nThe variable URBAN is not available for the DRC sample, which represents the Kinshasa region. We’ll assume that all women in Kinshasa live in an “urban” area in our analysis below.\n\n\nsamples_tbl %>% kbl(digits = 1) \n\n\n\nCOUNTRY\n\n\nSAMPLE\n\n\nRESPONDENTS\n\n\nMEAN AGE\n\n\nPCT URBAN\n\n\nPCT NO SCHOOL\n\n\nPCT MARRIED\n\n\nBurkina Faso\n\n\nbaseline\n\n\n6765\n\n\n28.5\n\n\n59.9\n\n\n64.1\n\n\n59.6\n\n\nBurkina Faso\n\n\ncovid\n\n\n3528\n\n\n29.7\n\n\n74.7\n\n\n54.3\n\n\n62.0\n\n\nDRC (Kinshasa)\n\n\nbaseline\n\n\n2634\n\n\n28.3\n\n\nNA\n\n\n8.0\n\n\n26.6\n\n\nDRC (Kinshasa)\n\n\ncovid\n\n\n1324\n\n\n29.5\n\n\nNA\n\n\n3.3\n\n\n34.0\n\n\nKenya\n\n\nbaseline\n\n\n9549\n\n\n28.8\n\n\n35.3\n\n\n49.5\n\n\n53.5\n\n\nKenya\n\n\ncovid\n\n\n5986\n\n\n31.1\n\n\n38.2\n\n\n45.4\n\n\n62.1\n\n\nNigeria (Lagos/Kano)\n\n\nbaseline\n\n\n2627\n\n\n29.5\n\n\n76.4\n\n\n32.3\n\n\n62.0\n\n\nNigeria (Lagos/Kano)\n\n\ncovid\n\n\n1346\n\n\n31.4\n\n\n87.8\n\n\n16.3\n\n\n63.5\n\n\nComparing the two samples for each country, we see that the covid follow up represents a sub-sample of the baseline participants that is generally a bit older (adjusting for the passage of time), more urban, more educated, and are more likely to be currently married. If we built a multinomial model without sample weights, our predictions would reflect these biases as well.\nFortunately, the variable CVQWEIGHT corrects the baseline sample weight FQWEIGHT for predicted telephone access and other sources of loss to follow up. If we use the correct weights for each sample in our imap_dfr() function above, we should produce similar estimates for each sample’s target population:\n\nRead more about the construction of CVQWEIGHT here.\n\n\npopulations_tbl <- list(baseline, covid) %>% \n  imap_dfr(~{\n    if(\"FQWEIGHT\" %in% names(.x)){\n      wt <- \"FQWEIGHT\"\n    } else {\n      wt <- \"CVQWEIGHT\"\n    }\n    .x %>% \n      as_survey_design(weights = !!wt, ids = EAID) %>% \n      group_by(COUNTRY) %>% \n      summarise(\n        SAMPLE = if_else(.y == 1, \"baseline\", \"covid\"),\n        `MEAN AGE` = survey_mean(AGE, vartype = NULL),\n        `PCT URBAN` = 100 * survey_mean(URBAN, vartype = NULL), \n        `PCT NO SCHOOL` = 100 * survey_mean(EDUCATTGEN == 1, vartype = NULL), \n        `PCT MARRIED` = 100 * survey_mean(MARSTAT == 21, vartype = NULL)   \n      ) \n  }) %>% \n  arrange(COUNTRY)\n\n\n\nTip: If you would like to produce confidence intervals for each of these population-level estimates, use vartype == \"ci\". Note that EAID has no impact on the point estimates we’ve shown.\n\n\npopulations_tbl %>% kbl(digits = 1) \n\n\n\nCOUNTRY\n\n\nSAMPLE\n\n\nMEAN AGE\n\n\nPCT URBAN\n\n\nPCT NO SCHOOL\n\n\nPCT MARRIED\n\n\nBurkina Faso\n\n\nbaseline\n\n\n28.9\n\n\n22.8\n\n\n59.9\n\n\n68.6\n\n\nBurkina Faso\n\n\ncovid\n\n\n27.9\n\n\n21.4\n\n\n55.1\n\n\n68.9\n\n\nDRC (Kinshasa)\n\n\nbaseline\n\n\n28.3\n\n\nNA\n\n\n0.4\n\n\n27.0\n\n\nDRC (Kinshasa)\n\n\ncovid\n\n\n28.9\n\n\nNA\n\n\n0.4\n\n\n31.4\n\n\nKenya\n\n\nbaseline\n\n\n28.8\n\n\n30.2\n\n\n4.5\n\n\n53.3\n\n\nKenya\n\n\ncovid\n\n\n28.9\n\n\n27.5\n\n\n1.9\n\n\n54.3\n\n\nNigeria (Lagos/Kano)\n\n\nbaseline\n\n\n29.7\n\n\n72.1\n\n\n22.6\n\n\n64.1\n\n\nNigeria (Lagos/Kano)\n\n\ncovid\n\n\n30.4\n\n\n81.9\n\n\n9.8\n\n\n63.3\n\n\nHere, we’ve used as_survey_design() to specify the correct weight wt in each iteration of imap_dfr(). Then, we used survey_mean() to estimate the mean / proportion for each sample’s target population. Although you might observe some differences between the point estimates derived from baseline and covid, the systematic biases we identified in the samples are no longer present. This will be easier to see in a faceted lollipop plot where we chart both summary tables side-by-side.\n\n\npopulations_tbl %>%  \n  mutate(TBL = \"weighted\") %>% \n  rbind(\n    samples_tbl %>% select(-RESPONDENTS) %>% mutate(TBL = \"unweighted\")\n  ) %>% \n  pivot_longer(-c(COUNTRY, SAMPLE, TBL)) %>% \n  ggplot(aes(x = value, y = TBL, color = SAMPLE)) + \n  facet_grid(\n    rows = vars(COUNTRY), \n    cols = vars(name),\n    scale = \"free_x\",\n    as.table = TRUE\n  ) +\n  geom_point(size = 3) + \n  geom_line(aes(group = TBL), alpha = .5, color = \"#000000\") + \n  theme_pma(\"Sample design: weighted vs unweighted\", legend.position = \"top\")\n\n\n\n\nIn nearly every case, the gap between baseline and covid is narrower for the weighted population estimates than it is for the unweighted sample statistics.\nFor example, consider the summary statistic PCT URBAN. 59.9% of the women in the Burkina Faso baseline sample reside in urban areas, compared to 74.7% of women in the covid sample. That’s a 14.8% difference! With weights applied, we use baseline to estimate that only 22.8% of women in Burkina Faso actually live in urban areas; compare this to the 21.4% estimate produced from covid. The difference between the two population estimates is much smaller - just 1.4%.\nChange in purchasing power\nWe’ll now focus our attention only on the respondents who participated in both baseline and covid as we explore changes that occurred during the intervening months. We’ll create a merged dataset that contains one row per person and drops anyone who didn’t participate in the covid survey. We should also preserve duplicate variables - or variables that appear in both extracts; we’ll need to change their names so that it’s easy to determine which version came from which survey.\nEither left_join() or right_join() from the dplyr package can be used here; the only difference is that left_join() discards rows from the data provided to “y”, while right_join() discards rows from the data provided to “x” (we could put baseline in either position). We’ll use left_join().\nEach participant in baseline will have a unique identification code in FQINSTID that appears again in covid. So, we’ll tell left_join() to merge rows connected by the same FQINSTID with by = \"FQINSTID\"\nFinally, we’ll use the suffix argument to handle variables that appear in both extracts. For example, AGE from covid will be renamed AGE_CV, while AGE from baseline will be renamed AGE_BASE.\n\n\nmerged <- left_join(\n  x = covid,\n  y = baseline,\n  by = \"FQINSTID\",\n  suffix = c(\"_CV\", \"_BASE\")\n) \n\n\n\nThe variables we’ll use to construct our model’s dependent variable - HHDECDAILY and CVBUYDECIDER - will now appear together in the same row for each woman who participated in both surveys. For both variables, the universe is women who were currently married or living with male partner. Before we get started, let’s take a quick look at an alluvial plot showing the general shifts from one variable to the other:\n\n\nmerged %>% \n  select(FQINSTID, HHDECDAILY, CVBUYDECIDER) %>% \n  pivot_longer(!FQINSTID) %>% \n  mutate(\n    name = if_else(name == \"HHDECDAILY\", \"Before COVID-19\", \"Summer 2020\") %>% \n      as_factor() %>% \n      fct_rev(),\n    value = value %>% \n      as_factor() %>% \n      fct_recode(\n        \"Resdponent\" = \"1\", \"Husband/partner\" = \"2\", \"Joint\" = \"3\",\n        \"Someone else\" = \"4\", \"No response\" = \"98\", \"Not partnered\" =  \"99\"\n      ) %>% \n      fct_rev()\n  ) %>% \n  ggplot(aes(\n    x = name,\n    stratum = value,\n    fill = value,\n    alluvium = FQINSTID\n  )) + \n  geom_stratum(alpha = 0.7) + \n  geom_flow() +\n  coord_flip() + \n  theme_pma(\n    title = \"Who usually makes decisions about \\n household purchases for daily needs?\",\n    subtitle = \"Female respondents to the PMA baseline and COVID-19 surveys\",\n    legend.position = \"bottom\"\n  ) \n\n\n\n\nHere, we see that a majority of women who independently made purchasing decisions at baseline began either making decisions jointly or deferred to their husband/partner or someone else after COVID-19 restrictions began. At the same time, a sizable portion of the women who made decisions jointly at baseline no longer reported any role in the covid survey. We’ll say that all of these women have “Less” purchasing power when we create our dependent variable.\nSome women experienced change in the opposite direction: these include women who gained some authority after having none at baseline, and also women who previously made decisions jointly, but now bear bear full responsibility. We’ll say that these women have “More” purchasing power.\nFinally, all other women will be said to have the “Same” level of purchasing power unless either variable contains “No response or missing” or “NIU (not in universe)”. In the latter case, we’ll use the value NA. This means we will be analyzing a sample of women who were married or living with a male partner both before and during COVID-19 restrictions.\n\n\nmerged <- merged %>% \n   mutate(PURCHASE_PWR = factor(\n     case_when(\n       HHDECDAILY == 1 & CVBUYDECIDER %in% 2:4 ~ \"Less\",\n       HHDECDAILY == 3 & CVBUYDECIDER %in% c(2, 4) ~  \"Less\",\n       HHDECDAILY == 2 & CVBUYDECIDER %in% c(1, 3) ~ \"More\",\n       HHDECDAILY == 3 & CVBUYDECIDER == 1 ~ \"More\",\n       HHDECDAILY == 4 & CVBUYDECIDER %in% c(1, 3) ~ \"More\",\n       HHDECDAILY < 90 & CVBUYDECIDER < 90 ~ \"Same\"\n     ),\n     levels = c( \"Less\", \"Same\", \"More\")\n   ))\n\n\n\nMultinomial modeling\nLet’s now see what our derived variable PURCHASE_PWR can tell us about each sample’s target population. As shown above, we’ll again specify the sampling weight CVQWEIGHT and the cluster IDs - this time using the COVID-19 version in EAID_CV - as survey design information; we’ll then pass this information to a survey_mean() summary function to produce point-estimates and a cluster-robust 95% confidence interval for each level of PURCHASE_POWER. We’ll plot these estimates in a grouped bar chart, omitting the percentage of women who are not married / cohabitating with a partner.\n\nKeep in mind: only the Burkina Faso and Kenya samples are nationally representative. The DRC and Nigeria samples represent sub-national regions.\n\n\nmerged %>% \n  as_survey_design(\n    weights = CVQWEIGHT,\n    ids = EAID_CV\n  ) %>% \n  group_by(COUNTRY_BASE, PURCHASE_PWR) %>% \n  summarise(est = 100 * survey_mean(vartype = \"ci\")) %>% \n  filter(!is.na(PURCHASE_PWR)) %>% \n  ggplot(aes(x = COUNTRY_BASE, y = est, fill = PURCHASE_PWR)) + \n  geom_bar(width = .6, position = position_dodge(0.6), stat = \"identity\") +\n  geom_errorbar(\n    aes(ymin = est_low, ymax = est_upp),\n    width = 0.2,\n    position = position_dodge(0.6),\n    alpha = 0.5\n  ) + \n  theme_pma(\n    title = \"Net change in purchasing power for daily needs\",\n    subtitle = \"Estimated percentages for populations of women age 15-49\",\n    legend.position = \"bottom\"\n  ) + \n  coord_flip()\n\n\n\n\nThe percentage of women in each population who gained “More” purchasing power after COVID-19 restrictions began is significantly lower than the percentage of women who maintained the “Same” or experienced “Less” purchasing power (we know this because the 95% confidence intervals do not overlap). The comparison between “Same” and “Less” is not so clear: while the point estimates suggest that there may be fewer women with “Less” purchasing power, the difference is not statistically significant (except in Kenya, where the two confidence intervals do not overlap).\nTo demonstrate a multinomial model for these outcomes, we’ll select a set of variables that describe demographic features and economic circumstances for each woman. As a reminder: for variables that appeared in both baseline and covid, we’ll need to specify which to include in our model by appending the suffix _BASE or _CV - for the most part, we’ll use the baseline version. We’ll include these covariates (modifying / recoding as needed):\nAGE_BASE - age at baseline\nURBAN_BASE - lived in an urban area at baseline: TRUE or FALSE\nWEALTHT - wealth score tertile: Highest, Middle, Lowest (reference group)\nRELIGION - religion of the household head recoded as Muslim, Christian, Other (reference group)\nPARTNERECON indicates whether married / partnered women said on the covid survey that there were “currently economically reliant” on their husband / partner for basic needs: TRUE or FALSE\nWORKWK indicates whether women indicated on the baseline survey that she had done any work outside the home in the past week: TRUE or FALSE\n\n\nmerged <- merged %>% \n  mutate(\n    RELIGION = factor(\n      case_when(\n        RELIGION == 100 ~ \"Muslim\",\n        RELIGION %in% 200:300 ~ \"Christian\",\n        RELIGION < 990 ~ \"Other\"\n      ),\n      levels = c(\"Other\", \"Muslim\", \"Christian\")\n    ),\n    WEALTHT = as_factor(WEALTHT),\n    URBAN_BASE = case_when(\n      COUNTRY_BASE == \"DRC (Kinshasa)\" ~ TRUE,\n      URBAN_BASE == 1 ~ TRUE,\n      URBAN_BASE == 0 ~ FALSE\n    ),\n    across(c(PARTNERECON, WORKWK), ~case_when(\n      .x == 1 ~ TRUE,\n      .x == 0 ~ FALSE\n    ))\n  ) \n\n\n\nThe svyVGAM package can interpret the very same call to as_survey_design() shown above. We’ll use the generic modeling function svy_vglm() to build our model; it looks similar to the svyglm function we’ve used to build linear and binary logit models elsewhere, except that the argument family takes a function describing the type of model we want to fit. Use multinomial(refLevel = \"Same\") to specify a multinomial model with “Same” as a reference group:\n\nSee package documentation for other supported modeling functions\n\n\npma_model <- merged %>%  \n  as_survey_design(\n    weights = CVQWEIGHT,\n    id = EAID_CV\n  ) %>% \n  svy_vglm(\n    formula = PURCHASE_PWR ~ \n      AGE_BASE +\n      RELIGION +\n      WEALTHT +\n      URBAN_BASE +\n      PARTNERECON + \n      WORKWK + \n      COUNTRY_BASE,\n    design = ., \n    family = multinomial(refLevel = \"Same\")\n  ) \n\n\n\nOne drawback here is that the output of a model created by svyVGAM (or by the VGAM package) cannot be handled by broom::tidy(), which we normally use to clean and standardize model output. Fortunately, broom contains a non-exported function that’s capable of handling something similar: the model output created by svyglm() from the sibling survey package! You’ll find it in the broom namespace if you use ::: like so:\n\n\nbroom:::tidy.svyglm\n\n\nfunction (x, conf.int = FALSE, conf.level = 0.95, exponentiate = FALSE, \n    ...) \n{\n    ret <- as_tibble(summary(x)$coefficients, rownames = \"term\")\n    colnames(ret) <- c(\"term\", \"estimate\", \"std.error\", \"statistic\", \n        \"p.value\")\n    coefs <- tibble::enframe(stats::coef(x), name = \"term\", value = \"estimate\")\n    ret <- left_join(coefs, ret, by = c(\"term\", \"estimate\"))\n    if (conf.int) {\n        ci <- broom_confint_terms(x, level = conf.level, ...)\n        ret <- dplyr::left_join(ret, ci, by = \"term\")\n    }\n    if (exponentiate) {\n        ret <- exponentiate(ret)\n    }\n    ret\n}\n<bytecode: 0x7fa8c8dd3528>\n<environment: namespace:broom>\n\nWe’ll modify this function a bit, creating our own tidy method tidy.svyVGAM() (you may need to make modifications for general use):\n\n\ntidy.svyVGAM <- function(\n  x, \n  conf.int = FALSE, \n  conf.level = 0.95,\n  exponentiate = FALSE, \n  ...\n){\n  # Replace `summary(x)$coefficients` with `summary(x)$coeftable`\n  ret <- as_tibble(summary(x)$coeftable, rownames = \"term\")\n  \n  # All of this stays the same:\n  colnames(ret) <- c(\"term\", \"estimate\", \"std.error\", \"statistic\", \"p.value\")\n  coefs <- tibble::enframe(stats::coef(x), name = \"term\", value = \"estimate\")\n  ret <- left_join(coefs, ret, by = c(\"term\", \"estimate\"))\n  if (conf.int){\n    ci <- broom:::broom_confint_terms(x, level = conf.level, ...)\n    ret <- dplyr::left_join(ret, ci, by = \"term\")\n  }\n  if (exponentiate){ret <- broom:::exponentiate(ret)}\n  \n  # This part only works for the multinomial case, and only if your covariates\n  # have no \":\" in their names - NOT FOR GENERAL USE\n  ret %>% \n    separate(term, into = c(\"term\", \"y.level\"), sep = \":\") %>% \n    arrange(y.level) %>% \n    relocate(y.level, .before = term)\n}\n\n\n\nNow, let’s look at our model results. We’ll exponentiate our coefficients, add significance “stars”, and label each y.level manually to make this table easier to read:\n\n\ntidy_pma_model <- tidy.svyVGAM(pma_model, exponentiate = TRUE, conf.int = TRUE)\n\n\n\n\n\ntidy_pma_model %>% \n  select(-y.level) %>% \n  rename(PURCHASE_PWR = term) %>% \n  mutate(sig = case_when(\n    p.value < 0.001 ~ \"\\\\*\\\\*\\\\*\",\n    p.value < 0.01 ~ \"\\\\*\\\\*\",\n    p.value < 0.05 ~ \"\\\\*\",\n    T ~ \"\"\n  )) %>% \n  kbl(digits = 3) %>% \n  pack_rows(\"Less\", 1, 12) %>% \n  pack_rows(\"More\", 13, 24)\n\n\n\nPURCHASE_PWR\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\nconf.low\n\n\nconf.high\n\n\nsig\n\n\nLess\n\n\n(Intercept)\n\n\n1.102\n\n\n0.302\n\n\n0.322\n\n\n0.747\n\n\n0.609\n\n\n1.994\n\n\n\n\nAGE_BASE\n\n\n1.001\n\n\n0.005\n\n\n0.100\n\n\n0.920\n\n\n0.991\n\n\n1.011\n\n\n\n\nRELIGIONMuslim\n\n\n0.602\n\n\n0.212\n\n\n-2.398\n\n\n0.016\n\n\n0.398\n\n\n0.912\n\n\n*\n\n\nRELIGIONChristian\n\n\n0.823\n\n\n0.149\n\n\n-1.312\n\n\n0.189\n\n\n0.615\n\n\n1.101\n\n\n\n\nWEALTHTMiddle tertile\n\n\n0.875\n\n\n0.107\n\n\n-1.244\n\n\n0.214\n\n\n0.709\n\n\n1.080\n\n\n\n\nWEALTHTHighest tertile\n\n\n0.939\n\n\n0.121\n\n\n-0.523\n\n\n0.601\n\n\n0.741\n\n\n1.189\n\n\n\n\nURBAN_BASETRUE\n\n\n1.176\n\n\n0.116\n\n\n1.398\n\n\n0.162\n\n\n0.937\n\n\n1.476\n\n\n\n\nPARTNERECONTRUE\n\n\n1.465\n\n\n0.094\n\n\n4.055\n\n\n0.000\n\n\n1.218\n\n\n1.762\n\n\n***\n\n\nWORKWKTRUE\n\n\n1.158\n\n\n0.084\n\n\n1.756\n\n\n0.079\n\n\n0.983\n\n\n1.365\n\n\n\n\nCOUNTRY_BASEDRC (Kinshasa)\n\n\n0.585\n\n\n0.221\n\n\n-2.429\n\n\n0.015\n\n\n0.380\n\n\n0.902\n\n\n*\n\n\nCOUNTRY_BASEKenya\n\n\n0.676\n\n\n0.156\n\n\n-2.503\n\n\n0.012\n\n\n0.497\n\n\n0.919\n\n\n*\n\n\nCOUNTRY_BASENigeria (Lagos/Kano)\n\n\n0.763\n\n\n0.201\n\n\n-1.348\n\n\n0.178\n\n\n0.514\n\n\n1.131\n\n\n\n\nMore\n\n\n(Intercept)\n\n\n0.677\n\n\n0.306\n\n\n-1.277\n\n\n0.201\n\n\n0.372\n\n\n1.232\n\n\n\n\nAGE_BASE\n\n\n0.991\n\n\n0.006\n\n\n-1.451\n\n\n0.147\n\n\n0.980\n\n\n1.003\n\n\n\n\nRELIGIONMuslim\n\n\n1.525\n\n\n0.240\n\n\n1.760\n\n\n0.078\n\n\n0.953\n\n\n2.439\n\n\n\n\nRELIGIONChristian\n\n\n1.069\n\n\n0.207\n\n\n0.321\n\n\n0.749\n\n\n0.712\n\n\n1.603\n\n\n\n\nWEALTHTMiddle tertile\n\n\n0.941\n\n\n0.122\n\n\n-0.494\n\n\n0.621\n\n\n0.741\n\n\n1.196\n\n\n\n\nWEALTHTHighest tertile\n\n\n0.773\n\n\n0.140\n\n\n-1.848\n\n\n0.065\n\n\n0.588\n\n\n1.016\n\n\n\n\nURBAN_BASETRUE\n\n\n1.266\n\n\n0.129\n\n\n1.824\n\n\n0.068\n\n\n0.983\n\n\n1.631\n\n\n\n\nPARTNERECONTRUE\n\n\n0.693\n\n\n0.107\n\n\n-3.420\n\n\n0.001\n\n\n0.562\n\n\n0.855\n\n\n***\n\n\nWORKWKTRUE\n\n\n0.638\n\n\n0.107\n\n\n-4.209\n\n\n0.000\n\n\n0.518\n\n\n0.787\n\n\n***\n\n\nCOUNTRY_BASEDRC (Kinshasa)\n\n\n0.739\n\n\n0.233\n\n\n-1.297\n\n\n0.195\n\n\n0.468\n\n\n1.167\n\n\n\n\nCOUNTRY_BASEKenya\n\n\n0.901\n\n\n0.149\n\n\n-0.704\n\n\n0.482\n\n\n0.673\n\n\n1.205\n\n\n\n\nCOUNTRY_BASENigeria (Lagos/Kano)\n\n\n0.918\n\n\n0.203\n\n\n-0.420\n\n\n0.675\n\n\n0.617\n\n\n1.367\n\n\n\n\nOnce you’ve got the model output in a tidy format, you can also pass it to a tidyverse aligned graphing function, like the popular dwplot from dotwhisker:\n\n\ntidy_pma_model %>% \n  mutate(\n    model = if_else(\n      y.level == 1, \n      \"Less Purchasing Power\",\n      \"More Purchasing Power\", \n    ),\n    sig = gtools::stars.pval(p.value)\n  ) %>%\n  relabel_predictors(c(\n    AGE_BASE = \"Age at baseline\",\n    RELIGIONMuslim = \"Muslim Head of Household\",\n    RELIGIONChristian = \"Christian Head of Household\",\n    `WEALTHTMiddle tertile` = \"Middle Wealth Tertile\",\n    `WEALTHTHighest tertile` = \"Highest Wealth Tertile\",\n    URBAN_BASETRUE = \"Urban Residence\",\n    `COUNTRY_BASEDRC (Kinshasa)` = \"DRC (Kinshasa)\",\n    COUNTRY_BASEKenya = \"Kenya\",\n    `COUNTRY_BASENigeria (Lagos/Kano)` = \"Nigeria (Lagos/Kano)\",\n    PARTNERECONTRUE = \"Reliant on partner\",\n    WORKWKTRUE = \"Work outside home\"\n  )) %>% \n  dotwhisker::dwplot(\n    dodge_size = 0.3,\n    vline = geom_vline(xintercept = 1, colour = \"grey60\", linetype = 2)\n  ) + \n  guides(color = guide_legend(reverse = TRUE)) + \n  theme_pma(\n    title = \n      \"Which factors impact women's purchasing power during COVID-19?\", \n    subtitle = \n      'Odds ratios relative to \"no change\" (95% CI)',\n    legend.position = \"top\"\n  ) \n\n\n\n\nBecause we’ve exponentiated the coefficients produced by this model, each estimate shows how each covariate changes the odds of experiencing a given level of PURCHASE_PWR relative to the reference group of women who maintained the same level of autonomy since COVID-19 restrictions began. For example, an estimate of 1.0 would indicate equal odds, 2.0 would indicate double odds, and so on.\nGenerally, the effects of demographic factors in our model are pretty limited. For example, notice the proximity of both AGE_BASE estimates to 1.0. Each additional year of age at baseline is estimated to change the odds that a woman would experience “Less” purchasing power by just 0.001 - or 0.1%; this is not a statistically significant difference from 1.0, as you’ll notice that the 95% confidence interval includes values both above and below “equal odds”. The “More” estimate for AGE_BASE tells a similar story: while we estimate that each year of age at baseline contributes to a 0.9% drop in the odds that a woman would gain “More” purchasing power, this difference is not sufficiently far enough from “equal odds” to indicate statistical significance. Perhaps surprisingly, neither of the variables AGE_BASE, WEALTHT, or URBAN_BASE are significant predictors for any outcome of PURCHASE_PWR.\nOn the other hand, we see some evidence that RELIGION may have a more meaningful impact, particularly for women living with a Muslim head of household. The estimated odds that such a woman would lose purchasing power are just 60.2% of the estimated odds that she would maintain the same level. Meanwhile, her estimated odds for gaining power are 152.5% - or about one and a half times higher than - her odds of maintaining the same level. The former estimate includes a 95% confidence interval that includes no values above 1.0, but the interval for the latter estimate just barely overlaps with 1.0. Hence, only the estimate for “Less” purchasing power meets the formal requirement for statistical significance.\nCompared to demographic factors, the economic factors we’ve selected are much more powerful predictors for all levels of PURCHASE_PWR. Controlling for household wealth via WEALTHT, women who indicated on the COVID-19 survey that they were currently economically reliant on their husband/partner were both likely to have lost purchasing power, and unlikely to have gained it. Meanwhile, women who indicated on the baseline survey that they recently worked outside the home were somewhat likely to lose purchasing power, while they were unlikely to gain more. Three of the four estimates from these variables were statistically significant even at the 99.9% confidence threshold.\nHow might these conclusions change if we hadn’t bothered to include CVQWEIGHT and EAID_CV? Without CVQWEIGHT, the point estimates for each of our covariates would shift in a direction reflecting the sample biases in the COVID-19 survey. Sample cluster information specified by EAID_CV doesn’t change those point estimates, but it does impact the estimated standard error for each point estimate; if we had omitted EAID_CV, we would have generally underestimated standard error, leading to confidence intervals that are too narrow. Fortunately, the new svyVGAM package made it incredibly easy to incorporate both survey design elements into our multinomial model.\nWrap-up\nThe four samples we’ve been examining throughout this summer-long series on PMA COVID-19 data are just one part of a larger panel study you’ll find on the IPUMS PMA website in the months and years ahead. You’ll find information about samples from other countries and plans for additional follow-up surveys on the PMA survey methodology page.\nHere at the PMA Data Analysis Hub, we plan to change gears in the coming weeks as we begin a new series on PMA Nutrition Data. However, we’ll continue to focus on COVID-19 data when new surveys become available. For updates, keep an eye on the New Data tag or look for us on Twitter.\n\n\n\n",
    "preview": "posts/2021-08-15-covid-analysis/images/alluvial.png",
    "last_modified": "2022-04-13T13:10:46-04:00",
    "input_file": {},
    "preview_width": 1422,
    "preview_height": 714
  },
  {
    "path": "posts/2021-08-07-pma-intro/",
    "title": "New Online Course: Introduction to IPUMS PMA Data Analysis",
    "description": "Explore IPUMS PMA data with R right in your browser, or download Stata code for offline practice",
    "author": [],
    "date": "2021-08-07",
    "categories": [],
    "contents": "\nToday, we’re proud to announce the launch of a brand new feature on the IPUMS PMA Data Analysis Hub: our very first online course!\nWhether you’re a beginner-level data analyst exploring statistical software for the first time, or if you’re a more advanced analyst looking for a guided tour of IPUMS PMA data, we think our new Introduction to IPUMS PMA Data Analysis is a great place to start. Over time, we’ll add courses on more advanced topics in the new Courses menu in the navigation bar at the top of your screen.\n\n\n\n\nClick here to get started\nWe expect most people will probably need about an hour to complete the Introduction course, but you’re welcome to work at your own pace. You can also leave and resume your progress at any time.\nUpon completion, we offer a downloadable certificate signed by the IPUMS PMA team, plus a script containing all of the code you mastered during the course.\nRequirements\nIPUMS PMA data are free to use, and all of our online courses will be free, as well. To get started, you just need to register and agree to our Terms of Use.\nWe’ve created exercises for both R and Stata users, so you’ll need to choose a preferred language at the start of each course.\nR users: you’ll find an embedded R console where you can practice coding exercises right in your browser. We’ve pre-installed all of the packages necessary to complete each exercise, and you’ll receive interactive feedback to help you identify any mistakes along the way.\nStata users: you’ll need access to a copy of the Stata program. We’ll provide example code that you’ll run offline, and you’ll need to use the output from Stata to answer multiple choice questions in our “guided practice” section.\n\nWe’re able to offer interactive practice and feedback to R users thanks to the amazing learnr and gradethis packages for R.\nIPUMS PMA courses are hosted by Qualtrics, so you may need to deactive your browser’s ad blocker in order see course content. If you have any difficulties, please contact us!\n\n\n\n",
    "preview": "posts/2021-08-07-pma-intro/../../images/new_course.png",
    "last_modified": "2022-04-13T13:10:46-04:00",
    "input_file": {},
    "preview_width": 2999,
    "preview_height": 1687
  },
  {
    "path": "posts/2021-08-01-covid-batches/",
    "title": "Three ways to visualize binary survey data",
    "description": "You can compare levels of trust and efficacy for 13 information sources in 4 countries with data from the new PMA COVID-19 survey. Let's talk data visualization options.",
    "author": [
      {
        "name": "Tayler Nelson",
        "url": {}
      },
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-08-01",
    "categories": [
      "COVID-19",
      "Data Visualization",
      "ggplot2",
      "fmsb",
      "Bar Charts",
      "Lollipop Charts",
      "Radar Charts"
    ],
    "contents": "\n\nContents\nSetup\nLogical variables\nUsing dplyr::across\n\nPre-processing\nSummary Table\nPlot theme\n\nBar Charts\nLollipop Chart\nRadar Chart\nWrap-up\n\nIn our last post, we discussed some of the strategies you might use to compare items from the PMA COVID-19 questionnaire that use a Likert-type response scale. Another type of question used in the COVID-19 survey - and all PMA surveys - follows the “select all that apply” format. Responses from this type of question appear as a series of related binary (“yes” or “no”) variables on the IPUMS PMA website.\nIn this post, we’ll go over some of the strategies you might use to process and synthesize data from a large number of related variables, like those created from “select all that apply” style questions. First, we’ll review one of our favorite tools for manipulating lots of variables at once: the across function from dplyr. Then, we’ll explore our data in three different layouts: the faceted bar chart, the lollipop chart, and the beautiful (if controversial) radar chart.\nAs we’ll see, each of these three layouts makes it possible to compare multiple questions posed with the same list of “select all that apply” response options. In our case, we’ll look at two questions that are each related to sources of information about COVID-19. Because both questions feature the same list of 13 possible information sources, we’ll be working with 26 variables in total:\n202. How did you learn about Coronavirus (COVID-19)? Select all that apply:\n\n[] Newspaper\n[] Radio\n[] Television\n[] Poster / billboard\n[] Town crier\n[] Phone message\n[] Family\n[] Friends / neighbors\n[] Community/religious leaders\n[] Social media (Twitter, Facebook, WhatsApp)\n[] Health personnel\n[] Messages from government or authorities\n[] School\n[] None of the above\n[] No response\n204. Which of these sources do you trust for accurate information about\nCoronavirus (COVID-19)? Select all that apply:\n\n[] Newspaper\n[] Radio\n[] Television\n[] Poster / billboard\n[] Town crier\n[] Phone message\n[] Family\n[] Friends / neighbors\n[] Community/religious leaders\n[] Social media (Twitter, Facebook, WhatsApp)\n[] Health personnel\n[] Messages from government or authorities\n[] School\n[] None of the above\n[] No response\nSetup\nBefore we think about how to visualize the responses to both of these questions, we’ll need to change a few things about the way they’re coded in each of the 26 corresponding variables. Suppose we’ve downloaded an extract from the IPUMS PMA website (all four samples, Female Respondents only) and we’ve put it in the “data” folder in our working directory. We’ll load a few packages (which you’ll need to install if you haven’t done so before), and we’ll load the extract into R:\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\nlibrary(srvyr)\nlibrary(showtext)\nlibrary(gtsummary)\nlibrary(fmsb)\n\ncovid <- read_ipums_micro(\n  ddi = \"data/pma_00032.xml\",\n  dat = \"data/pma_00032.dat.gz\"\n)\n\n\n\nYou’ll find that all of the variables derived from the response options for the first question (“How did you learn about Coronavirus (COVID-19)?”) share the same prefix CVLEARN, and all of the variables derived from the response options from the second question (“Which of these sources do you trust for accurate information about Coronavirus (COVID-19)?”) share the same prefix CVTRUST. For example, you’ll find the responses for “Newspaper” recorded in CVLEARNNEWS and CVTRUSTNEWS.\n\nHarmonized data from IPUMS will feature patterned variable names wherever possible. This makes it easy to apply a function over several related variables.\nTaking a look at a variable like CVTRUSTNEWS, you’ll notice that these variables contain several different top-codes associated with different reasons for non-response:\n\n\ncovid %>% count(CVTRUSTNEWS)\n\n\n# A tibble: 5 x 2\n                  CVTRUSTNEWS     n\n                    <int+lbl> <int>\n1  0 [No]                      7071\n2  1 [Yes]                     4886\n3  2 [None of the above]        208\n4 98 [No response or missing]    10\n5 99 [NIU (not in universe)]      9\n\nThe top-codes 98 and 99 should be familiar to regular IPUMS data users: they represent women who selected the “No response” option, and women who were ineligible to respond (see the Universe tab). The code 2 represents women who trust “None of the above” sources, including “Newspaper”.\nImportantly, the number of women who selected codes 2, 98, and 99 will be the same for all variables derived from the same “select all that apply” question. While there are some analytic contexts where you might want to identify women who selected “None of the above”, this information could be collapsed with “No” responses in our plots. The simplest way to visualize data from these variables is to first transform them into simple binary indicators taking the logical values TRUE, FALSE, or NA.\nLogical variables\nIn previous posts, we’ve suggested changing labelled variables into factors for most data visualization and analysis applications. That’s because IPUMS value labels won’t appear in graphics or model summary output by default; you’ll instead see the numeric codes associated with each response (0, 1, 2, 98, 99, etc).\nBinary variables are different: it’s not always necessary to plot both the “Yes” and “No” responses, and this is particularly true where the non-response frequency is low. Look at this stacked bar chart that includes all of the available response categories, including non-response options:\n\n\n\nThe non-response options barely appear on the plot at all: they comprise less than 1% of the respondents for each sample, so their presence in the legend adds unnecessary clutter. Meanwhile, the options “No” and “None of the above” could be collapsed into a single response; however, because we’ll be plotting 26 variables like this one, we’ll find that plotting only the “Yes” responses will provide much needed visual space to the final chart. In other words, we’ll rely on the reader to infer “No” responses through the use of negative space.\nBecause we plan to plot only the proportion of “Yes” responses in each variable, we won’t need value labels displayed in a legend. This makes it unnecessary to convert our variables into factors. Instead, we’ll convert our variables into logical objects that take the values TRUE, FALSE, or NA. As we’ll see, this makes it easy to pre-filter only the cases where our variables of interest were coded 1 for “Yes”.\nAnother reason you should avoid creating binary factors is that factors are not meaningful in certain mathematical contexts. For example, we might want to exploit the mean of a binary variable as a handy way to generate the proportion of women who responded “Yes”. This won’t work if you create a factor:\n\n\nmy_factor <- factor(c(1, 0, 1))\nmean(my_factor)\n\n\n[1] NA\n\nLogical objects behave like integers in mathematical evaluation: every TRUE value is automatically treated as the value 1, and every FALSE value is automatically treated as the value 0.\n\n\nmy_logical <- c(TRUE, FALSE, TRUE)\nmean(my_logical)\n\n\n[1] 0.6666667\n\nConverting labelled integer variables into logical variables is simple, but you must first remove value labels with the function zap_labels(). Here, we’ll also want to collapse code 2 together with code 0, and we’ll adopt the value NA for non-response codes 98 and 99. If we were working with just one variable (like CVTRUSTNEWS), we could combine all of these steps together in a single mutate() function like this:\n\n\nrecoded <- covid %>% \n  mutate(\n    CVTRUSTNEWS = CVTRUSTNEWS %>% \n      lbl_collapse(~if_else(.val == 2, 0L, .val)) %>%\n      lbl_na_if(~.val %in% 98:99) %>% \n      zap_labels() %>% \n      as.logical()\n  )\n\n\n\n\n\n\n\n© 2017 (MPL 2.0)\n\n\nrecoded %>% count(CVTRUSTNEWS)\n\n\n# A tibble: 3 x 2\n  CVTRUSTNEWS     n\n  <lgl>       <int>\n1 FALSE        7279\n2 TRUE         4886\n3 NA             19\n\nHowever, we’ll want to apply the same changes to all of the 26 variables we’ve discussed. It would be tedious to manually recode 26 variables in series, and it would also be difficult to make changes if we needed to do so later. Instead, we’ll change all of our variables in one step using the across() function from dplyr.\nUsing dplyr::across\nYou can use across() inside mutate() to edit variables “in place”, which means that it is unnecessary to assign every recoded variable to its old name with a line like CVTRUSTNEWS = CVTRUSTNEWS. The first argument in across() specifies the variable(s) to be modified, and the second argument specifies how you’ll modify them (an optional third argument .names can be used to create new variable names, preserving the original variables under their old names if desired). For example, this code is equivalent to the code shown above:\n\n\nrecoded <- covid %>% \n  mutate(across(\n    CVLEARNNEWS,\n    ~.x %>% \n      lbl_collapse(~if_else(.val == 2, 0L, .val)) %>%\n      lbl_na_if(~.val %in% 98:99) %>% \n      zap_labels() %>% \n      as.logical()\n  ))\n\n\n\nYou can use anonymous functions throughout the tidyverse using the symbol ~ and the pronoun .x.\nHere .x represents each of the variables selected for manipulation with across().\nOf course, the entire purpose of across() is to apply a function to multiple variables. You can use tidy selection to identify variables, which means you provide variable names in a vector without quotation marks (e.g. c(CVTRUSTNEWS, CVTRUSTTV, CVTRUSTRADIO)), or you can use the following selection helpers:\neverything() Matches all variables\nlast_col() Select the last variable, possibly with an offset\nstarts_with() Starts with a prefix\nends_with() Ends with a suffix\ncontains() Contains a literal string\nmatches() Matches a regular expression\nnum_range() Matches a numerical range like x01, x02, x03\n\n\n\n\n© 2018 RStudio (CC0 1.0)\nWe’ll use the “or” operator | to manipulate any variable that starts_with(\"CVTRUST\") or starts_with(\"CVLEARN\"):\n\n\ncovid <- covid %>% \n  mutate(across(\n    starts_with(\"CVTRUST\") | starts_with(\"CVLEARN\"),\n    ~.x %>% \n      lbl_collapse(~if_else(.val == 2, 0L, .val)) %>%\n      lbl_na_if(~.val %in% 98:99) %>% \n      zap_labels() %>% \n      as.logical()\n  ))\n\n\n\nPre-processing\nNow that we’ve recoded all 26 variables as logical objects, we’ll take two additional pre-processing steps to prepare our data for visualization:\nAs discussed in our last post, we’ll pre-calculate the summary statistics we’d like to display in our plots. We’ll store this information in a table called summary.\nWe’ll build a custom theme for ggplot2 that uses colors, fonts, and layout conventions matching the overall design of this blog. We’ll call this theme_pma(), and we’ll pipe it into the code used to create our charts below.\nSummary Table\nWith a little practice, most of us can visualize the final chart we want to create. Visualizing the intermediate data format we’ll need to build that chart can be much harder!\nParticularly for beginners, we think it’s important to start with a list of all the dimensions you think you might want to display in your plot. Then, plan to construct a summary table that includes one column for each dimension. Any column containing text should be formatted exactly as you want it to be shown in your final plot. For example,\nOur data come from two “select all that apply” questions with an identicial list of response options. Let’s list each response option in a column called SOURCE (as in “source of information”), and we’ll identify the original question with “CVTRUST” or “CVLEARN” in a second column called QUESTION.\nWe’ll include the third column called COUNTRY so that we can break down responses by country (we’ll also note the sub-national region for samples that are not nationally representative).\nFor each QUESTION, we’ll calculate a weighted population-level estimate for the proportion of women who trust / learned about COVID-19 from each SOURCE in each COUNTRY. We’ll store point-estimates in a column called EST, and we’ll store the upper and lower limits of a 95% confidence interval in UPP and LOW, respectively.\nLastly, we should create readable labels for each QUESTION in a column that we’ll call QTEXT.\nWe’ll use map_df() from the purrr package to build this table by iterating through all of the variables containing the prefixes “CVTRUST” and “CVLEARN”.\n\n\nsummary <- map_df(\n  # The first argument of `map_df()` is a vector we'd like the iterate\n  # through. \n  c(\"CVTRUST\", \"CVLEARN\"),\n  \n  # The second argument of `map_df()` is a function applied in each \n  # iteration. When you see `.x` below, it refers to the strings \"CVTRUST\" or\n  # \"CVLEARN\".\n  ~covid %>% \n    \n    # Convert COUNTRY to a factor with edited labels\n    mutate(\n      COUNTRY = COUNTRY %>% \n        as_factor() %>% \n        fct_recode(\n          `DRC (Kinshasa)` = \"Congo, Democratic Republic\",\n          `Nigeria (Lagos & Kano)` = \"Nigeria\"\n        ) %>% \n        fct_drop()\n    ) %>% \n    \n    # Specify survey design information with `CVQWEIGHT` and `EAID`\n    as_survey_design(weight = CVQWEIGHT, id = EAID) %>% \n    \n    # Estimate the proportion of TRUE responses for every source (by COUNTRY)\n    group_by(COUNTRY) %>% \n    summarise(across(\n      starts_with(.x),\n      function(var){100 * survey_mean(var, vartype = \"ci\", na.rm = T)}\n    )) %>% \n    \n    # Add the suffix \"_EST\" to each point estimate\n    # Ensure that all variable names use upper-case\n    rename_with(~paste0(.x, \"_EST\"), !contains(\"_\") & !COUNTRY) %>% \n    rename_with(~toupper(.x), everything()) %>% \n    \n    # Up to this point, each source has three columns: the point estimate,\n    # and the upper and lower-limits of the 95% confidence interval. We will \n    # use `pivot_longer` to store each source in a separate row. Each source\n    # label will appear in a new column called `SOURCE`.\n    pivot_longer(\n      !COUNTRY,\n      names_pattern = paste0(.x, \"(.*)_(.*)\"),\n      names_to = c(\"SOURCE\", \".value\"),\n      values_to = \"PCT\"\n    ) %>%\n    \n    # Relabel `SOURCE` with the labels we want to appear on our plots.\n    mutate(\n      SOURCE = SOURCE %>%\n        as_factor() %>%\n        fct_recode(\n          `Family` = \"FAM\",\n          `Radio` = \"RADIO\",\n          `TV` = \"TV\",\n          `Poster / Billboard` = \"POSTER\",\n          `Town Crier` = \"CRIER\",\n          `Phone Message` = \"PHONE\",\n          `Community Leaders` = \"LEADER\",\n          `Health Workers` = \"HW\",\n          `Social Media` = \"SOCMEDIA\",\n          `Friends / Neighbors` = \"FRIEND\",\n          `Government` = \"GOV\",\n          `School` = \"SCHOOL\",\n          `Newpaper` = \"NEWS\"\n        )\n    ) %>% \n  \n  # Finally, create `QUESTION` to hold the string represented by `.x`, and \n  # QTEXT to hold the text labels that we'll use to identify the \n  # original survey question on our plot\n  mutate(QUESTION = .x, .before = SOURCE) %>% \n  mutate(QTEXT = case_when(\n    QUESTION == \"CVTRUST\" ~ \"Which do you trust for COVID-19 information?\",\n    QUESTION == \"CVLEARN\" ~ \"How did you learn about COVID-19?\"\n  ))\n) \n\n\n\n\n\n\n\n© RStudio (CC0 1.0)\nThe resulting table has one row for each unique combination of COUNTRY, QUESTION, and SOURCE.\n\n\nsummary\n\n\n# A tibble: 104 x 7\n   COUNTRY    QUESTION SOURCE       EST   LOW   UPP QTEXT             \n   <fct>      <chr>    <fct>      <dbl> <dbl> <dbl> <chr>             \n 1 Burkina F… CVTRUST  Family      73.3  68.0  78.7 Which do you trus…\n 2 Burkina F… CVTRUST  Friends /…  67.6  62.2  73.0 Which do you trus…\n 3 Burkina F… CVTRUST  Government  76.8  69.4  84.2 Which do you trus…\n 4 Burkina F… CVTRUST  Health Wo…  89.0  85.5  92.5 Which do you trus…\n 5 Burkina F… CVTRUST  Community…  74.3  69.4  79.2 Which do you trus…\n 6 Burkina F… CVTRUST  Newpaper    45.6  39.0  52.3 Which do you trus…\n 7 Burkina F… CVTRUST  Phone Mes…  50.0  44.6  55.5 Which do you trus…\n 8 Burkina F… CVTRUST  Poster / …  54.6  48.6  60.5 Which do you trus…\n 9 Burkina F… CVTRUST  Radio       90.7  88.1  93.3 Which do you trus…\n10 Burkina F… CVTRUST  School      67.2  60.0  74.4 Which do you trus…\n11 Burkina F… CVTRUST  Social Me…  38.3  33.0  43.5 Which do you trus…\n12 Burkina F… CVTRUST  Town Crier  58.5  53.2  63.8 Which do you trus…\n13 Burkina F… CVTRUST  TV          72.7  67.2  78.3 Which do you trus…\n14 DRC (Kins… CVTRUST  Family      31.3  23.2  39.5 Which do you trus…\n15 DRC (Kins… CVTRUST  Friends /…  27.7  20.7  34.8 Which do you trus…\n# … with 89 more rows\n\nPlot theme\nA custom theme usually modifies one of the pre-made themes available in ggplot2. Here, we make some small changes to theme_minimal(), and we’ll list the modified theme together with a few additional ggplot2 functions that we’ll want to use in each plot. Our theme will also contain a custom font that we’ve downloaded and saved in the “fonts” subfolder of our project root directory.\n\n\nfont_add(\n  family = \"cabrito\", \n  regular = \"../../fonts/cabritosansnormregular-webfont.ttf\"\n)\nshowtext_auto()\n\ntheme_pma <- function(title, subtitle){\n  components <- list(\n    # We'll use `theme_minimal()` as a baseline\n    theme_minimal() %+replace% \n      theme(\n        \n        # Text elements\n        text = element_text(                    # text default\n          family = \"cabrito\", \n          size = 10\n        ), \n        plot.title = element_text(              # title override\n          size = 18, \n          color = \"#00263A\",\n          margin = margin(b = 5)\n        ), \n        plot.subtitle = element_text(           # subtitle override\n          size = 12,\n          margin = margin(b = 5)\n        ),\n        legend.title = element_blank(),         # legend title override\n        \n        # Grid elements\n        panel.grid.minor = element_blank(),     # strip minor gridlines\n        axis.ticks = element_blank(),           # strip axis ticks\n        \n        # Legend elements\n        legend.position = \"bottom\",\n      ),\n    \n    # We'll define custom colors for each COUNTRY  \n    scale_fill_manual(\n      values = alpha(\n        alpha = .85,   # .85 creates bars that are 15% transparent\n        colour = c(\n          \"#81A88D\",   # Green\n          \"#CCBA72\",   # Tan\n          \"#98579B\",   # PMA Pink\n          \"#00263A\"    # IPUMS Navy\n        )\n      )\n    ),\n    \n    # A similar color scheme will by used to color binary geom_points\n    scale_color_manual(\n      values = alpha(\n        alpha = .85,   # .85 creates bars that are 15% transparent\n        colour = c(\n          \"#98579B\",   # PMA Pink\n          \"#00263A\"    # IPUMS Navy\n        )\n      )\n    ),\n    \n    # Title and labels\n    labs(\n      title = toupper(title),\n      subtitle = \"Estimated percentage for populations of women age 15-49 in summer 2020\",\n      x = NULL,\n      y = NULL,\n      fill = NULL\n    ),\n    \n    # Flip coordinates and sort legend items\n    coord_flip(),\n    guides(fill = guide_legend(reverse = TRUE))\n    \n  )\n}\n\n\n\n\n\n\n\n© RStudio (CC0 1.0)\nBar Charts\nWe’re now ready to apply what we learned about bar charts in our last post to the binary variables we’ve summarized in summary. At first, you might consider plotting the variables from each QUESTION separately; to do this, you’d first need to use filter(QUESTION == \"CVLEARN\"). You should also consider how you’d like to order the 13 different sources of information in SOURCE: here, we use fct_reorder(SOURCE, EST, mean) to sort the levels of SOURCE according to the mean value of EST across the four samples.\nFirst, consider the responses to “How did you learn about COVID-19?”\n\n\nsummary %>% \n  filter(QUESTION == \"CVLEARN\") %>% \n  mutate(SOURCE = fct_reorder(SOURCE, EST, mean)) %>% \n  ggplot(aes(fill = COUNTRY, y = EST, x = SOURCE)) + \n  geom_bar(width = .6, position = position_dodge(0.6), stat = \"identity\") +\n  geom_errorbar(\n    aes(ymin = LOW, ymax = UPP),\n    width = 0.2,\n    position = position_dodge(0.6),\n    alpha = 0.5\n  ) +\n  theme_pma(\"How did you learn about COVID-19?\") \n\n\n\n\nWhen the PMA COVID-19 survey was fielded (summer 2020), we estimate that radio, television, friends / neighbors, and family were the most effective sources reaching women with information about COVID-19 across the four sampled countries. However, this plot also shows stark differences between countries: we can easily see that radio was comparatively less effective at reaching women in Kinshasa, whereas television was comparatively more effective. Meanwhile, television reached a much smaller share of the women in Burkina Faso compared to women in the other countries.\nAt the lower end of the spectrum, very few women in any country learned about COVID-19 from posters / billboards, town criers, or their school. Newspapers reached almost no women in Kinshasa or Burkina Faso, but they appeared to be more effective in Lagos / Kano and in Kenya. Perhaps most surprisingly, social media reached a only a modest number of women, although its role varies considerably between countries.\nLet’s now look at the responses to “Which of these sources do you trust for accurate information about COVID-19?”\n\n\nsummary %>% \n  filter(QUESTION == \"CVTRUST\") %>% \n  mutate(SOURCE = fct_reorder(SOURCE, EST, mean)) %>% \n  ggplot(aes(fill = COUNTRY, y = EST, x = SOURCE)) + \n  geom_bar(width = .6, position = position_dodge(0.6), stat = \"identity\") +\n  geom_errorbar(\n    aes(ymin = LOW, ymax = UPP),\n    width = 0.2,\n    position = position_dodge(0.6),\n    alpha = 0.5\n  ) +\n  theme_pma(\n    \"Which do you trust for COVID-19 information?\", \n    \"Estimated percentage of women aged 15-49 (summer 2020)\"\n  ) \n\n\n\n\nA clear strength of this layout is that we easily see the large differences in trust for each source between countries: women in Burkina Faso appear to hold much higher levels of trust in sources of information, overall. Taking into account the error bars produced by our 95% confidence interval, it’s also easy to observe certain similarities between women in Kenya and Kinshasa.\nWe’ve again sorted information sources using the mean value of EST across countries, making it easy to rank each source from “most trusted” to “least trusted” across countries. Radio and television were generally the most trusted sources of information, followed by health workers and government officials. The same sources that reached the smallest proportion of women in our last chart - posters / billboards, town criers, and schools - are also the least trusted sources here.\nOne important limitation of this layout is that - except for the top and bottom sources on each list - it’s difficult to keep track of the rank order of sources between charts. It’s also hard to tell whether trusted sources are also effective messengers of COVID-19 information, as the two charts are not yet aligned side-by-side. We’ll solve this problem by faceting the two charts together in a single display.\nHere, we’ll omit the filter() function and instead use facet_wrap(vars(QTEXT)) to build one plot for each QTEXT (the custom text labels we wrote for each question above).\n\n\nsummary %>% \n  mutate(SOURCE = fct_reorder(SOURCE, EST, mean)) %>% \n  ggplot(aes(fill = COUNTRY, y = EST, x = SOURCE)) + \n  geom_bar(width = .6, position = position_dodge(0.6), stat = \"identity\") +\n  geom_errorbar(\n    aes(ymin = LOW, ymax = UPP),\n    width = 0.2,\n    position = position_dodge(0.6),\n    alpha = 0.5\n  ) +\n  theme_pma(\n    \"Are trusted sources reaching\n    women with COVID-19 information?\"\n  ) + \n  facet_wrap(vars(QTEXT)) \n\n\n\n\nThis time, we’ve ranked the most trusted and effective sources according to the highest common mean value for both “CVLEARN” and “CVTRUST” across countries. Radio and TV both reach and are trusted by comparable proportions of women across countries. Beyond those two sources, we see get an overall sense that - as of summer 2020 - most sources fell short of reaching the share of women in each country who would trust them for accurate information about COVID-19.\nWe like a lot of things about this faceted bar chart: while it’s easy to compare sources within and across countries, we’re also able to directly compare responses to both survey questions at the same time. And, unlike the other charts we’ll explore below, it allows us to include error bars representing the 95% confidence interval for each population-level estimate.\nOn the other hand, this plot is not particularly concise: it uses a good deal of space, and it forces the reader to scan two grids when comparing the effectiveness and trust of any particular source.\nLollipop Chart\nIf the main point you’d like to emphasize with these data is the disparity between effectiveness and trust for each source, you might consider plotting both survey questions on the same grid using a lollipop chart. The lollipop chart is also useful in certain contexts where space is limited, as it minimizes the surface area of each geom.\nLet’s take a look at a lollipop chart where the estimated proportion of women who learned from each source is connected on a line with the proportion of women who trust each source. In the previous plot, we saw that levels of trust are generally higher than levels of effectiveness for each source, but we couldn’t easily identify exceptions to this trend; here we’ll draw a dashed line any time the proportion of women who trust a source is lower than the proportion of women who learned from the source. We’ll do this by adding a new column to summary that takes the value “dashed” in those cases, and “solid” otherwise.\n\n\nsummary <- summary %>% \n  group_by(COUNTRY, SOURCE) %>%  \n  mutate(DEFICIT = if_else(\n    any(QUESTION == \"CVTRUST\" & EST == min(EST)), \n    \"solid\", \n    \"dashed\"\n  )) %>% \n  ungroup() \n\n\n\nWe’ll create one “lollipop” for each source by linking two geom_point() markers for each source with a geom_line(), and we’ll use facet_wrap()to build one panel for each COUNTRY. To make this plot easier to interpret, we’ll use a pink circle to represent the our point estimate EST for “CVLEARN”, and a blue triangle to represent the our point estimate EST for “CVTRUST”. Then, wherever “CVTRUST” lags behind “CVLEARN”, we’ll use the column DEFICIT we added to summary to instruct geom_line to draw a “dashed” line instead of a “solid” one.\n\n\nsummary %>% \n  mutate(SOURCE = fct_reorder(SOURCE, EST, mean)) %>% \n  ggplot(aes(x = SOURCE, y = EST)) + \n  geom_point(aes(shape = QTEXT, color = QTEXT), size = 3) +\n  geom_line(aes(linetype = DEFICIT), alpha = .5, show.legend = FALSE) + \n  facet_wrap(vars(COUNTRY)) +\n  theme_pma(\n    \"Are trusted sources reaching\n    women with COVID-19 information?\"\n  ) + \n  theme(legend.position = \"top\")\n\n\n\n\nCompared to the faceted bar chart, this lollipop chart allows us to easily see the size of the gap between the proportion of women who trust each source and the number of women who had learned about COVID-19 from the source in summer 2020. We can also easily identify the sources in each country that are trusted by fewer women than had they had reached: as you might expect, these are typically “social” sources of information like friends / neighbors, family members, and social media.\nThis chart works pretty well for our data, where we only need to compare responses from two “select all that apply” questions. You might be wondering, though, what to do with three or more: in that case, the lollipop chart might not be your best option. Instead, you might consider overlaying several survey questions with semi-transparent layers in a radar chart.\nRadar Chart\nIn a radar chart configuration, each SOURCE will be plotted on a polar coordinate grid - much like the numbers on a clock. The value in EST will map the radial distance of each SOURCE from the center. Otherwise, we’ll use the same layout we adopted for the lollipop chart above: we’ll create one facet for each COUNTRY and we’ll plot both survey questions from QUESTION on the same grid.\nUnfortunately, radar charts are not natively supported in ggplot2, so we’ll need to rely on another package called fmsb that uses base R graphics and syntax conventions. We won’t get into the details here, but if you’d like to see more examples using the fmsb package, we recommend checking out the excellent R Graph Gallery.\n\nIf you’re interested in a ggplot2 approach to radar charts, check out the excellent ggradar package.\nIn short, we’ll need to transform summary once more by pivoting the EST value for each SOURCE into separate columns. Moreover, we’ll define a border_color and a fill_color for each of our survey questions; we’ll use blue for variables derived from “CVTRUST”, and we’ll use pink for those derived from “CVLEARN”.\n\n\nsummary <- summary %>% \n  mutate(SOURCE = str_replace(SOURCE, \" (?=[:alpha:])\", \"\\n\")) %>% \n  pivot_wider(\n    id_cols = c(COUNTRY, QUESTION),\n    names_from = SOURCE,\n    values_from = EST\n  ) %>% \n  mutate(\n    border_color = if_else(\n      QUESTION == \"CVTRUST\",\n      \"#00263A\", # d blue\n      \"#98579B\"  # d pink\n    ),\n    fill_color = if_else(\n      QUESTION == \"CVTRUST\",\n      \"#7A99AC50\", # l blue\n      \"#e8bce850\"  # l pink\n    )\n  )\n\nsummary\n\n\n# A tibble: 8 x 17\n  COUNTRY QUESTION Family `Friends /\\nNei… Government `Health\\nWorker…\n  <fct>   <chr>     <dbl>            <dbl>      <dbl>            <dbl>\n1 Burkin… CVTRUST    73.3             67.6      76.8             89.0 \n2 DRC (K… CVTRUST    31.3             27.7      37.7             47.4 \n3 Kenya   CVTRUST    42.0             40.1      61.2             57.8 \n4 Nigeri… CVTRUST    27.1             32.8      29.5             34.1 \n5 Burkin… CVLEARN    22.7             31.9       2.07            13.0 \n6 DRC (K… CVLEARN    16.6             40.5       5.38             8.24\n7 Kenya   CVLEARN    28.7             45.3      20.7             17.6 \n8 Nigeri… CVLEARN    32.6             53.0       8.66             8.68\n# … with 11 more variables: Community Leaders <dbl>, Newpaper <dbl>,\n#   Phone Message <dbl>, Poster / Billboard <dbl>, Radio <dbl>,\n#   School <dbl>, Social Media <dbl>, Town Crier <dbl>, TV <dbl>,\n#   border_color <chr>, fill_color <chr>\n\n\nWe’ve also inserted a line break symbol \\n wherever a SOURCE name contains a space followed by a letter. This will make the final plot a bit narrower and easier to read.\nThe easiest way to create a faceted plot with base R graphics is to create a custom layout() defined by a matrix containing an index number for each element you’ll place in a facet. We’ll create each of these elements in order:\nA title (in the “outer margin area” oma), and subtitle (in the facet numbered 1)\nFour radar charts: one for each country (in facets numbered 2 through 5)\nA legend (in the facet numbered 6)\nIf you’d like, you can preview the layout with layout.show().\n\n\nplot.new()\npar(\n  family = \"cabrito\",\n  oma = c(1, 1, 10, 1),\n  mar = c(2, 0, 2, 0)\n)\nlayout(\n  matrix(\n    c(1, 1, 2, 3, 4, 5, 6, 6), \n    ncol = 2, \n    byrow = TRUE\n  ),\n  heights = c(.5, 6, 6, 2)\n)\n\nlayout.show(6)\n\n\n\n\nNow, we’ll iterate through each facet one at a time. In order to build the radar charts, we’ll need to use radar_chart() in a for-loop, in which we’ll remove all rows from summary except for those containing a particular COUNTRY. Because radar_chart() requires additional rows containing the min and max values for each grid, we’ll add them with rbind(100, 0, .) within each loop.\n\n\n# Layout \nplot.new()\npar(\n  family = \"cabrito\",\n  oma = c(1, 1, 10, 1),\n  mar = c(2, 0, 2, 0)\n)\nlayout(\n  matrix(\n    c(1, 1, 2, 3, 4, 5, 6, 6),\n    ncol = 2,\n    byrow = TRUE\n  ),\n  heights = c(.5, 6, 6, 2)\n)\n\n# Title \npar(mar = c(0, 0, 0, 0))\nplot.new()\ntitle(\n  main = toupper(\"Are trusted sources reaching\n    women with COVID-19 information?\"),\n  outer = TRUE, \n  cex.main = 3.5,\n  col.main =  \"#00263A\"\n)\npar(mar = c(0, 0, 1, 0))\nmtext(\n  \"Estimated percentage for populations of women age 15-49 in summer 2020\",\n  cex = 1.25\n)\n\n# Loop through each Country\npar(mar = c(1, 0, 2, 0))\nfor(i in unique(summary$COUNTRY)){\n  dat <- summary %>% \n    filter(COUNTRY == i) %>% \n    rbind(100, 0, .) %>% \n    column_to_rownames(\"QUESTION\") %>% \n    select(-COUNTRY)\n  \n  border_color <- dat %>% \n    slice(3:4) %>% \n    pull(border_color)\n  \n  fill_color <- dat %>% \n    slice(3:4) %>% \n    pull(fill_color)\n  \n  radarchart(\n    dat %>% select(-border_color, -fill_color),\n    axistype = 1,\n    \n    # polygon\n    pcol = border_color, pfcol = fill_color, plwd = 4, plty = 1,\n    \n    # grid\n    cglcol=  \"grey\", cglty = 1, axislabcol = \"grey\", \n    caxislabels = seq(0,100,20), cglwd = 0.8,\n    \n    # labels\n    vlcex = 0.8,\n    \n    # title \n    title = i, cex.main = 2\n  )\n}\n\n# Legend \nplot.new()\npar(mar = c(0, 0, 0, 0))\nlegend(\n  \"top\",\n  legend = c(\"Which do you trust for COVID-19 information?\",\n             \"How did you learn about COVID-19?\"),\n  horiz = FALSE,\n  bty = \"n\",\n  pch = 20 ,\n  col = unique(summary$border_color),\n  text.col =  \"#00263A\",\n  cex = 2,\n  pt.cex = 4,\n  y.intersp = 1.5\n)\n\n\n\n\nThere are quite a few important caveats to the radar chart, but we think these are a bit more intuitive than the lollipop chart shown above. The perimeter of the blue “trust” shape is clearly larger than the perimeter of the pink “learn” shape in all four countries, and it’s easy to identify cases where a particular source has reached a larger share of the population than the share that trusts it.\nOn the other hand, the circular layout of the radar chart makes it nearly impossible to visualize which of the source is most trusted and effective. If the overall rank order of the response options is an important take-away for your readers, you should almost certainly choose the lollipop chart or the faceted bar chart instead.\nAn additional consideration here: we’ve highlighted the radar chart because it allows you to overlay the responses to each “select all that apply” question, rather than plotting them side-by-side. You should still use caution, however, not to overcrowd your chart with too many layers.\nWrap-up\nWhich chart do you like best for the “sources of information” data in the PMA COVID-19 survey? Let us know what you think in the comments below, or reach out to us at the brand new IPUMS Global Health Twitter account!\nJoin us again in two weeks, when we’ll be wrapping up our series on the PMA COVID-19 survey with a tutorial showing how to connect it with data from the 2020 baseline survey.\n\n\n\n",
    "preview": "posts/2021-08-01-covid-batches/images/preview2.png",
    "last_modified": "2022-04-13T13:10:46-04:00",
    "input_file": {},
    "preview_width": 1134,
    "preview_height": 872
  },
  {
    "path": "posts/2021-07-15-covid-likert/",
    "title": "Visualizing perceptions of risk from COVID-19",
    "description": "A guide to bar charts for Likert-type psychometric scales built with ggplot2.",
    "author": [
      {
        "name": "Saeun Park",
        "url": "http://www.linkedin.com/in/saeun-park"
      },
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-07-15",
    "categories": [
      "COVID-19",
      "Descriptive Analysis",
      "Data Visualization",
      "ggplot2"
    ],
    "contents": "\n\nContents\nSetup\nFeatured variable: COVIDCONCERN\n\nBasic Bar Charts\nPosition\nStat\n\nCustomization\nColor\nLabels and Fonts\n\nAdvanced Bar Charts\nDivergent Stacked Bar Chart\nFaceted Neutral / Non-response\nFaceted Question Series\n\nNext Steps\n\nAs we’ve mentioned throughout this series, one of the most important focus areas of the new PMA COVID-19 survey has to do with perceptions of risk expressed by women during the early months of the pandemic. Because all respondents to the COVID-19 survey are participants in a multi-year panel study examining broad topics in reproductive health, analysts will soon be able to link women’s attitudes and beliefs about COVID-19 during the summer of 2020 to longer-term health and family planning outcomes.\nIn this post, we’ll examine one of the most common data visualization tools used to explore attitudinal data: the bar chart. In the PMA COVID-19 survey, women are asked to rate their level of concern for several different types of risk associated with the pandemic. The survey uses a four-point scale for such questions, and it includes the following response options:\nNot concerned\nA little concerned\nConcerned\nVery concerned\nThis type of scale is common in psychometric research, particularly where analysts want to compare attitudes about a wide range of topics. You might notice that the responses follow a bi-polar format, where more neutral responses are organized at the center, and more extreme responses are listed on either side. This type for scale is sometimes called the Likert scale after the pioneering social psychologist, Rensis Likert.\nThe bar chart is typically used for Likert-type data because:\nit is ordinal (responses should be arranged from a low-level of concern to a high-level of concern)\nit is discrete (responses are restricted to a small number of pre-defined choices)\nrepeated use of the same scale allows us to align and compare levels of concern on multiple questions\nWe’ll discuss some of the many choices you’ll have to make about layout, and we’ll show how to implement them with the tidyverse package ggplot2.\n\nWe also recommend the packages likert and hh for Likert-type data.\nSetup\nYou’ll find the data featured in this post if you navigate to the new COVID-19 Unit of Analysis in the IPUMS PMA data extract system. Our examples feature data from all four samples (Female Respondents only).\nTo follow along, make sure to create an extract that includes these variables:\nCOUNTRY\nCVQWEIGHT\nEAID\nCOVIDCONCERN\nCOMMCOVIDWORRY\nPREGFEELNOW\nYou’ll also need to install the following packages as needed (current versions are recommended):\nipumsr (0.4.5)\ntidyverse (1.3.1)\nsrvyr (1.0.1)\nshowtext (0.9.2)\ngtsummary (1.4.1)\nLoad those packages and your data extract into R (be sure to change the file paths to match the location of your own extract):\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\nlibrary(srvyr)\nlibrary(showtext)\nlibrary(gtsummary)\n\ncovid <- read_ipums_micro(\n  ddi = \"data/pma_00032.xml\",\n  dat = \"data/pma_00032.dat.gz\"\n)\n\n\n\nFeatured variable: COVIDCONCERN\nTo start, let’s take a look at just one of the variables that uses the Likert-type scale shown above. In COVIDCONCERN, women who have not already been infected with COVID-19 are asked to rate their level of concern for becoming infected:\nHow concerned are you about getting infected yourself?\n(Read all options)\n\n  [] Very concerned\n  [] Concerned\n  [] A little concerned\n  [] Not concerned\n  [] I am currently / was infected with COVID-19\n  [] No response\n\nIn addition to the two non-response options shown on the questionnaire, women could also be NIU (not in universe) if they had already been infected.\nLet’s break down the responses to this question by COUNTRY. First, following the explanation in our last post, we’d strongly recommend transforming both variables into factor objects (this will ensure that their value labels are displayed in graphics output). We’ll also edit the COUNTRY labels for DRC and Nigeria, and we’ll describe the NIU cases for COVIDCONCERN as women who Never heard or read about COVID-19.\n\nReminder: only the Burkina Faso and Kenya samples are nationally representative. The DRC and Nigeria samples represent sub-national regions.\n\n\ncovid <- covid %>% \n  mutate(\n    across(where(is.labelled), ~as_factor(.x) %>% fct_drop), \n    COUNTRY = COUNTRY %>%\n      fct_recode(\n        `DRC (Kinshasa)` = \"Congo, Democratic Republic\",\n        `Nigeria (Lagos & Kano)` = \"Nigeria\"\n      ),\n    COVIDCONCERN = COVIDCONCERN %>% \n      fct_recode(\n        `Never heard or read about COVID-19` = \"NIU (not in universe)\"\n      )\n  )\n\n\n\nUsing the gtsummary package featured in our last post, you might preview the breakdown of COVIDCONCERN by COUNTRY in a table as follows:\n\n\ncovid %>% tbl_summary(by = COUNTRY, include = COVIDCONCERN) \n\n\n\nCharacteristic\n      Burkina Faso, N = 3,5281\n      DRC (Kinshasa), N = 1,3241\n      Kenya, N = 5,9861\n      Nigeria (Lagos & Kano), N = 1,3461\n    Concerned about getting infected\n\n\n\nNot concerned\n238 (6.7%)\n259 (20%)\n236 (3.9%)\n39 (2.9%)A little concerned\n365 (10%)\n161 (12%)\n171 (2.9%)\n30 (2.2%)Concerned\n752 (21%)\n210 (16%)\n759 (13%)\n170 (13%)Very concerned\n2,168 (61%)\n689 (52%)\n4,818 (80%)\n1,100 (82%)Currently / previously infected with COVID-19\n2 (<0.1%)\n1 (<0.1%)\n0 (0%)\n2 (0.1%)No response or missing\n0 (0%)\n2 (0.2%)\n2 (<0.1%)\n1 (<0.1%)Never heard or read about COVID-19\n3 (<0.1%)\n2 (0.2%)\n0 (0%)\n4 (0.3%)\n        \n          1\n          \n           \n          n (%)\n          \n      \n    \n\n\n\n\n\n© 2020 Daniel D. Sjoberg (MIT)\nNow we’re ready to begin arranging these summary data into a bar chart with ggplot2.\nBasic Bar Charts\nAs you might know, ggplot2 is part of the tidyverse family of packages. For regular readers of this blog, this means that you’ll be able to use the same grammar that you’re used to seeing elsewhere, but with one important difference: while you’ll be able to pipe functions to ggplot() with the familiar %>% operator, functions within the package use their own pipe-like operator +.\n\n\n\n\n© RStudio (CC0 1.0)\nThis + operator allows the user to assemble multiple layers of visual information onto the same plot. These layers are built from functions that start with the prefix geom_, because each layer is more-or-less defined by the geometric shapes that convey information about the data.\nWhile these geom_ functions are simple to use and combine, you’ll first need to define some common parameters with the function ggplot(). This function initializes a kind of “skeleton” plot - or canvas - onto which you’ll layer each geom_ function. Usually, you’ll identify variables here that you’ll want to map onto the x and y-axes, or onto the “fill” styles (e.g. colors and shadings) within your plot’s geometric shapes.\n\nLooking for a free introduction to ggplot2? Try ggplot2: Elegant Graphics for Data Analysis.\nWe’ll use the geom_bar() function after we define some basic parameters for our plot in ggplot():\n\n\ncovid %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN)) + \n  geom_bar()\n\n\n\n\n\nA stacked bar chart showing the frequency of each response per sample\nIn the above function, we initialize our plot with ggplot() and define its basic aesthetic qualities with aes(): we specify that we’ll plot each COUNTRY on the x-axis, and - in whatever geometric shapes we draw next - we’ll fill its segments with colors defined by COVIDCONCERN. Note that the ggplot() function doesn’t draw anything, itself. Instead, we pipe ggplot to geom_bar(), which is responsible for drawing and stacking the bars.\nBut what about the values that appeared on the y-axis? We didn’t specify anything in our data, but it seems like ggplot() automatically calculated the number of women in each country who selected each response. While this might be a useful default in some situations, here we’d much rather normalize these bars as a percentage of the total number of responses for each sample. We’ll do this by manipulating the position argument in geom_bar().\nPosition\nThe position argument in geom_bar() determines how the bars representing each response should be arranged on our plot. This argument can take one of several position adjustment functions, and its default behavior uses position_stack() to “stack” bars representing the frequency of each response. This kind of bar chart is known as a stacked bar chart.\nIf we want to normalize the size of our bars to the size of each sample, we can use position_fill() to stretch each stack of bars to an equal length. The result allows us to compare the proportion of responses across samples:\n\n\ncovid %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN)) + \n  geom_bar(position = position_fill())\n\n\n\n\n\nA stacked bar chart showing the proportion of each response per sample\nThis arrangement is helpful for comparing more extreme responses, but you may notice that it’s still a bit hard to compare the proportion of moderate responses in the middle of each stack. For this reason, you might consider using position_dodge() to transform our stacked bar chart into a grouped bar chart.\n\n\ncovid %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN)) + \n  geom_bar(position = position_dodge())\n\n\n\n\nA grouped bar chart showing the frequency of each response per sample\nNote: the bars for Kenya and Burkina Faso appear wider because they contain zero responses for some levels of COVIDCONCERN. Check out position_dodge2() for more control over the width of these bars.\nUnfortunately, when we switch position from position_fill() to position_dodge(), we’re no longer able to stretch each bar to a normalized length. Instead, we’ll need to pre-calculate the proportion of each response and pass it to geom_bar() via the stat argument.\nStat\nIn each of the above plots, we’ve relied on the default behavior of geom_bar() to calculate the frequency of each response and - when requested - to stretch each bar to a normalized length. There are many reasons why you might want to pass your own statistics to geom_bar(), and you can do so with the argument stat = \"identity\".\nFor example, we might create a table of summary statistics showing the proportion of responses to COVIDCONCERN by COUNTRY:\n\n\nconcern_tbl <- covid %>% \n  as_survey_design() %>%\n  group_by(COUNTRY, COVIDCONCERN) %>%\n  summarise(PERCENT = 100 * survey_mean(vartype = NULL))\n\nconcern_tbl\n\n\n# A tibble: 25 x 3\n# Groups:   COUNTRY [4]\n   COUNTRY        COVIDCONCERN                                 PERCENT\n   <fct>          <fct>                                          <dbl>\n 1 Burkina Faso   Not concerned                                 6.75  \n 2 Burkina Faso   A little concerned                           10.3   \n 3 Burkina Faso   Concerned                                    21.3   \n 4 Burkina Faso   Very concerned                               61.5   \n 5 Burkina Faso   Currently / previously infected with COVID-…  0.0567\n 6 Burkina Faso   Never heard or read about COVID-19            0.0850\n 7 DRC (Kinshasa) Not concerned                                19.6   \n 8 DRC (Kinshasa) A little concerned                           12.2   \n 9 DRC (Kinshasa) Concerned                                    15.9   \n10 DRC (Kinshasa) Very concerned                               52.0   \n# … with 15 more rows\n\nNow, if we pass our summary table concern_tbl to ggplot(), we’ll be able to map response percentages in the PERCENT column to the y-axis. In the geom_bar() function, we’ll use stat = \"identity\" to ensure that our pre-calculated statistics are displayed:\n\n\nconcern_tbl %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN, y = PERCENT)) + \n  geom_bar(\n    position = position_dodge(),\n    stat = \"identity\"\n  ) \n\n\n\n\n\nA grouped bar chart showing response percentages per sample\nYou might also consider pre-calculating statistics if you want to add layers of text or error bars to your plot. As we’ve discussed elsewhere, we love using as_survey_design() and survey_mean() from the srvyr package to generate population-level estimates with cluster-robust standard errors. Here, we’ll use CVQWEIGHT as a weighting variable and EAID as the identification number for each sample cluster, thus creating a population-level summary table called concern_pop:\n\n\nconcern_pop <- covid %>% \n  as_survey_design(weight = CVQWEIGHT, id = EAID) %>%\n  group_by(COUNTRY, COVIDCONCERN) %>%\n  summarise(PERCENT = 100 * survey_mean(vartype = \"ci\"))\n\nconcern_pop\n\n\n# A tibble: 25 x 5\n# Groups:   COUNTRY [4]\n   COUNTRY    COVIDCONCERN             PERCENT PERCENT_low PERCENT_upp\n   <fct>      <fct>                      <dbl>       <dbl>       <dbl>\n 1 Burkina F… Not concerned             6.18        3.70        8.66  \n 2 Burkina F… A little concerned        8.35        5.61       11.1   \n 3 Burkina F… Concerned                17.7        14.3        21.2   \n 4 Burkina F… Very concerned           67.7        62.1        73.3   \n 5 Burkina F… Currently / previously …  0.0251     -0.0103      0.0604\n 6 Burkina F… Never heard or read abo…  0.0484     -0.0149      0.112 \n 7 DRC (Kins… Not concerned            18.8        14.9        22.7   \n 8 DRC (Kins… A little concerned        9.77        7.71       11.8   \n 9 DRC (Kins… Concerned                17.0        13.0        21.1   \n10 DRC (Kins… Very concerned           54.0        48.5        59.5   \n# … with 15 more rows\n\nNote the addition of PERCENT_low and PERCENT_upp, representing the lower and upper bounds of a 95% confidence interval for each population-level estimate of PERCENT. We’ll use these in a new layer created by geom_errorbar():\n\n\nconcern_pop %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN, y = PERCENT)) + \n  geom_bar(\n    position =  position_dodge(),\n    stat = \"identity\"\n  ) + \n  geom_errorbar(\n    aes(ymin = PERCENT_low, ymax = PERCENT_upp),\n    width = 0.2,\n    position = position_dodge(width = 0.9)\n  )\n\n\n\n\n\nA grouped bar chart showing population-level estimates with 95% confidence intervals\nLikewise, pre-calculating statistics in a table like concern_pop makes it easy to access statistics by name in geom_text(). In this example, adding the text label for each value of PERCENT is redundant with the y-axis (not recommended), but you could also include text from any column in the pre-calculated table:\n\n\nconcern_pop %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN, y = PERCENT)) + \n  geom_bar(\n    position = \"dodge\",\n    stat = \"identity\"\n  ) + \n  geom_text(\n    aes(label = round(PERCENT, 0)),\n    position = position_dodge(0.9),\n    vjust = -0.5\n  )\n\n\n\n\n\nA grouped bar chart showing population-level estimates, annotated with text\nCustomization\nSo far, we’ve focused all of our attention on passing the correct statistics to geom_bar(). Unfortunately, this is only half the battle: our plots still aren’t very readable!\nYou may have noticed, for example, that the legend in each of our plots seems to take up about one third of the usable space. In a blog like ours - where many of you might be reading this post on a mobile phone - this layout is certainly not ideal. Instead, we’ll flip the x and y-axes, and then we’ll position the legend below the plot.\nFor example, let’s return to the stacked bar chart showing the population-level percentages for each response:\n\n\nconcern_pop %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN, y = PERCENT)) + \n  geom_bar(stat = \"identity\") + \n  coord_flip() + \n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFlip your bar chart into a horizontal orientation with coord_flip().\nThe function coord_flip() pivots our plot into a horizontal orientation, and another new function - theme() - allows us to move our legend. However, the legend now occupies too much horizontal space: one of the responses appears to be cut-off by the right-hand margin of the page.\nIt is possible to manipulate the layout of your legend with another function, guides(). For example, you might arrange the response codes into two separate columns:\n\n\nconcern_pop %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN, y = PERCENT)) + \n  geom_bar(stat = \"identity\") + \n  coord_flip() + \n  theme(legend.position = \"bottom\") + \n  guides(fill = guide_legend(ncol = 2))\n\n\n\n\nThe guides() function controls the layout of the legend with guide_legend().\nYou can also control the layout of the axes with guide_axis().\nHowever, in our particular case, it might make more sense to simply drop the three types of non-response completely. We might do so, in part, because the remaining responses are part of an ordinal set. If we restrict the plotted values only to those ordinal responses, we’ll also be able to add an ordinal color scheme to our plot making the relationship between each response much clearer.\nColor\nAn easy way to drop non-response options in our particular case is to filter only those four responses containing the word “concern” (upper or lower case). Then, when only the four ordinal responses remain, we’ll use scale_fill_brewer() to select an ordinal color scheme (“blues” by default). This time, we’ll use guides() to reverse the order of the responses in our legend:\n\n\nconcern_pop %>% \n  filter(grepl(\"concern\", COVIDCONCERN, ignore.case = TRUE)) %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN, y = PERCENT)) + \n  geom_bar(stat = \"identity\") + \n  coord_flip() + \n  theme(legend.position = \"bottom\") + \n  scale_fill_brewer() + \n  guides(fill = guide_legend(reverse = TRUE))\n\n\n\n\nNon-response categories have been dropped, and the remaining responses are represented by an ordinal color scheme\nNote that the bars no longer sum to 100%\nYou can choose from several color palettes with scale_fill_brewer(), or you can define your own colors using scale_fill_manual(), where you’ll assign a color to each response via a named character vector.\nFor example, here we’ll use some of the hex color codes you’ll see in the CSS throughout this blog:\n\n\nconcern_pop %>% \n  filter(grepl(\"concern\", COVIDCONCERN, ignore.case = TRUE)) %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN, y = PERCENT)) + \n  geom_bar(stat = \"identity\") + \n  coord_flip() + \n  theme(legend.position = \"bottom\") + \n  scale_fill_manual(\n    values = alpha(\n      colour = c(\n        \"Very concerned\" = \"#00263A\",        # IPUMS Navy\n        \"Concerned\" = \"#4E6C7D\",             # IPUMS Dark-Grey\n        \"A little concerned\" = \"#7A99AC\",    # IPUMS Blue-Grey\n        \"Not concerned\" = \"#F1F5F7\"          # IPUMS Light-Grey\n      )\n    )\n  ) + \n  guides(fill = guide_legend(reverse = TRUE))\n\n\n\n\n\nA user-defined ordinal color scheme\nLabels and Fonts\nThere are several ways to add text labels to a plot, but we find it easiest to define every label together in a single function, labs(). If you want to omit a particular label, you can simply set it to NULL:\n\n\nconcern_pop %>% \n  filter(grepl(\"concern\", COVIDCONCERN, ignore.case = TRUE)) %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN, y = PERCENT)) + \n  geom_bar(stat = \"identity\") + \n  coord_flip() + \n  theme(legend.position = \"bottom\") + \n  scale_fill_manual(\n    values = alpha(\n      colour = c(\n        \"Very concerned\" = \"#00263A\",  \n        \"Concerned\" = \"#4E6C7D\", \n        \"A little concerned\" = \"#7A99AC\", \n        \"Not concerned\" = \"#F1F5F7\"\n      )\n    )\n  ) + \n  guides(fill = guide_legend(reverse = TRUE)) + \n  labs(\n    title = \"CONCERN ABOUT GETTING INFECTED WITH COVID-19\",\n    subtitle = \"Estimated percentage for populations of women age 15-49 (summer 2020)\",\n    x = NULL,\n    y = NULL,\n    fill = NULL\n  ) \n\n\n\n\n\nAdded a title and subtitle. Removed axis and legend labels.\nAs you can see, the default label fonts for ggplot2 do not match the fonts used on our blog. If this is an important consideration, you can download a .ttf file for your preferred font from a repository like Google Fonts, and then load that file into R with font_add().\n\n\nfont_add(\n  family = \"cabrito\", \n  regular = \"fonts/cabritosansnormregular-webfont.ttf\"\n)\n\n\n\n\nWe saved our ttf file in the fonts sub-folder of our working directory.\nOnce you’ve loaded a font into R, you can make it accessible to ggplot2 for the remainder of your R session with the function showtext::showtext_auto().\n\n\nshowtext_auto()\n\n\n\nNow, we can build on our custom theme() by defining a general font family and size in text. We can also tweak specific details for the title and plot.subtitle:\n\n\nconcern_pop %>% \n  filter(grepl(\"concern\", COVIDCONCERN, ignore.case = TRUE)) %>% \n  ggplot(aes(x = COUNTRY, fill = COVIDCONCERN, y = PERCENT)) + \n  geom_bar(stat = \"identity\") + \n  coord_flip() + \n  scale_fill_manual(\n    values = alpha(\n      colour = c(\n        \"Very concerned\" = \"#00263A\",  \n        \"Concerned\" = \"#4E6C7D\", \n        \"A little concerned\" = \"#7A99AC\", \n        \"Not concerned\" = \"#F1F5F7\"\n      )\n    )\n  ) + \n  guides(fill = guide_legend(reverse = TRUE)) + \n  labs(\n    title = \"CONCERN ABOUT GETTING INFECTED WITH COVID-19\",\n    subtitle = \"Estimated percentage for populations of women age 15-49 (summer 2020)\",\n    x = NULL,\n    y = NULL,\n    fill = NULL\n  ) + \n  theme(\n    text = element_text(family = \"cabrito\", size = 10),\n    title = element_text(size = 14, color = \"#00263A\"),\n    plot.subtitle = element_text(size = 12),\n    legend.position = \"bottom\"\n  ) \n\n\n\n\n\n\n\n© Yixuan Qiu (Apache >= 2.0)\n\n\n\n\nCustom font family and sizes implemented with showtext\nAdvanced Bar Charts\nDivergent Stacked Bar Chart\nIn the previous section, we decided to drop the three types of non-response for COVIDCONCERN so that we could adopt an ordinal color scheme (each color corresponds with an ordinal level of concern). This improved the readability of our plot by making the relationship between response options more clear. However, this decision also came with a small cost: because our bars no longer represent 100% of each population, it’s a bit harder to compare the percentage of women represented by the responses on the right side of the plot (“Not concerned”).\nIn this case, you might consider the divergent stacked bar chart, where “positive” and “negative” levels of concern are plotted in opposite directions from an origin point on our x-axis. You might also consider this if you wanted to directly juxtapose the most extreme responses on our scale: “Very concerned” and “Not concerned”.\nNote that three of the responses on our scale reflect some level of concern about getting infected with COVID-19; we’ll plot these responses in the positive direction on our x-axis. The negative response - “Not concerned” - will be plotted in the negative direction if we multiply PERCENT by -1 for those cases. We’ll also give our negative response a secondary color (“PMA Pink”) and draw a vertical line at the origin to provide extra clarity. Finally, we’ll use a new function breaks() to fully customize the order of responses in our legend:\n\n\nconcern_pop <- concern_pop %>% \n  mutate(PERCENT = if_else(\n   COVIDCONCERN == \"Not concerned\",\n   -PERCENT,                                  # Multiply by -1\n   PERCENT\n  )) %>% \n  filter(grepl(\"concern\", COVIDCONCERN, ignore.case = T)) \n\nconcern_pop\n\n\n# A tibble: 16 x 5\n# Groups:   COUNTRY [4]\n   COUNTRY            COVIDCONCERN     PERCENT PERCENT_low PERCENT_upp\n   <fct>              <fct>              <dbl>       <dbl>       <dbl>\n 1 Burkina Faso       Not concerned      -6.18       3.70         8.66\n 2 Burkina Faso       A little concer…    8.35       5.61        11.1 \n 3 Burkina Faso       Concerned          17.7       14.3         21.2 \n 4 Burkina Faso       Very concerned     67.7       62.1         73.3 \n 5 DRC (Kinshasa)     Not concerned     -18.8       14.9         22.7 \n 6 DRC (Kinshasa)     A little concer…    9.77       7.71        11.8 \n 7 DRC (Kinshasa)     Concerned          17.0       13.0         21.1 \n 8 DRC (Kinshasa)     Very concerned     54.0       48.5         59.5 \n 9 Kenya              Not concerned      -4.84       2.44         7.23\n10 Kenya              A little concer…    3.45       2.12         4.79\n11 Kenya              Concerned          13.1       10.4         15.7 \n12 Kenya              Very concerned     78.6       74.6         82.7 \n13 Nigeria (Lagos & … Not concerned      -3.17       1.45         4.89\n14 Nigeria (Lagos & … A little concer…    2.04       0.899        3.19\n15 Nigeria (Lagos & … Concerned          14.1        6.18        22.0 \n16 Nigeria (Lagos & … Very concerned     80.3       72.6         87.9 \n\n\nThe PERCENT value for negative responses are multiplied by -1.\n\n\nconcern_pop %>% \n  ggplot(aes(x = PERCENT, y = COUNTRY, fill = COVIDCONCERN)) + \n  geom_bar(stat = \"identity\") +\n  \n  # draws a vertical line at 0 on the x axis\n  geom_vline(xintercept = 0) +\n  \n  # define fill colors (values) and the arrangement of the legend (breaks)\n  scale_fill_manual(\n    values = alpha(\n      colour = c(\n        \"Very concerned\" = \"#00263A\",           # PMA Pink\n        \"Concerned\" = \"#4E6C7D\",                # IPUMS Dark-Grey\n        \"A little concerned\" = \"#7A99AC\",       # IPUMS Blue-Grey\n        \"Not concerned\" = \"#98579B\"             # IPUMS Light-Grey\n      )\n    ),\n    breaks = c(\n      \"Not concerned\",\n      \"Very concerned\",  \n      \"Concerned\", \n      \"A little concerned\"\n    )\n  ) + \n  \n  # define labels (labs) and format them as desired (theme)\n  labs(\n    title = \"CONCERN ABOUT GETTING INFECTED WITH COVID-19\",\n    subtitle = \"Estimated percentage for populations of women age 15-49 (summer 2020)\",\n    x = NULL,\n    y = NULL,\n    fill = NULL\n  ) + \n  theme(\n    text = element_text(family = \"cabrito\", size = 10),\n    title = element_text(size = 14, color = \"#00263A\"),\n    plot.subtitle = element_text(size = 12),\n    legend.position = \"bottom\",\n  ) \n\n\n\n\n\nA divergent bar plot shows positive and negative responses oriented in opposite directions.\nWhile it is still difficult to compare women who are “Concerned” or “A little concerned”, this type of chart makes it easy to compare the most extreme response while also comparing the full set of negative response to the full set of positive responses.\n\nRead more about the debate surrounding divergent stacked bar charts here and here.\nA word of caution: data visualization experts disagree about what to do with middle / neutral responses. While it’s possible to distribute these responses in halves on the outside or in the middle of each bar stack, we much prefer a facet showing both neutral and non-response options to the side.\nFaceted Neutral / Non-response\nAll of the plots we’ve explored so far have contained a single panel, where both the x and y-axes are uninterrupted for the full width of the display. In some cases, you may want to facet multiple panels together.\nFor example, consider the variable PREGFEELNOW, in which women describe how they would feel if they became pregnant “now”. As we’ll see, this variable contains both a large number of middle / neutral responses (“Mixed happy and unhappy”) and a large number of non-responses (e.g. women who were pregnant at the time, or who simply did not respond). We’ll use a facet to show these responses in a separate panel alongside those who provided a positive or negative opinion.\nFirst, we’ll create a summary table and clean up the factor levels for clarity. As we’ve shown above, we’ll make PERCENT a negative value for negative responses (“Very unhappy” or “Sort of unhappy”):\n\n\npg_tbl <- covid %>% \n  as_survey_design(weight = CVQWEIGHT, id = EAID) %>%\n  group_by(COUNTRY, PREGFEELNOW) %>%\n  summarise(PERCENT = 100 * survey_mean(vartype = NULL)) %>% \n  mutate(\n    PREGFEELNOW = factor(\n      PREGFEELNOW, \n      levels = c(\n        \"Sort of unhappy\",\n        \"Very unhappy\", \n        \"Sort of happy\",      \n        \"Very happy\",\n        \"No response or missing\",\n        \"NIU (not in universe)\",\n        \"Mixed happy and unhappy\"\n      )\n    ) %>% fct_recode(`Currently Pregnant` = \"NIU (not in universe)\"),\n    PERCENT = if_else(\n      PREGFEELNOW %in% c(\"Very unhappy\", \"Sort of unhappy\"), \n      -PERCENT, \n      PERCENT\n    )\n  )\n\npg_tbl\n\n\n# A tibble: 28 x 3\n# Groups:   COUNTRY [4]\n   COUNTRY        PREGFEELNOW             PERCENT\n   <fct>          <fct>                     <dbl>\n 1 Burkina Faso   Very unhappy            -29.1  \n 2 Burkina Faso   Sort of unhappy         -11.1  \n 3 Burkina Faso   Mixed happy and unhappy   5.65 \n 4 Burkina Faso   Sort of happy            15.0  \n 5 Burkina Faso   Very happy               30.8  \n 6 Burkina Faso   No response or missing    0.333\n 7 Burkina Faso   Currently Pregnant        7.99 \n 8 DRC (Kinshasa) Very unhappy            -44.6  \n 9 DRC (Kinshasa) Sort of unhappy         -11.2  \n10 DRC (Kinshasa) Mixed happy and unhappy   5.90 \n# … with 18 more rows\n\nNext, we’ll create a new column that indicates whether we want each response to appear in the second panel in our faceted display. Let’s call this column ASIDE:\n\n\npg_tbl <- pg_tbl %>% \n  mutate(ASIDE = PREGFEELNOW %in% c(\n      \"Mixed happy and unhappy\",\n      \"No response or missing\",\n      \"Currently Pregnant\" \n  ))\n\npg_tbl\n\n\n# A tibble: 28 x 4\n# Groups:   COUNTRY [4]\n   COUNTRY        PREGFEELNOW             PERCENT ASIDE\n   <fct>          <fct>                     <dbl> <lgl>\n 1 Burkina Faso   Very unhappy            -29.1   FALSE\n 2 Burkina Faso   Sort of unhappy         -11.1   FALSE\n 3 Burkina Faso   Mixed happy and unhappy   5.65  TRUE \n 4 Burkina Faso   Sort of happy            15.0   FALSE\n 5 Burkina Faso   Very happy               30.8   FALSE\n 6 Burkina Faso   No response or missing    0.333 TRUE \n 7 Burkina Faso   Currently Pregnant        7.99  TRUE \n 8 DRC (Kinshasa) Very unhappy            -44.6   FALSE\n 9 DRC (Kinshasa) Sort of unhappy         -11.2   FALSE\n10 DRC (Kinshasa) Mixed happy and unhappy   5.90  TRUE \n# … with 18 more rows\n\nOur plot will look similar to the divergent bar chart we made in the previous section, but will now add a new function facet_grid() that divides pg_tbl into separate panels defined by ASIDE:\n\n\npg_tbl %>% \n  ggplot(aes(x = COUNTRY, fill = PREGFEELNOW, y = PERCENT)) + \n  geom_bar(stat = \"identity\") + \n  coord_flip() + \n  \n  # facet_grid() can distribute facets in rows and/or columns\n  facet_grid(\n    cols = vars(ASIDE), # here, we choose columns defined by ASIDE\n    scales = \"free\",    # \"free\" scales allows for independent facet scales  \n    space = \"free\"      # \"free\" space allows for independent facet widths\n  ) + \n  \n  # we define fill colors (values) and the arrangement of the legend (breaks)\n  scale_fill_manual(\n    values = alpha(c(\n      \"Very unhappy\" =  \"#98579B\",   \n      \"Sort of unhappy\" = \"#e8bce8\",                  \n      \"Mixed happy and unhappy\" =  \"#969696\",         \n      \"Sort of happy\" =  \"#7A99AC\",            \n      \"Very happy\" = \"#00263A\",     \n      \"Currently Pregnant\" = \"#cccccc\", \n      \"No response or missing\" = \"#F1F5F7\"\n    )),\n    breaks = c(\n      \"Sort of unhappy\",\n      \"Very unhappy\", \n      \"Very happy\",\n      \"Sort of happy\", \n      \"Mixed happy and unhappy\",\n      \"Currently Pregnant\",\n      \"No response or missing\"\n    )\n  ) + \n  guides(fill = guide_legend(nrow = 2, byrow = T)) + \n  \n  # In theme(), we control labeling for each facet:\n  theme(\n    text = element_text(family = \"cabrito\", size = 10),\n    title = element_text(size = 14, color = \"#00263A\"),\n    plot.subtitle = element_text(size = 12),\n    legend.position = \"bottom\",\n    strip.text = element_blank(), # leaves facet labels blank\n    strip.background = element_blank() # removes background for facet labels\n  ) + \n  \n  # All other labels are defined in labs() \n  labs(\n    title = \"IF YOU GOT PREGNANT NOW, HOW WOULD YOU FEEL?\",\n    subtitle = \"Estimated percentage for populations of women age 15-49 (summer 2020)\",\n    x = NULL,\n    y = NULL,\n    fill = NULL\n  ) \n\n\n\n\n\nA faceted divergent bar chart\nFaceted Question Series\nAnother reason you might want to use facets is to align responses to questions that use a common response scale. For example, the variable COMMCOVIDWORRY uses the same response options shown in COVIDCONCERN, and it reflects each woman’s level of concern for the spread of COVID-19 in her community. If we align two bar charts for COVIDCONCERN and COMMCOVIDWORRY with facet_grid(), we’ll be able to easily compare women’s concerns for personal and communal health.\nFirst, we’ll use pivot_longer to organize responses to COVIDCONCERN and COMMCOVIDWORRY in separate rows. Then, we’ll pre-calculate our summary statistics in a table called covid_pop.\n\n\ncovid_pop <- covid %>% \n  select(COUNTRY, CVQWEIGHT, EAID, COVIDCONCERN, COMMCOVIDWORRY) %>% \n  pivot_longer(\n    c(COVIDCONCERN, COMMCOVIDWORRY),\n    names_to = \"QUESTION\",\n    values_to = \"RESPONSE\"\n  ) %>% \n  as_survey_design(weight = CVQWEIGHT, id = EAID) %>%\n  group_by(COUNTRY, QUESTION, RESPONSE) %>% \n  summarise(PERCENT = survey_mean(vartype = NULL)) %>% \n  filter(grepl(\"concern\", RESPONSE, ignore.case = T)) \n\ncovid_pop\n\n\n# A tibble: 32 x 4\n# Groups:   COUNTRY, QUESTION [8]\n   COUNTRY        QUESTION       RESPONSE           PERCENT\n   <fct>          <chr>          <fct>                <dbl>\n 1 Burkina Faso   COMMCOVIDWORRY Not concerned       0.0422\n 2 Burkina Faso   COMMCOVIDWORRY A little concerned  0.0741\n 3 Burkina Faso   COMMCOVIDWORRY Concerned           0.215 \n 4 Burkina Faso   COMMCOVIDWORRY Very concerned      0.668 \n 5 Burkina Faso   COVIDCONCERN   Not concerned       0.0618\n 6 Burkina Faso   COVIDCONCERN   A little concerned  0.0835\n 7 Burkina Faso   COVIDCONCERN   Concerned           0.177 \n 8 Burkina Faso   COVIDCONCERN   Very concerned      0.677 \n 9 DRC (Kinshasa) COMMCOVIDWORRY Not concerned       0.161 \n10 DRC (Kinshasa) COMMCOVIDWORRY A little concerned  0.0943\n# … with 22 more rows\n\n\nTo keep things simple, we’ll again drop all of the non-response options by filtering only values in RESPONSE containing the word “concern”.\nThis time, we’ll build separate facets for each QUESTION. We’ll also arrange facets in the direction perpendicular to the direction of the bars (i.e. in rows).\n\n\ncovid_pop %>% \n  ggplot(aes(x = COUNTRY, y = PERCENT, fill = RESPONSE)) + \n  geom_bar(stat = \"identity\") + \n  geom_vline(xintercept = 0) +\n  coord_flip() + \n  \n  # This time, we'll add labels to each facet with labeller()\n  facet_grid(\n    rows = vars(QUESTION), \n    scales = \"free\",\n    space = \"free\",\n    labeller = labeller(QUESTION = c(\n      COMMCOVIDWORRY = \"Getting infected\",\n      COVIDCONCERN = \"Spread in community\"\n    ))\n  ) + \n  \n  # Define fill colors (values) and legend orientation\n  scale_fill_manual(\n    values = alpha(colour = c(\n      \"Very concerned\" = \"#00263A\",        # IPUMS Navy\n      \"Concerned\" = \"#4E6C7D\",             # IPUMS Dark-Grey\n      \"A little concerned\" = \"#7A99AC\",    # IPUMS Blue-Grey\n      \"Not concerned\" = \"#F1F5F7\"          # IPUMS Light-Grey\n    ))\n  ) + \n  guides(fill = guide_legend(reverse = TRUE)) + \n  \n  # We'll format the labels defined above in strip.text.y\n  # We also increase the panel.spacing by 1 \"line\"\n  theme(\n    text = element_text(family = \"cabrito\", size = 10),\n    title = element_text(size = 14, color = \"#00263A\"),\n    plot.subtitle = element_text(size = 12),\n    legend.position = \"bottom\",\n    strip.background = element_blank(),\n    strip.text.y = element_text(size = 12, angle = 0),\n    panel.spacing = unit(1, \"lines\")\n  ) + \n  \n  # All other labels are defined in labs() \n  labs(\n    title = \"COVID-19 CONCERNS: PERSONAL VS COMMUNAL\",\n    subtitle = \"Estimated percentage for populations of women age 15-49 (summer 2020)\",\n    x = NULL,\n    y = NULL,\n    fill = NULL\n  ) \n\n\n\n\nNext Steps\nOf course, bar charts are only one of the many ways you might choose to visualize Likert-type data from the PMA COVID-19 survey. We think faceted bar charts are a great way to compare data from several questions that use the same response scale, or to showcase the different types of non-response you’ll find in the top-codes used throughout all of the IPUMS PMA data series.\nThe customization options afforded by ggplot2 are incredibly powerful, but they can also be overwhelming! We’ll practice using tools from ggplot2 again in our next post, where we’ll be thinking about ways to visualize larger batches of related variables.\n\n\n\n",
    "preview": "posts/2021-07-15-covid-likert/images/faceted.png",
    "last_modified": "2022-04-13T13:10:46-04:00",
    "input_file": {},
    "preview_width": 1388,
    "preview_height": 682
  },
  {
    "path": "posts/2021-07-01-covid-tables/",
    "title": "Making Tables with PMA COVID-19 Data",
    "description": "Showcasing the gtsummary package for sample descriptive statistics, weighted population estimates, and model summary output.",
    "author": [
      {
        "name": "Shelby Rutzick",
        "url": "https://www.linkedin.com/in/shelby-rutzick/"
      },
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-07-01",
    "categories": [
      "COVID-19",
      "gtsummary",
      "srvyr",
      "purrr",
      "Descriptive Analysis",
      "Data Manipulation",
      "Weights"
    ],
    "contents": "\n\nContents\nSetup\nDescriptive Statistics Table\nDisplay value labels\nCustomize variable labels\nChange default statistics\nCustomize headers & footnotes\n\nSampling Weights\nModel Summary Table\nResults from one model\nResults from several models\n\nOutput Options\nNext Steps\n\nEarlier this spring, IPUMS PMA released a harmonized version of the PMA COVID-19 survey, which comes from a telephone interview with reproductive aged women in four countries who are all participants in an ongoing panel study related to family planning and reproductive health. We’re excited to feature this urgent resource all summer long here on the Data Analysis Hub; you’ll find find future posts related to PMA COVID-19 data and our last post - an introduction to the available data - if you follow along here.\nAs always, one of our main goals on this blog is to introduce tools that make it easy for anyone to explore new data and develop new ideas for research projects. Today, we’ll be diving into a topic that has probably frustrated everyone who has ever presented or published statistical findings at one time or another: making publication-ready tables.\nIf you talk to students or colleagues who use R, you might be surprised to learn that many of us don’t actually use statistical software to make the tables you see when you read an academic article. In reality, plenty of us just use R to make a model, and then we copy and paste the output into a table we make by hand with Microsoft Word! This can save lots of time, and it’s a perfectly reasonable solution if you know that you can make exactly what you want with the tools that Word provides.\nYou might consider making tables with R if you’ve ever found yourself:\nmanually inserting information to several rows or columns that could be calculated by R (like significance symbols *, **, and ***)\nendlessly tweaking row height, column width, or fonts\ncorrecting copy / paste errors or typos made while transferring information between R and Word\nrevisiting work you’ve already done to format a table for one publication, only to change it all for a different publication, a presentation, or a new file format (PDF, HTML, etc)\n\n\n\n\n© 2020 Daniel D. Sjoberg (MIT)\nIn this post, we’ll show you how to get up and running with flexible, easy-to-make tables using gtsummary, an R package that builds on the same tidyverse conventions we’ve featured elsewhere on this blog. There are a lot of different packages available to help make tables with R, but - as we’ll see - we love gtsummary because we think it allows users to maximize choice of style and output formats, all while minimizing the amount of code necessary to implement those choices.\n\nIf gtsummary doesn’t fit your needs, we also recommend gt (which does much of the heavy-lifting for gtsummary), kableExtra, flextable, and huxtable for different contexts.\nSetup\nIn our last post, we explained that you’ll find all of the PMA COVID-19 survey data if you select the new COVID-19 Unit of Analysis in the IPUMS PMA data extract system.\nIn this post, we’ll work with a data extract containing the following variables. You’ll be able to follow along with our coding examples if you create and download an extract containing all four samples (Female Respondents only) and these variables:\nAGE\nMARSTAT\nEDUCATTGEN\nURBAN\nHLTHCAREDIFFFEAR\nYou’ll also need to install these R packages if you don’t haven’t done so before (current versions are recommended):\nipumsr (0.4.5)\ntidyverse (1.3.1)\nsurvey (4.0)\nsrvyr (1.0.1)\ngtsummary (1.4.1)\nWhen you’ve finished downloading your data extract and installing all of these packages, load the packages and use read_ipums_micro() to load the data extract into R (make sure to change the file paths to match your own extract):\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\nlibrary(survey)\nlibrary(srvyr)\nlibrary(gtsummary)\n\ncovid <- read_ipums_micro(\n  ddi = \"data/pma_00032.xml\",\n  dat = \"data/pma_00032.dat.gz\"\n)\n\n\n\n\n\n\nAs a reminder: women who were interviewed for the PMA COVID-19 survey are participants in a ongoing panel study focused on core PMA topics in reproductive health. The baseline survey for this panel study was conducted just a few months prior to the COVID-19 survey (between November 2019 and February 2020), but data from the baseline survey are not included in the COVID-19 dataset you’ll download here. We will show how to locate and merge data from the baseline survey in an upcoming post in this series. The COVID-19 survey data are structured like all of the other cross-sectional survey datasets available from IPUMS PMA: each woman’s responses are stored in a single row.\n\n\ncovid\n\n\n# A tibble: 12,184 × 12\n          SAMPLE  COUNTRY  YEAR ROUND   EAID CONSENTFQ CVQWEIGHT   AGE\n       <int+lbl> <int+lb> <int> <dbl>  <dbl> <int+lbl>     <dbl> <int>\n 1 85411 [Burki… 1 [Burk…  2020     1 8.54e8   1 [Yes]     2.13     35\n 2 85411 [Burki… 1 [Burk…  2020     1 8.54e8   1 [Yes]     0.309    29\n 3 85411 [Burki… 1 [Burk…  2020     1 8.54e8   1 [Yes]     0.624    25\n 4 85411 [Burki… 1 [Burk…  2020     1 8.54e8   1 [Yes]     0.265    38\n 5 85411 [Burki… 1 [Burk…  2020     1 8.54e8   1 [Yes]     0.133    30\n 6 85411 [Burki… 1 [Burk…  2020     1 8.54e8   1 [Yes]     0.944    16\n 7 85411 [Burki… 1 [Burk…  2020     1 8.54e8   1 [Yes]     0.361    29\n 8 85411 [Burki… 1 [Burk…  2020     1 8.54e8   1 [Yes]     0.234    29\n 9 85411 [Burki… 1 [Burk…  2020     1 8.54e8   1 [Yes]     2.99     41\n10 85411 [Burki… 1 [Burk…  2020     1 8.54e8   1 [Yes]     0.194    27\n# … with 12,174 more rows, and 4 more variables: MARSTAT <int+lbl>,\n#   EDUCATTGEN <int+lbl>, URBAN <int+lbl>, HLTHCAREDIFFFEAR <int+lbl>\n\n\nEvery COVID-19 data extract will contain 7 preselected variables in addition to those you select, yourself.\nDescriptive Statistics Table\nThe great thing about gtsummary is that you can make a high quality table with just one line of code, but you can also customize any element of your table and easily apply custom styling (you can choose between several journal-specific themes or create your own). And, unlike many of other table-making packages for R, gtsummary supports printing directly to HTML, PDF, Word, and Rich Text Format.\nBecause gtsummary is designed with tidyverse users in-mind, you can pipe functions like dplyr::select directly into the function tbl_summary, which will then identify the object class for each variable and calculate default summary statistics accordingly. To demonstrate, we’ll select a few demographic variables, then break them down by COUNTRY in a basic call to tbl_summary():\n\n\ncovid %>% \n  select(AGE, MARSTAT, EDUCATTGEN, URBAN, COUNTRY) %>% \n  tbl_summary(by = COUNTRY)\n\n\n\nCharacteristic\n      1, N = 3,5281\n      2, N = 1,3241\n      7, N = 5,9861\n      9, N = 1,3461\n    Age in female respondent questionnaire\n29 (22, 36)\n28 (22, 36)\n30 (24, 38)\n31 (24, 39)Marital status, female questionnaire\n\n\n\n10\n882 (25%)\n605 (46%)\n1,206 (20%)\n348 (26%)21\n2,187 (62%)\n450 (34%)\n3,717 (62%)\n855 (64%)22\n254 (7.2%)\n170 (13%)\n367 (6.1%)\n26 (1.9%)31\n126 (3.6%)\n82 (6.2%)\n493 (8.2%)\n77 (5.7%)32\n78 (2.2%)\n16 (1.2%)\n201 (3.4%)\n39 (2.9%)98\n1 (<0.1%)\n1 (<0.1%)\n2 (<0.1%)\n1 (<0.1%)Highest level of school attended, general (4 categories)\n\n\n\n1\n1,213 (34%)\n4 (0.3%)\n119 (2.0%)\n86 (6.4%)2\n702 (20%)\n40 (3.0%)\n2,598 (43%)\n134 (10.0%)3\n1,374 (39%)\n884 (67%)\n2,217 (37%)\n637 (47%)4\n239 (6.8%)\n395 (30%)\n1,052 (18%)\n486 (36%)98\n0 (0%)\n1 (<0.1%)\n0 (0%)\n3 (0.2%)Urban/rural status\n2,636 (75%)\n0 (NA%)\n2,289 (38%)\n1,182 (88%)Unknown\n0\n1,324\n0\n0\n        \n          1\n          \n           \n          Median (IQR); n (%)\n          \n      \n    \n\n\nThis table is not quite done yet, but notice that all of the fonts and other CSS style elements you see throughout this blog have been automatically applied to this table. Imagine how hard that would be if we made our table with Word or Excel!\n\nℹ Column(s) AGE, MARSTAT, EDUCATTGEN, URBAN, and COUNTRY are class \n'haven_labelled'. This is an intermediate datastructure not meant for analysis. \nConvert columns with `haven::as_factor()`,`labelled::to_factor()`, \n`labelled::unlabelled()`, and `unclass()`. 'haven_labelled' value labels are \nignored when columns are not converted. Failure to convert may have unintended \nconsequences or result in error.\n\n• https://haven.tidyverse.org/articles/semantics.html\n• https://larmarange.github.io/labelled/articles/intro_labelled.html#unlabelled\n\nDisplay value labels\nThis is a very helpful starting point, but it’s certainly not a finished product yet. The biggest issue is related to the alert message shown above: as we’ve discussed in previous posts, the categorical variables you’ll find in IPUMS data extracts are usually imported as haven_labelled objects, rather than the more common factor class of objects. In practice, this means that every response option from the questionnaire has both a value and a label:\n\n\ncovid %>% count(MARSTAT)\n\n\n# A tibble: 6 × 2\n                             MARSTAT     n\n                           <int+lbl> <int>\n1 10 [Never married]                  3041\n2 21 [Currently married]              7209\n3 22 [Currently living with partner]   817\n4 31 [Divorced or separated]           778\n5 32 [Widow or widower]                334\n6 98 [No response or missing]            5\n\n\nYou can access value labels with the ipumsr function ipums_val_labels.\nThe variable MARSTAT is a haven_labelled object where the value of each response is an integer (10, 21, 22, 31, 32, or 98), and the label describing each value is shown in square brackets to the right.\nWhen gtsummary warns you that\nThis is an intermediate datastructure not meant for analysis\n…it’s referring to the fact that labels are only an attribute of the variable. Attributes are metadata meant to assist the analyst running R in real-time, but they aren’t typically used by R in graphics or computational analysis.\nIn our table, gtsummary displays the numeric value for each response, rather than the much more readable labels. The easiest way to change this behavior is to coerce all of our categorical variables to the factor object class.\nWe recommend dividing this process into three steps:\nIdentify any labels in your dataset that represent non-response codes, like No response or missing shown for MARSTAT. We’ll want to exclude these from our table, so we’ll convert them to the generic missing value NA with ipumsr::lbl_na_if().\nIdentify any labelled variables that are not categorical. For example, the variable AGE in our dataset is labelled because the values 90 through 99 can represent either a respondent’s age in years (if not labelled) or a non-response code (if labelled). After converting non-response codes to NA in step 1, we’ll want to change the class of variables like AGE with ipumsr::zap_labels().\nCoerce all remaining labelled variables as factors with ipumsr::as_factor(), and remove any unused response options with fct_drop().\n\n\ncovid <- covid %>% \n  mutate(\n    across(everything(), ~lbl_na_if(\n      .x,\n      ~.lbl %in% c(\n        \"Logical edit - missing\",\n        \"Not interviewed (female questionnaire)\",\n        \"Not interviewed (household questionnaire)\",\n        \"Don't know\",\n        \"No response or missing\",\n        \"NIU (not in universe)\"\n      )\n    )),\n    across(AGE, zap_labels),\n    across(where(is.labelled), ~as_factor(.x) %>% fct_drop)\n  )\n\n\n\nCommon mistake: make sure to use the function as_factor() from ipumsr, and not the base R function as.factor(). The difference is that the former will use labels for each factor level, while the latter will use the original numeric values.\nCoercing categorical variables as factors will greatly improve the readability of our table. Because we’ve introduced NA values, we’ll add the argument missing = \"no\" to exclude them from our table:\n\n\ncovid %>% \n  select(AGE, MARSTAT, EDUCATTGEN, URBAN, COUNTRY) %>% \n  tbl_summary(by = COUNTRY, missing = \"no\")\n\n\n\nCharacteristic\n      Burkina Faso, N = 3,5281\n      Congo, Democratic Republic, N = 1,3241\n      Kenya, N = 5,9861\n      Nigeria, N = 1,3461\n    Age in female respondent questionnaire\n29 (22, 36)\n28 (22, 36)\n30 (24, 38)\n31 (24, 39)Marital status, female questionnaire\n\n\n\nNever married\n882 (25%)\n605 (46%)\n1,206 (20%)\n348 (26%)Currently married\n2,187 (62%)\n450 (34%)\n3,717 (62%)\n855 (64%)Currently living with partner\n254 (7.2%)\n170 (13%)\n367 (6.1%)\n26 (1.9%)Divorced or separated\n126 (3.6%)\n82 (6.2%)\n493 (8.2%)\n77 (5.7%)Widow or widower\n78 (2.2%)\n16 (1.2%)\n201 (3.4%)\n39 (2.9%)Highest level of school attended, general (4 categories)\n\n\n\nNever attended\n1,213 (34%)\n4 (0.3%)\n119 (2.0%)\n86 (6.4%)Primary/Middle school\n702 (20%)\n40 (3.0%)\n2,598 (43%)\n134 (10.0%)Secondary/post-primary\n1,374 (39%)\n884 (67%)\n2,217 (37%)\n637 (47%)Tertiary/post-secondary\n239 (6.8%)\n395 (30%)\n1,052 (18%)\n486 (36%)Urban/rural status\n\n\n\nRural\n892 (25%)\n0 (NA%)\n3,697 (62%)\n164 (12%)Urban\n2,636 (75%)\n0 (NA%)\n2,289 (38%)\n1,182 (88%)\n        \n          1\n          \n           \n          Median (IQR); n (%)\n          \n      \n    \n\nCustomize variable labels\nYou may have noticed that gtsummary ignored the value labels for each of our haven_labelled variables before we converted them into factor variables, but it did find and use variable labels. For example, you see the variable label Age in female respondent questionnaire instead of the variable name AGE.\n\nYou can access variable labels with the ipumsr function ipums_var_label.\nWhile this is sometimes helpful behavior, we feel that the word “Age” would have been fine on its own. Likewise, we’d like to clean up the labels for MARSTAT, EDUCATTGEN, and URBAN to make them as concise as possible.\nYou can override the ipumsr value labels in your table without changing the underlying data. Just add them as a list of formulas via the label argument: the variable name goes on the left of ~, and a character string containing the desired label goes on the right.\nThere are a few supporting functions that allow you to stylize these labels. We’ll use italicize_labels() to print our new labels in italics.\n\n\ncovid %>% \n  select(AGE, MARSTAT, EDUCATTGEN, URBAN, COUNTRY) %>% \n  tbl_summary(\n    by = COUNTRY,\n    missing = \"no\",\n    label = list(\n      AGE ~ \"Age\",\n      MARSTAT ~ \"Marital status\",\n      EDUCATTGEN ~ \"Education\",\n      URBAN ~ \"Urban vs Rural\"\n    )\n  ) %>% \n  italicize_labels() \n\n\n\nCharacteristic\n      Burkina Faso, N = 3,5281\n      Congo, Democratic Republic, N = 1,3241\n      Kenya, N = 5,9861\n      Nigeria, N = 1,3461\n    Age\n29 (22, 36)\n28 (22, 36)\n30 (24, 38)\n31 (24, 39)Marital status\n\n\n\nNever married\n882 (25%)\n605 (46%)\n1,206 (20%)\n348 (26%)Currently married\n2,187 (62%)\n450 (34%)\n3,717 (62%)\n855 (64%)Currently living with partner\n254 (7.2%)\n170 (13%)\n367 (6.1%)\n26 (1.9%)Divorced or separated\n126 (3.6%)\n82 (6.2%)\n493 (8.2%)\n77 (5.7%)Widow or widower\n78 (2.2%)\n16 (1.2%)\n201 (3.4%)\n39 (2.9%)Education\n\n\n\nNever attended\n1,213 (34%)\n4 (0.3%)\n119 (2.0%)\n86 (6.4%)Primary/Middle school\n702 (20%)\n40 (3.0%)\n2,598 (43%)\n134 (10.0%)Secondary/post-primary\n1,374 (39%)\n884 (67%)\n2,217 (37%)\n637 (47%)Tertiary/post-secondary\n239 (6.8%)\n395 (30%)\n1,052 (18%)\n486 (36%)Urban vs Rural\n\n\n\nRural\n892 (25%)\n0 (NA%)\n3,697 (62%)\n164 (12%)Urban\n2,636 (75%)\n0 (NA%)\n2,289 (38%)\n1,182 (88%)\n        \n          1\n          \n           \n          Median (IQR); n (%)\n          \n      \n    \n\nChange default statistics\nWhat about the statistics that tbl_summary() calculates? By default, tbl_summary() reports the median (and IQR) for integer variables like AGE, and it reports the frequency (and percentage) of each level for all of the factor variables we’ve created.\nYou can change the statistics calculated for one or more variables by name, or you can change them for all variables of a similar type (e.g. all_categorical). You’ll need to choose or define a custom function, then provide it to the stat argument as a character string between curly brackets like this:\n\"{mean}\"\nHere, we’ll demonstrate how to calculate the mean (and standard deviation) for AGE, and the percentage for all responses to all factors / categorical variables.\nYou may also decide to feature information about which statistics were calculated more prominently alongside the variable labels, rather than in the footer. Simply pipe your table to the function add_stat_label() as shown below:\n\n\ncovid %>% \n  select(AGE, MARSTAT, EDUCATTGEN, URBAN, COUNTRY) %>% \n  tbl_summary(\n    by = COUNTRY,\n    missing = \"no\",\n    label = list(\n      AGE ~ \"Age\",\n      MARSTAT ~ \"Marital status\",\n      EDUCATTGEN ~ \"Education\",\n      URBAN ~ \"Urban vs Rural\"\n    ),\n    stat = list(\n      AGE ~ \"{mean} ({sd})\",\n      all_categorical() ~\"{p}\"\n    )\n  )%>% \n  italicize_labels() %>% \n  add_stat_label()\n\n\n\nCharacteristic\n      Burkina Faso, N = 3,528\n      Congo, Democratic Republic, N = 1,324\n      Kenya, N = 5,986\n      Nigeria, N = 1,346\n    Age, Mean (SD)\n30 (9)\n29 (9)\n31 (9)\n31 (9)Marital status, %\n\n\n\nNever married\n25\n46\n20\n26Currently married\n62\n34\n62\n64Currently living with partner\n7.2\n13\n6.1\n1.9Divorced or separated\n3.6\n6.2\n8.2\n5.7Widow or widower\n2.2\n1.2\n3.4\n2.9Education, %\n\n\n\nNever attended\n34\n0.3\n2.0\n6.4Primary/Middle school\n20\n3.0\n43\n10.0Secondary/post-primary\n39\n67\n37\n47Tertiary/post-secondary\n6.8\n30\n18\n36Urban vs Rural, %\n\n\n\nRural\n25\nNA\n62\n12Urban\n75\nNA\n38\n88\n\n\nMore information about functions for table statistics can be found here.\nCustomize headers & footnotes\nTable headers and footnotes can be customized with the functions modify_header() and modify_footnote(). We’ll remove the frequencies from our header, use the abbreviated label DR Congo, and remove the label Characteristic from the first column. Lastly, we’ll add a title to our table with modify_spanning_header().\n\n\ncovid %>% \n  select(AGE, MARSTAT, EDUCATTGEN, URBAN, COUNTRY) %>% \n  tbl_summary(\n    by = COUNTRY,\n    missing = \"no\",\n    stat = list(\n      AGE ~ \"{mean} ({sd})\",\n      all_categorical() ~\"{p}\"\n    ),\n    label = list(\n      AGE ~ \"Age\",\n      MARSTAT ~ \"Marital status\",\n      EDUCATTGEN ~ \"Education\",\n      URBAN ~ \"Urban vs Rural\"\n    )\n  ) %>% \n  add_stat_label() %>% \n  italicize_labels() %>% \n  modify_header(update = list(\n      label ~ \" \",\n      stat_1 ~ \"**Burkina Faso**\",\n      stat_2 ~ \"**DR Congo <br> (Kinshasa)**\",\n      stat_3 ~ \"**Kenya**\",\n      stat_4 ~ \"**Nigeria <br> (Lagos & Kano)**\"\n  )) %>% \n  modify_spanning_header(\n    everything() ~ \"## Sample Demographics\"\n  ) \n\n\n\n\n        Sample Demographics\n\n      \n    \n      Burkina Faso\n      DR Congo  (Kinshasa)\n      Kenya\n      Nigeria  (Lagos & Kano)\n    Age, Mean (SD)\n30 (9)\n29 (9)\n31 (9)\n31 (9)Marital status, %\n\n\n\nNever married\n25\n46\n20\n26Currently married\n62\n34\n62\n64Currently living with partner\n7.2\n13\n6.1\n1.9Divorced or separated\n3.6\n6.2\n8.2\n5.7Widow or widower\n2.2\n1.2\n3.4\n2.9Education, %\n\n\n\nNever attended\n34\n0.3\n2.0\n6.4Primary/Middle school\n20\n3.0\n43\n10.0Secondary/post-primary\n39\n67\n37\n47Tertiary/post-secondary\n6.8\n30\n18\n36Urban vs Rural, %\n\n\n\nRural\n25\nNA\n62\n12Urban\n75\nNA\n38\n88\n\nText provided to modify_header(), modify_footnote(), and modify_spanning_header() can be stylized with either markdown syntax (shown) or HTML.\nHeaders can span individuals columns (as shown in modify_header()), groups of columns, or everything() (as shown in modify_spanning_header()).\nTip: if you simply want to move the sample size from the header into its own row (rather than delete it, as we’ve done here), you could create a new factor variable N where every person gets the value 1 in the step after our select() function.\nSampling Weights\nWe mentioned in our last post that the PMA COVID-19 survey comes with a new weighting variable, CVQWEIGHT, which is analogous to the variable FQWEIGHT found in other Household and Female samples. CVQWEIGHT can be used to estimate all of the statistics shown in our table for the broader population represented by each sample (note that two of the samples are not nationally representative):\n\nYou’ll find more detail about the construction of PMA COVID-19 survey weights here.\nBurkina Faso: nationally representative\nKenya: nationally representative\nDRC: Kinshasa only\nNigeria: Lagos and Kano only\nThe srvyr package includes several functions that make it easy to incorporate survey weights into a tidy workflow. Simply provide information about the survey design to srvyr::as_survey_design(), and then pipe this information to a survey analysis function.\nFor example, a tidy workflow calculating the mean AGE of women in each of the four samples might look like this:\n\n\ncovid %>% \n  group_by(COUNTRY) %>% \n  summarise(mean(AGE))\n\n\n# A tibble: 4 × 2\n  COUNTRY                    `mean(AGE)`\n  <fct>                            <dbl>\n1 Burkina Faso                      29.7\n2 Congo, Democratic Republic        29.5\n3 Kenya                             31.1\n4 Nigeria                           31.4\n\nYou can use CVQWEIGHT to estimate the mean AGE of reproductive age women in each of the four target populations like this:\n\n\ncovid %>% \n  as_survey_design(weight = CVQWEIGHT) %>%\n  group_by(COUNTRY) %>% \n  summarise(survey_mean(AGE))\n\n\n# A tibble: 4 × 3\n  COUNTRY                     coef `_se`\n  <fct>                      <dbl> <dbl>\n1 Burkina Faso                27.9 0.370\n2 Congo, Democratic Republic  28.9 0.327\n3 Kenya                       28.9 0.186\n4 Nigeria                     30.4 0.329\n\n\nNotice that all four samples skew a bit older compared to their target populations.\nHappily, gtsummary can read survey information from the function as_survey_design(). This saves us the trouble of calculating weighted statistics for each of the variables in our table; instead, we can create weighted statistics for our table with just one line of code if we swap tbl_summary for its companion function, tbl_svysummary():\n\n\ncovid %>% \n  as_survey_design(weight = CVQWEIGHT) %>% # CVQWEIGHT goes here\n  select(AGE, MARSTAT, EDUCATTGEN, URBAN, COUNTRY) %>% \n  tbl_svysummary( # use tbl_svysummary() in place of tbl_summary()\n    by = COUNTRY,\n    missing = \"no\",\n    stat = list(\n      AGE ~ \"{mean} ({sd})\",\n      all_categorical() ~\"{p}\"\n    ),\n    label = list(\n      AGE ~ \"Age\",\n      MARSTAT ~ \"Marital status\",\n      EDUCATTGEN ~ \"Education\",\n      URBAN ~ \"Urban vs Rural\"\n    )\n  ) %>% \n  italicize_labels() %>% \n  add_stat_label() %>% \n  modify_header(update = list(\n      label ~ \" \",\n      stat_1 ~ \"**Burkina Faso**\",\n      stat_2 ~ \"**DR Congo <br> (Kinshasa)**\",\n      stat_3 ~ \"**Kenya**\",\n      stat_4 ~ \"**Nigeria <br> (Lagos & Kano)**\"\n  )) %>% \n  modify_spanning_header(\n    everything() ~ \"## Weighted Population Estimates\"\n  )\n\n\n\n\n        Weighted Population Estimates\n\n      \n    \n      Burkina Faso\n      DR Congo  (Kinshasa)\n      Kenya\n      Nigeria  (Lagos & Kano)\n    Age, Mean (SD)\n28 (9)\n29 (9)\n29 (9)\n30 (9)Marital status, %\n\n\n\nNever married\n22\n47\n30\n27Currently married\n69\n31\n54\n63Currently living with partner\n6.1\n13\n5.8\n2.4Divorced or separated\n1.9\n6.3\n7.3\n5.1Widow or widower\n1.4\n1.9\n2.8\n2.3Education, %\n\n\n\nNever attended\n55\n0.4\n1.9\n9.8Primary/Middle school\n19\n5.7\n46\n13Secondary/post-primary\n24\n72\n39\n46Tertiary/post-secondary\n1.8\n22\n13\n31Urban vs Rural, %\n\n\n\nRural\n79\nNA\n73\n18Urban\n21\nNA\n27\n82\n\n\n\n\n\n© Greg Freedman Ellis et al. (GPL 2 | GPL 3)\nWe’ve now made a weighted descriptive statistics table, and we’ve only changed two lines of code. As we’ll see, creating a summary table from a model that uses sample design information can be just as easy.\nModel Summary Table\nThe gtsummary package also contains a function designed to summarise and format output from regression models. For example, let’s build a simple logistic regression model for HLTHCAREDIFFFEAR, which indicates whether a woman experienced difficulty accessing healthcare because she was afraid of becoming infected with COVID-19. We’ll try modeling this outcome using the demographic variables that are available for all four samples: AGE, MARSTAT, and EDUCATTGEN (URBAN was not available for the DRC sample).\nFirst, we’ll recode HLTHCAREDIFFFEAR into a binary indicator that’s suitable for use in a logistic regression model. We can collapse responses “No” and “None of the above”, since the latter indicates that the woman experienced no difficulties accessing healthcare at all.\n\n\ncovid %>% count(HLTHCAREDIFFFEAR)\n\n\n# A tibble: 4 × 2\n  HLTHCAREDIFFFEAR      n\n  <fct>             <int>\n1 No                 1101\n2 Yes                3881\n3 None of the above  7114\n4 <NA>                 88\n\ncovid <- covid %>% \n  mutate(HLTHCAREDIFFFEAR = fct_collapse(HLTHCAREDIFFFEAR, No = c(\n    \"No\", \n    \"None of the above\"\n  ))) \n\ncovid %>% count(HLTHCAREDIFFFEAR)\n\n\n# A tibble: 3 × 2\n  HLTHCAREDIFFFEAR     n\n  <fct>            <int>\n1 No                8215\n2 Yes               3881\n3 <NA>                88\n\nResults from one model\nBecause IPUMS PMA samples are collected with geographic clusters - represented by EAID - we generally recommend specifying both a sample weight and a cluster identification with as_survey_design(). We’ll need to use a function that can build a general linear model using that survey design information, so we’ll use survey::svyglm(), rather than the base R function glm that might be more familiar. The output of a call to svyglm() is not formatted as a publication-ready table. Let’s see what happens when we build a model for our Burkina Faso sample:\n\n\ncovid %>% \n  filter(COUNTRY == \"Burkina Faso\") %>% \n  as_survey_design(weight = CVQWEIGHT, id = EAID) %>% \n  survey::svyglm(\n    formula = HLTHCAREDIFFFEAR ~ AGE + MARSTAT + EDUCATTGEN, \n    family = \"quasibinomial\"\n  ) \n\n\n1 - level Cluster Sampling design (with replacement)\nWith (164) clusters.\nCalled via srvyr\nSampling variables:\n - ids: EAID\n - weights: CVQWEIGHT\n\nCall:  svyglm(formula = HLTHCAREDIFFFEAR ~ AGE + MARSTAT + EDUCATTGEN, \n    design = ., family = \"quasibinomial\")\n\nCoefficients:\n                         (Intercept)  \n                             -0.7495  \n                                 AGE  \n                             -0.0128  \n            MARSTATCurrently married  \n                              0.5784  \nMARSTATCurrently living with partner  \n                             -0.3228  \n        MARSTATDivorced or separated  \n                              0.3920  \n             MARSTATWidow or widower  \n                              0.1639  \n     EDUCATTGENPrimary/Middle school  \n                             -0.0782  \n    EDUCATTGENSecondary/post-primary  \n                             -0.3467  \n   EDUCATTGENTertiary/post-secondary  \n                              0.1427  \n\nDegrees of Freedom: 3526 Total (i.e. Null);  155 Residual\n  (1 observation deleted due to missingness)\nNull Deviance:      4381 \nResidual Deviance: 4299     AIC: NA\n\n\nBecause our use of weights results in non-integer outcomes, we’ll also need to use the “quasibinomial” modeling distribution, rather than the more typical “binomial” distribution.\nThe function gtsummary::tbl_regression() will tidy this output into a much more reader-friendly format. We’ll assign labels to each of our variables using the same label argument we saw before, and we’ll also choose to exponentiate our regression coefficients so that the results will reflect odds ratios:\n\n\ncovid %>% \n  filter(COUNTRY == \"Burkina Faso\") %>% \n  as_survey_design(weight = CVQWEIGHT, id = EAID) %>% \n  survey::svyglm(\n    formula = HLTHCAREDIFFFEAR ~ AGE + MARSTAT + EDUCATTGEN, \n    family = \"quasibinomial\"\n  ) %>% \n  tbl_regression(\n    exponentiate = TRUE,\n    label = list(\n      AGE ~ \"Age\",\n      MARSTAT ~ \"Marital status\",\n      EDUCATTGEN ~ \"Education\"   \n    )\n  ) \n\n\n\nCharacteristic\n      OR1\n      95% CI1\n      p-value\n    Age\n0.99\n0.96, 1.01\n0.3Marital status\n\n\nNever married\n—\n—\nCurrently married\n1.78\n1.02, 3.13\n0.043Currently living with partner\n0.72\n0.25, 2.06\n0.5Divorced or separated\n1.48\n0.69, 3.18\n0.3Widow or widower\n1.18\n0.41, 3.42\n0.8Education\n\n\nNever attended\n—\n—\nPrimary/Middle school\n0.92\n0.61, 1.41\n0.7Secondary/post-primary\n0.71\n0.44, 1.12\n0.14Tertiary/post-secondary\n1.15\n0.66, 2.02\n0.6\n        \n          1\n          \n           \n          OR = Odds Ratio, CI = Confidence Interval\n          \n      \n    \n\nWe can also add conventional “stars” representing the significance of each coefficient with the add_significance_stars() function. Here, we could choose to display cluster-robust standard error estimates, but we’ll display 95% confidence intervals instead. We’ll also customize the header and add a title, using the same modify functions shown above.\n\n\ncovid %>% \n  filter(COUNTRY == \"Burkina Faso\") %>% \n  as_survey_design(weight = CVQWEIGHT, id = EAID) %>% \n  survey::svyglm(\n    formula = HLTHCAREDIFFFEAR ~ AGE + MARSTAT + EDUCATTGEN, \n    family = \"quasibinomial\"\n  ) %>% \n  tbl_regression(\n    exp = TRUE,\n    label = list(\n      AGE ~ \"Age\",\n      MARSTAT ~ \"Marital status\",\n      EDUCATTGEN ~ \"Education\"   \n    )\n  ) %>%\n  modify_footnote(everything() ~ NA, abbreviation = TRUE) %>%\n  add_significance_stars(hide_se = TRUE, hide_ci = FALSE) %>%\n  modify_header(update = list(\n    label ~ \" \" ,\n    estimate ~ '**Burkina Faso**',\n    ci ~ \"95% CI\"\n  )) %>% \n  modify_spanning_header(\n    everything() ~ \"## Odds Ratios obtained from Logistic Regression\"\n  ) \n\n\n\n\n        Odds Ratios obtained from Logistic Regression\n\n      \n    \n      Burkina Faso1\n      95% CI\n    Age\n0.99\n0.96, 1.01Marital status\n\nNever married\n—\n—Currently married\n1.78*\n1.02, 3.13Currently living with partner\n0.72\n0.25, 2.06Divorced or separated\n1.48\n0.69, 3.18Widow or widower\n1.18\n0.41, 3.42Education\n\nNever attended\n—\n—Primary/Middle school\n0.92\n0.61, 1.41Secondary/post-primary\n0.71\n0.44, 1.12Tertiary/post-secondary\n1.15\n0.66, 2.02\n        \n          1\n          \n           \n          *p<0.05; **p<0.01; ***p<0.001\n          \n      \n    \n\nResults from several models\nResearchers often report results from several models if, for example, they want to compare results including a range of different controls. You might also decide to model data from each of the COVID-19 samples separately in order to highlight important differences between their target populations. How would you merge results from four models into a single table?\nIf you repeat the same code shown above for each of the four samples, you’ll obtain four separate tables. We recommend using purrr::map() to store these tables in a list, which you can then pass to gtsummary::tbl_merge(). Here, we map over each of the factor levels in COUNTRY, using tbl_regression() to build a regression table for each. We pipe a list of four tables to tbl_merge(), and then add a header and title.\n\n\nlevels(covid$COUNTRY) %>% \n  map(~{\n    covid %>% \n      as_survey_design(weight = CVQWEIGHT) %>% \n      filter(COUNTRY == .x) %>% \n      survey::svyglm(\n        formula = HLTHCAREDIFFFEAR ~ AGE + MARSTAT + EDUCATTGEN, \n        family = \"quasibinomial\"\n      ) %>% \n      tbl_regression(\n        exp = TRUE,\n        label = list(\n          AGE ~ \"Age\",\n          MARSTAT ~ \"Marital status\",\n          EDUCATTGEN ~ \"Education\"   \n        )\n      ) %>% \n      italicize_labels() %>% \n      modify_footnote(everything() ~ NA, abbreviation = TRUE) %>%\n      add_significance_stars(hide_se = T, hide_ci = F) %>% \n      modify_header(update = list(ci ~ \"95% CI\"))\n  }) %>% \n  tbl_merge() %>% \n  modify_header(update = list(\n    label ~ \" \" ,\n    estimate_1 ~ '**Burkina Faso**',\n    estimate_2 ~ '**DR Congo <br> (Kinshasa)**',\n    estimate_3 ~ '**Kenya**',\n    estimate_4 ~ '**Nigeria <br> (Lagos & Kano)**'\n  )) %>% \n  modify_spanning_header(\n    everything() ~ \"## Odds Ratios obtained from Logistic Regression\"\n  ) \n\n\n\n\n\n\n\n© RStudio (CC0 1.0)\npurrr is included with library(tidyverse).\n\n\n\n        Odds Ratios obtained from Logistic Regression\n\n      \n    \n      Burkina Faso1\n      95% CI\n      DR Congo  (Kinshasa)1\n      95% CI\n      Kenya1\n      95% CI\n      Nigeria  (Lagos & Kano)1\n      95% CI\n    Age\n0.99\n0.97, 1.01\n0.97*\n0.95, 1.00\n0.98***\n0.97, 0.99\n0.99\n0.97, 1.01Marital status\n\n\n\n\n\n\n\nNever married\n—\n—\n—\n—\n—\n—\n—\n—Currently married\n1.78\n0.92, 3.45\n1.16\n0.73, 1.83\n1.21\n0.97, 1.52\n1.64\n0.95, 2.83Currently living with partner\n0.72\n0.32, 1.62\n0.55\n0.27, 1.11\n0.81\n0.59, 1.11\n2.81\n0.94, 8.40Divorced or separated\n1.48\n0.50, 4.35\n1.94\n0.95, 3.98\n1.26\n0.92, 1.73\n1.10\n0.49, 2.49Widow or widower\n1.18\n0.38, 3.62\n0.70\n0.08, 6.11\n1.09\n0.72, 1.65\n0.39\n0.10, 1.56Education\n\n\n\n\n\n\n\nNever attended\n—\n—\n—\n—\n—\n—\n—\n—Primary/Middle school\n0.92\n0.58, 1.47\n0.39\n0.02, 6.06\n1.50\n0.95, 2.38\n0.85\n0.33, 2.17Secondary/post-primary\n0.71\n0.43, 1.16\n0.99\n0.10, 9.67\n1.31\n0.82, 2.09\n0.80\n0.37, 1.73Tertiary/post-secondary\n1.15\n0.71, 1.88\n1.29\n0.13, 12.7\n1.47\n0.91, 2.37\n0.78\n0.35, 1.74\n        \n          1\n          \n           \n          *p<0.05; **p<0.01; ***p<0.001\n          \n      \n    \n\nOutput Options\nSo now you know that you can make a great-looking table in R that renders nicely in HTML (you’re reading this post on a web page, after all). But what if you want to export your table to a Word document, PDF, or some other format?\nFor Word documents, try piping your table to the function gtsummary::as_flex_table() like this, and then copy / paste the result directly into Word. (You may need to install the package flextable first).\n\n\ncovid %>% \n  select(AGE, MARSTAT, EDUCATTGEN, URBAN, COUNTRY) %>% \n  tbl_summary(by = COUNTRY) %>% \n  as_flex_table()\n\n\n\nSkip the copy and paste step! Did you know that you can create Word documents in R with RMarkdown?\nSeveral printers work well for PDF output, including the very popular kable_extra. If you’re making a PDF with RMarkdown, for example, you could pipe your table into gtsummary::as_kable_extra(). (You may need to install the package kable_extra first).\n\n\ncovid %>% \n  select(AGE, MARSTAT, EDUCATTGEN, URBAN, COUNTRY) %>% \n  tbl_summary(by = COUNTRY) %>% \n  as_kable_extra()\n\n\n\nYou’ll find more information about output options here.\nNext Steps\nWe hope you found these steps helpful in using R to create tables for descriptive statistics, survey weights, and model summary output. As always, feel free to reach out to us with any questions. In our next post, we will show how to make likert-style stacked bar charts with R using the PMA COVID-19 survey data. Check back here in two weeks for the next post in this series!\n\n\n\n",
    "preview": "posts/2021-07-01-covid-tables/images/gtsummary_wide.png",
    "last_modified": "2022-04-13T13:10:46-04:00",
    "input_file": {},
    "preview_width": 483,
    "preview_height": 230
  },
  {
    "path": "posts/2021-06-15-covid-discovery/",
    "title": "New PMA COVID-19 Survey Data",
    "description": "A new panel study promises insights into the impact of COVID-19 on family planning and reproductive health.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-06-15",
    "categories": [
      "COVID-19",
      "Panel Data",
      "Data Discovery",
      "New Data"
    ],
    "contents": "\n\nContents\nSample Design\nTopics\nHealthcare Access\nCOVID-related Experience\nCOVID Information Sources\nCOVID Knowledge\nCOVID Prevention\nPerceptions Around COVID\n\nNext Steps\n\nThe COVID-19 pandemic has strained healthcare systems across the globe, and researchers are already beginning to examine the short-term impacts of service disruption on family planning and reproductive health.1 This spring, IPUMS PMA released COVID-19 survey data collected from reproductive age women between May and August 2020 in these countries:\nBurkina Faso\nDemocratic Republic of Congo (DRC)\nKenya\nNigeria\n\n\n\nThese women are participants in an ongoing panel study focused on core PMA topics in reproductive health. The baseline survey data for this study have already been released, and we will demonstrate how to link records between the baseline survey and the COVID-19 follow-up in an upcoming post in this series. Subsequent waves of the panel study will help to show how women’s backgrounds and levels of knowledge, perceptions, and experiences with COVID-19 shape long-term family planning outcomes.\nClick here for more information on the COVID-19 Survey design, and to learn how it fits with the ongoing panel study.\nIn this post, we’ll cover the contents of the PMA COVID-19 survey. If you’re a registered IPUMS PMA user, you can obtain COVID-19 survey data by navigating to the new COVID-19 “Unit of Analysis.”\n\n\n\nClick here for help creating, downloading, and importing an IPUMS PMA data extract into R.\nSample Design\nThe PMA COVID-19 survey is a follow-up telephone survey administered to women who participated in an in-person baseline survey for a broader panel study. This baseline survey was collected between November 2019 and Februrary 2020 - prior to the appearance of COVID-19 in most countries.\nWhen the outbreak of COVID-19 grew into a global pandemic in the spring of 2020, PMA representatives partnered with the Ministries of Health in DRC, Kenya, Burkina Faso, and Nigeria to design a shorter - approximately 30 minute - survey responding directly to the effect of COVID-19 on women and their households.\n\nSeveral countries participating in the new PMA panel study had not completed baseline sample collection by March 2020 (Uganda, India, Niger, Cote d’Ivoire).\nWomen were selected for the baseline survey if they were age 15-49 and resided in a household screened at random from a sample cluster represented by EAID. All women surveyed at baseline where eligible to participate in the COVID-19 follow-up, provided that they 1) agreed to the interview, and 2) owned or had access to a telephone.\nA COVID-19 module was incorporated into their baseline surveys in late 2020, but these data have not yet been released.\nYou’ll find survey weights adjusted for the probability that a given woman had access to a telephone recorded in the new variable CVQWEIGHT. This weight is normalized for the target population of each sample (note that two of the samples are not nationally representative):\nBurkina Faso: nationally representative\nKenya: nationally representative\nDRC: Kinshasa only\nNigeria: Lagos and Kano only\nYou’ll find more detail about the construction of PMA COVID-19 survey weights here. For information about response rates for each sample, check out sample-specific Dataset Notes.\nTopics\nThe COVID-19 survey included a number of questions that you’ll also find in the baseline survey and in future rounds of the panel study. These include topics like fertility preferences, current or recent use of family planning, and core demographic information. You might use these variables, for example, to see if women who were using a particular contraceptive method at the time of the baseline survey had stopped using that method during the first few months of the COVID-19 outbreak.\nVariables from the remainder of the COVID-19 questionnaire are organized on the IPUMS PMA website under 6 topic headings:\nHealthcare Access\nCOVID-related Experience\nCOVID Information Sources\nCOVID Knowledge\nCOVID Prevention\nPerceptions Around COVID\n\n\n\nHealthcare Access\nAll sampled women report whether they have needed to visit a health facility since COVID-19 restrictions began - including family planning visits - in CVFACVISIT. Additionally, all sampled women report whether they experienced any of the following difficulties accessing healthcare services during the same time period (select all that apply, or none):\nfacility closed / no appointment available\nnot affordable\npartner does not approve\nno available transportation\ngovernment restrictions on movement\nfear of being infected with COVID-19 at healthcare facilities\nFinally, women who did visit a healthcare facility since COVID-19 restrictions began report whether they successfully accessed needed services in HCACCESS.\nCOVID-related Experience\nIn addition to their own experiences accessing healthcare during the outbreak, women who confirmed that they had heard or read about COVID-19 were also asked to report the impact of the virus on their communities and in their households.\nSpecifically, these women were asked to estimate whether most, some, few, or no people in their community had been infected, and whether any close relatives or friends had been infected. They were also asked to rate their level on concern about the spread of COVID-19 in their community.\nYou’ll find several measures related to household-level impacts, including indicators for whether anyone in the woman’s household experienced food insecurity, and whether the the household had experienced income loss. Related questions measure changes in married / partnered women’s autonomy during the outbreak, including whether they became more or less reliant on their partner for basic needs (if at all), and whether they or their partner now makes decisions about household purchases.\nCOVID Information Sources\nWomen who confirmed that they had heard or read about COVID-19 were also asked about several different sources of information about COVID-19. For each source of information, women were asked both:\nwhether they had learned about COVID-19 from the source, and\nwhether they trust the source for accurate information about COVID-19\n13 sources of information were listed (select all that apply, or none):\nNewspaper\nRadio\nTelevision\nPoster / billboard\nTown crier\nPhone message\nFamily\nFriends / neighbors\nCommunity/religious leaders\nSocial media (Twitter, Facebook, WhatsApp)\nHealth personnel\nMessages from government or authorities\nSchool\n\nNotably, all four samples used the same list of information sources.\nYou’ll also find variables in this topic heading related to awareness, trust, and use of an emergency number or call center for reporting suspected cases of COVID-19.\nCOVID Knowledge\nWomen who confirmed that they had heard or read about COVID-19 were asked to identify common symptoms of COVID-19 from this list (select all that apply, or none):\nFever\nCough\nShortness of breath/difficulty breathing\nChest pain\nSore throat\nRunny or stuffy nose\nMuscle or body aches\nHeadaches\nFatigue (tiredness)\nDiarrhea\nLoss of taste\nLoss of smell\nRash\nDizziness\nSneezing\nOther\nThese women were also asked whether any of the following actions could reduce the risk of being infected (available responses are “yes,” “no,” or “do not know” for each action):\nWashing hands with soap and water frequently\nWashing hands with hand sanitizer frequently\nAvoiding any close contact (2 meters) with people when you go out\nStaying in your home\nGetting vaccinated\nTraditional practices\nWearing something that covers your mouth and nose when you go out (a mask)\nAvoiding shaking hands with others\nCoughing/sneezing into your elbow or tissue\nPrayer\nCOVID Prevention\nWomen who confirmed that they had heard or read about COVID-19 were asked if they had personally taken any action to prevent becoming infected. If so, they were asked which of the following actions they had personally taken (select all that apply):\nWashing hands with soap and water frequently\nWashing hands with hand sanitizer frequently\nAvoiding any close contact (2 meters) with people when you go out\nStaying in your home\nGetting vaccinated\nTraditional practices\nWearing something that covers your mouth and nose when you go out (a mask)\nAvoiding shaking hands with others\nCoughing/sneezing into your elbow or tissue\nPrayer\nOther\nWomen who confirmed that they had heard or read about COVID-19 were also asked if they were able to avoid contact with people outside of their own household. If not, they were asked if any of the following reasons explained why they might not be able to avoid contact (select all that apply, or none):\nMy work or way of earning money requires me to leave the house\nI need to visit the market\nI need to visit the water source / well\nMy studies require me to leave the household\nI need to attend funerals in the community\nI need to attend religious services\nI need to visit my family/relatives\nTo seek out health care\nPerceptions Around COVID\nWomen who confirmed that they had heard or read about COVID-19 were asked several questions about their overall level of concern about COVID-19, including how concerned they were about getting infected, whether they were worried about the impact of COVID-19 on their household’s finances in the future, and whether they would conceal information about a family member’s COVID-19 infection.\nThese women were also asked whether each of the following statements are true about COVID-19 (available responses are “yes,” “no,” or “don’t know” for each statement):\nSome people cannot be infected with Coronavirus (COVID-19)\nMost people experience mild or no symptoms\nMost people develop serious illness requiring hospitalization\nPeople can be infected and not have symptoms\nOnly people with symptoms are contagious\nYou can become infected by shaking hands with someone who is infected\nYou can become infected by close contact with infected people even if you are not touching\nPeople of all ages can become infected\nCoronavirus (COVID-19) is mostly a risk to rich people\nNext Steps\nFor the next two months, we’ll be taking a deep dive into the PMA COVID-19 survey data. Along the way, we’ll showcase several examples of R code you can use to create publication-ready tables and data visualizations, and we’ll explore some of the research questions you might answer by linking COVID-19 data to the baseline survey. Check back here for a new post every two weeks!\n\n\n\nFerreira-Filho, Edson Santos, Nilson Roberto de Melo, Isabel Cristina Esposito Sorpreso, Luis Bahamondes, Ricardo Dos Santos Simões, José Maria Soares-Júnior, and Edmund Chada Baracat. 2020. “Contraception and Reproductive Planning During the COVID-19 Pandemic.” Expert Review of Clinical Pharmacology 13 (6): 615–22. http://dx.doi.org/10.1080/17512433.2020.1782738.\n\n\nSenderowicz, Leigh, and Jenny Higgins. 2020. “Reproductive Autonomy Is Nonnegotiable, Even in the Time of COVID-19.” Perspectives on Sexual and Reproductive Health 52 (2): 81–85. http://dx.doi.org/10.1363/psrh.12152.\n\n\nTemmerman, Marleen. 2021. “Family Planning in COVID-19 Times: Access for All.” The Lancet. Global Health 9 (6): e728–29. http://dx.doi.org/10.1016/S2214-109X(21)00231-X.\n\n\nFor discussion, see (Senderowicz and Higgins 2020), (Temmerman 2021), and (Ferreira-Filho et al. 2020).↩︎\n",
    "preview": "posts/2021-06-15-covid-discovery/../../images/new_data.png",
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {},
    "preview_width": 2555,
    "preview_height": 1437
  },
  {
    "path": "posts/2021-05-24-migration-data-analysis/",
    "title": "Visualizing migration patterns over time",
    "description": "How to visualize patterns in migration data using alluvial plots, line plots, and density plots.",
    "author": [
      {
        "name": "Nina Brooks",
        "url": "http://www.ninarbrooks.com/"
      }
    ],
    "date": "2021-06-02",
    "categories": [
      "Migration",
      "Data Analysis",
      "Data Visualization",
      "Descriptive Analysis",
      "ggalluvial",
      "ggridges"
    ],
    "contents": "\n\nContents\nSet Up\nVisualizing Migration: Alluvial Plots\nWhy people migrate\nWhen people migrate\n\nMigration is an incredibly important, global demographic process. Yet, studying migration is often challenging due to data limitations. As we showed in a recent post, several new PMA samples include data about each respondent’s complete migration history, organized in chronological order. They include information on when respondents move (their age), the district or region they moved from, whether the place they moved from was a city, a town, peri-urban, or rural, and reasons why they moved.\n\nMake sure to check out our Data Discovery post on these migration variables for a lot more detail on what information is collected and the unique data structure for the migration variables!\nThis data opens up the opportunity to examine many interesting questions about migration such as:\nIs migration primarily from rural to urban places?\nWhy do people migrate?\nWhen do people migrate?\nIn this post, we’ll walk through three descriptive analyses that address aspects of these questions using the 2019 Kenya sample migration data from the last post in this series. Descriptive, exploratory work like this is an essential first step to any good analysis – and visualizing the data can help illuminate patterns across different dimensions. First, we’ll demonstrate how to visualize flows of migration across the urban-rural spectrum. Then, we’ll dig into the reasons why people moved to previous residences. Finally, we’ll explore how these reasons vary according to age at the time of migration.\nSet Up\nWe’ll be working with the same Kenya 2019 data extract we created for the previous post in this series (female respondents only). It contains all of the variables shown on the migration topic page.\nIn addition to loading the two standard packages we always use (ipumsr and tidyverse), we also load the ggalluvial package that we’ll use to make an alluvial plot and the ggridges package that we’ll use to make an overlapping ridgeline (aka density) plot. If this is the first time you’re using ggalluvial and ggridges, make sure to install them first using install.packages(c(\"ggalluvial\", \"ggridges\")).\nRecall that the migration data are stored in wide format, with many variables to capture information about each move for every single individual. We’ll quickly run the code from the last post that uses pivot_longer() to convert this into the much more useful long format. We’ll also replace the special codes as NA and create an ID that represents a short identification number for each person.\n\n\nlibrary(ipumsr)\nlibrary(ggalluvial)\nlibrary(ggridges)\nlibrary(tidyverse)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00016.xml\",\n  data = \"data/pma_00016.dat.gz\"\n)\n\ndat <- dat %>% \n  mutate(across(everything(), ~{\n    lbl_na_if(.x, ~.lbl %in% c(\n      \"No response or missing\",\n      \"NIU (not in universe)\"\n    ))\n  })) %>% \n  rowid_to_column(\"ID\") %>% \n  select(ID, starts_with(\"PLACE\"), -PLACELIVENUM) %>% \n  pivot_longer(\n    cols = starts_with(\"PLACE\"), \n    names_pattern = \"PLACE([0-9]*)(.*)\",\n    names_to = c(\"PLACE\", \".value\"),\n    values_drop_na = TRUE\n  ) %>%\n  mutate(\n    UR = as_factor(UR),\n    PLACE = as.numeric(PLACE)\n  )\n\n\n\n\nRemember: change these file paths to match the download location for your own data extract!\nNow that the data are in a long format, each row of the data represents one place in a respondent’s migration history. For example, notice that person ID == 20 occupies two rows, one for each of the two places she listed:\n\n\ndat\n\n\n# A tibble: 5,251 x 24\n      ID PLACE    COUNTRY  DISTRICTKE MOVEAGE UR    YCHILDEDU YCOHABIT\n   <int> <dbl>  <int+lbl>   <int+lbl> <int+l> <fct> <int+lbl> <int+lb>\n 1     2     1 404 [Keny…  6 [Nairob…      16 Rural    0 [No]   0 [No]\n 2    11     1 404 [Keny… 10 [Kakame…      17 Rural    0 [No]   0 [No]\n 3    12     1 404 [Keny… 10 [Kakame…      16 City…    0 [No]   0 [No]\n 4    14     1 404 [Keny…  7 [Nandi]       29 Rural    0 [No]   0 [No]\n 5    14     2 404 [Keny… 32 [Migori]      19 City…    0 [No]   0 [No]\n 6    16     1 404 [Keny…  6 [Nairob…      21 Rural    0 [No]   0 [No]\n 7    19     1 404 [Keny… 33 [Mombas…      31 Peri…    0 [No]   0 [No]\n 8    20     1 404 [Keny…  8 [Nyamir…      19 City…    0 [No]   0 [No]\n 9    20     2 404 [Keny…  8 [Nyamir…      21 Peri…    0 [No]   0 [No]\n10    21     1 404 [Keny…  6 [Nairob…      34 Peri…    0 [No]   0 [No]\n# … with 5,241 more rows, and 16 more variables: YCONFLICT <int+lbl>,\n#   YDIVORCE <int+lbl>, YFARM <int+lbl>, YHLTHACCESS <int+lbl>,\n#   YHLTHPROB <int+lbl>, YJOBSEARCH <int+lbl>, YOTHER <int+lbl>,\n#   YOTHERSOCIAL <int+lbl>, YPOSTMAR <int+lbl>,\n#   YSCHOOLATTEND <int+lbl>, YSCHOOLDONE <int+lbl>,\n#   YSICKREL <int+lbl>, YSPOUSEJOB <int+lbl>, YWKCHANGE <int+lbl>,\n#   YWKNONSEAS <int+lbl>, YWKSEASON <int+lbl>\n\nVisualizing Migration: Alluvial Plots\nAlluvial plots are a useful way to represent flows of data according by categorical variables. A “classic” alluvial plot maps flows of passengers on the Titanic according to various characteristics and whether or not they survived.\n\n\n\nFigure 1: Figure from https://cran.r-project.org/web/packages/ggalluvial/vignettes/ggalluvial.html\n\n\n\nAlluvial plots are particularly useful for visualizing flows over time – this means we can map the characteristics of respondents across different moves and places they’ve lived! This can be really informative for migration data.\nOne topic migration researchers are often interested in studying is how people move across the urban-rural spectrum. The PMA migration module includes a variable that classifies each residence respondents previously lived in as urban, peri-urban, or rural. Here we can see that individual 2 previously lived in a rural location. Individual 14 lived in two previous residences: the most recent (PLACE == 1) was a rural location, and prior to that (PLACE == 2) she lived in a city or town.\n\nRemember, PMA considers moves in the migration data only if respondents lived in at least one other location for six months or more after the age of 15 or after her first marriage if married before the age of 15.\n\n\ndat %>%\n  select(ID, PLACE, UR)\n\n\n# A tibble: 5,251 x 3\n      ID PLACE UR        \n   <int> <dbl> <fct>     \n 1     2     1 Rural     \n 2    11     1 Rural     \n 3    12     1 City/town \n 4    14     1 Rural     \n 5    14     2 City/town \n 6    16     1 Rural     \n 7    19     1 Peri-urban\n 8    20     1 City/town \n 9    20     2 Peri-urban\n10    21     1 Peri-urban\n# … with 5,241 more rows\n\nOne way to visualize this data is to make a bar plot that shows the number of respondents in each residence category across all seven previous residences that PMA collects information about.\n\n\ndat %>%\n  ggplot(aes(x = factor(PLACE), fill = UR)) +\n    geom_bar(stat = \"count\") +\n    scale_fill_viridis_d()\n\n\n\n\nThis bar plot shows the distribution of living in an urban/peri-urban/rural location over different residences across the sample, but it doesn’t tell us anything about the flows. For example, we might want to know if people are moving from rural to urban places and vice versa. This is where an alluvial plot can add a lot of value! Another thing that is very apparent from this plot is that very few people have lived in more than three previous residences, so going forward we’ll restrict the sample to people who have lived in at least three previous locations.\nThe ggalluvial package makes it easy to generate alluvial plots using the ggplot2 grammar of graphics. There are a few key elements to an alluvial plot:\nAxes: axes are the dimensions represented by the vertical bars. In this example, the axes are the places respondents have lived.\nStrata: strata are the groups or categories each axis is divided into. In this example, each axis has the same strata (city/town, peri-urban, rural). But in the titanic example above, each axis represents a different categorical variable (class, sex, age) with different values.\nAlluvia: alluvia are the flows between categories across axes. The width or thickness of the alluvia depends on the size of that group.\n\n\n\n\n© RStudio (CC0 1.0)\nggplot2 is included with library(tidyverse).\nWe’ll specify these elements using the standard ggplot2 syntax. First, we’ll count the total number of places each respondent has lived so that we can restrict the alluvial plot to respondents with at least three previous residences and then look at the flows between different categories of residence for the three most recent places. When making the alluvial plot, we’ll add the axes using + geom_stratum(), the alluvia using + geom_flow(), and fill in the colors according to the UR variable.\n\n\ndat <- dat %>%\n  group_by(ID) %>%\n  mutate(TOTAL_PLACES = max(PLACE)) %>%\n  ungroup() \n\n\n# alluvial plot\ndat %>%\n  filter(TOTAL_PLACES >= 3 & PLACE < 4) %>%\n  ggplot(aes(x = PLACE, \n             stratum = UR, \n             alluvium = ID, \n             fill = UR)) +\n  geom_stratum() + \n  geom_flow() + \n  scale_fill_viridis_d() +\n  theme_minimal()\n\n\n\n\nWe can see quite a bit more detail about the types of places people are moving to and from with this alluvial plot compared to the bar plot. For example, we can see that most people who lived in a city/town moved to another urban location from place 3 to 2 to 1. Rural residents followed a similar pattern. In contrast, we see the most movement across categories from people whose 3rd most recent residence was peri-urban. Despite the fact that most urban migrants move to other urban locations and most rural migrants move to other rural locations, this plot also makes it clear there is a fair amount of rural to urban/peri-urban migration, and even urban to rural migration! Finally, we can also see there is a small number of people for whom we’re missing data on their oldest (PLACE == 3) location.\nIt was pretty simple to create this alluvial plot off-the-shelf, but we can do a bit of work to improve the clarity and presentation of this plot.\n\n\ndat %>%\n  filter(TOTAL_PLACES >= 3 & PLACE < 4) %>%\n  mutate(PLACE = PLACE %>% as_factor %>% fct_recode(\n    \"Most recent place\" = \"1\",\n    \"2nd most recent place\" = \"2\",\n    \"3rd most recent place\" = \"3\"\n  )) %>%\n  ggplot(aes(x = PLACE, \n             stratum = UR, \n             alluvium = ID, \n             fill = UR)) +\n  scale_x_discrete(expand = c(.1, .1)) +\n  geom_flow() + \n  geom_stratum(alpha = .5) + # increases the transparency of the axes' colors \n  scale_fill_viridis_d() +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        axis.title.y = element_text(angle = 0, hjust = 0)) + \n  labs(title = \"Migration from Place 3 to Place 1: Kenya 2019 Sample\",\n       subtitle = \"Flows by residence category\",\n       x = NULL,\n       fill = NULL,\n       y = \"Number of\\nPeople\") + # the \\n adds a line break\n  geom_segment(aes( # adds an arrow to indicate that time is moving from right to left\n    x = 0.75, xend = 3.16,\n    y = 0, yend = 0),\n    arrow = arrow(length=unit(0.30,\"cm\"), \n                  ends=\"first\", \n                  type = \"closed\"))\n\n\n\n\nWhy people migrate\nWe might also be interested in seeing how the reasons people migrate change from move to move. The PMA surveys asked why respondents moved to each previous place they lived, allowing people to select multiple responses. In fact, there are 19 possible answers for respondents to choose from. To make this a bit more manageable, let’s summarize the reasons people moved to their previous three locations and identify the most common reasons:\n\nUnfortunately, this information is not available for the respondent’s migration to their current place of residence.\n\n\ndat %>% \n  filter(TOTAL_PLACES >= 3 & PLACE < 4) %>%\n  group_by(PLACE) %>%\n  summarise(\n    across(starts_with(\"Y\"),\n           ~100*mean(.x))) %>%\n  pivot_longer( # pivot_longer to sort by reason\n    cols = starts_with(\"Y\"),\n    names_to = \"REASON\") %>%\n  pivot_wider(\n    names_from = \"PLACE\" # pivot wider to easily see each of the 3 places as columns\n  ) %>%\n  arrange(-`1`, -`2`, -`3`)\n\n\n# A tibble: 18 x 4\n   REASON           `1`    `2`    `3`\n   <chr>          <dbl>  <dbl>  <dbl>\n 1 YSCHOOLATTEND 21.0   21.6   21.6  \n 2 YPOSTMAR      19.3   13.5   14.9  \n 3 YJOBSEARCH    17.2   19.5   18.4  \n 4 YOTHERSOCIAL  12.9   18.7   17.0  \n 5 YOTHER        10.1   10.1   11.2  \n 6 YCONFLICT      8.91   8.05   8.91 \n 7 YWKSEASON      7.76   8.91   9.20 \n 8 YWKNONSEAS     7.18   4.60   4.31 \n 9 YSCHOOLDONE    5.17   2.87   4.89 \n10 YSPOUSEJOB     4.02   2.87   4.02 \n11 YFARM          3.45   3.45   5.75 \n12 YWKCHANGE      3.16   2.30   3.74 \n13 YHLTHACCESS    2.59   2.30   3.16 \n14 YCHILDEDU      1.72   1.72   2.59 \n15 YCOHABIT       1.15   2.59   2.30 \n16 YSICKREL       1.15   2.30   0.575\n17 YHLTHPROB      0.862  1.72   2.01 \n18 YDIVORCE       0.862  0.862  1.15 \n\nWe can see that across the three locations, the most common reasons to move are: to attend school (YSCHOOLATTEND), to join a spouse after marriage (YPOSTMAR), to look for a job (YJOBSEARCH), other social reasons (YOTHERSOCIAL), other (YOTHER), because of family or village conflict (YCONFLICT), and for seasonal work (YWKSEASON). Because it will be difficult to see much with so many categories, we’ll aggregate all the less common reasons into YOTHER.\nSince each reason is stored as a different binary variable, we’ll first pivot_longer() again to create a variable called REASON that store the reason for migrating and a binary variable, VALUE, that equals 1 if the individual selected this as a reason for migrating. Then, we’ll use the very handy forcats::fct_lump_n() from the tidyverse to lump together less common responses into a single “other” category.\nAdditionally, since individuals can select multiple reasons, this variable is not well-suited to an alluvial plot, so we’ll look at how the proportion of respondents who selected each reason changes from each migration.\n\n\nmig_reasons <- dat %>% \n  filter(TOTAL_PLACES >= 3 & PLACE < 4) %>%\n  pivot_longer( # pivot_longer to sort by reason\n    cols = starts_with(\"Y\"),\n    names_to = \"REASON\",\n    values_to = \"VALUE\"\n  ) %>% \n  mutate(REASON = REASON %>%\n           as_factor %>%\n           fct_lump_n(n = 8, w = VALUE, other = \"YOTHER\") %>% \n           fct_relevel(sort)\n  ) %>%\n  group_by(ID, PLACE, REASON, VALUE) %>%\n  slice(1) %>% # to get rid of duplicate OTHER rows\n  group_by(PLACE, REASON) %>% \n  summarise(PROP = mean(VALUE)) %>% \n  ungroup()\n\n\n\n\n\n\n\n© RStudio (CC0 1.0)\nforcats is included with library(tidyverse).\n\n\nmig_reasons %>%\n  ggplot(aes(x = PLACE, \n             y = PROP,\n             color = REASON,\n             group = REASON)) +\n  geom_line() +\n  geom_point() +\n  scale_color_viridis_d() +\n  theme_minimal()\n\n\n\n\n\nNote that because respondents can select multiple reasons for moving to each previous residence, the proportions of all reasons to migrate to each previous residence will not add up to 1.\nAlthough many of the reasons have a similar proportion of responses across migrations, we can see that the proportion of people moving to join a spouse after marriage and moving for non-seasonal work increased from the least recent place to most recent place, while the proportion moving for seasonal work and other social reasons decreased. The most common reason for migrating – to attend school – remains pretty constant across moves for these respondents.\nTo make things a little easier to read, we’ll rename the reasons for migrating and tidy up the plot labels.\n\n\nmig_reasons %>%\n  mutate(\n    PLACE = PLACE %>% \n      as_factor %>% \n      fct_recode(\n        \"Most recent place\" = \"1\",\n        \"2nd most recent place\" = \"2\",\n        \"3rd most recent place\" = \"3\"\n      ),\n    REASON = REASON %>% \n      fct_recode(\n        \"Family or village conflict\" = \"YCONFLICT\",\n        \"To look for a job\" = \"YJOBSEARCH\",\n        \"Other\" = \"YOTHER\",\n        \"Other social reasons\" = \"YOTHERSOCIAL\",\n        \"To join spouse after marriage\" = \"YPOSTMAR\",\n        \"To attend school\" = \"YSCHOOLATTEND\",\n        \"For work (non-seasonal)\" = \"YWKNONSEAS\",\n        \"For seasonal work\" = \"YWKSEASON\"\n      )\n  )  %>%\n  ggplot(aes(x = PLACE, \n             y = PROP,\n             color = REASON,\n             group = REASON)) +\n  geom_line() +\n  geom_point() +\n  scale_color_viridis_d() +\n  scale_x_discrete(expand = c(.1, .1)) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  theme_minimal() +\n  labs(color = NULL,\n       x = NULL,\n       y = NULL,\n       title = \"Reasons for Migrating from Place 3 to Place 1\",\n       subtitle = \"% of respondents with three moves\") +\n  theme(legend.position = \"bottom\",\n        axis.title.y = element_text(angle = 0, hjust = 0))\n\n\n\n\nWhen people migrate\nThe reasons people migrate likely differ by age and is of interest to researchers. To look at how the reasons for migration might differ by age, we’ll again look at the three most recent moves, where we have the most data. To visualize how the reasons for migration differ by age, we’ll use ggridges to make an overlapping density plot that shows the distribution of ages for each reason. We’ll use the same code from before to aggregate the less common reasons into an OTHER category and pivot_longer() to store all the reasons in a single variable.\n\nYou should see a warning that says “Removed 6 rows containing non-finite values (stat_density_ridges).” This is because MOVEAGE is missing for 6 moves.\n\n\ndat %>% \n  filter(TOTAL_PLACES >= 3 & PLACE < 4) %>%\n  pivot_longer( # pivot_longer to sort by reason\n    cols = starts_with(\"Y\"),\n    names_to = \"REASON\",\n    values_to = \"VALUE\"\n  ) %>% \n  mutate(REASON = REASON %>%\n           as_factor %>%\n           fct_lump_n(n = 8, w = VALUE, other = \"YOTHER\") %>% \n           fct_relevel(sort) %>% \n           fct_recode(\n             \"Family or village conflict\" = \"YCONFLICT\",\n             \"To look for a job\" = \"YJOBSEARCH\",\n             \"Other\" = \"YOTHER\",\n             \"Other social reasons\" = \"YOTHERSOCIAL\",\n             \"To join spouse after marriage\" = \"YPOSTMAR\",\n             \"To attend school\" = \"YSCHOOLATTEND\",\n             \"For work (non-seasonal)\" = \"YWKNONSEAS\",\n             \"For seasonal work\" = \"YWKSEASON\"\n           )\n  ) %>% \n  group_by(ID, PLACE, REASON, VALUE) %>%\n  slice(1)  %>% # to get rid of duplicate OTHER rows \n  ungroup %>% \n  filter(VALUE == 1) %>% \n  ggplot(aes(x = MOVEAGE,  y = REASON, fill = REASON)) +\n    geom_density_ridges() +\n    scale_fill_viridis_d() +\n    theme_minimal() +\n    theme(legend.position = \"none\") +\n    labs(y = NULL,\n         x = \"Age at move\",\n         title = \"Reasons for Migrating from Place 3 to Place 1\",\n         subtitle = \"Distribution by age at move\")\n\n\nWarning: Removed 6 rows containing non-finite values\n(stat_density_ridges).\n\n\nThis figure shows that people tend to migrate to attend school at younger ages than most of the other reasons, which is unsurprising. Comparing the distributions by age for migrating for seasonal and non-seasonal work, it appears more young people migrate for seasonal work. In contrast, the age distributions for moving to join a spouse after marriage, to look for a job, and for non-seasonal work are all pretty similar – suggesting individuals move for these reasons at similar ages. Interestingly, there are masses at the young end of the distribution for family or village conflict, other social reasons, and other. Something further investigation could dig into more!\nWe hope this helps generate ideas for how to visualize the PMA migration data! Let us know what migration questions you’re interested in researching!\n\n\n\n",
    "preview": "posts/2021-05-24-migration-data-analysis/images/migration_alluvial.png",
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {},
    "preview_width": 936,
    "preview_height": 574
  },
  {
    "path": "posts/2021-05-15-paa-2021/",
    "title": "Making the Contraceptive Calendar Data Work For You",
    "description": "R and Stata code with video from an event held at the Population Association of America 2021 Annual Meeting.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-05-15",
    "categories": [
      "PMA Publications",
      "PAA 2021",
      "Contraceptive Calendar",
      "Stata",
      "Video"
    ],
    "contents": "\n\nContents\nBreakout Session: R\nUsers\nBreakout Session: Stata\nUsers\nDownload Links\n\nOn May 4th, PMA and IPUMS PMA co-hosted a Population\nAssociation of America 2021 virtual data workshop showcasing the new\nPMA contraceptive\ncalendar data available for these samples:\nBurkina Faso 2020\nCongo (DR), Kinshasa 2019\nCongo (DR), Kongo Central 2019\nKenya 2019\nNigeria, Kano 2019\nNigeria, Lagos 2019\nThese data represent contraceptive use, pregnancy, pregnancy\ntermination, and birth information recalled by female respondents for\neach of several months preceding the PMA interview. Women sampled in\nBurkina Faso and Democratic Republic of the Congo were each asked to\nrecall monthly information for up to 24 months, while women sampled from\nKenya and Nigeria were asked to recall monthly information for up to 36\nmonths. Their responses are recorded in a single comma delimited string,\nwhere information about each month is represented by one of the\nfollowing codes:\nB = Birth\nP = Pregnant\nT = Pregnancy ended\n0 = No family planning method used\n1 = Female Sterilization\n2 = Male Sterilization\n3 = Implant\n4 = IUD\n5 = Injectables\n7 = Pill\n8 = Emergency Contraception\n9 = Male Condom\n10 = Female Condom\n11 = Diaphragm\n12 = Foam / Jelly\n13 = Standard Days / Cycle beads\n14 = LAM\n30 = Rhythm method\n31 = Withdrawal\n39 = Other traditional methods\nIn this video, PMA and IPUMS PMA explain the background behind\ncontraceptive calendar data and show some of the ways you might consider\nusing it in longitudinal analysis. We also give a conceptual overview of\nthe steps both R and Stata users should take to reshape\nthe data into a long format. After the overview, R and\nStata users split into separate breakout sessions to work with a\nhands-on coding example using data from the Kenya 2019 sample; this\nexample shows how to build a Kaplan-Meier\nsurvival curve for cohorts of women who were using the same family\nplanning method in the first month of the contraceptive calendar.\n\nCheck out our recent post on migration recall\ndata for information and practice with longitudinal data structures.\nThe same 2019 and 2020 samples that contain contraceptive calendar data\nalso include migration recall data.\n\n\nDownload\nPowerpoint slides here. A transcript of the chat from this session\n(including typed responses from the Q&A) is also available here (participant names are\nredacted).\nBreakout Session: R Users\nR users can load a fixed-width IPUMS PMA data extract with help from\nthe ipumsr package (if\nyou’re new to this blog, check out detailed instructions here).\nWe also use packages from tidyverse to reformat the\ndata, as well as survival\nand ggfortify\nfor specific survival analysis functions.\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\nlibrary(survival)\nlibrary(ggfortify)\noptions(tibble.print_min = 20, tibble.min_extra_cols = 5)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00001.xml\",\n  data = \"data/pma_00001.dat.gz\"\n) \n\n\n\n\nThis code looks for my data file and DDI codebook in a folder called\n“data” inside of my R working directory. Make sure to change these paths\nas needed!\nWhen you open any IPUMS PMA data extract from the Household and\nFemale Survey, you’ll find the data organized with one respondent per\nrow. Here, there are 9,549 rows each representing one female respondent\n(all other household members have been excluded):\n\n\ndat \n\n\n# A tibble: 9,549 × 17\n         SAMPLE COUNTRY  YEAR HHID  PERSONID ELIGIBLE   EAID CONSENTFQ\n      <int+lbl> <int+l> <int> <chr> <chr>    <int+lb>  <dbl> <int+lbl>\n 1 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n 2 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n 3 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n 4 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n 5 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n 6 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n 7 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n 8 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n 9 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n10 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n11 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n12 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n13 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n14 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n15 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n16 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n17 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n18 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n19 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n20 40410 [Keny… 7 [Ken…  2019 4042… 4042019… 1 [Yes,… 4.04e8   1 [Yes]\n# … with 9,529 more rows, and 9 more variables: FQINSTID <chr>,\n#   CONSENTHQ <int+lbl>, FQWEIGHT <dbl>, STRATA <int+lbl>,\n#   SUBNATIONAL <int+lbl>, AGE <int+lbl>, BIRTHEVENT <int+lbl>,\n#   WORKYR <int+lbl>, CALENDARKE <chr+lbl>\n\nFor the purpose of this exercise only we create a short\nidentifying number for each respondent called ID. Then, we\nselect only the variables ID and CALENDARKE\n(dropping all of the other variables pre-selected for every IPUMS PMA\nextract).\n\nIn practice, you should use the variable PERSONID to track\nunique respondents; we use ID instead here only because it\nfits better on the screen.\n\n\ndat <- dat %>% \n  rowid_to_column(\"ID\") %>% \n  select(ID, CALENDARKE)\n\ndat\n\n\n# A tibble: 9,549 × 2\n      ID CALENDARKE                                                   \n   <int> <chr+lbl>                                                    \n 1     1 0,0,B,P,P,P,P,P,P,P,P,0,0,0,0,0,0,0,0,0,0,0,0,3,3,3,3,3,3,3,…\n 2     2 ,7,7,7,7,7,7,7,7,0,B,P,P,P,P,P,P,P,P,0,0,0,0,0,9,9,9,9,9,9,9…\n 3     3 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,…\n 4     4 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,…\n 5     5 ,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,B,P,P,P,P,P,P,P,P,0,0,0,0,0…\n 6     6 5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,…\n 7     7 5,5,5,5,5,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,B,P,P,P,P,P,…\n 8     8 P,P,P,P,P,P,P,P,0,0,0,0,0,0,0,14,14,14,14,14,14,14,B,P,P,P,P…\n 9     9 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,…\n10    10 ,P,P,P,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9…\n11    11 ,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0…\n12    12 ,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0…\n13    13 ,P,P,P,P,P,P,P,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9…\n14    14 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,…\n15    15 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14…\n16    16 3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,…\n17    17 ,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5…\n18    18 ,5,5,5,5,5,5,5,5,5,5,5,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7…\n19    19 0,0,0,0,0,0,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,…\n20    20 ,P,P,P,P,P,P,P,5,5,5,5,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0…\n# … with 9,529 more rows\n\nAs you can see, CALENDARKE includes the response codes\nshown above, each separated by a comma. Each string contains 36 codes:\nthese represent the 36 months from January 2017 through December 2019\n(the last month in which Kenya 2019 samples were collected). The\nleft-most code represents the most recent available month.\nSome strings begin with a comma (i.e. the most recent month is\nblank). These are individuals who were interviewed in November 2019,\nrather than December. When we split the string into 36 columns, we must\nshift these individuals to the right, leaving a blank value in the\nleft-most column (December 2019). For example, notice the blank value\nthat appears in the new column cal_ke36 for the person\nID == 2.\n\n\ndat <- dat %>% \n  separate(\n    col = CALENDARKE,\n    into = paste0(\"cal_ke\", 36:1),\n    fill = \"left\"\n  ) \n\ndat\n\n\n# A tibble: 9,549 × 37\n      ID cal_ke36 cal_ke35 cal_ke34 cal_ke33 cal_ke32 cal_ke31\n   <int> <chr>    <chr>    <chr>    <chr>    <chr>    <chr>   \n 1     1 \"0\"      0        B        P        P        P       \n 2     2 \"\"       7        7        7        7        7       \n 3     3 \"0\"      0        0        0        0        0       \n 4     4 \"0\"      0        0        0        0        0       \n 5     5 \"\"       5        5        5        5        5       \n 6     6 \"5\"      5        5        5        5        5       \n 7     7 \"5\"      5        5        5        5        5       \n 8     8 \"P\"      P        P        P        P        P       \n 9     9 \"0\"      0        0        0        0        0       \n10    10 \"\"       P        P        P        9        9       \n11    11 \"\"       0        0        0        0        0       \n12    12 \"\"       0        0        0        0        0       \n13    13 \"\"       P        P        P        P        P       \n14    14 \"0\"      0        0        0        0        0       \n15    15 \"0\"      0        0        0        0        0       \n16    16 \"3\"      3        3        3        3        3       \n17    17 \"\"       5        5        5        5        5       \n18    18 \"\"       5        5        5        5        5       \n19    19 \"0\"      0        0        0        0        0       \n20    20 \"\"       P        P        P        P        P       \n# … with 9,529 more rows, and 30 more variables: cal_ke30 <chr>,\n#   cal_ke29 <chr>, cal_ke28 <chr>, cal_ke27 <chr>, cal_ke26 <chr>,\n#   cal_ke25 <chr>, cal_ke24 <chr>, cal_ke23 <chr>, cal_ke22 <chr>,\n#   cal_ke21 <chr>, cal_ke20 <chr>, cal_ke19 <chr>, cal_ke18 <chr>,\n#   cal_ke17 <chr>, cal_ke16 <chr>, cal_ke15 <chr>, cal_ke14 <chr>,\n#   cal_ke13 <chr>, cal_ke12 <chr>, cal_ke11 <chr>, cal_ke10 <chr>,\n#   cal_ke9 <chr>, cal_ke8 <chr>, cal_ke7 <chr>, cal_ke6 <chr>, …\n\nLet’s now pivot the data from wide to long format so that we’ll be\nable to mark time in a new column called MONTH.\nThe argument names_pattern pulls the number from each\nvariable starting with cal_ke, which we then put in the new\ncolumn MONTH.\n\n\noptions(tibble.print_min = 40)\n\ndat <- dat %>% \n  pivot_longer(\n    starts_with(\"cal_ke\"),\n    names_pattern = \"cal_ke(.*)\",\n    names_to = \"MONTH\",\n    values_to = \"FP\"\n  ) \n\ndat\n\n\n# A tibble: 343,764 × 3\n      ID MONTH FP   \n   <int> <chr> <chr>\n 1     1 36    \"0\"  \n 2     1 35    \"0\"  \n 3     1 34    \"B\"  \n 4     1 33    \"P\"  \n 5     1 32    \"P\"  \n 6     1 31    \"P\"  \n 7     1 30    \"P\"  \n 8     1 29    \"P\"  \n 9     1 28    \"P\"  \n10     1 27    \"P\"  \n11     1 26    \"P\"  \n12     1 25    \"0\"  \n13     1 24    \"0\"  \n14     1 23    \"0\"  \n15     1 22    \"0\"  \n16     1 21    \"0\"  \n17     1 20    \"0\"  \n18     1 19    \"0\"  \n19     1 18    \"0\"  \n20     1 17    \"0\"  \n21     1 16    \"0\"  \n22     1 15    \"0\"  \n23     1 14    \"0\"  \n24     1 13    \"3\"  \n25     1 12    \"3\"  \n26     1 11    \"3\"  \n27     1 10    \"3\"  \n28     1 9     \"3\"  \n29     1 8     \"3\"  \n30     1 7     \"3\"  \n31     1 6     \"3\"  \n32     1 5     \"3\"  \n33     1 4     \"3\"  \n34     1 3     \"3\"  \n35     1 2     \"3\"  \n36     1 1     \"3\"  \n37     2 36    \"\"   \n38     2 35    \"7\"  \n39     2 34    \"7\"  \n40     2 33    \"7\"  \n# … with 343,724 more rows\n\n\nNotice: each person ID now occupies 36 rows, so we increase\nthe length of all printed dataframes to 40.\nWe’ve now created a variable FP containing the original\nCALENDARKE variable codes. This variable will be much\neasier to work with if we 1) convert it into a factor, and 2) replace\nmissing values with NA (e.g. month 36 for individuals\ninterviewed in November 2018). We’ll also coerce MONTH from\na “character” to an “integer” class.\n\n\ndat <- dat %>%\n  mutate(\n    MONTH = as.integer(MONTH),\n    FP = FP %>%\n      na_if(\"\") %>%\n      fct_recode(\n        \"Birth\" = \"B\",\n        \"Pregnant\" = \"P\",\n        \"Pregnancy ended\" = \"T\",\n        \"No family planning method used\" = \"0\",\n        \"Female Sterilization\" = \"1\",\n        \"Male Sterilization\" = \"2\",\n        \"Implant\" = \"3\",\n        \"IUD\" = \"4\",\n        \"Injectables\" = \"5\",\n        \"Pill\" = \"7\",\n        \"Emergency Contraception\" = \"8\",\n        \"Male Condom\" = \"9\",\n        \"Female Condom\" = \"10\",\n        \"Diaphragm\" = \"11\",\n        \"Foam / Jelly\" = \"12\",\n        \"Standard Days / Cycle beads\" = \"13\",\n        \"LAM\" = \"14\",\n        \"Rhythm method\" = \"30\",\n        \"Withdrawal\" = \"31\",\n        \"Other traditional methods\" = \"39\"\n      )\n  )\n\ndat\n\n\n# A tibble: 343,764 × 3\n      ID MONTH FP                            \n   <int> <int> <fct>                         \n 1     1    36 No family planning method used\n 2     1    35 No family planning method used\n 3     1    34 Birth                         \n 4     1    33 Pregnant                      \n 5     1    32 Pregnant                      \n 6     1    31 Pregnant                      \n 7     1    30 Pregnant                      \n 8     1    29 Pregnant                      \n 9     1    28 Pregnant                      \n10     1    27 Pregnant                      \n11     1    26 Pregnant                      \n12     1    25 No family planning method used\n13     1    24 No family planning method used\n14     1    23 No family planning method used\n15     1    22 No family planning method used\n16     1    21 No family planning method used\n17     1    20 No family planning method used\n18     1    19 No family planning method used\n19     1    18 No family planning method used\n20     1    17 No family planning method used\n21     1    16 No family planning method used\n22     1    15 No family planning method used\n23     1    14 No family planning method used\n24     1    13 Implant                       \n25     1    12 Implant                       \n26     1    11 Implant                       \n27     1    10 Implant                       \n28     1     9 Implant                       \n29     1     8 Implant                       \n30     1     7 Implant                       \n31     1     6 Implant                       \n32     1     5 Implant                       \n33     1     4 Implant                       \n34     1     3 Implant                       \n35     1     2 Implant                       \n36     1     1 Implant                       \n37     2    36 <NA>                          \n38     2    35 Pill                          \n39     2    34 Pill                          \n40     2    33 Pill                          \n# … with 343,724 more rows\n\nWe’re now ready to begin our analysis. To keep our example simple,\nour survival curves will show the duration of continuously used\nfamily planning methods for cohorts of women who were using the\nsame method in January 2017. These survival curves will estimate the\nprobability that an individual “survives” - or continues using - a given\nmethod at each of 36 months, assuming that she used it in month 1.\nWe’ll exclude the duration of use after any break (for example, if a\nwoman stopped using family planning to become pregnant, but then started\nagain afterward).\nLet’s begin with women who were using the contraceptive pill in\nJanuary 2017. Remove all other women, saving those who remain as a\nsub-sample called pills:\n\n\npills <- dat %>% \n  group_by(ID) %>% \n  mutate(use_m1 = case_when(FP == \"Pill\" & MONTH == 1 ~ TRUE) %>% any()) %>% \n  filter(use_m1)\n\npills \n\n\n# A tibble: 10,332 × 4\n# Groups:   ID [287]\n      ID MONTH FP          use_m1\n   <int> <int> <fct>       <lgl> \n 1    18    36 <NA>        TRUE  \n 2    18    35 Injectables TRUE  \n 3    18    34 Injectables TRUE  \n 4    18    33 Injectables TRUE  \n 5    18    32 Injectables TRUE  \n 6    18    31 Injectables TRUE  \n 7    18    30 Injectables TRUE  \n 8    18    29 Injectables TRUE  \n 9    18    28 Injectables TRUE  \n10    18    27 Injectables TRUE  \n11    18    26 Injectables TRUE  \n12    18    25 Injectables TRUE  \n13    18    24 Pill        TRUE  \n14    18    23 Pill        TRUE  \n15    18    22 Pill        TRUE  \n16    18    21 Pill        TRUE  \n17    18    20 Pill        TRUE  \n18    18    19 Pill        TRUE  \n19    18    18 Pill        TRUE  \n20    18    17 Pill        TRUE  \n21    18    16 Pill        TRUE  \n22    18    15 Pill        TRUE  \n23    18    14 Pill        TRUE  \n24    18    13 Pill        TRUE  \n25    18    12 Pill        TRUE  \n26    18    11 Pill        TRUE  \n27    18    10 Pill        TRUE  \n28    18     9 Pill        TRUE  \n29    18     8 Pill        TRUE  \n30    18     7 Pill        TRUE  \n31    18     6 Pill        TRUE  \n32    18     5 Pill        TRUE  \n33    18     4 Pill        TRUE  \n34    18     3 Pill        TRUE  \n35    18     2 Pill        TRUE  \n36    18     1 Pill        TRUE  \n37    39    36 Pill        TRUE  \n38    39    35 Pill        TRUE  \n39    39    34 Pill        TRUE  \n40    39    33 Pill        TRUE  \n# … with 10,292 more rows\n\nThe next several steps will help us remove every record for each\nwoman except for the last recorded month in which she used the\npill. For those whose last month is month 36, we will say she\n“survived” the full observation period.\nTo avoid re-entry cases (returning to use of the pill), we’ll find\nthe earliest month that a woman in this cohort was not using\nthe pill. The month prior to this will be her last_month of\nusing the pill. For the first person in this cohort\nID == 18, for example, the last_month of use\nshould be MONTH == 24.\n\n\npills <- pills %>% \n  mutate(\n    non_use_month = case_when(FP != \"Pill\" | is.na(FP) ~ MONTH),\n    last_month = ifelse(\n      all(is.na(non_use_month)),\n      36,\n      min(non_use_month, na.rm = T) - 1\n    )\n  ) \n\npills\n\n\n# A tibble: 10,332 × 6\n# Groups:   ID [287]\n      ID MONTH FP          use_m1 non_use_month last_month\n   <int> <int> <fct>       <lgl>          <int>      <dbl>\n 1    18    36 <NA>        TRUE              36         24\n 2    18    35 Injectables TRUE              35         24\n 3    18    34 Injectables TRUE              34         24\n 4    18    33 Injectables TRUE              33         24\n 5    18    32 Injectables TRUE              32         24\n 6    18    31 Injectables TRUE              31         24\n 7    18    30 Injectables TRUE              30         24\n 8    18    29 Injectables TRUE              29         24\n 9    18    28 Injectables TRUE              28         24\n10    18    27 Injectables TRUE              27         24\n11    18    26 Injectables TRUE              26         24\n12    18    25 Injectables TRUE              25         24\n13    18    24 Pill        TRUE              NA         24\n14    18    23 Pill        TRUE              NA         24\n15    18    22 Pill        TRUE              NA         24\n16    18    21 Pill        TRUE              NA         24\n17    18    20 Pill        TRUE              NA         24\n18    18    19 Pill        TRUE              NA         24\n19    18    18 Pill        TRUE              NA         24\n20    18    17 Pill        TRUE              NA         24\n21    18    16 Pill        TRUE              NA         24\n22    18    15 Pill        TRUE              NA         24\n23    18    14 Pill        TRUE              NA         24\n24    18    13 Pill        TRUE              NA         24\n25    18    12 Pill        TRUE              NA         24\n26    18    11 Pill        TRUE              NA         24\n27    18    10 Pill        TRUE              NA         24\n28    18     9 Pill        TRUE              NA         24\n29    18     8 Pill        TRUE              NA         24\n30    18     7 Pill        TRUE              NA         24\n31    18     6 Pill        TRUE              NA         24\n32    18     5 Pill        TRUE              NA         24\n33    18     4 Pill        TRUE              NA         24\n34    18     3 Pill        TRUE              NA         24\n35    18     2 Pill        TRUE              NA         24\n36    18     1 Pill        TRUE              NA         24\n37    39    36 Pill        TRUE              NA         36\n38    39    35 Pill        TRUE              NA         36\n39    39    34 Pill        TRUE              NA         36\n40    39    33 Pill        TRUE              NA         36\n# … with 10,292 more rows\n\nWe must now identify whether the last_month represents\ncessation or right-censoring. Remember that a large number of women in\nour sample have missing values in the 36th month: they are\nright-censored at month 35 if they had been continuously using\nthe pill until that time, so we cannot say that they ceased using at\nmonth 35!\nTo make this easier, we’ll create a logical variable\nright_censored that simply indicates whether each person is\nmissing a value for MONTH == 36.\n\n\npills <- pills %>% \n  mutate(right_censored = ifelse(MONTH == 36 & is.na(FP), T, F) %>% any())\n\npills \n\n\n# A tibble: 10,332 × 7\n# Groups:   ID [287]\n      ID MONTH FP       use_m1 non_use_month last_month right_censored\n   <int> <int> <fct>    <lgl>          <int>      <dbl> <lgl>         \n 1    18    36 <NA>     TRUE              36         24 TRUE          \n 2    18    35 Injecta… TRUE              35         24 TRUE          \n 3    18    34 Injecta… TRUE              34         24 TRUE          \n 4    18    33 Injecta… TRUE              33         24 TRUE          \n 5    18    32 Injecta… TRUE              32         24 TRUE          \n 6    18    31 Injecta… TRUE              31         24 TRUE          \n 7    18    30 Injecta… TRUE              30         24 TRUE          \n 8    18    29 Injecta… TRUE              29         24 TRUE          \n 9    18    28 Injecta… TRUE              28         24 TRUE          \n10    18    27 Injecta… TRUE              27         24 TRUE          \n11    18    26 Injecta… TRUE              26         24 TRUE          \n12    18    25 Injecta… TRUE              25         24 TRUE          \n13    18    24 Pill     TRUE              NA         24 TRUE          \n14    18    23 Pill     TRUE              NA         24 TRUE          \n15    18    22 Pill     TRUE              NA         24 TRUE          \n16    18    21 Pill     TRUE              NA         24 TRUE          \n17    18    20 Pill     TRUE              NA         24 TRUE          \n18    18    19 Pill     TRUE              NA         24 TRUE          \n19    18    18 Pill     TRUE              NA         24 TRUE          \n20    18    17 Pill     TRUE              NA         24 TRUE          \n21    18    16 Pill     TRUE              NA         24 TRUE          \n22    18    15 Pill     TRUE              NA         24 TRUE          \n23    18    14 Pill     TRUE              NA         24 TRUE          \n24    18    13 Pill     TRUE              NA         24 TRUE          \n25    18    12 Pill     TRUE              NA         24 TRUE          \n26    18    11 Pill     TRUE              NA         24 TRUE          \n27    18    10 Pill     TRUE              NA         24 TRUE          \n28    18     9 Pill     TRUE              NA         24 TRUE          \n29    18     8 Pill     TRUE              NA         24 TRUE          \n30    18     7 Pill     TRUE              NA         24 TRUE          \n31    18     6 Pill     TRUE              NA         24 TRUE          \n32    18     5 Pill     TRUE              NA         24 TRUE          \n33    18     4 Pill     TRUE              NA         24 TRUE          \n34    18     3 Pill     TRUE              NA         24 TRUE          \n35    18     2 Pill     TRUE              NA         24 TRUE          \n36    18     1 Pill     TRUE              NA         24 TRUE          \n37    39    36 Pill     TRUE              NA         36 FALSE         \n38    39    35 Pill     TRUE              NA         36 FALSE         \n39    39    34 Pill     TRUE              NA         36 FALSE         \n40    39    33 Pill     TRUE              NA         36 FALSE         \n# … with 10,292 more rows\n\nWe’ll create another logical variable ceased to indicate\nwhether each woman actually stopped using the pill at her\nlast_month. If not (either because last_month\nis 36, or she is right-censored and last_month is 35), it\nwill take the value FALSE.\n\n\npills <- pills %>% \n  mutate(\n    ceased = case_when(\n      right_censored & last_month == 35 ~ F,\n      last_month == 36 ~ F,\n      last_month < 36 ~ T\n    )\n  ) %>% \n  select(ID, MONTH, FP, last_month, ceased)\n\npills\n\n\n# A tibble: 10,332 × 5\n# Groups:   ID [287]\n      ID MONTH FP          last_month ceased\n   <int> <int> <fct>            <dbl> <lgl> \n 1    18    36 <NA>                24 TRUE  \n 2    18    35 Injectables         24 TRUE  \n 3    18    34 Injectables         24 TRUE  \n 4    18    33 Injectables         24 TRUE  \n 5    18    32 Injectables         24 TRUE  \n 6    18    31 Injectables         24 TRUE  \n 7    18    30 Injectables         24 TRUE  \n 8    18    29 Injectables         24 TRUE  \n 9    18    28 Injectables         24 TRUE  \n10    18    27 Injectables         24 TRUE  \n11    18    26 Injectables         24 TRUE  \n12    18    25 Injectables         24 TRUE  \n13    18    24 Pill                24 TRUE  \n14    18    23 Pill                24 TRUE  \n15    18    22 Pill                24 TRUE  \n16    18    21 Pill                24 TRUE  \n17    18    20 Pill                24 TRUE  \n18    18    19 Pill                24 TRUE  \n19    18    18 Pill                24 TRUE  \n20    18    17 Pill                24 TRUE  \n21    18    16 Pill                24 TRUE  \n22    18    15 Pill                24 TRUE  \n23    18    14 Pill                24 TRUE  \n24    18    13 Pill                24 TRUE  \n25    18    12 Pill                24 TRUE  \n26    18    11 Pill                24 TRUE  \n27    18    10 Pill                24 TRUE  \n28    18     9 Pill                24 TRUE  \n29    18     8 Pill                24 TRUE  \n30    18     7 Pill                24 TRUE  \n31    18     6 Pill                24 TRUE  \n32    18     5 Pill                24 TRUE  \n33    18     4 Pill                24 TRUE  \n34    18     3 Pill                24 TRUE  \n35    18     2 Pill                24 TRUE  \n36    18     1 Pill                24 TRUE  \n37    39    36 Pill                36 FALSE \n38    39    35 Pill                36 FALSE \n39    39    34 Pill                36 FALSE \n40    39    33 Pill                36 FALSE \n# … with 10,292 more rows\n\n\nFor display purposes, we drop all variables except for ID,\nMONTH, FP, last_month, and\nceased.\nRemove all rows except for the row containing each woman’s\nlast_month. The result will be a data frame where each\nwoman in the pills cohort occupies only one row,\nwhich 1) shows her last month of recorded use and 2) indicates whether\nwe know that she actually stopped using the pill in her last month.\n\n\npills <- pills %>% filter(last_month == MONTH) \n\npills\n\n\n# A tibble: 287 × 5\n# Groups:   ID [287]\n      ID MONTH FP    last_month ceased\n   <int> <int> <fct>      <dbl> <lgl> \n 1    18    24 Pill          24 TRUE  \n 2    39    36 Pill          36 FALSE \n 3    44     5 Pill           5 TRUE  \n 4    59    36 Pill          36 FALSE \n 5    60     6 Pill           6 TRUE  \n 6    99    36 Pill          36 FALSE \n 7   188    36 Pill          36 FALSE \n 8   202    36 Pill          36 FALSE \n 9   218    35 Pill          35 FALSE \n10   233    12 Pill          12 TRUE  \n11   260     2 Pill           2 TRUE  \n12   290    35 Pill          35 FALSE \n13   298    20 Pill          20 TRUE  \n14   335    12 Pill          12 TRUE  \n15   340    11 Pill          11 TRUE  \n16   419    36 Pill          36 FALSE \n17   423    36 Pill          36 FALSE \n18   428     4 Pill           4 TRUE  \n19   460    16 Pill          16 TRUE  \n20   488    17 Pill          17 TRUE  \n21   551    32 Pill          32 TRUE  \n22   669    36 Pill          36 FALSE \n23   697    23 Pill          23 TRUE  \n24   707    26 Pill          26 TRUE  \n25   757    33 Pill          33 TRUE  \n26   767    23 Pill          23 TRUE  \n27   785    18 Pill          18 TRUE  \n28   836     1 Pill           1 TRUE  \n29   837    12 Pill          12 TRUE  \n30   850    35 Pill          35 FALSE \n31   930    36 Pill          36 FALSE \n32   943    13 Pill          13 TRUE  \n33   955     5 Pill           5 TRUE  \n34   977    36 Pill          36 FALSE \n35  1001    36 Pill          36 FALSE \n36  1037    36 Pill          36 FALSE \n37  1120     7 Pill           7 TRUE  \n38  1167    19 Pill          19 TRUE  \n39  1233    36 Pill          36 FALSE \n40  1271    32 Pill          32 TRUE  \n# … with 247 more rows\n\nLet’s now fit the Kaplan Meier estimator with survfit,\nwhich takes a survival object created by Surv. The function\nsummary shows the survival probabilities at each month in a\ncolumn called survival:\n\n\npills <- survfit(Surv(last_month, ceased) ~ 1, data = pills)\n\nsummary(pills)\n\n\nCall: survfit(formula = Surv(last_month, ceased) ~ 1, data = pills)\n\n time n.risk n.event survival std.err lower 95% CI upper 95% CI\n    1    287       4    0.986 0.00692        0.973        1.000\n    2    283       6    0.965 0.01082        0.944        0.987\n    3    277       7    0.941 0.01393        0.914        0.968\n    4    270      10    0.906 0.01723        0.873        0.940\n    5    260      14    0.857 0.02066        0.818        0.899\n    6    246       4    0.843 0.02146        0.802        0.886\n    7    242       7    0.819 0.02274        0.775        0.865\n    8    235       5    0.801 0.02355        0.757        0.849\n    9    230       3    0.791 0.02400        0.745        0.839\n   10    227       5    0.774 0.02471        0.727        0.823\n   11    222       8    0.746 0.02571        0.697        0.798\n   12    214      21    0.672 0.02770        0.620        0.729\n   13    193       9    0.641 0.02831        0.588        0.699\n   14    184       6    0.620 0.02865        0.567        0.679\n   15    178       2    0.613 0.02875        0.559        0.672\n   16    176       5    0.596 0.02897        0.542        0.655\n   17    171       8    0.568 0.02924        0.513        0.628\n   18    163       6    0.547 0.02938        0.492        0.608\n   19    157       7    0.523 0.02948        0.468        0.584\n   20    150       2    0.516 0.02950        0.461        0.577\n   21    148       2    0.509 0.02951        0.454        0.570\n   22    146       3    0.498 0.02951        0.444        0.560\n   23    143       6    0.477 0.02948        0.423        0.539\n   24    137       9    0.446 0.02934        0.392        0.507\n   25    128       3    0.436 0.02927        0.382        0.497\n   26    125       4    0.422 0.02915        0.368        0.483\n   27    121       1    0.418 0.02912        0.365        0.479\n   28    120       3    0.408 0.02901        0.355        0.469\n   29    117       2    0.401 0.02893        0.348        0.462\n   31    115       2    0.394 0.02884        0.341        0.455\n   32    113       3    0.383 0.02870        0.331        0.444\n   33    110       3    0.373 0.02854        0.321        0.433\n   34    107       3    0.362 0.02837        0.311        0.422\n\nWe can plot this with autoplot:\n\n\nautoplot(\n  pills,\n  main = \"Kaplan-Meier survival estimate: Pills\",\n  xlab = \"Months\",\n  ylab = \"Probability of Continuous Use\",\n  ylim = c(0, 1),\n  censor = F\n)\n\n\n\n\nFor additional examples using other family planning methods, download the R Markdown script from\nthis breakout session. Video from the session is included below:\n\n\nBreakout Session: Stata Users\nIPUMS PMA extracts for Stata should be decompressed before use and\nloaded with an appropriate filepath:\n. clear\n. use \"[filepath]/pma_00001.dta\"\n. cd \"[filepath]\"\n. set more off\n\nRemember to set your own filepath and change the name of your file to\nmatch your own data extract!\nAs shown in the R example above, this dataset contains 9,549 rows\nwhere each row represents one respondent to the Female Questionnaire.\nYou’ll find a unique identification number for each respondent in\npersonid, and their comma-separated contraceptive calendar\nstrings in calendarke. We’ll show these two variables for\nthe first 3 respondents:\n. list personid calendarke in 1/3\n\n     +----------------------------------------------------------------------+\n  1. |                                           personid                   |\n     |                              404201900050442019002                   |\n     |----------------------------------------------------------------------|\n     | calendarke                                                           |\n     |   0,0,B,P,P,P,P,P,P,P,P,0,0,0,0,0,0,0,0,0,0,0,0,3,3,3,3,3,3,3,3,3,.. |\n     +----------------------------------------------------------------------+\n\n     +----------------------------------------------------------------------+\n  2. |                                           personid                   |\n     |                              404201900009272019002                   |\n     |----------------------------------------------------------------------|\n     | calendarke                                                           |\n     |   ,7,7,7,7,7,7,7,7,0,B,P,P,P,P,P,P,P,P,0,0,0,0,0,9,9,9,9,9,9,9,9,9.. |\n     +----------------------------------------------------------------------+\n\n     +----------------------------------------------------------------------+\n  3. |                                           personid                   |\n     |                              404201900099612019003                   |\n     |----------------------------------------------------------------------|\n     | calendarke                                                           |\n     |   0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,.. |\n     +----------------------------------------------------------------------+\nAs you can see, calendarke includes the same\ncontraceptive calendar codes shown above, each separated by a comma.\nEach string contains 36 codes: these represent the 36 months from\nJanuary 2017 through December 2019 (the last month in which Kenya 2019\nsamples were collected). The left-most code represents the most\nrecent available month.\nNotice the second listed person\n(personid 404201900009272019002); their\ncalendarke string begins with a comma rather than a\nresponse code. This indicates a person who was interviewed in November\n2019, rather than December. Because December 2019 would have been a\nfuture month for such a person, their first value is blank.\nSplit the calendarke string into 36 separate columns\nwith the split function:\n. split calendarke, p(,) gen(cal_ke)\nvariables created as string: \ncal_ke1   cal_ke7   cal_ke13  cal_ke19  cal_ke25  cal_ke31\ncal_ke2   cal_ke8   cal_ke14  cal_ke20  cal_ke26  cal_ke32\ncal_ke3   cal_ke9   cal_ke15  cal_ke21  cal_ke27  cal_ke33\ncal_ke4   cal_ke10  cal_ke16  cal_ke22  cal_ke28  cal_ke34\ncal_ke5   cal_ke11  cal_ke17  cal_ke23  cal_ke29  cal_ke35\ncal_ke6   cal_ke12  cal_ke18  cal_ke24  cal_ke30  cal_ke36\nThen, reshape the data from wide to long format as shown in the R\nexample above. The index number for each month will pivot downward into\na new column called month, and the woman’s response code\nfor each month will pivot downward into an adjacent column called\ncal_ke:\n. reshape long cal_ke, i(personid) j(month)\n(note: j = 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \n> 26 27 28 29 30 31 32 33 34 35 36)\n\nData                               wide   ->   long\n-----------------------------------------------------------------------------\nNumber of obs.                     9549   ->  343764\nNumber of variables                  52   ->      18\nj variable (36 values)                    ->   month\nxij variables:\n           cal_ke1 cal_ke2 ... cal_ke36   ->   cal_ke\n-----------------------------------------------------------------------------\nNotice that the dataset now has 343,764 rows, where each of our 9,549\nrespondents occupies 36 rows apiece (one for each\nmonth).\nBy default, Stata numbered each month in increasing order from left\nto right. As we’ve discussed, however, the contraceptive calendar data\nare chronologically organized from right to left (the most recent month\nis stored in the first month of the calendarke string). We\nsuggest renumbering the cal_ke variables here so that\ncal_ke1 represents the first month, January 2017.\n. replace month = 37 - month\n(343,764 real changes made)\n. sort personid month\nYou might also find it useful to create century month codes\ncmc for each month, beginning with 1405 for January\n2017.\n. gen cmc = month + 1404\nAs a final clean-up step, we create a numeric version of\ncal_ke called numcal_ke by changing the codes\nfor pregnancy, pregnancy termination, and birth to 90,\n91, and 92 respectively. We then provide\nlabels to each of the values in numcal_ke.\n. gen numcal_ke = cal_ke\n(3,755 missing values generated)\n. replace numcal_ke = \"90\" if numcal_ke == \"P\"\n(24,364 real changes made)\n. replace numcal_ke = \"91\" if numcal_ke == \"T\"\n(341 real changes made)\n. replace numcal_ke = \"92\" if numcal_ke == \"B\"\n(2,934 real changes made)\n. destring numcal_ke, replace\nnumcal_ke: all characters numeric; replaced as byte\n(3755 missing values generated)\n\n. label define calendar 92 \"Birth\" 90 \"Pregnant\" 91 \"Pregnancy ended\" 0 \"No \n> family planning method used\" 1 \"Female Sterilization\" 2 \"Male Sterilization\" 3 \n> \"Implant\" 4 \"IUD\" 5 \"Injectables\" 7 \"Pill\" 8 \"Emergency Contraception\" 9 \"Male \n> Condom\" 10 \"Female Condom\" 11 \"Diaphragm\" 12 \"Foam / Jelly\" 13 \"Standard Days / \n> Cycle beads\" 14 \"LAM\" 30 \"Rhythm method\" 31 \"Withdrawal\" 39 \"Other traditional \n> methods\"\n\n. label values numcal_ke calendar\nFinally, we’re ready to begin our analysis. As with the R example\nabove, we’ll create survival curves showing the duration of\ncontinuously used family planning methods for cohorts\nof women who were using the same method in January 2017. These curves\nwill estimate the probability that an individual “survives” - or\ncontinues using - a given method at each of 36 months, assuming that she\nused it in month 1. We’ll exclude the duration of use after any\nbreak (for example, if a woman stopped using family planning to become\npregnant, but then started again afterward).\nConsider the cohort of women who were all using the contraceptive\npill in January 2017 (month 1). We’ll flag these cases and include all\nrows from those women in a sub-sample called\npill_sample:\n. recode numcal_ke (7=1) (else=0), gen(pill)\n(162306 differences between numcal_ke and pill)\n. gen pill_temp = 0 \n. replace pill_temp = 1 if pill == 1 & month == 1\n(287 real changes made)\n. egen pill_sample = max(pill_temp), by(personid)\nThe function stset establishes the data in memory as\n“survival-time” data, where the variable month records time\nin months, the identification number for each person is provided by\nid(personid), and cessation of use\n(i.e. failure) is marked by the first instance where\npill==0 for each person in the sub-sample.\n. stset month, id(personid) failure(pill==0)\n\n                id:  personid\n     failure event:  pill == 0\nobs. time interval:  (month[_n-1], month]\n exit on or before:  failure\n\n-----------------------------------------------------------------------------\n> -\n    343,764  total observations\n    328,001  observations begin on or after (first) failure\n-----------------------------------------------------------------------------\n> -\n     15,763  observations remaining, representing\n      9,549  subjects\n      9,463  failures in single-failure-per-subject data\n     15,763  total analysis time at risk and under observation\n                                                at risk from t =         0\n                                     earliest observed entry t =         0\n                                          last observed exit t =        36\nThe function sts list produces a similar table to the\none produced by summary(pills) in the R example above. The\ncolumn Survivor Function estimates the probability of\n“surviving” - or continuously using - the pill at each month shown in\nthe column Time.\n.  sts list if pill_sample == 1\n\n         failure _d:  pill == 0\n   analysis time _t:  month\n                 id:  personid\n\n           Beg.          Net            Survivor      Std.\n  Time    Total   Fail   Lost           Function     Error     [95% Conf. Int.]\n-------------------------------------------------------------------------------\n     2      287      4      0             0.9861    0.0069     0.9633    0.9947\n     3      283      6      0             0.9652    0.0108     0.9362    0.9811\n     4      277      7      0             0.9408    0.0139     0.9064    0.9628\n     5      270     10      0             0.9059    0.0172     0.8658    0.9345\n     6      260     14      0             0.8571    0.0207     0.8111    0.8927\n     7      246      4      0             0.8432    0.0215     0.7957    0.8805\n     8      242      7      0             0.8188    0.0227     0.7692    0.8588\n     9      235      5      0             0.8014    0.0235     0.7504    0.8431\n    10      230      3      0             0.7909    0.0240     0.7392    0.8336\n    11      227      5      0             0.7735    0.0247     0.7206    0.8177\n    12      222      8      0             0.7456    0.0257     0.6911    0.7920\n    13      214     21      0             0.6725    0.0277     0.6149    0.7234\n    14      193      9      0             0.6411    0.0283     0.5827    0.6936\n    15      184      6      0             0.6202    0.0286     0.5614    0.6735\n    16      178      2      0             0.6132    0.0287     0.5543    0.6668\n    17      176      5      0             0.5958    0.0290     0.5366    0.6500\n    18      171      8      0             0.5679    0.0292     0.5085    0.6229\n    19      163      6      0             0.5470    0.0294     0.4876    0.6025\n    20      157      7      0             0.5226    0.0295     0.4633    0.5786\n    21      150      2      0             0.5157    0.0295     0.4564    0.5717\n    22      148      2      0             0.5087    0.0295     0.4495    0.5648\n    23      146      3      0             0.4983    0.0295     0.4391    0.5545\n    24      143      6      0             0.4774    0.0295     0.4185    0.5337\n    25      137      9      0             0.4460    0.0293     0.3878    0.5024\n    26      128      3      0             0.4355    0.0293     0.3776    0.4920\n    27      125      4      0             0.4216    0.0291     0.3641    0.4779\n    28      121      1      0             0.4181    0.0291     0.3607    0.4744\n    29      120      3      0             0.4077    0.0290     0.3506    0.4639\n    30      117      2      0             0.4007    0.0289     0.3438    0.4568\n    32      115      2      0             0.3937    0.0288     0.3371    0.4498\n    33      113      3      0             0.3833    0.0287     0.3271    0.4391\n    34      110      3      0             0.3728    0.0285     0.3170    0.4285\n    35      107      3      0             0.3624    0.0284     0.3070    0.4178\n    36      104     18     86             0.2997    0.0270     0.2477    0.3532\n-------------------------------------------------------------------------------\nA survival curve representing this table can be made with:\nsts graph if pill_sample == 1\n\n\n\n\nThis plot is similar to the one generated by autoplot in R,\nexcept that 1) it does not include a shaded 95% confidence interval, and\n2) right-censored cases are not excluded, producing a sharp downward\nturn in month 36.\nFor additional examples using other family planning methods, download the Stata .do\nfile from this breakout session here. Video from the session is\nincluded below:\n\n\nDownload Links\nPowerpoint\nSlides\nR Markdown Script\nStata .do\nFile\nChat Transcript (participant\nnames are redacted)\n\n\n\n",
    "preview": "posts/2021-05-15-paa-2021/images/featured.png",
    "last_modified": "2022-06-14T10:43:16-04:00",
    "input_file": {},
    "preview_width": 2880,
    "preview_height": 1800
  },
  {
    "path": "posts/2021-05-01-storymaps/",
    "title": "Visualizing PMA Data with StoryMaps",
    "description": "Five outstanding undergraduate research projects integrate dynamic data visualization with spatial analysis and narrative.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-05-03",
    "categories": [
      "PMA Publications",
      "StoryMaps",
      "Undergrads",
      "Teaching"
    ],
    "contents": "\n\nContents\nAttainment of Sex Preference in India\nIntimate Partner Violence and Body Weight\nHigher Probability that Women Report IPV\nEmpowered Women Raise Healthy Children\nWealth and Healthcare can Save Pregnant Women\n\nWhen great new research gets published with PMA data, we like to share it with you in a PMA Publications post. Sometimes we’ll take a deep dive into the R code you can use to reproduce great analysis, but today we’ll take a look at a different tool that undergraduate students are using to learn about IPUMS PMA and other IPUMS Global Health data at the University of Minnesota.\n\nHave a recent publication using PMA data that you’d like to feature in a PMA Publications post? Please let us know!\nThis semester, students in the Global Health Survey Analysis course used an amazing tool called StoryMaps to develop interactive narratives exploring different topics related to family planning. StoryMaps have been used in both the undergraduate and graduate curriculum throughout the College of Liberal Arts and beyond - we encourage you to check out the full gallery of student projects here!\nThanks to course professors Elizabeth Boyle and Kathryn Grace for sharing this great work!\nAttainment of Sex Preference in India\nAuthor: Lara Rae Erdmann\n\n\n\n\nIntimate Partner Violence and Body Weight\nAuthor: Jaclyn Willems\n\n\n\n\nHigher Probability that Women Report IPV\nAuthor: Peyton Retterath\n\n\n\n\nEmpowered Women Raise Healthy Children\nAuthor: Kassandra Fate\n\n\n\n\nWealth and Healthcare can Save Pregnant Women\nAuthor: Hana al’Absi\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-05-01-storymaps/images/featured.png",
    "last_modified": "2023-03-02T10:52:53-05:00",
    "input_file": {},
    "preview_width": 2190,
    "preview_height": 1254
  },
  {
    "path": "posts/2021-04-15-migration-discovery/",
    "title": "Formatting Migration Recall Data for Longitudinal Analysis",
    "description": "Use tidyr::pivot_longer to reshape wide data into a long format.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-04-15",
    "categories": [
      "Migration",
      "Data Discovery",
      "Data Manipulation",
      "pivot_longer",
      "regex"
    ],
    "contents": "\n\nContents\nData Availability\nLongitudinal Data Structures\nPivot Longer into One Column\nPivot Longer into Multiple Columns\n\n\nMost of the data you’ll find at IPUMS PMA comes from cross-sectional surveys, where each respondent is interviewed only once. However, there are some items on the Female Questionnaire that ask respondents to recall past events. When these recall data are linked to a measure of time, the data can be restructured to simulate longitudinal data – or repeated observations on individuals over time. Once the data are in this structure, we can use a range of analytic tools to determine how the frequency or duration of past experiences explains current outcomes.\n\nCurrently, only the 2016 Ethiopia Maternal and Newborn Health survey contains data from follow-up interviews. Panel data related to contraceptive use is coming soon!\nOne place where you’ll find this type of data is on the migration variables page. In our last post, we saw that PMA samples from Ethiopia began including information about each respondent’s single most most recent migration experience beginning with the 2016 sample. More recently, a number of samples from other countries have collected data about each respondent’s complete migration history, organized in chronological order. These samples include:\nBurkina Faso 2020\nCongo (DR), Kinshasa 2019\nCongo (DR), Kongo Central 2019\nKenya 2019\nNigeria, Kano 2019\nNigeria, Lagos 2019\nIn this post, we’ll take a look at the available information in the migration data collected from these newer samples. As we’ll see, female respondents who indicate that they have migrated at least once receive the same set of questions for each place they have lived, resulting in a dataset that is exceptionally wide and cumbersome to use in most time-dependent applications. We’ll show how to reshape an example data extract into a much friendlier long format using the function tidyr::pivot_longer.\nData Availability\nThe samples listed above contain data from nearly identical survey questions. In the interview, a respondent is first asked how long they have lived in their current place of residence; if they indicate that they have not “always” lived in the same place, they are then asked how many places they’ve lived for more than six months after age 15 or their first marriage (whichever happened first).\n\nInterviewers were instructed to define a place as “a community, village, or neighborhood”.\nRespondents who list at least one such place are then asked to recall information about each place, starting with the place before their current residence. Information about the most recent place is represented by variables beginning with the prefix PLACE1. Information about the second most recent place is represented by the prefix PLACE2, and so forth.\nIn each of these samples, the same questions are repeated for each place until all of the respondent’s previous places of residence are fully enumerated. The available information about each place includes:\nits country\nits district or region\nthe respondent’s age when she moved to the place\nwhether the place was a city, a town, peri-urban, or rural (not available for Nigeria samples)\nAdditionally, the respondent could list multiple reasons for migrating to each place (note that this information is not available for the respondent’s migration to their current place of residence). Options include:\nlooking for a job\nseasonal work\nwork (non-seasonal)\nwant to change jobs\nfamily or village conflict\nto attend school\nmove after completed school\njoin spouse after marriage\nco-reside with boy/girlfriend\ndivorce/widowhood\nhospitalization/health problem\nbetter access to health service\ncaring for sick relative\nfollowed spouse to job\nbetter land for farming\nbetter education for children\nother social reasons\nother\nBecause the respondent can choose multiple reasons, we’ll find one binary indicator for each of these 18 reasons. As you might imagine, this results in a very wide dataset! Some respondents move as many as 11 times, resulting in 198 columns from just this one repeated multiple-response question.\nThe wide shape of these data is more than an inconvenience: most longitudinal analysis applications require easy access to the time interval between events. In their current format, each numbered PLACE variable represents a single migration event, but it’s difficult to tell how much time passed between any two migrations for a given person. To make this kind of analysis possible, we need to pivot the migration variables into a long format accompanied by a new variable showing the time interval between each migration.\nLongitudinal Data Structures\nLet’s take a look at the way migration history variables are currently formatted for one of the samples we discussed above. For this example, we’ve created a data extract containing all of the available migration data for the Kenya 2019 sample (female respondents only). We’ll load it and the following packages into R:\n\n\nlibrary(tidyverse)\nlibrary(ipumsr)\n\ndat <- read_ipums_micro(\n  ddi = \"data/pma_00022.xml\",\n  data = \"data/pma_00022.dat.gz\"\n)\n\n\n\n\nRemember: change these file paths to match the download location for your own data extract!\n\n\n\nLike all IPUMS PMA data extracts, this dataset reflects a cross-sectional survey design where every response from each person is stored in a single row. If you’re familiar with longitudinal data structures, you know that repeated observations from the same respondents are stored in separate rows, where each row represents a different moment in time. Why might this be the case?\nAs we’ll see in our own data, the values for repeated observations and the amount of time that passes between observations are related only by a common pattern in the names for each variable when they’re stored together in a wide format. In our case, the only mark of time between migrations is the respondent’s age. Consider the following respondents, who have each migrated at least twice:\n\n\ndat %>% \n  filter(PLACELIVENUM %in% 2:7) %>% \n  select(ends_with(\"DISTRICTKE\"), ends_with(\"MOVEAGE\")) %>% \n  relocate(starts_with(\"PLACE1\"), starts_with(\"PLACE2\"))\n\n\n# A tibble: 1,206 x 14\n  PLACE1DISTRICTKE PLACE1MOVEAGE PLACE2DISTRICTKE PLACE2MOVEAGE\n         <int+lbl>     <int+lbl>        <int+lbl>     <int+lbl>\n1  7 [Nandi]                  29    32 [Migori]              19\n2  8 [Nyamira]                19     8 [Nyamira]             21\n3  6 [Nairobi]                34     3 [Kiambu]              28\n4  6 [Nairobi]                25    35 [Nakuru]               0\n5 43 [Trans-Nzoia]            15    28 [Machakos]             0\n# … with 1,201 more rows, and 10 more variables:\n#   PLACE3DISTRICTKE <int+lbl>, PLACE4DISTRICTKE <int+lbl>,\n#   PLACE5DISTRICTKE <int+lbl>, PLACE6DISTRICTKE <int+lbl>,\n#   PLACE7DISTRICTKE <int+lbl>, PLACE3MOVEAGE <int+lbl>,\n#   PLACE4MOVEAGE <int+lbl>, PLACE5MOVEAGE <int+lbl>,\n#   PLACE6MOVEAGE <int+lbl>, PLACE7MOVEAGE <int+lbl>\n\nPLACE1DISTRICTKE shows the administrative district of the last place a respondent lived before their current place of residence, and PLACE1MOVEAGE shows her age when she moved there. PLACE2DISTRICTKE shows the district of the second most recent place she lived, and PLACE2MOVEAGE shows her age when she moved there. The same pattern would be repeated for all of the places a person might have lived (in this sample, some respondents migrated as many as 7 times).\n\nYou might notice that the respondent in the second row recalls her prior places of residence in reverse chronological order. This particular type of recall error is also easier to fix when we pivot_longer.\nSuppose you wanted to know something very simple about the relationship between these variables, such as the average age of female migrants arriving at each district in the sample. In this wide format, you would first have to find the mean PLACE1MOVEAGE for every district in PLACE1DISTRICTKE, then the mean PLACE2MOVEAGE for every district in PLACE2DISTRICTKE, and so forth for all 7 places. Then, you’d need to find the frequency weighted mean for each district in all 7 places. That’s quite a bit of extra work for just one simple statistic!\nImagine you wanted to model the effect of a time-dependent variable on an outcome of interest. For example, you might suppose that the number of times a female respondent gives birth could be related to the length of time she’s lived in a district where there are relatively few family planning services available. As you can see, we’d have a hard time building an appropriate model because the relevant data are currently strewn across 14 different variables. Instead, we’d much prefer two work with the data in a long format with only two variables: one representing DISTRICTKE and one representing MOVEAGE.\nPivot Longer into One Column\nFor the moment, let’s continue working just with the district for each place in an individual’s migration history. To keep things simple, we’ll create a dataset called district containing only the variables ending with the string DISTRICTKE.\n\n\ndistrict <- dat %>% select(ends_with(\"DISTRICTKE\")) \n\ndistrict\n\n\n# A tibble: 9,549 x 7\n   PLACE1DISTRICTKE PLACE2DISTRICTKE PLACE3DISTRICTKE PLACE4DISTRICTKE\n          <int+lbl>        <int+lbl>        <int+lbl>        <int+lbl>\n1 99 [NIU (not in … 99 [NIU (not in… 99 [NIU (not in… 99 [NIU (not in…\n2  6 [Nairobi]      99 [NIU (not in… 99 [NIU (not in… 99 [NIU (not in…\n3 99 [NIU (not in … 99 [NIU (not in… 99 [NIU (not in… 99 [NIU (not in…\n4 99 [NIU (not in … 99 [NIU (not in… 99 [NIU (not in… 99 [NIU (not in…\n5 99 [NIU (not in … 99 [NIU (not in… 99 [NIU (not in… 99 [NIU (not in…\n# … with 9,544 more rows, and 3 more variables:\n#   PLACE5DISTRICTKE <int+lbl>, PLACE6DISTRICTKE <int+lbl>,\n#   PLACE7DISTRICTKE <int+lbl>\n\nAs you can see, a lot of the information contained in district isn’t really necessary. Every row holds information on 7 places of residence, but most respondents migrated only to 1 or 2 places if they ever migrated at all. The best approach here is to tell R that labels like NIU (not in universe) and No response or missing each represent a type of missing data that we can recode as NA. We can do that with help from ipumsr::lbl_na_if and dplyr::across:\n\n\ndistrict <- district %>% \n  mutate(across(everything(), ~{\n    lbl_na_if(.x, ~.lbl %in% c(\n      \"No response or missing\",\n      \"NIU (not in universe)\"\n    ))\n  }))\n\ndistrict\n\n\n# A tibble: 9,549 x 7\n  PLACE1DISTRICTKE PLACE2DISTRICTKE PLACE3DISTRICTKE PLACE4DISTRICTKE\n         <int+lbl>        <int+lbl>        <int+lbl>        <int+lbl>\n1     NA                         NA               NA               NA\n2      6 [Nairobi]               NA               NA               NA\n3     NA                         NA               NA               NA\n4     NA                         NA               NA               NA\n5     NA                         NA               NA               NA\n# … with 9,544 more rows, and 3 more variables:\n#   PLACE5DISTRICTKE <int+lbl>, PLACE6DISTRICTKE <int+lbl>,\n#   PLACE7DISTRICTKE <int+lbl>\n\n\nSee this post for additional details on recoding variables with ipumsr and dplyr::across.\nIn order to keep track of individuals, let’s also add a column ID that represents a short identification number for each person:\n\n\ndistrict <- district %>% rowid_to_column(\"ID\")\ndistrict\n\n\n# A tibble: 9,549 x 8\n     ID PLACE1DISTRICTKE PLACE2DISTRICTKE PLACE3DISTRICTKE\n  <int>        <int+lbl>        <int+lbl>        <int+lbl>\n1     1     NA                         NA               NA\n2     2      6 [Nairobi]               NA               NA\n3     3     NA                         NA               NA\n4     4     NA                         NA               NA\n5     5     NA                         NA               NA\n# … with 9,544 more rows, and 4 more variables:\n#   PLACE4DISTRICTKE <int+lbl>, PLACE5DISTRICTKE <int+lbl>,\n#   PLACE6DISTRICTKE <int+lbl>, PLACE7DISTRICTKE <int+lbl>\n\nNow, we’re ready to use the function tidyr::pivot_longer to reshape district. The simplest way to use this function is to specify a group of columns with the argument cols:\n\n\n\n\n\ndistrict %>% pivot_longer(cols = ends_with(\"DISTRICTKE\"))\n\n\n# A tibble: 66,843 x 3\n      ID name                    value\n   <int> <chr>               <int+lbl>\n 1     1 PLACE1DISTRICTKE NA          \n 2     1 PLACE2DISTRICTKE NA          \n 3     1 PLACE3DISTRICTKE NA          \n 4     1 PLACE4DISTRICTKE NA          \n 5     1 PLACE5DISTRICTKE NA          \n 6     1 PLACE6DISTRICTKE NA          \n 7     1 PLACE7DISTRICTKE NA          \n 8     2 PLACE1DISTRICTKE  6 [Nairobi]\n 9     2 PLACE2DISTRICTKE NA          \n10     2 PLACE3DISTRICTKE NA          \n# … with 66,833 more rows\n\n\n\n\n\n© 2018 RStudio (CC0 1.0)\ntidyr is included with library(tidyverse).\nBy default, the name of each column moves into a single column called name, and the value of each column moves into an adjascent column called value. We can manually change the names of these columns with the arguments names_to and values_to:\n\n\ndistrict %>% pivot_longer(\n  cols = ends_with(\"DISTRICTKE\"),\n  names_to = \"PLACE\",\n  values_to = \"DISTRICTKE\"\n)\n\n\n# A tibble: 66,843 x 3\n      ID PLACE              DISTRICTKE\n   <int> <chr>               <int+lbl>\n 1     1 PLACE1DISTRICTKE NA          \n 2     1 PLACE2DISTRICTKE NA          \n 3     1 PLACE3DISTRICTKE NA          \n 4     1 PLACE4DISTRICTKE NA          \n 5     1 PLACE5DISTRICTKE NA          \n 6     1 PLACE6DISTRICTKE NA          \n 7     1 PLACE7DISTRICTKE NA          \n 8     2 PLACE1DISTRICTKE  6 [Nairobi]\n 9     2 PLACE2DISTRICTKE NA          \n10     2 PLACE3DISTRICTKE NA          \n# … with 66,833 more rows\n\nEven more conveniently, we can generate these columns automatically if we identify a pattern in the original column names. This approach efficiently handles both the names of the new columns and the values stored in each column. Notice that we’ve manually specified the name of the column DISTRICTKE above; this is fine if we’re only pivoting one column, but we want to avoid manually writing a name for each new column when we start working with several variables at once. Also, notice the values that appear in the PLACE column; wouldn’t it be more convenient to extract the index number for each place, rather than the full names of the original columns?\nWe’ll use the additional argument names_pattern to solve both problems at once. Any string enclosed with parentheses () in names_pattern can be passed, in sequential order, to names_to. In this example, we specify a pattern where the string PLACE will be followed by a single-digit number ([0-9]) followed by the string (DISTRICTKE). The argument names_to places the single-digit number in a column called PLACE, and it places the string DISTRICTKE in a column that uses a pronoun .value to represent the contents of the string.\n\n\ndistrict %>% \n  pivot_longer(\n    cols = ends_with(\"DISTRICTKE\"), \n    names_pattern = \"PLACE([0-9])(DISTRICTKE)\",\n    names_to = c(\"PLACE\", \".value\")\n  ) \n\n\n# A tibble: 66,843 x 3\n      ID PLACE   DISTRICTKE\n   <int> <chr>    <int+lbl>\n 1     1 1     NA          \n 2     1 2     NA          \n 3     1 3     NA          \n 4     1 4     NA          \n 5     1 5     NA          \n 6     1 6     NA          \n 7     1 7     NA          \n 8     2 1      6 [Nairobi]\n 9     2 2     NA          \n10     2 3     NA          \n# … with 66,833 more rows\n\nWe can improve the scalability of this code just a little bit more by adding the wildcard . in names_pattern to represent “any character” and the operator * to represent “any number of times”. This allows us to write ([0-9]*) to find an integer of any length (in case some respondents move 10 places or more), and (.*) to find a string of any length afterward (this saves us the trouble of writing “DISTRICTKE”).\n\n\ndistrict %>% \n  pivot_longer(\n    cols = ends_with(\"DISTRICTKE\"), \n    names_pattern = \"PLACE([0-9]*)(.*)\",\n    names_to = c(\"PLACE\", \".value\")\n  ) \n\n\n# A tibble: 66,843 x 3\n      ID PLACE   DISTRICTKE\n   <int> <chr>    <int+lbl>\n 1     1 1     NA          \n 2     1 2     NA          \n 3     1 3     NA          \n 4     1 4     NA          \n 5     1 5     NA          \n 6     1 6     NA          \n 7     1 7     NA          \n 8     2 1      6 [Nairobi]\n 9     2 2     NA          \n10     2 3     NA          \n# … with 66,833 more rows\n\nNotice that there are now 66,843 rows in district: that’s 7 rows for 7 places per respondent. Adding the argument values_drop_NA = TRUE drops placeholder values for respondents who lived in fewer than 7 places:\n\n\ndistrict %>% \n  pivot_longer(\n    cols = ends_with(\"DISTRICTKE\"), \n    names_pattern = \"PLACE([0-9]*)(.*)\",\n    names_to = c(\"PLACE\", \".value\"),\n    values_drop_na = TRUE\n  ) \n\n\n# A tibble: 5,165 x 3\n      ID PLACE    DISTRICTKE\n   <int> <chr>     <int+lbl>\n 1     2 1      6 [Nairobi] \n 2    11 1     10 [Kakamega]\n 3    12 1     10 [Kakamega]\n 4    14 1      7 [Nandi]   \n 5    14 2     32 [Migori]  \n 6    16 1      6 [Nairobi] \n 7    19 1     33 [Mombasa] \n 8    20 1      8 [Nyamira] \n 9    20 2      8 [Nyamira] \n10    21 1      6 [Nairobi] \n# … with 5,155 more rows\n\nThis step causes any respondent who has never migrated from a place they lived for 6 months or more after age 15 / first marriage to be filtered out of the data. Here, we see the first 10 rows from all of the remaining female respondents. Individuals 14 and 20 lived in two such places: individual 14 first lived in the district Migori, then moved to Nandi, and finally moved to her current residence (not shown). Individual 20 first lived in Nyamira, then moved to another place also in Nyamira, and finally moved to her current residence (not shown). All of the other displayed respondents lived in exactly one such place. Next, we’ll add the age at which each of the women moved to each location.\n\nRemember: these migration history variables contain information about each place a person has lived prior to their current residence. You’ll find information on the woman’s current district of residence in either GEOKE (for Kenya samples) or SUBNATIONAL (for all samples, including Kenya).\nPivot Longer into Multiple Columns\nNow that we know how to use wildcard operators in pivot_longer, we’ll be able to start pivoting multiple columns at once. Let’s start by adding the respondent’s age when they moved to each place. Using the same processing steps we used to make district, we’ll create a new dataset called age.\n\n\nage <- dat %>% \n  select(ends_with(\"DISTRICTKE\"), ends_with(\"MOVEAGE\")) %>% \n  mutate(across(everything(), ~{\n    lbl_na_if(.x, ~.lbl %in% c(\n      \"No response or missing\",\n      \"NIU (not in universe)\"\n    ))\n  })) %>% \n  rowid_to_column(\"ID\")\n\n\n\n\n\nage %>% relocate(ID, starts_with(\"PLACE1\"), starts_with(\"PLACE2\"))\n\n\n# A tibble: 9,549 x 15\n      ID PLACE1DISTRICTKE PLACE1MOVEAGE PLACE2DISTRICTKE PLACE2MOVEAGE\n   <int>        <int+lbl>     <int+lbl>        <int+lbl>     <int+lbl>\n 1     1     NA                      NA               NA            NA\n 2     2      6 [Nairobi]            16               NA            NA\n 3     3     NA                      NA               NA            NA\n 4     4     NA                      NA               NA            NA\n 5     5     NA                      NA               NA            NA\n 6     6     NA                      NA               NA            NA\n 7     7     NA                      NA               NA            NA\n 8     8     NA                      NA               NA            NA\n 9     9     NA                      NA               NA            NA\n10    10     NA                      NA               NA            NA\n# … with 9,539 more rows, and 10 more variables:\n#   PLACE3DISTRICTKE <int+lbl>, PLACE4DISTRICTKE <int+lbl>,\n#   PLACE5DISTRICTKE <int+lbl>, PLACE6DISTRICTKE <int+lbl>,\n#   PLACE7DISTRICTKE <int+lbl>, PLACE3MOVEAGE <int+lbl>,\n#   PLACE4MOVEAGE <int+lbl>, PLACE5MOVEAGE <int+lbl>,\n#   PLACE6MOVEAGE <int+lbl>, PLACE7MOVEAGE <int+lbl>\n\n\nWe’re using relocate here just so that we can display the DISTRICTKE and MOVEAGE variables side-by-side. It doesn’t change anything else about the structure of the data!\nBecause we’re using the wildcard pattern (.*), the function will treat the string MOVEEAGE the same way it treats DISTRICTKE. We only need to add the new columns to cols:\n\n\nage <- age %>% \n  pivot_longer(\n    cols = c(ends_with(\"DISTRICTKE\"), ends_with(\"MOVEAGE\")), \n    names_pattern = \"PLACE([0-9]*)(.*)\",\n    names_to = c(\"PLACE\", \".value\"),\n    values_drop_na = TRUE\n  ) \n\nage\n\n\n# A tibble: 5,246 x 4\n      ID PLACE    DISTRICTKE   MOVEAGE\n   <int> <chr>     <int+lbl> <int+lbl>\n 1     2 1      6 [Nairobi]         16\n 2    11 1     10 [Kakamega]        17\n 3    12 1     10 [Kakamega]        16\n 4    14 1      7 [Nandi]           29\n 5    14 2     32 [Migori]          19\n 6    16 1      6 [Nairobi]         21\n 7    19 1     33 [Mombasa]         31\n 8    20 1      8 [Nyamira]         19\n 9    20 2      8 [Nyamira]         21\n10    21 1      6 [Nairobi]         34\n# … with 5,236 more rows\n\nThe advantages we’ve gained with a longer data format are starting to become clear! Suppose you wanted to know the average age of migrants arriving at each of Kenya’s administrative districts in this sample. You could find this information easily with just one summarise function:\n\n\nage %>% \n  group_by(DISTRICTKE) %>% \n  summarise(MEAN_AGE = mean(MOVEAGE, na.rm = T))\n\n\n# A tibble: 48 x 2\n      DISTRICTKE MEAN_AGE\n       <int+lbl>    <dbl>\n 1  1 [Bungoma]      18.5\n 2  2 [Kericho]      18.0\n 3  3 [Kiambu]       20.7\n 4  4 [Kilifi]       17.1\n 5  5 [Kitui]        19.3\n 6  6 [Nairobi]      20.0\n 7  7 [Nandi]        18.4\n 8  8 [Nyamira]      17.9\n 9  9 [Siaya]        16.1\n10 10 [Kakamega]     17.1\n# … with 38 more rows\n\nLet’s now pivot all of the migration history columns in our original dataset dat. This time, we’ll specify that all of the desired cols start with the same prefix PLACE (but we’ll drop the column PLACELIVENUM, since it contains the string “PLACE” we’re using in names_pattern):\n\n\ndat <- dat %>% \n  mutate(across(everything(), ~{\n    lbl_na_if(.x, ~.lbl %in% c(\n      \"No response or missing\",\n      \"NIU (not in universe)\"\n    ))\n  })) %>% \n  rowid_to_column(\"ID\") %>% \n  select(ID, starts_with(\"PLACE\"), -PLACELIVENUM) %>% \n  pivot_longer(\n    cols = starts_with(\"PLACE\"), \n    names_pattern = \"PLACE([0-9]*)(.*)\",\n    names_to = c(\"PLACE\", \".value\"),\n    values_drop_na = TRUE\n  )\n\ndat\n\n\n# A tibble: 5,251 x 24\n      ID PLACE COUNTRY  DISTRICTKE MOVEAGE       UR YCHILDEDU YCOHABIT\n   <int> <chr>   <int>   <int+lbl> <int+l> <int+lb> <int+lbl> <int+lb>\n 1     2 1         404  6 [Nairob…      16 30 [Rur…    0 [No]   0 [No]\n 2    11 1         404 10 [Kakame…      17 30 [Rur…    0 [No]   0 [No]\n 3    12 1         404 10 [Kakame…      16 10 [Cit…    0 [No]   0 [No]\n 4    14 1         404  7 [Nandi]       29 30 [Rur…    0 [No]   0 [No]\n 5    14 2         404 32 [Migori]      19 10 [Cit…    0 [No]   0 [No]\n 6    16 1         404  6 [Nairob…      21 30 [Rur…    0 [No]   0 [No]\n 7    19 1         404 33 [Mombas…      31 20 [Per…    0 [No]   0 [No]\n 8    20 1         404  8 [Nyamir…      19 10 [Cit…    0 [No]   0 [No]\n 9    20 2         404  8 [Nyamir…      21 20 [Per…    0 [No]   0 [No]\n10    21 1         404  6 [Nairob…      34 20 [Per…    0 [No]   0 [No]\n# … with 5,241 more rows, and 16 more variables: YCONFLICT <int+lbl>,\n#   YDIVORCE <int+lbl>, YFARM <int+lbl>, YHLTHACCESS <int+lbl>,\n#   YHLTHPROB <int+lbl>, YJOBSEARCH <int+lbl>, YOTHER <int+lbl>,\n#   YOTHERSOCIAL <int+lbl>, YPOSTMAR <int+lbl>,\n#   YSCHOOLATTEND <int+lbl>, …\n\nWe’re left with a very manageable 24 migration history variables. Among these, all of the variables starting with Y indicate a possible reason “why” a respondent migrated to a particular PLACE. The simplest way to work with these Y variables is to use tidy selection functions, like starts_with(\"Y\"). For example, suppose you wanted to know the percentage of all migrations in the sample that happened for all of the available reasons:\n\n\ndat %>% \n  summarise(across(starts_with(\"Y\"), ~100*mean(.x))) %>% \n  glimpse()\n\n\nRows: 1\nColumns: 18\n$ YCHILDEDU     <dbl> 1.980575\n$ YCOHABIT      <dbl> 2.418587\n$ YCONFLICT     <dbl> 8.931632\n$ YDIVORCE      <dbl> 0.8188916\n$ YFARM         <dbl> 4.05637\n$ YHLTHACCESS   <dbl> 1.866311\n$ YHLTHPROB     <dbl> 0.9331556\n$ YJOBSEARCH    <dbl> 16.85393\n$ YOTHER        <dbl> 9.502952\n$ YOTHERSOCIAL  <dbl> 12.53095\n$ YPOSTMAR      <dbl> 24.01447\n$ YSCHOOLATTEND <dbl> 22.73853\n$ YSCHOOLDONE   <dbl> 4.361074\n$ YSICKREL      <dbl> 1.371167\n$ YSPOUSEJOB    <dbl> 2.704247\n$ YWKCHANGE     <dbl> 1.885355\n$ YWKNONSEAS    <dbl> 3.77071\n$ YWKSEASON     <dbl> 6.189297\n\nNow that we’ve reshaped our migration recall data from a wide format to a long format, obtaining this summary data is a snap. And, as we’ll see in an upcoming migration Data Analysis post, using these data in longitudinal analysis can be just as easy.\n\n\n\n\n",
    "preview": "posts/2021-04-15-migration-discovery/images/tidyr_wide.png",
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {},
    "preview_width": 960,
    "preview_height": 540
  },
  {
    "path": "posts/2021-04-01-et-internal-migration/",
    "title": "Unmet need for family planning after internal migration",
    "description": "Summary and source code from a recent article using data from Ethiopia.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-04-02",
    "categories": [
      "Migration",
      "PMA Publications",
      "svyglm",
      "bootstraps"
    ],
    "contents": "\n\nContents\nMotivation\nData\nDependent variable\nKey independent variable\nCovariates\nSub-sample\nReference groups\n\nRegression Model\nInterpretation\nPredicted Probabilities\n\n\n\n\n\nWhen great new research gets published with PMA data on a topic we’re covering here on the Data Analysis Hub, we’ll cover the highlights and explore some source code in a PMA Publications post.\n\nHave a recent publication using PMA data that you’d like to feature in a PMA Publications post? Please let us know!\nAs part of our new series on women’s migration experiences and their impact on family planning, let’s dig into a paper from University of Minnesota researchers Emily Groene and Devon Kristiansen (2021) published in the journal Population, Space and Place.\nMotivation\nAs we’ll see throughout this series, migration can be associated with major changes in an individual’s fertility intentions and family planning access, and it can either increase or decrease the likelihood of experiencing unmet need for family planning under different circumstances. Groene & Kristiansen focus their attention on the particular circumstances around rural-to-urban internal (within-country) migration, which is one of the prevailing modes of migration throughout the countries surveyed by PMA (McAuliffe and Ruhs 2017).\nConsider all of the potential changes a person might experience when moving from a rural to an urban area: Groene & Kristiansen outline literature that suggests quite a few ways that these changes might impact fertility behavior. Some are likely to increase demand for family planning, for example:\nIncreased availability and access to health services and long-acting contraceptives (Skiles et al. 2015)\nNew opportunities for employment, education, and greater wealth that can delay or limit plans for additional births (Schultz 1994)\nDiminished incentives for larger family sizes tied to rural culture and livelihoods (Abebe 2007)\nAcculturation, or adoption of destination cultural roles and values (Kohler 2000)\nOn the other hand, several offsetting factors may push to maintain or even decrease demand for family planning:\nSpousal separation tied to seasonal migration for employment (Sevoyan and Agadjanian 2013)\nFamily planning preferences established prior to migration (Kulu 2005)\nSelection into destinations where familiar cultural roles and values are prevalent (Courgeau 1989)\nEven when we focus our analysis on rural-urban internal migrants, it’s very hard to predict how these and other factors might react to determine the family planning needs for any given person. From a policy perspective, where planning is needed to identify and address unmet need for family planning services on a larger scale, Groene & Kristiansen offer important insights into the ways that migration experiences are tied to a particular place. Using female respondents from the Ethiopia 2017 and 2018 samples, they compare unmet need among rural-urban internal migrants to the unmet need experienced by non-migrants in both rural and urban settings. They find that migrants are less likely to experience unmet need compared to non-migrants, controlling for a number of demographic factors.\nUnmet need is the difference between an individual’s reproductive intentions and contraceptive behavior.\nIn this post, we’ll show how to recreate their analysis using an IPUMS PMA data extract in R.\nData\nThe Ethiopia 2017 and 2018 samples were among the first PMA samples to include questions related to women’s most recent migration experience, and about the region where they were born. Their responses are included in variables listed in the migration variable group:\nLIVEINREGION - How long living continuously in current region\nLIVEINREGIONYRS - Number of years continuously living in current region\nLASTREGION - Region/country of residence before current region\nLASTUR - Urban/rural status of residence before current region\nBIRTHREGIONET - Region of woman’s birth, Ethiopia\nBIRTHUR - Urban/rural status of region of woman’s birth\nMIGMAINRSN - The main reason why moved to current place of residence\nMIGPREKID - Gave birth before moved to current region\nMIGPREKIDNUM - Number of sons/daughters before moving to current region\n\nA 2013 sample of women from Kinshasa, DRC were also given questions related to their recent migration history, but these data have not been made available for public use. See Anglewicz et al. (2017).\nGroene & Kristiansen use the variable LIVEINREGION to determine whether a woman has always lived in the same place and, if not, they use BIRTHUR together with URBAN to identify those who ultimately moved from a rural place to an urban place. We’ve created a data extract containing these and all of the other variables discussed below (female respondents only); we’ll start by loading it and the following packages in R:\n\n\nlibrary(ipumsr)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(survey)\nlibrary(srvyr)\n\ndat <- ipumsr::read_ipums_micro(\n  ddi = \"data/pma_00019.xml\",\n  data = \"data/pma_00019.dat.gz\"\n)\n\n\n\nIf you’re a registered user at pma.ipums.org, you can recreate the authors’ data extract by selecting the variables mentioned in this post.\nSee our guide for help importing IPUMS data extracts into R.\nWe’ll first label the various non-response values in this dataset with the value NA using ipumsr::lbl_na_if applied to all variables with dplyr::across:\n\n\ndat <- dat %>% \n  mutate(\n    across(everything(), ~lbl_na_if(\n      .x,\n      ~.lbl %in% c(\n        \"Don't know\",\n        \"No response or missing\",\n        \"NIU (not in universe)\",\n        \"NIU (not in universe) or missing\"\n      )\n    ))\n  )\n\n\n\nEthiopia samples are stratified by region (GEOET) and urban status (URBAN), resulting in 21 sampling strata from which primary sampling units (EAID) are selected. The authors exclude women from any STRATA where fewer than 200 women were sampled across both sample years:\n\nPMA uses a multistage, stratified cluster sample design. For more information, see PMA’s sample design memo.\n\n\ndat %>% count(STRATA) \n\n\n# A tibble: 21 × 2\n                                  STRATA     n\n                               <int+lbl> <int>\n 1 23101 [Addis Ababa - urban, Ethiopia]  1833\n 2 23102 [Amhara - urban, Ethiopia]       1005\n 3 23103 [Amhara - rural, Ethiopia]       1651\n 4 23104 [Oromiya - urban, Ethiopia]      1216\n 5 23105 [Oromiya - rural, Ethiopia]      2275\n 6 23106 [Other, Ethiopia]                 839\n 7 23107 [SNNP - urban, Ethiopia]         1904\n 8 23108 [SNNP - rural, Ethiopia]         1241\n 9 23109 [Tigray - urban, Ethiopia]       1455\n10 23110 [Tigray - rural, Ethiopia]        810\n11 23111 [Dire Dawa - urban, Ethiopia]      22\n12 23112 [Dire Dawa - rural, Ethiopia]      29\n13 23113 [Afar - urban, Ethiopia]           32\n14 23114 [Afar - rural, Ethiopia]          218\n15 23115 [Somali - urban, Ethiopia]         73\n16 23116 [Somali - rural, Ethiopia]        123\n17 23117 [Gambella - urban, Ethiopia]       34\n18 23118 [Gambella - rural, Ethiopia]       23\n19 23119 [Harari - urban, Ethiopia]         29\n20 23120 [Harari - rural, Ethiopia]         26\n21 23121 [BG - rural, Ethiopia]            172\n\nNote that this will drop women from STRATA numbered 23111-23113 and 23115-23121:\n\n\ndat <- dat %>% \n  group_by(STRATA) %>% \n  mutate(STRATA_N = n()) %>% \n  ungroup() %>% \n  filter(STRATA_N > 200)\n\n\n\nDependent variable\nNow, consider the dependent variable UNMETYN, which is a constructed variable indicating whether each respondent currently has an unmet need for family planning. All respondents to the female questionnaire are included in the universe for UNMETYN, so women who are not able to become pregnant or are not sexually active are determined to have “no unmet need.”\nUNMETYN is a recoded binary indicator from UNMETNEED, which contains additional details on types of unmet need.\nWithin the combined sample of female respondents from both years, about 12% of women demonstrated unmet need for family planning:\n\n\ndat %>% summarize(mean_UNMETYN = mean(UNMETYN, na.rm = T)) \n\n\n# A tibble: 1 × 1\n  mean_UNMETYN\n         <dbl>\n1        0.120\n\nWe’ll use the survey package - and its tidy companion srvyr - to specify PMA sample design in our population estimates. The function srvyr::survey_mean uses information about the survey design (given by srvyr::as_survey_design) to estimate that an average woman aged 15-49 in Ethiopia has about a 15% chance of experiencing unmet need for family planning, with a 95% confidence interval ranging between 13.5% and 16.7%:\n\n\n\n\n© Greg Freedman Ellis et al. (GPL 2 | GPL 3)\n\n\ndat %>% \n  as_survey_design(\n    id = EAID,\n    nest = T,\n    weight = FQWEIGHT,\n    strata = STRATA\n  ) %>% \n  summarize(pop_UNMETYN = survey_mean(UNMETYN, vartype = \"ci\", na.rm = T))\n\n\n# A tibble: 1 × 3\n  pop_UNMETYN pop_UNMETYN_low pop_UNMETYN_upp\n        <dbl>           <dbl>           <dbl>\n1       0.151           0.135           0.167\n\nsrvyr brings parts of dplyr syntax to survey analysis, using the survey package.\nKey independent variable\nIn order to conduct a three-way comparison between rural-urban migrants, rural non-migrants, and urban non-migrants, the authors construct a variable we’ll call MIGRANT_DIR.\nThe first component of MIGRANT_DIR evaluates whether each woman ever migrated from her place of birth. Using LIVEINREGION, any woman reporting that she has “always” lived in her current region is not a migrant, and any woman who has lived in her current region for a number of “months or years” is a migrant (note: we cannot determine the migration history for all of the remaining cases, so they will be excluded from further analysis).\n\n\ndat %>% count(LIVEINREGION)\n\n\n# A tibble: 4 × 2\n             LIVEINREGION     n\n                <int+lbl> <int>\n1 10 [Always]             11777\n2 20 [Currently visiting]   124\n3 30 [Months or years]     2539\n4 NA                          7\n\nMigrants who were born in a rural place !BIRTHUR and now live in an urban place URBAN meet the definition for rural-urban migrant. Non-migrants are classified by their current URBAN status only. All other women are implicitly given the value NA and then filtered out of the dataset.\n\nWe implicitly assign NA to any cases that aren’t specified by the logical statements inside case_when().\n\n\ndat <- dat %>% \n   mutate(\n     across(c(BIRTHUR, URBAN), ~.x %>% zap_labels),\n     MIGRANT = case_when(\n       LIVEINREGION == 30 ~ T, \n       LIVEINREGION == 10 ~ F\n     ),\n     MIGRANT_DIR = case_when(\n       MIGRANT & !BIRTHUR & URBAN ~ \"rural to urban\",\n       !MIGRANT & !URBAN ~ \"nonmigrant - rural\",\n       !MIGRANT & URBAN ~ \"nonmigrant - urban\"\n     ) \n   ) %>% \n  filter(!is.na(MIGRANT_DIR))\n\n\n\n\nRemember: BIRTHUR and URBAN are labeled integers. Our use of zap_labels allows R to ignore their assigned labels and, instead, treat them as logicals where 1 == TRUE and 0 == FALSE.\n\n\ndat %>% count(MIGRANT_DIR)\n\n\n# A tibble: 3 × 2\n  MIGRANT_DIR            n\n  <chr>              <int>\n1 nonmigrant - rural  6437\n2 nonmigrant - urban  5340\n3 rural to urban      1421\n\nYou may notice that we’ve created MIGRANT_DIR as a string, or a character object. We’ll coerce it as a factor later so we can easily use each of the three classifications in a logistic regression model.\nCovariates\nThe authors control for a number of covariates in addition to MIGRANT_DIR. The following covariates are recoded versions of existing PMA variables:\nBIRTHS: number of children ever born CHEB (2017), or the woman’s total number of birth events BIRTHEVENT (2018, e.g. birth of twins is a single event)\nPARTNERED: recoded MARSTAT, indicating if the woman is either currently married or living with a partner\nRELGEN: recoded RELIGION as “muslim,” “christian,” or “other”\n\n\ndat <- dat %>% \n  mutate(\n    across(c(BIRTHEVENT, CHEB), ~.x %>% zap_labels),\n    BIRTHS = case_when(\n      YEAR == 2018 ~ BIRTHEVENT, \n      T ~ CHEB\n    ),\n    PARTNERED = case_when(\n      MARSTAT %in% 21:22 ~ T, \n      !is.na(MARSTAT) ~ F\n    ),\n    RELGEN = case_when(\n      RELIGION == 100 ~ \"muslim\",\n      RELIGION >= 200 & RELIGION < 300 ~ \"christian\",\n      T ~ \"other\"\n    )\n  )\n\n\n\nThe remaining covariates are used without further modification:\nAGE: the woman’s age (years)\nWEALTHQ: wealth quintile\nEDUCATTGEN: education level (general)\nHCVISITY: whether the woman visited a health facility in the last 12 months\nSUBNATIONAL: subnational region\nYEAR: survey year (2017 or 2018)\nSub-sample\nAs discussed above, the authors exclude any female respondents from small STRATA (n < 200) and those who are neither rural-urban migrants nor non-migrants. Additionally, they remove rural-urban migrants who moved to Ethiopia from another country. Women can indicate this information in two places: they may either list a foreign country in LASTREGION or indicate “abroad” as their region of birth in BIRTHREGIONET.\n\n\ndat %>% count(LASTREGION)\n\n\n# A tibble: 18 × 2\n                   LASTREGION     n\n                    <int+lbl> <int>\n 1 101 [Tigray]                  50\n 2 102 [Afar]                     7\n 3 103 [Amhara]                 399\n 4 104 [Oromia]                 360\n 5 105 [Ethiopia Somali]          1\n 6 106 [Benishangul Gumuz]        4\n 7 107 [SNNPR]                  390\n 8 108 [Gambella]                 4\n 9 109 [Harari]                   7\n10 110 [Addis Ababa]            116\n11 111 [Dire Dawa]                7\n12 202 [Saudi Arabia]            33\n13 204 [Beirut]                   5\n14 205 [United Arab Emirates]     9\n15 206 [Sudan]                    5\n16 210 [Lebanon]                  1\n17 300 [Other]                   23\n18  NA                        11777\n\ndat %>% count(BIRTHREGIONET)\n\n\n# A tibble: 12 × 2\n                                               BIRTHREGIONET     n\n                                                   <int+lbl> <int>\n 1  1 [Tigray Region]                                         2110\n 2  2 [Afar Region]                                            430\n 3  3 [Amhara Region]                                         2911\n 4  4 [Oromia Region]                                         3472\n 5  5 [Somali Region]                                          166\n 6  6 [Benishangul-Gumuz Region]                               148\n 7  7 [Southern Nations, Nationalities, and Peoples' Region]  3057\n 8  8 [Gambella Region]                                         26\n 9  9 [Harari Region]                                           35\n10 10 [Addis Ababa (city)]                                     814\n11 11 [Dire Dawa (city)]                                        27\n12 12 [Abroad]                                                   2\n\ndat <- dat %>% \n  mutate(\n    EXTERNAL = case_when(\n      LASTREGION %in% 200:900 | BIRTHREGIONET == 12 ~ T,\n      T ~ F\n    )\n  ) %>% \n  filter(!EXTERNAL)\n\n\n\nThe authors also exclude women whose PARTNERED status (i.e. sexual activity) cannot be determined, and women who indicate that they are either “infertile” in FERTPREF or “menopausal / hysterectomy” in TIMEMENSTRUATE. Women who are not at risk of pregnancy for these reasons cannot have unmet need, so they are removed from the sample.\n\n\ndat %>% count(PARTNERED)\n\n\n# A tibble: 3 × 2\n  PARTNERED     n\n  <lgl>     <int>\n1 FALSE      5513\n2 TRUE       7606\n3 NA            2\n\ndat %>% count(FERTPREF)\n\n\n# A tibble: 4 × 2\n                 FERTPREF     n\n                <int+lbl> <int>\n1  1 [Have another child]  8983\n2  2 [No more children]    2702\n3  3 [Infertile]            225\n4 NA                       1211\n\ndat %>% count(TIMEMENSTRUATE)\n\n\n# A tibble: 8 × 2\n                TIMEMENSTRUATE     n\n                     <int+lbl> <int>\n1  1 [Days]                     3113\n2  2 [Weeks]                    4111\n3  3 [Months]                   2955\n4  4 [Years]                    1276\n5  5 [Menopausal/hysterectomy]    85\n6  6 [Before last birth]        1231\n7  7 [Never menstruated]         317\n8 NA                              33\n\ndat <- dat %>% \n  mutate(\n    INFERTILE = case_when(\n      FERTPREF == 3 | TIMEMENSTRUATE == 5 ~ T,\n      T ~ F\n    )\n  ) %>% \n  filter(!is.na(PARTNERED), !INFERTILE)\n\n\n\nLastly, they exclude women with missing values on any of the remaining covariates.\n\n\ndat <- dat %>%\n  filter(\n    !if_any(c(UNMETYN, EDUCATTGEN, HCVISITY, BIRTHS, MCP), is.na),\n  )\n\n\n\nFrom 15,010 female respondents included in the original extract, this sub-sampling procedure leaves us with 12,630 remaing cases.\n\n\ndat %>% summarize(n = n())\n\n\n# A tibble: 1 × 1\n      n\n  <int>\n1 12630\n\nReference groups\nAs a final processing step, we’ll coerce each of our categorical variables (including MIGRANT_DIR) as factors. All but one of these is a labelled integer object where we’ll use the response with the lowest value as a reference group; because we created MIGRANT_DIR as a character object, we’ll specify its reference group manually:\n\n\ndat <- dat %>% \n  mutate(\n    across(\n      c(\n        MIGRANT_DIR, \n        RELGEN, \n        WEALTHQ, \n        EDUCATTGEN, \n        HCVISITY, \n        SUBNATIONAL, \n        PARTNERED,\n        YEAR\n      ), \n      ~as_factor(.) %>% droplevels()\n    ),\n    MIGRANT_DIR = fct_relevel(MIGRANT_DIR, \"nonmigrant - urban\")\n  )\n\n\n\nRegression Model\nFinally, we’re ready to build a regression model for UNMETYN using MIGRANT_DIR and the covariates discussed above!\nRecall that the function srvyr::survey_mean estimated that 15.1% of all women aged 15-49 in Ethiopia experience unmet need for family planning. This estimate used all of the women in our original sample prior to the sub-sampling procedure we just discussed. Now that we’ve created a sub-sample from the original dataset, let’s see how the population estimate has changed:\n\n\ndat %>% \n  as_survey_design(\n    id = EAID,\n    nest = T,\n    weight = FQWEIGHT,\n    strata = STRATA\n  ) %>% \n  summarize(pop_UNMETYN = survey_mean(UNMETYN, vartype = \"ci\", na.rm = T))\n\n\n# A tibble: 1 × 3\n  pop_UNMETYN pop_UNMETYN_low pop_UNMETYN_upp\n        <dbl>           <dbl>           <dbl>\n1       0.157           0.140           0.174\n\nNow that we’ve removed some cases (notably, all women who are infertile), the estimated population mean is close, but somewhat higher at 15.7%.\nGroene & Kristiansen build a multilevel logistic regression model for UNMETYN that breaks down this full-population estimate for each of the sub-groups represented by our independent variables. We’ll report the exponentiated coefficient estimates for each variable, which means that we’ll need to interpret each estimate as a change in the odds that a woman will experience UNMETYN relative to a woman in a reference group.\nWe’ll build the authors’ model m1 using the function survey::svyglm, which - like survey_mean - uses information about the sample design provided by as_survey_design to generate cluster-robust standard error estimates:\n\n\nm1 <- dat %>% \n  as_survey_design(\n    id = EAID,\n    nest = T,\n    weight = FQWEIGHT,\n    strata = STRATA\n  ) %>% \n  svyglm(\n    UNMETYN ~  \n      AGE + \n      MIGRANT_DIR +\n      RELGEN + \n      WEALTHQ +\n      EDUCATTGEN + \n      BIRTHS + \n      HCVISITY + \n      SUBNATIONAL +\n      PARTNERED + \n      YEAR,\n    design = .,\n    family = \"quasibinomial\",\n  ) \n\n\n\nWe tell svyglm to fit a logistic regression model with family = \"quasibinomial\".\nWhy “quasi” binomial? A simple binomial distribution yields the same point estimates and standard errors, but generates a warning because our use of sample weights produces a non-integer count of women with unmet need.\nTo simplify the output a bit, we’ll show a tidy table with just the term, point estimate, the 95% confidence interval, and the p-value (each rounded to two decimal places):\n\n\nm1 %>% \n  tidy(exp = T, conf.int = T) %>% \n  select(term, estimate, conf.low, conf.high, p.value) %>% \n  mutate(across(where(is.numeric), ~round(.x, 2))) \n\n\n# A tibble: 27 × 5\n   term                            estimate conf.low conf.high p.value\n   <chr>                              <dbl>    <dbl>     <dbl>   <dbl>\n 1 (Intercept)                         0.13     0.06      0.27    0   \n 2 AGE                                 0.96     0.94      0.97    0   \n 3 MIGRANT_DIRnonmigrant - rural       1.15     0.84      1.55    0.38\n 4 MIGRANT_DIRrural to urban           0.75     0.59      0.96    0.02\n 5 RELGENother                         0.88     0.58      1.34    0.54\n 6 RELGENchristian                     0.59     0.48      0.72    0   \n 7 WEALTHQLower quintile               0.99     0.79      1.25    0.96\n 8 WEALTHQMiddle quintile              1.06     0.84      1.33    0.63\n 9 WEALTHQHigher quintile              0.82     0.64      1.05    0.11\n10 WEALTHQHighest quintile             0.84     0.56      1.27    0.42\n11 EDUCATTGENPrimary/Middle school     1.05     0.87      1.26    0.59\n12 EDUCATTGENSecondary/post-prima…     0.76     0.55      1.05    0.1 \n13 EDUCATTGENTertiary/post-second…     1        0.68      1.49    0.98\n14 BIRTHS                              1.24     1.18      1.31    0   \n15 HCVISITYYes                         0.85     0.71      1.01    0.06\n16 SUBNATIONALAfar, Ethiopia           0.23     0.12      0.44    0   \n17 SUBNATIONALAmhara, Ethiopia         0.55     0.44      0.69    0   \n18 SUBNATIONALOromiya, Ethiopia        0.91     0.73      1.14    0.41\n19 SUBNATIONALSomali, Ethiopia         0.74     0.33      1.7     0.48\n20 SUBNATIONALBenishangul-Gumuz, …     0.55     0.28      1.08    0.08\n21 SUBNATIONALSNNP, Ethiopia           0.9      0.68      1.2     0.48\n22 SUBNATIONALGambella, Ethiopia       0.86     0.15      4.9     0.86\n23 SUBNATIONALHarari, Ethiopia         2.06     1.69      2.52    0   \n24 SUBNATIONALAddis Ababa, Ethiop…     0.98     0.69      1.4     0.93\n25 SUBNATIONALDire Dawa, Ethiopia      0.77     0.47      1.27    0.3 \n26 PARTNEREDTRUE                       6.69     4.75      9.43    0   \n27 YEAR2018                            0.88     0.74      1.05    0.15\n\nInterpretation\nControlling for all of the covariates we’ve discussed, the authors find that rural-urban internal migrants are less likely than both urban and rural non-migrants to experience unmet need for family planning!\nHow do we identify this finding in the model output? Notice that the estimated odds of experiencing UNMETYN for rural to urban migrants is 0.75, and that the associated 95% confidence interval ranges from 0.59 to 0.95: this represents the migrants’ odds compared to urban non-migrants. If the 95% confidence interval included the value 1.0, we would say that there’s more than a 5% chance that the migrants’ odds could be equal to the odds experienced by urban non-migrants. Because it does not include 1.0, we instead say that there’s a statistically significant difference between the two groups (at the 5% confidence threshold).\nBecause the authors selected urban non-migrants as a reference group, our model output shows the relationship between rural non-migrants and rural-urban migrants a bit less clearly. Although the point estimate for rural to urban migrants (0.75) is lower than the point estimate for nonmigrant - rural (1.15), their respective confidence intervals overlap. In order to see that they actually are statistically different, we’d need to run the model again with a different reference group.\nPredicted Probabilities\n\n\n\nWhile the output from our logistic regression model helps show the relative difference between groups, we’re not yet able to predict the absolute risk of UNMETYN for each group. Recall that, before building our model, we calculated that the average unmet need for all women in Ethiopia (excluding external migrants, infertile women, etc) was about 15.7%. We’ll now estimate the average unmet need experienced by all women in Ethiopia sorted into the three groups represented by MIGRANT_DIR.\nThe predict function allows us to make a prediction about each woman’s likelihood of experiencing unmet need according to the model m1. When we tell predict to return type = \"response\", it gives us the predicted probability that each woman should have UNMETYN.\n\n\ntibble(predicted = predict(m1, type = \"response\"))\n\n\n# A tibble: 12,630 × 1\n   predicted  \n   <svystat>  \n 1 0.072659141\n 2 0.338704987\n 3 0.033291206\n 4 0.376765517\n 5 0.025819303\n 6 0.528723102\n 7 0.009790659\n 8 0.088323159\n 9 0.044348246\n10 0.027093896\n# … with 12,620 more rows\n\nIf we wanted to compare each individual’s predicted probability to the value they actually do have for UNMETYN, we could attach our prediction back to our dataset. Remember that the original UNMETYN variable is binary, whereas the predictions are continuous probabilities that range from 0 to 1. Here, we hope to see that women whose predicted probability exceeds 0.50 have UNMETYN == 1, while those whose predicted probability is less than 0.50 have UNMETYN == 0:\n\n\ntibble(predicted = predict(m1, type = \"response\")) %>% \n  bind_cols(dat) %>% \n  select(predicted, UNMETYN) \n\n\n# A tibble: 12,630 × 2\n   predicted             UNMETYN\n   <svystat>           <int+lbl>\n 1 0.072659141 0 [No unmet need]\n 2 0.338704987 0 [No unmet need]\n 3 0.033291206 0 [No unmet need]\n 4 0.376765517 0 [No unmet need]\n 5 0.025819303 0 [No unmet need]\n 6 0.528723102 1 [Unmet need]   \n 7 0.009790659 0 [No unmet need]\n 8 0.088323159 0 [No unmet need]\n 9 0.044348246 0 [No unmet need]\n10 0.027093896 0 [No unmet need]\n# … with 12,620 more rows\n\nWe can also use predict to calculate predicted probabilities for hypothetical samples. For instance, the authors provide the predicted probabilities for a hypothetical sample of women that is completely identical to the real sample, except that they all share the same value for MIGRANT_DIR (all other variables are kept at their originial values). The mean predicted probability derived from this kind of hypothetical sample is known as a predictive margin.\nWhile the point estimates for each group in MIGRANT_DIR are easy to calculate with predict, the confidence intervals for those estimates are a bit harder to obtain. Here, we’ll use rsample::bootstraps to generate 100 replicates of our sample. This will allow us to rebuild our model 100 times:\n\n\nset.seed(1) # This ensures reproducible bootstrap sampling\n\nboots_dat <- dat %>% \n  rsample::bootstraps(100, EAID) %>% \n  transmute(\n    id = parse_number(id),\n    splits = map(splits, as_tibble),\n    model = map(splits, ~{\n      .x %>% \n        as_survey_design(\n          id = EAID,\n          nest = T,\n          weight = FQWEIGHT,\n          strata = STRATA\n        ) %>% \n        svyglm(\n          UNMETYN ~  \n            AGE + \n            MIGRANT_DIR +\n            RELGEN + \n            WEALTHQ +\n            EDUCATTGEN + \n            BIRTHS + \n            HCVISITY + \n            SUBNATIONAL +\n            PARTNERED + \n            YEAR,\n          design = .,\n          family = \"quasibinomial\",\n        ) \n    })\n  )\n\nboots_dat\n\n\n# A tibble: 100 × 3\n      id splits                 model   \n   <dbl> <list>                 <list>  \n 1     1 <tibble [12,630 × 38]> <svyglm>\n 2     2 <tibble [12,630 × 38]> <svyglm>\n 3     3 <tibble [12,630 × 38]> <svyglm>\n 4     4 <tibble [12,630 × 38]> <svyglm>\n 5     5 <tibble [12,630 × 38]> <svyglm>\n 6     6 <tibble [12,630 × 38]> <svyglm>\n 7     7 <tibble [12,630 × 38]> <svyglm>\n 8     8 <tibble [12,630 × 38]> <svyglm>\n 9     9 <tibble [12,630 × 38]> <svyglm>\n10    10 <tibble [12,630 × 38]> <svyglm>\n# … with 90 more rows\n\n\n\n\n\n© 2018 RStudio (CC0 1.0)\nrsample is included with library(tidymodels).\nNotice that each row of boots_dat contains a completely resampled version of dat contained in each row of the column splits. The column model contains the output from a model that’s uniquely fitted to the resampled data in splits.\nNext, we’ll use predict separately for each row in boots_dat. Because we generate three new rows each time - one prediction for each group in MIGRANT_DIR - the resulting data frame has 300 rows.\n\n\nboots_dat <- boots_dat %>% \n  rowwise() %>%\n  mutate(nested_predictions = list(map_df(levels(dat$MIGRANT_DIR), ~{\n    predict(\n      model, \n      type = \"response\", \n      newdata = splits %>% mutate(MIGRANT_DIR = .x)) %>% \n      tibble() %>% \n      bind_cols(splits) %>% \n      as_survey_design(\n        id = EAID,\n        nest = T,\n        weight = FQWEIGHT,\n        strata = STRATA\n      ) %>% \n      summarise(predicted = survey_mean(., vartype = \"ci\")) %>% \n      mutate(MIGRANT_DIR = .x) %>% \n      select(MIGRANT_DIR, predicted) \n  }))) %>% \n  unnest(nested_predictions) \n\nboots_dat\n\n\n# A tibble: 300 × 5\n      id splits                 model    MIGRANT_DIR        predicted\n   <dbl> <list>                 <list>   <chr>                  <dbl>\n 1     1 <tibble [12,630 × 38]> <svyglm> nonmigrant - urban    0.151 \n 2     1 <tibble [12,630 × 38]> <svyglm> nonmigrant - rural    0.163 \n 3     1 <tibble [12,630 × 38]> <svyglm> rural to urban        0.112 \n 4     2 <tibble [12,630 × 38]> <svyglm> nonmigrant - urban    0.149 \n 5     2 <tibble [12,630 × 38]> <svyglm> nonmigrant - rural    0.155 \n 6     2 <tibble [12,630 × 38]> <svyglm> rural to urban        0.0840\n 7     3 <tibble [12,630 × 38]> <svyglm> nonmigrant - urban    0.142 \n 8     3 <tibble [12,630 × 38]> <svyglm> nonmigrant - rural    0.155 \n 9     3 <tibble [12,630 × 38]> <svyglm> rural to urban        0.133 \n10     4 <tibble [12,630 × 38]> <svyglm> nonmigrant - urban    0.133 \n# … with 290 more rows\n\nFinally, we’ll calculate:\nthe predicted probability for each group from the mean of 100 bootstrap predictions\nthe standard error of each group’s predicted probability from the standard deviation of 100 bootstrap predictions\nthe 95% confidence interval from the product of each group’s standard error and qnrom(0.975)\n\n\ngroup_predictions <- boots_dat %>% \n  group_by(MIGRANT_DIR) %>% \n  summarise(\n    mean = mean(predicted),\n    se = sd(predicted),\n    lower = mean - se*qnorm(0.975),\n    upper = mean + se*qnorm(0.975)\n  )\n\ngroup_predictions\n\n\n# A tibble: 3 × 5\n  MIGRANT_DIR         mean      se  lower upper\n  <chr>              <dbl>   <dbl>  <dbl> <dbl>\n1 nonmigrant - rural 0.161 0.00568 0.149  0.172\n2 nonmigrant - urban 0.143 0.0125  0.119  0.168\n3 rural to urban     0.117 0.0171  0.0831 0.150\n\nAnd here are those intervals plotted with geom_errorbarh and geom_point:\n\n\nggplot(group_predictions) +\n  geom_errorbarh(\n    color = \"#A2269C\", \n    aes(height = .2, xmin = lower, xmax = upper, y = MIGRANT_DIR)\n  ) + \n  geom_point(\n    color = \"#A2269C\", \n    aes(x = mean, y = MIGRANT_DIR)\n  ) +\n  geom_text(\n    nudge_y = 0.2,\n    aes(label = round(mean, 3), x = mean, y = MIGRANT_DIR)\n  ) + \n  scale_x_continuous(breaks = seq(.08, .18, by = .02)) +\n  theme_minimal() + \n  labs(\n    subtitle = \"95% Confidence Interval\",\n    title = \"Predicted Probability of Unmet Need for Family Planning\",\n    y = \"\",\n    x = \"\"\n  ) + \n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14),\n    plot.subtitle = element_text(hjust = 0.5, size = 10)\n  ) \n\n\n\n\nAs you can see, the confidence intervals for each group in MIGRANT_DIR overlap quite a bit. However, the probability that a rural-urban internal migrant will experience unmet need for family planning seems to be generally lower than the other groups: we show a point-estimate of just 11.7% for migrants compared to 14.3% and 16.1% respectively for urban and rural non-migrants.\nTo learn more about the conceptual reasons why rural-urban internal migrants in Ethiopia might experience less unmet need for family planning compared to non-migrants, be sure to checkout out Groene & Kristiansen’s full article published at Populations, Space and Place! And, for more information about migration data available in other PMA samples, stay tuned for upcoming posts in this series.\n\n\n\nAbebe, Tatek. 2007. “Changing Livelihoods, Changing Childhoods: Patterns of Children’s Work in Rural Southern Ethiopia.” Children’s Geographies 5 (1-2): 77–93. https://doi.org/10.1080/14733280601108205.\n\n\nAnglewicz, Philip, Jamaica Corker, and Patrick Kayembe. 2017. “The Fertility of Internal Migrants to Kinshasa.” Genus 73 (1): 4. http://dx.doi.org/10.1186/s41118-017-0020-8.\n\n\nCourgeau, D. 1989. “Family Formation and Urbanization.” Population. English Selection 44 (1): 123–46. https://www.ncbi.nlm.nih.gov/pubmed/12157901.\n\n\nGroene, Emily A, and Devon Kristiansen. 2021. “Unmet Need for Family Planning After Internal Migration: Analysis of Ethiopia 2017–2018 PMA Survey Data.” Population, Space and Place 27 (1). https://onlinelibrary.wiley.com/doi/10.1002/psp.2376.\n\n\nKohler, Hans-Peter. 2000. “Social Interactions and Fluctuations in Birth Rates.” Population Studies 54 (2): 223–37. https://doi.org/10.1080/713779084.\n\n\nKulu, Hill. 2005. “Migration and Fertility: Competing Hypotheses Re-Examined.” European Journal of Population/Revue Européenne de Démographie 21 (1): 51–87. https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/content/pdf/10.1007/s10680-005-3581-8.pdf&casa_token=ofnVP7_3oy4AAAAA:nOmsfJTITgKjtiNcXj6u9GsVD9yHCkWsqmAtwTs6aG3vrQaL9DlhaOwcxFQMYweYNSt1mAtGNNonsZ-9.\n\n\nMcAuliffe, Marie, and Martin Ruhs. 2017. “World Migration Report 2018.” International Office of Migration, Geneva. https://publications.iom.int/fr/system/files/pdf/wmr_2018_en_chapter7.pdf.\n\n\nSchultz, T Paul. 1994. “Human Capital, Family Planning, and Their Effects on Population Growth.” The American Economic Review 84 (2): 255–60. http://www.jstor.org/stable/2117839.\n\n\nSevoyan, Arusyak, and Victor Agadjanian. 2013. “Contraception and Abortion in a Low-Fertility Setting: The Role of Seasonal Migration.” International Perspectives on Sexual and Reproductive Health 39 (3): 124–32. http://dx.doi.org/10.1363/3912413.\n\n\nSkiles, Martha Priedeman, Marc Cunningham, Andrew Inglis, Becky Wilkes, Ben Hatch, Ariella Bock, and Janine Barden-O’Fallon. 2015. “The Effect of Access to Contraceptive Services on Injectable Use and Demand for Family Planning in Malawi.” International Perspectives on Sexual and Reproductive Health 41 (1): 20–30. http://dx.doi.org/10.1363/4102015.\n\n\n\n\n",
    "preview": "posts/2021-04-01-et-internal-migration/images/pred_prob_h4.png",
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {},
    "preview_width": 2683,
    "preview_height": 1200
  },
  {
    "path": "posts/2021-02-09-march-2021-data-release/",
    "title": "New SDP Data Available Spring 2021",
    "description": "Get details on new variables related to labor & delivery services, antenatal care, vaccinations, facility shipment schedules, and more!",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-03-15",
    "categories": [
      "New Data",
      "Data Discovery"
    ],
    "contents": "\n\nContents\nLabor and Delivery\nAntenatal Care\nVaccinations\nFacility Stockouts & Expected Shipments\nNational Health Programs\n\n\n\n\nWe’re excited to announce the release of several new Service Delivery Point samples this month over at pma.ipums.org! As always, you’ll find the new data harmonized with older samples wherever the new surveys repeat questions you’ve seen before. The new samples also contain a big batch of new variables derived from questions that were posed for the very first time in PMA surveys, so we’d like to introduce a few of the highlights here.\n\n\n\nThe new samples included in this release represent data collected from:\nBurkina Faso 2020\nCongo (DR) 2019\nEthiopia 2019\nKenya 2019\nNigeria 2019\nUganda 2019\nLabor and Delivery\nWe’ve added a variable group in the Other Health Services topic offering more than 60 new variables related to Labor and Delivery. Many of these are currently available only for the Ethiopia 2019 sample, which piloted the new questions.\nFor example, you’ll find new variables about delivery personnel, including those showing whether a facility has a skilled birth attendant or a provider able to perform C-section delivery available 24 hours per day. Other variables describe the infrastructure available for labor and delivery, including the number of delivery rooms and beds, labor rooms, maternity waiting rooms, and newborn resuscitation tables. You’ll also find a number of variables describing the environment inside of a facility’s delivery rooms, including whether they are private, heated, and whether they have several specific delivery guidelines and protocols posted in the room.\nSeveral labor and delivery statistics are also provided for the month preceding the interview. These include the total number of facility deliveries, cesarian deliveries, stillbirths (both fresh and macerated), and neonatal deaths (reported separately for those occurring within 24 hours and one week). Other variables report whether certain services were provided any time within 3 months preceding the interview, including:\ninstrument / assisted delivery\ncaesarean section\nparenteral antibiotics for infections\nparenteral anticonvulsants for high blood pressure (Diazepam, Magnesium Sulfate, or other) or hypertension (Hydralazine, Nifedipine, Methyldopa, or other)\nparenteal / oral uterotonics for hemorrhage (Ergometrine, Misoprostol tablets, Oxytocin, or other)\ncortisteroids for fetal lung maturation\nmanual placenta removal\npartographs to monitor labor\nnewborn resuscitation\nblood transfusion\npostpartum implant insertion\npostpartum IUD insertion\npostpartum tubal ligation\nLastly, a number of variables indicate whether a particular service is typically provided at a facility. These include,\nneonatal intensive care, and whether it was available on the day of the interview\nreferrals for outgoing newborns and pregnant, laboring, and postpartum women; policies on referrals made from other facilities\nbreastfeeding assistance, newborn skin contact, and family planning discussions with new mothers prior to discharge\nAntenatal Care\nAs with Labor and Delivery, a new Antenatal Care group contains a number of variables that are currently available only for the Ethiopia 2019 sample, such as:\nwhether antenatal care was available on the day of the interview\nwhether trained staff are available to use ultrasound, and whether they were available on the day of the interview\nthe total number of rooms for antenatal care, and whether they are private\nwhether a number of different procedures are typically provided as a routine part of antenatal care (for example: blood pressure, weight, HIV testing, and several blood / urine tests)\nBeyond Ethiopia 2019, several of the other new samples included questions related to topics that are normally discussed with patients during an antenatal visit:\nimmediate and exclusive breastfeeding\nreturn to fertility after pregnancy\nhealthy timing and spacing of pregnancies\nfamily planning methods available to use while breastfeeding\nuse of the lactational amenorrhea method (LAM) for family planning, and plans for a transition to other methods\ninterest in a postpartum IUD or other long-acting family planning methods\nIn earlier survey rounds, PMA questionnaires included questions on whether these topics were discussed with a new mother after birth. The new samples differentiate between whether these topics were covered before the mother left the facility after delivery (e.g DISPPSPACE) or at a postnatal care visit later on (e.g. DISPNCSPACE).\nVaccinations\nThe Ethiopia 2019 sample also includes some of the first PMA variables related to vaccination. You’ll find indicators for whether a facility typically provides immunization services, whether those services were provided on the day of the interview, and whether a woman visiting the facility for her child’s immunization would be offered family planning services or counseling during the visit.\nThe availability of the following vaccines are also provided:\nBCG\nIPV and oral polio\nMeasles\nPCV\nPentavalent\nRota\nTetanus toxoid\nVitamin A\n\nEach of these may be “observed” by the interviewer, or else “reported” without observation.\nFacility Stockouts & Expected Shipments\nPMA has included variables related to contraceptive stockouts for many samples dating back to 2014. Four of the new samples dig deeper into the reasons why facilities experience stockouts, and also report the expected delivery time for methods that were out of stock on the day of the interview.\nFor each of the following methods, the expected delivery time is reported by two variables: a numeric value and a unit (e.g. days, weeks, months) that defines the value.\ndiaphragms\nDepo Provera\nemergency contraception\nfemale condoms\nfoam / jelly\nimplants\nIUDs\nmale condoms\npills\nSayana Press\nStandard Days/Cycle Beads\n\n\n\nIt’s recommended that users construct their own derived variables for expected delivery times using whichever unit of time they prefer. For example, notice that the values for expected delivery of Depo Provera DEPOVAL are reported either in weeks or months in DEPOUNIT:\n\n\ndat %>% count(DEPOVAL, DEPOUNIT)\n\n\n# A tibble: 18 x 3\n                      DEPOVAL                    DEPOUNIT     n\n                    <int+lbl>                   <int+lbl> <int>\n 1  0                          1 [Weeks]                      3\n 2  1                          1 [Weeks]                     55\n 3  1                          2 [Months]                    29\n 4  2                          1 [Weeks]                     16\n 5  2                          2 [Months]                     9\n 6  3                          1 [Weeks]                      8\n 7  3                          2 [Months]                     9\n 8  4                          1 [Weeks]                      2\n 9  4                          2 [Months]                     1\n10  6                          2 [Months]                     1\n11  7                          1 [Weeks]                      1\n12 12                          2 [Months]                     1\n13 14                          1 [Weeks]                      1\n14 30                          2 [Months]                     5\n15 60                          2 [Months]                     1\n16 99 [NIU (not in universe)] 97 [Don't know]                92\n17 99 [NIU (not in universe)] 98 [No response or missing]     1\n18 99 [NIU (not in universe)] 99 [NIU (not in universe)]   1492\n\nSuppose you wanted to create a derived variable called DEPO_WKS that simply reports the expected delivery time of Depo Provera in weeks. For any value that’s currently reported in months (DEPOUNIT == 2), you might decide to multiply the value in DEPOVAL by 4. Don’t forget to handle non-response values (e.g. 97, 98, 99) separately!\n\n\ndat %>% \n  mutate(DEPO_WKS = case_when(\n      DEPOUNIT == 2 ~ DEPOVAL * 4, \n      DEPOUNIT > 90 ~ NA_real_, \n      T ~ as.double(DEPOVAL) \n    )) %>% \n  count(DEPO_WKS)\n\n\n# A tibble: 15 x 2\n   DEPO_WKS     n\n      <dbl> <int>\n 1        0     3\n 2        1    55\n 3        2    16\n 4        3     8\n 5        4    31\n 6        7     1\n 7        8     9\n 8       12     9\n 9       14     1\n10       16     1\n11       24     1\n12       48     1\n13      120     5\n14      240     1\n15       NA  1585\n\nDEPOVAL is an integer, but R coerces it into a double when you apply multiplication (what if multiplication creates non-integer values?). This is why we tell R to use the double class NA_real_ if DEPOUNIT > 90, and then to use as.double(DEPOVAL) if neither DEPOUNIT == 2 nor DEPOUNIT > 90. All of the values created by case_when have to be in the same class!\nFor facilities that were currently out of stock of a method that they normally provide, these new samples include variables explaining why the method was out of stock. With Depo Provera, for example, we can now see that a majority of stockouts across samples are caused by shipments that were ordered, but did not arrive:\n\n\ndat %>% count(OUTWHYDEPO)\n\n\n# A tibble: 8 x 2\n                                         OUTWHYDEPO     n\n                                          <int+lbl> <int>\n1  1 [Did not place order for shipment]                23\n2  2 [Ordered but did not receive shipment]           154\n3  3 [Did not order right quantities]                   8\n4  4 [Ordered but did not receive right quantities]    17\n5  5 [Unexpected increase in consumption]               5\n6  9 [Other]                                           27\n7 97 [Don't know]                                       1\n8 99 [NIU (not in universe)]                         1492\n\nNational Health Programs\nLastly, we’ve created a new variable group related to participation in national health programs. While we may see more data in upcoming samples, these variables currently describe facility participation in programs provided by the National Hospital Insurance Fund (NHIF) for Kenya. Specifically, you’ll find an indicator for whether a facility in the Kenya 2019 sample provides family planning methods / services covered by NHIF and, if so, whether it provides each of these:\nEdu Afya\nLinda Mama (number of enrolled adolescents and adult women)\nStandard Program\nSuper Program\nother program\n\n\n\n",
    "preview": "posts/2021-02-09-march-2021-data-release/../../images/new_data.png",
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {},
    "preview_width": 2555,
    "preview_height": 1437
  },
  {
    "path": "posts/2021-02-19-analyzing-the-individual-in-context/",
    "title": "Putting It All Together: Analyzing the Individual in Context",
    "description": "Analyzing women's contraceptive use while considering service delivery point and spatial contextual factors.",
    "author": [
      {
        "name": "Nina Brooks",
        "url": "http://www.ninarbrooks.com/"
      }
    ],
    "date": "2021-03-02",
    "categories": [
      "Individuals in Context",
      "Service Delivery Points",
      "Data Analysis",
      "survey",
      "dotwhisker"
    ],
    "contents": "\n\nContents\nSetup: Load Packages and Data\nRecoding covariates\nRegression Models\nIndividual factors: model with glm\nIndividual factors: model with svyglm\nAvailabillity: modeling with SDP variables\nAccessibility: modeling with external spatial variables\n\n\n\n\n\nThroughout our series on Individuals in Context, we’ve been looking at PMA Service Delivery Point (SDP) data as a resource for understanding the health services environment experienced by women surveyed in PMA Household and Female samples. We created summary variables that capture the SDPs that provide services within the same enumeration areas PMA uses to construct samples of individuals. We’ve also shown how to complement SDP data with additional information about women’s lived environment collected from external geospatial data sources.\nIn this final post, we’ll bring everything together and demonstrate the kind of analysis you might want to do with the contextual data we’ve collected in this series. Specifically, we’ll analyze women’s current contraceptive use, FPCURRUSE, taking into account:\nFPCURRUSE indicates whether a woman is currently using any method of family planning, or doing something to delay or avoid pregnancy.\nindividual factors about each woman collected in the Household and Female survey\navailability factors related to the supply of family planning services provided by SDPs in each woman’s enumeration area\naccessibility factors in each woman’s enumeration area - including measures of population density and transportation infrastructure - that we collected from external data sources\nThe availability of both detailed individual data on family planning and supply-side (service delivery) factors is one of the unique advantages of the PMA data.\nSetup: Load Packages and Data\nWe’ll load the packages tidyverse and ipumsr, as usual. Additionally, we’ll load tidymodels, which helps apply tidyverse principles to the models we’ll be building, and a few other packages we’ll discuss below.\n\n\nlibrary(tidyverse)\nlibrary(ipumsr)\nlibrary(tidymodels)\nlibrary(survey)\nlibrary(dotwhisker)\n\n\n\nWe’ll be using both of the Burkina Faso datasets we created in earlier posts in this series:\nbf_merged contains a handful of variables from each sampled woman merged with summary variables about the SDPs that serve her enumeration area (created in this post).\nint contains population and road density variables for each enumeration area (created in this post).\n\nRemember, to use the GPS data you must request access directly from our partners at pmadata.org. The version of int we’re using in this post is based on the real GPS locations but the GPS data itself is not included.\nAs a reminder, let’s take a glimpse at the variables we’ve currently got in each:\n\n\n\n\n\nglimpse(bf_merged)\n\n\nRows: 6,944\nColumns: 10\n$ EAID                <dbl+lbl> 7003, 7003, 7003, 7003, 7003, 7003, …\n$ SAMPLE              <int+lbl> 85405, 85405, 85405, 85405, 85405, 8…\n$ N_SDP               <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3…\n$ NUM_METHODS_PROV    <int> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, …\n$ NUM_METHODS_INSTOCK <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8…\n$ NUM_METHODS_OUT3MO  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ MEAN_OUTDAY         <dbl> NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, …\n$ PERSONID            <chr> \"0700300000019732017504\", \"0700300000019…\n$ URBAN               <int+lbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ FPCURRUSE           <int+lbl> 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, …\n\nThe variables N_SDP, NUM_METHODS_PROV, NUM_METHODS_INSTOCK, NUM_METHODS_OUT3MO, MEAN_OUTDAY, and URBAN all describe the the enumeration area (EAID) where a woman identified by PERSONID resides. The only other variable from the Household and Female questionnaire, itself, is FPCURRUSE. We’ll add more variables describing each woman in a moment.\n\n\n\n\n\nglimpse(int)\n\n\nRows: 83\nColumns: 7\n$ EAID        <dbl> 7003, 7006, 7009, 7016, 7026, 7042, 7048, 7056, …\n$ ROAD_LENGTH <dbl> 30.29857, 28.87695, 24.08644, 41.92500, 67.67416…\n$ PMACC       <chr> \"BF\", \"BF\", \"BF\", \"BF\", \"BF\", \"BF\", \"BF\", \"BF\", …\n$ PMAYEAR     <dbl> 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, …\n$ REGION      <chr> \"5. centre-nord\", \"5. centre-nord\", \"8. est\", \"1…\n$ DATUM       <chr> \"WGS84\", \"WGS84\", \"WGS84\", \"WGS84\", \"WGS84\", \"WG…\n$ POP_DENSITY <dbl> 74.04364, 51.75554, 15.66303, 91.25882, 416.2320…\n\nWe’ll be using ROAD_LENGTH and POP_DENSITY, but first we’ll need to merge int to bf_merged by matching up the EAID for each woman:\n\n\nbf_merged <- left_join(bf_merged, int, by = \"EAID\")\n\n\n\nLet’s now introduce some new variables obtained from each woman’s responses to the Household and Female questionnaire. We’ll merge a new data extract with the following variables collected from the Burkina Faso 2017 and 2018 surveys (female respondents only):\nAGE - Age (in years)\nMARSTAT - Marital status\nEDUCATTGEN - Highest level of school attended, general (4 categories)\nWEALTHQ - Wealth score quintile\nBIRTHEVENT - Number of birth events\n\nFor a refresher on accessing and importing PMA data in R, check out our post Import IPUMS PMA Data Into R.\nFollowing the practice we used when we made bf_merged, we’ll simply handle all of the different non-response codes in this new extract by recoding them as NA. Then, we’ll merge the extract to bf_merged by matching up each person by PERSONID:\n\n\nbf_merged <- ipumsr::read_ipums_micro(\n  ddi = \"data/pma_00018.xml\",\n  data_file = \"data/pma_00018.dat.gz\") %>% \n  select(PERSONID, AGE, MARSTAT, EDUCATTGEN, WEALTHQ, BIRTHEVENT, STRATA) %>% \n  mutate(across(everything(), ~lbl_na_if(\n    .x,\n    ~.lbl %in% c(\n      \"Not interviewed (female questionnaire)\",\n      \"Not interviewed (household questionnaire)\",\n      \"Don't know\",\n      \"No response or missing\",\n      \"NIU (not in universe)\"\n    )\n  ))) %>% \n  right_join(bf_merged, by = \"PERSONID\")\n\n\n\nRecoding covariates\nAll five of the new variables we’ve introduced are loaded into R as members of both the integer and the haven_labelled class of objects. But really, only AGE and BIRTHEVENT should be treated like continuous measures in our analysis. For MARSTAT, EDUCATTGEN, and WEALTHQ, the integer values associated with each response are arbitrary; we’re much more interested in the labels associated with these numeric values because each of these three variables reflects a categorical measurement.\n\n\nbf_merged %>% \n  select(MARSTAT, EDUCATTGEN, WEALTHQ) %>% \n  map(class)\n\n\n$MARSTAT\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"integer\"       \n\n$EDUCATTGEN\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"integer\"       \n\n$WEALTHQ\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"integer\"       \n\nAs you might know, the normal way to handle categorical variables in a regression model is to create a binary dummy variable associated with each response, and R normally performs this task automatically when it encounters a variable that’s a member of the factor class.\nIf we want, we can simply coerce these variables as factors. When we do this and then use the factor in a regression model, R will select the lowest numbered response as a “reference group” and create binary dummy variables for the other responses. This makes sense with WEALTHQ, where we’d interpret the coefficient for each wealth quintile as an effect relative to being in the lowest quintile.\n\n\nbf_merged %>% count(WEALTHQ)\n\n\n# A tibble: 6 × 2\n                WEALTHQ     n\n              <int+lbl> <int>\n1  1 [Lowest quintile]   1200\n2  2 [Lower quintile]    1031\n3  3 [Middle quintile]    984\n4  4 [Higher quintile]   1253\n5  5 [Highest quintile]  2474\n6 NA                        2\n\nbf_merged <- bf_merged %>% \n  mutate(WEALTHQ = as_factor(WEALTHQ)) \n\nbf_merged %>% count(WEALTHQ)\n\n\n# A tibble: 6 × 2\n  WEALTHQ              n\n  <fct>            <int>\n1 Lowest quintile   1200\n2 Lower quintile    1031\n3 Middle quintile    984\n4 Higher quintile   1253\n5 Highest quintile  2474\n6 <NA>                 2\n\nAlternatively, we might decide to make our own binary dummy variables. This makes sense when we might want to collapse several responses into one larger category, as with MARSTAT: here, for the purpose of analyzing FPCURRUSE, we probably only care about whether the woman is partnered (the reasons why she might not be partnered are less meaningful).\n\n\nbf_merged %>% count(MARSTAT)\n\n\n# A tibble: 5 × 2\n                             MARSTAT     n\n                           <int+lbl> <int>\n1 10 [Never married]                  1876\n2 21 [Currently married]              4307\n3 22 [Currently living with partner]   410\n4 31 [Divorced or separated]           163\n5 32 [Widow or widower]                188\n\nbf_merged <- bf_merged %>%\n  mutate(MARSTAT = lbl_relabel(\n      MARSTAT,\n      lbl(1, \"partnered\") ~ .val %in% 21:22,\n      lbl(0, \"unpartnered\") ~ .val %in% c(10, 31, 32)\n  )) \n\nbf_merged %>% count(MARSTAT)\n\n\n# A tibble: 2 × 2\n          MARSTAT     n\n        <dbl+lbl> <int>\n1 0 [unpartnered]  2227\n2 1 [partnered]    4717\n\nAnother reason to consider recoding categorical variables: what if one response option dominates a huge proportion of the responses in your data? Is it worth sacrificing additional degrees of freedom to accommodate dummy variables that could otherwise be merged together? This is the case with EDUCATTGEN, where over half of the responses are “never attended.” We’ll create a single, simplified binary variable where the responses are “some schooling” or “no schooling.”\n\n\nbf_merged %>% count(EDUCATTGEN)\n\n\n# A tibble: 5 × 2\n                    EDUCATTGEN     n\n                     <int+lbl> <int>\n1  1 [Never attended]           3605\n2  2 [Primary/Middle school]    1212\n3  3 [Secondary/post-primary]   1893\n4  4 [Tertiary/post-secondary]   231\n5 NA                               3\n\nbf_merged <- bf_merged %>% \n  mutate(EDUCATTGEN = lbl_relabel(\n      EDUCATTGEN,\n      lbl(1, \"some schooling\") ~ .val %in% 2:4,\n      lbl(0, \"no school\") ~ .val == 1\n  )) \n\nbf_merged %>% count(EDUCATTGEN)\n\n\n# A tibble: 3 × 2\n           EDUCATTGEN     n\n            <dbl+lbl> <int>\n1  0 [no school]       3605\n2  1 [some schooling]  3336\n3 NA                      3\n\nThe last thing we’ll do here is coerce SAMPLE as a factor so that we can control for arbitrary differences caused by selection into the two samples (recall that our dataset contains two samples from Burkina Faso 2017 and 2018). Because the women in each SAMPLE were surveyed in two different years, this essentially operates like a survey-year fixed effect.\n\n\nbf_merged <- bf_merged %>% \n  mutate(SAMPLE = as.factor(SAMPLE)) \n\nbf_merged %>% count(SAMPLE)\n\n\n# A tibble: 2 × 2\n  SAMPLE     n\n  <fct>  <int>\n1 85405   3556\n2 85408   3388\n\nRegression Models\nWe’re now ready to examine the relative effects individual factors on FPCURRUSE compared to the availability and accessibility of family planning services in each woman’s enumeration area. Let’s begin with a simple model containing the factors we added to the dataset above.\nIndividual factors: model with glm\nMost R users probably use the generalized linear model function glm for this purpose. To keep our demonstration as simple as possible, we’ll fit a model using the Ordinary Least-Squares (OLS) method that glm adopts by default. We’ll use the tidymodels function broom::tidy to clean up the output for our model’s coefficient estimates.\n\nRecall that FPCURRUSE is a binary response (“yes” or “no”), so you might consider fitting a logit model by adding the argument family = 'binomial' to glm().\n\n\nm1 <- glm(\n  FPCURRUSE ~\n    AGE + \n    MARSTAT + \n    EDUCATTGEN + \n    BIRTHEVENT  + \n    WEALTHQ + \n    SAMPLE,\n  data = bf_merged\n)\n\ntidy(m1)\n\n\n# A tibble: 10 × 5\n   term                    estimate std.error statistic  p.value\n   <chr>                      <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)              0.0421   0.0260       1.62  1.06e- 1\n 2 AGE                     -0.00280  0.000948    -2.95  3.17e- 3\n 3 MARSTAT                  0.201    0.0145      13.9   5.21e-43\n 4 EDUCATTGEN               0.159    0.0143      11.2   9.42e-29\n 5 BIRTHEVENT               0.0289   0.00390      7.40  1.48e-13\n 6 WEALTHQLower quintile    0.0319   0.0204       1.56  1.18e- 1\n 7 WEALTHQMiddle quintile   0.0222   0.0208       1.07  2.85e- 1\n 8 WEALTHQHigher quintile   0.0884   0.0198       4.46  8.25e- 6\n 9 WEALTHQHighest quintile  0.166    0.0191       8.67  5.24e-18\n10 SAMPLE85408              0.00515  0.0114       0.453 6.51e- 1\n\nBecause the outcome (FPCURRUSE) is binary, this linear regression is a linear probability model and the coefficients on each term should be interpreted as a percentage point change in the probability of current family planning use.\nFor each of the binary dummy variables we created, the coefficient estimate shows how much the probability FPCURRUSE == \"yes\" increases if the value of the dummy variable is 1. For example, in MARSTAT the value 1 represents “partnered” women, while the value 0 represented “unpartnered” women. The coefficient on MARSTAT is 0.201, meaning our model predicts that being partnered is associated with an increase in the expected probability of family planning use by 0.201.\nIs this a meaningful difference? Consider that the mean of FPCURRUSE is 0.34: this is the probability you might use to guess a woman’s likelihood for using family planning if we didn’t have access to any other variables. Relative to that, an increase of 0.201 is pretty substantive.\nWhat about the other coefficients? We also see a large increase in the probability of family planning use for women who have “some schooling,” and a smaller increase for those who have more children.\nNotice what happened with WEALTHQ, the variable we coerced as a factor above. As expected, R created a binary dummy variable from each response option except the reference group, which is the “lowest quintile.” It’s important to remember that each of these dummy variables represents the effect a being in a particular quintile relative to the “lowest quintile.” These results show that family planning use increases with wealth, which is expected (although the effects don’t become large or statistically significant until we get to the “high” and “highest” income quintiles).\nIndividual factors: model with svyglm\nThere is one problem with the model we created above: as we’ve discussed, PMA samples households randomly within the same enumeration area, and it’s likely that households located together will share many common features. This violates one of the basic assumptions of OLS regression, where we expect modeling errors to be uncorrelated (Cameron and Miller 2015). To address this, we’ll need to use a model that allows us to specify the complexities of PMA survey design. A common approach uses the survey package developed by Thomas Lumley.1\n\nWe’ll use the package svyglm to specify PMA survey design whenever we create analytic models on the PMA Data Analysis Hub!\nLumley’s modeling function survey::svyglm is similar to glm, except that it takes a special design argument where glm takes a data argument. We use the function survey::svydesign to specify the data, the cluster ids from EAID, and the sampling strata STRATA (if we were using the sample weights from FQWEIGHT, we could do that here, too):\n\n\nm2 <- svyglm(\n  FPCURRUSE ~\n    AGE + \n    MARSTAT + \n    EDUCATTGEN + \n    BIRTHEVENT  + \n    WEALTHQ + \n    SAMPLE,\n  design = svydesign(\n    ids = ~EAID,\n    strata = ~STRATA,\n    data = bf_merged\n  )\n)\n\ntidy(m2)\n\n\n# A tibble: 10 × 5\n   term                    estimate std.error statistic  p.value\n   <chr>                      <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)              0.0421    0.0366      1.15  2.54e- 1\n 2 AGE                     -0.00280   0.00114    -2.45  1.65e- 2\n 3 MARSTAT                  0.201     0.0157     12.8   3.19e-20\n 4 EDUCATTGEN               0.159     0.0167      9.53  2.13e-14\n 5 BIRTHEVENT               0.0289    0.00405     7.13  6.41e-10\n 6 WEALTHQLower quintile    0.0319    0.0244      1.31  1.95e- 1\n 7 WEALTHQMiddle quintile   0.0222    0.0282      0.788 4.33e- 1\n 8 WEALTHQHigher quintile   0.0884    0.0302      2.92  4.62e- 3\n 9 WEALTHQHighest quintile  0.166     0.0283      5.86  1.30e- 7\n10 SAMPLE85408              0.00515   0.0145      0.356 7.23e- 1\n\nTo see how this impacts our model estimates, let’s visualize the confidence interval for each coefficient with dotwhisker::dwplot. We’ll use the same function a few times here, and we’ll want to repeat the same visual elements each time, so we’ll just wrap everything together in a custom function we’re calling pma_dwplot():\n\n\npma_dwplot <- function(...){\n  dwplot(\n    bind_rows(...),\n    dodge_size = 0.8,\n    vline = geom_vline(xintercept = 0, colour = \"grey60\", linetype = 2)) +\n    scale_color_viridis_d(option = \"plasma\", end = .7) +\n    theme_minimal()\n}\n\npma_dwplot(\n  tidy(m1) %>% mutate(model = \"glm\"),\n  tidy(m2) %>% mutate(model = \"svyglm\")\n)\n\n\n\n\nWe can see from this plot that the confidence intervals obtained from svyglm are wider than those we got from glm, but the point estimates for each coefficient are unchanged. We also added a dashed line at 0 to make it really easy to see when coefficients are statistically insignificant at the 5% level (if so, the “whiskers” of a 95% confidence interval will cross 0).\nAvailabillity: modeling with SDP variables\nWhile these individual factors are important, we should also expect the availability and accessibility of family planning services to partially determine their use (Bongaarts 2011). Back in an earlier post, we observed that the women in our sample appeared to be 5% more likely to use family planning if they lived in an enumeration area where no SDPs reported a recent contraceptive stockout, compared to women living in areas where at least one SDP did experience a recent stockout. Now we’ll see if that difference is statistically significant, controlling for other factors.\n\nFor our purposes, a “recent stockout” is a stockout of any contraceptive method normally provided by an SDP if the stockout occurred within 3 months prior to the survey.\nFirst, we’ll create a binary variable STOCKOUT indicating whether each woman lives in an enumeration area where at least one SDP reported a recent stockout:\n\n\nbf_merged <- bf_merged %>%\n  mutate(STOCKOUT = case_when(\n    NUM_METHODS_OUT3MO > 0 ~ 1,\n    NUM_METHODS_OUT3MO == 0 ~ 0\n  ))\n\nbf_merged %>% count(STOCKOUT)\n\n\n# A tibble: 3 × 2\n  STOCKOUT     n\n     <dbl> <int>\n1        0  4561\n2        1  1725\n3       NA   658\n\nNext, we’ll add STOCKOUT to our previous model, along with NUM_METHODS_PROV (the number of methods available from at least one SDP serving the woman’s enumeration area) and N_SDP (the number of sampled SDPs serving the woman’s enumeration area).\n\n\nm3 <- svyglm(\n  FPCURRUSE ~\n    AGE + \n    MARSTAT + \n    EDUCATTGEN + \n    BIRTHEVENT  + \n    WEALTHQ + \n    SAMPLE + \n    STOCKOUT + \n    NUM_METHODS_PROV + \n    N_SDP,\n  design = svydesign(\n    ids = ~EAID,\n    strata = ~STRATA,\n    data = bf_merged\n  )\n)\n\ntidy(m3)\n\n\n# A tibble: 13 × 5\n   term                     estimate std.error statistic  p.value\n   <chr>                       <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)              0.113      0.105      1.08   2.85e- 1\n 2 AGE                     -0.00249    0.00114   -2.19   3.23e- 2\n 3 MARSTAT                  0.201      0.0161    12.5    1.94e-19\n 4 EDUCATTGEN               0.168      0.0169     9.93   6.35e-15\n 5 BIRTHEVENT               0.0272     0.00414    6.57   7.77e- 9\n 6 WEALTHQLower quintile    0.0380     0.0244     1.56   1.24e- 1\n 7 WEALTHQMiddle quintile   0.0211     0.0287     0.736  4.64e- 1\n 8 WEALTHQHigher quintile   0.0879     0.0300     2.93   4.58e- 3\n 9 WEALTHQHighest quintile  0.162      0.0270     6.02   7.55e- 8\n10 SAMPLE85408              0.000951   0.0175     0.0542 9.57e- 1\n11 STOCKOUT                -0.0444     0.0206    -2.16   3.44e- 2\n12 NUM_METHODS_PROV        -0.00199    0.0104    -0.192  8.48e- 1\n13 N_SDP                   -0.0165     0.0120    -1.38   1.72e- 1\n\nIndeed, women living in an enumeration area where we’re aware of recent stockouts are less likely to be currently using family planning! The effect isn’t quite as large as some of the individual level factors we’ve examined, but it is statistically significant (p < 0.05).\nDoes the introduction of SDP variables change our estimates for the individual factors we examined previously? A new dwplot seems to show little difference:\n\n\npma_dwplot(\n  tidy(m2) %>% mutate(model = \"Individual-only\"),\n  tidy(m3) %>% mutate(model = \"SDP + Individual\")\n)\n\n\n\n\nAccessibility: modeling with external spatial variables\nAvailability of family planning methods (or lack thereof) is not the same as accessibility. The variables we created in our last post using external geospatial data allow us to explore some factors related to accessibility, which is what we’ll add now. We’ll complement these external variables with URBAN, indicating whether the woman lives in an urban area.\n\n\nm4 <- svyglm(\n  FPCURRUSE ~\n    AGE + \n    MARSTAT + \n    EDUCATTGEN + \n    BIRTHEVENT  + \n    WEALTHQ + \n    SAMPLE + \n    STOCKOUT + \n    NUM_METHODS_PROV + \n    N_SDP + \n    POP_DENSITY + \n    ROAD_LENGTH + \n    URBAN,\n  design = svydesign(\n    ids = ~EAID,\n    strata = ~STRATA,\n    data = bf_merged\n  )\n)\n\ntidy(m4) \n\n\n# A tibble: 16 × 5\n   term                       estimate  std.error statistic  p.value\n   <chr>                         <dbl>      <dbl>     <dbl>    <dbl>\n 1 (Intercept)              0.0833     0.117         0.712  4.79e- 1\n 2 AGE                     -0.00303    0.00112      -2.71   8.61e- 3\n 3 MARSTAT                  0.210      0.0157       13.4    1.97e-20\n 4 EDUCATTGEN               0.162      0.0174        9.30   1.28e-13\n 5 BIRTHEVENT               0.0284     0.00417       6.82   3.41e- 9\n 6 WEALTHQLower quintile    0.0343     0.0249        1.38   1.72e- 1\n 7 WEALTHQMiddle quintile   0.0124     0.0291        0.426  6.72e- 1\n 8 WEALTHQHigher quintile   0.0405     0.0312        1.30   1.99e- 1\n 9 WEALTHQHighest quintile  0.0734     0.0384        1.91   6.07e- 2\n10 SAMPLE85408              0.00133    0.0179        0.0744 9.41e- 1\n11 STOCKOUT                -0.0483     0.0211       -2.29   2.53e- 2\n12 NUM_METHODS_PROV        -0.00225    0.0104       -0.216  8.30e- 1\n13 N_SDP                   -0.0158     0.0124       -1.27   2.09e- 1\n14 POP_DENSITY             -0.00000144 0.00000522   -0.276  7.83e- 1\n15 ROAD_LENGTH              0.00110    0.00144       0.760  4.50e- 1\n16 URBAN                    0.0773     0.0370        2.09   4.03e- 2\n\npma_dwplot(\n  tidy(m2) %>% mutate(model = \"Individual-only\"),\n  tidy(m3) %>% mutate(model = \"SDP + Individual\"),\n  tidy(m4) %>% mutate(model = \"All\")\n) \n\n\n\n\nThis figure with all three models reveals that marital status, education, number of births, and living in an enumeration area that faced recent stockouts are all significantly associated with current family planning use. However, it’s pretty difficult to compare the effects across all the variables. The coefficients on age, population density, and road length are particularly hard to examine and compare. dotwhisker includes a very handy function that re-scales continuous variables on the right-hand side of your regression model to make them more comparable to binary predictors. Specifically, dotwhisker::by_2sd() re-scales continuous input variables by 2 standard deviations following Gelman (2008).2\nWhile we’re adding some last touches to make the plot more readable, we’ll also provide a title, clearer variable names on the Y axis, a tighter scale on the X axis, and a caption at the bottom.\n\n\nlist(\n  tidy(m2) %>% mutate(model = \"Individual-only\"),\n  tidy(m3) %>% mutate(model = \"SDP + Individual\"),\n  tidy(m4) %>% mutate(model = \"All\")\n) %>% \n  map(~by_2sd(.x, bf_merged)) %>% \n  bind_rows() %>% \n  relabel_predictors(\n    c(\n      AGE = \"Age\",  \n      MARSTAT = \"Married\", \n      EDUCATTGEN = \"Some Schooling\", \n      BIRTHEVENT = \"No. of Children\",\n      `WEALTHQLower quintile` = \"Lower Wealth Quintile\", \n      `WEALTHQMiddle quintile` = \"Middle Wealth Quintile\",\n      `WEALTHQHigher quintile` = \"Higher Wealth Quintile\", \n      `WEALTHQHighest quintile` = \"Highest Wealth Quintile\", \n      STOCKOUT = \"Recent Stockout\", \n      NUM_METHODS_PROV = \"No. of FP Methods\",\n      N_SDP = \"No. of SDP Providers\",\n      POP_DENSITY = \"Population Density (w/i 10 km)\",\n      ROAD_LENGTH = \"Road length (w/i 10 km)\",\n      URBAN = \"Lives in Urban EA\",\n      SAMPLE85408 = \"2018 Sample\"\n    )\n  ) %>% \n  dwplot(\n    dodge_size = 0.8,\n    vline = geom_vline(xintercept = 0, colour = \"grey60\", linetype = 2)\n  ) + \n  scale_color_viridis_d(option = \"plasma\", end = .7) +\n  theme_minimal() +\n  labs(\n    x = \"Coefficient\",\n    color = NULL,\n    title = \"Marital Status Is the Strongest Predictor of Family Planning Use\",\n    subtitle = \"Impact of Individual and Contextual Factors on Family Planning Use\",\n    caption = \"Source: IPUMS PMA (Burkina Faso 2017-2018), DIVA-GIS (road length), and WorldPop (population density)\"\n  ) +\n  scale_x_continuous(limits = c(-0.1, 0.3)) + # to make space for the legend\n  theme(\n    legend.position = c(0.8, 0.2),\n    title = element_text(size = 8),\n    legend.text = element_text(size = 8),\n    plot.caption = element_text(hjust = 0), #left align the caption\n    legend.background = element_rect(colour = \"grey80\")\n  )\n\n\n\n\nNow that we’ve re-scaled the continuous input variables by two standard deviations, we can much more easily see the relationship between age and family planning use. Across all models a one-year increase in a woman’s age is associated with a five percentage point lower expected probability of using family planning. This effect is statistically significant at the 5% level in all three models as well.\nThe relationships we observed with marital status, education, and number of children are quite stable across all the models – even as we added variables representing the service environment and broader context of contraceptive availability the coefficients did not meaningfully change.\nThis is in pretty striking contrast to what happens to the wealth quintile variables. When we included only woman and SDP characteristics, being in either the higher and highest wealth quintiles was associated with large and statistically significant increases in the probability of using family planning. But as we added geospatial variables and the URBAN variable in particular, the coefficients become smaller and the confidence intervals become wider. This indicates that there was likely omitted variable bias because wealth is correlated with living in an urban area but when we excluded URBAN the wealth quintile variables were capturing some of this relationship with family planning use.\nEven though this analysis was relatively simple, it was quite informative about different drivers of family planning use. You could easily extend this analysis to include other factors that influence family planning use, incorporate fixed or random effects, or take advantage of the multiple years of survey data!\nAs always, let us know if you have any questions on this post or if you’re working any fertility related analyses and you have a question that we can help address with the blog!\n\n\n\nBongaarts, John. 2011. “Can Family Planning Programs Reduce High Desired Family Size in Sub-Saharan Africa?” International Perspectives on Sexual and Reproductive Health 37 (4): 209–16. https://doi.org/10.1363/3720911.\n\n\nCameron, A. Colin, and Douglas L. Miller. 2015. “A Practitioner’s Guide to Cluster-Robust Inference.” Journal of Human Resources 50 (2): 317–72.\n\n\nGelman, Andrew. 2008. “Scaling Regression Inputs by Dividing by Two Standard Deviations.” Statistics in Medicine 27 (15): 2865–73. https://doi.org/10.1002/sim.3107.\n\n\nLumley, Thomas. 2011. Complex Surveys: A Guide to Analysis Using R. Wiley Series in Survey Methodology. John Wiley & Sons.\n\n\nWe highly recommend Lumley’s (2011) book, Complex Surveys: A Guide to Analysis Using R.↩︎\nWe recommend checking out the full paper, but the short explanation is that with binary predictors you are comparing a value of 0 to a value of 1 when interpreting coefficients. A 1-unit change in a binary predictor is equivalent to a 2 standard deviation change because the standard deviation of a binary variable with equal probabilities is 0.5.↩︎\n",
    "preview": "posts/2021-02-19-analyzing-the-individual-in-context/images/results.png",
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {},
    "preview_width": 1950,
    "preview_height": 1199
  },
  {
    "path": "posts/2021-02-04-merging-external-spatial-data/",
    "title": "Merging external spatial data",
    "description": "How to integrate external spatial data with PMA data.",
    "author": [
      {
        "name": "Nina Brooks",
        "url": "http://www.ninarbrooks.com/"
      }
    ],
    "date": "2021-02-15",
    "categories": [
      "Individuals in Context",
      "Service Delivery Points",
      "Data Manipulation",
      "join",
      "sf",
      "raster",
      "Spatial"
    ],
    "contents": "\n\nContents\nData\nSetup: Load packages and data\nPopulation Density: working with raster data\nRoad Networks: Working with vector data\n\n\n\n\nOur last post showed how to read, merge, and map the PMA GPS data - and how mapping can shed light on interesting spatial variation. A big advantage of the PMA GPS data is that you can also merge in other sources of spatial data, which opens up enormous opportunities for analyzing how contextual and environmental factors affect topics of interest in the PMA data. In this post, we’ll show how to merge in two different types of spatial data and construct variables of interest.\nData\nWe’ll be using toy PMA GPS data for this post. To use real PMA GPS data you must request access directly from our partners at pmadata.org. The toy data we’ll use here contains randomly sampled locations within Burkina Faso which have no actual relationship to the EAs in the PMA data. This means none of the interpretations of spatial patterns will hold, but all the code will run.\nWe will also be introducing two different spatial datasets that represent different kinds of spatial data. The first is population density data from WorldPop.1 If you want to download the data from the WorldPop site, we’re using the “Unconstrained individual countries 2000-2020 (1 km resolution)” data from 2017 for Burkina Faso. This is raster data, which means the data are stored as a grid of values which are rendered on a map as pixels. You can think of this as a matrix that is spatially referenced – that is each pixel represents a specific area of land on the Earth. Lots of spatial data are stored as rasters including climate data (e.g., temperature and rainfall), elevation, and satellite images. Note that the raster data is saved as a .tiff (which is a common way of storing raster data). The resolution of the raster maps to the area that each pixel represents in the real world. The population density is 1 km resolution, which means that each pixel represents a 1 km by 1 km square on the ground. The figure below shows the impact of different spatial resolutions for the same raster data.2\n\n\n\nFigure 1: Source: NEON\n\n\n\n\nThere are tons of resources on earth data science in R. We recommend the resources by Earth Lab and NEON by NSF. This post is an excellent introduction to working with rasters in R!\nPopulation density is also conceptually important to the SDP data on contraceptive supply that we’ve been examining through this series of posts. Population density may provide a more nuanced characterization of urbanization than the URBAN variable. Additionally, density may be correlated with longer wait times at clinics, which may also impact contraceptive use at the individual level.\nThe second spatial dataset we’ll introduce is data on road networks in Burkina Faso from the Digital Chart of the World and made publicly available by DIVA-GIS, an excellent source for publicly available spatial datasets. Road networks serve as a proxy for accessibility to health clinics – an important component of the contraceptive service environment – that may be more nuanced than the binary urban/rural distinction. To download the road data, go to DIVA-GIS Data and select Burkina Faso from the Country dropdown and Roads from the Subject dropdown. The road data is called vector data and is stored in a shapefile (.shp). Vector data is used to represent real world features and are three basic types: points, lines, and polygons. The road data we’re using in this post is an example of vector line data.\n\nRemember the administrative boundaries we used in the previous post were polygons and the GPS points for the PMA enumeration areas were points. Both are vector data!\nSetup: Load packages and data\nWe’ll be using many of the packages from the last few posts, as well as a new package for specifically working with raster data – appropriately called raster – and one called units, which enables easy conversion between objects of different units. Make sure to install the raster and units packages first and then load everything we’ll be using today:\n\n\nlibrary(sf) # primary spatial package\nlibrary(raster) # for working with raster data\nlibrary(viridis) # for color palettes\nlibrary(units) # to easily convert between units\nlibrary(tidyverse)\n\n\n\nLet’s start by reading in the raster using raster::raster() and check out the meta-data.\n\n\npop_density <- raster(\"bfa_pd_2017_1km.tif\")\npop_density\n\n\nclass      : RasterLayer \ndimensions : 682, 951, 648582  (nrow, ncol, ncell)\nresolution : 0.008333333, 0.008333333  (x, y)\nextent     : -5.517917, 2.407083, 9.407917, 15.09125  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : /Users/Matt/R/pma-data-hub/_posts/2021-02-04-merging-external-spatial-data/bfa_pd_2017_1km.tif \nnames      : bfa_pd_2017_1km \nvalues     : 0.281988, 8820.016  (min, max)\n\nBecause rasters are essentially just matrices, you can think of the dimensions in the same way. At a spatial resolution of 1 km, this raster covers all of Burkina Faso with 648,582 cells. The resolution describes the size of the cells (the length of one side of each square cell). You may be wondering why this is showing up as 0.00833 when the data has a spatial scale of 1 km by 1 km. This is because the units that the resolution is reported in depend on the coordinate reference system of the data. More on this in a moment.\nThe extent (or spatial extent) refers to the geographic area that the raster covers. The values are in the same coordinate reference system as the raster. The coordinate reference system or crs is the next piece of meta-data we have. “A coordinate reference system (CRS) is a coordinate-based local, regional or global system used to locate geographical entities.”3 The crs for this raster is +proj=longlat +datum=WGS84 +no_defs. The crs contains several pieces of information including the datum (WGS84) and the projection.4 The appropriate CRS to use for any given spatial task depends on what part of the world the data represent and what kind of spatial operations you’ll be performing. It’s really important to know what crs your data are in and make sure that all your spatial data are in the same  crs if you use more than one kind. Otherwise, they won’t line up on a map and any spatial analysis or processing you do will be incorrect.\nThe projection of this raster data is described as longlat, which actually is not a projection. A projection refers to how the Earth’s surface is flattened so it can be represented as a 2-dimensional raster grid. These data use a geographic coordinate system, simply the raw latitude and longitude coordinates, rather than a projected coordinate system, which would transform the coordinates into a 2-dimensional plane. Latitude and longitude locate positions on the Earth using angles, so the spacing of each line of latitude as you move north or south along the Earth is not uniform. The units of this reference system are in degrees (of latitude and longitude), so the 0.00833 resolution we saw above is reporting the spatial resolution in degrees, rather than meters or kilometers. This crs is not ideal for measuring distances because the distance covered by a single degree of latitude or longitude varies greatly across the Earth’s surface. This also means that the stated 1 km resolution is only nominal. At the equator, 0.00833 degrees is approximately equal to 1 km, but this distance, and the ground area represented by each pixel, will vary. Fortunately, Burkina Faso is relatively close to the equator, so the pixels will be quite close to 1 km by 1 km.\nThe last piece of meta-data to look at are the values – this is reporting the minimum and maximum values across all of the cells. Because these are population density data, it can be interpreted as the number of people in each pixel divided by the area of each pixel (which we know is 1 km2)\nNow that we’ve reviewed the raster attributes, let’s see what it looks like. We can use the basic plot function to do this.\n\n\nplot(pop_density)\n\n\n\n\nWe can see three locations stand out in terms of population density. First is Ouagadougou the capital of Burkina Faso and largest city, right in the center. Then we can see higher density around Bobo Dioulasso and Banfora in the southwest of the country, which are the second and third largest cities in the country.\nNext we’ll load the roads data using sf::st_read().\n\n\nroads <- st_read(\"BFA_roads/BFA_roads.shp\", quiet = TRUE)\nroads\n\n\nSimple feature collection with 1149 features and 5 fields\ngeometry type:  MULTILINESTRING\ndimension:      XY\nbbox:           xmin: -5.482261 ymin: 9.407643 xmax: 2.393089 ymax: 15.08071\ngeographic CRS: WGS 84\nFirst 10 features:\n       MED_DESCRI      RTT_DESCRI F_CODE_DES ISO   ISOCOUNTRY\n1  Without Median Secondary Route       Road BFA BURKINA FASO\n2  Without Median Secondary Route       Road BFA BURKINA FASO\n3  Without Median Secondary Route       Road BFA BURKINA FASO\n4  Without Median Secondary Route       Road BFA BURKINA FASO\n5  Without Median Secondary Route       Road BFA BURKINA FASO\n6  Without Median Secondary Route       Road BFA BURKINA FASO\n7  Without Median Secondary Route       Road BFA BURKINA FASO\n8  Without Median Secondary Route       Road BFA BURKINA FASO\n9  Without Median Secondary Route       Road BFA BURKINA FASO\n10 Without Median Secondary Route       Road BFA BURKINA FASO\n                         geometry\n1  MULTILINESTRING ((-0.720550...\n2  MULTILINESTRING ((-0.583273...\n3  MULTILINESTRING ((-0.397415...\n4  MULTILINESTRING ((-0.142728...\n5  MULTILINESTRING ((-0.403059...\n6  MULTILINESTRING ((-0.171111...\n7  MULTILINESTRING ((-0.116756...\n8  MULTILINESTRING ((0.0672155...\n9  MULTILINESTRING ((-1.245636...\n10 MULTILINESTRING ((-1.50246 ...\n\nThis sf object also contains meta-data (shown at the top). In terms of meta-data, the geometry type field tells us this data is a MULTILINESTRING object, which makes sense since these are roads. The bbox (short for bounding box), is the same information as the extent field for the raster data – it tells us the bounds of the geographic area that this spatial data covers. We see the geographic CRS which is the coordinate reference system of the data. For this roads dataset it is WGS84, which is the same as the population density raster data.\nThe roads data contains several variables: MED_DESCRI, RTT_DESCRI, F_CODE_DES, ISO, ISOCOUNTRY, and geometry. The first three variables provide some information about the types of roads in this data. ISO and ISOCOUNTRY simply provide country codes and names for the data. Finally, we see the geometry variable, which is the variable that contains the spatial information in an sf object.\nWe can also plot this roads data to see what it looks like.\n\n\nplot(roads)\n\n\n\n\nBy calling the basic plot function, we get a panel of plots of the road network, with one plot for each variable. We can see some variation in color MED_DESCRI and RTT_DESCRI, indicating that there multiple values for those variables. If we wanted just a single plot of the road network, we can get that by calling plot on the geometry variable:\n\n\nplot(roads$geometry)\n\n\n\n\nFinally, we’ll load the “toy” GPS data and convert it to an sf object. The option crs = 4326 means that we are creating this with the WGS84 coordinate reference system because 4326 is the EPSG code for WGS84.\n\nMost crs are assigned an “EPSG code”, which is a unique ID that can be used to identify a CRS.\n\n\ngps <- read_csv(\"bf_gps_fake.csv\") %>%\n  rename(EAID = EA_ID) %>% # rename to be consistent with other PMA data\n  st_as_sf(\n    coords = c(\"GPSLONG\", \"GPSLAT\"), \n    crs = 4326)\n\n\n\n\n\n\nPopulation Density: working with raster data\nWe want to construct a variable that captures the population density at each enumeration area in the data. We’ll use sf::st_buffer() to do this, which will construct a buffer circle around each GPS point. The PMA GPS data are randomly displaced to protect the privacy of respondents, so it’s imperative to consider this displacement when working with the GPS data to do spatial operations. Because the maximum displacement distance is 10 km, if we construct buffers with a radius of 10 km we can be 100% confident that the true locations of each GPS point fall within that buffer.\n\nUrban EAs are displaced from their true location up to 2 km. Rural EAs are displaced from their true location up to 5 km. Additionally, a random sample of 1% of rural EAs are displaced up to 10km.\n\n\nbuffers <- st_buffer(gps, dist = 10000)\n\n\nWarning in st_buffer.sfc(st_geometry(x), dist, nQuadSegs, endCapStyle\n= endCapStyle, : st_buffer does not correctly buffer longitude/\nlatitude data\ndist is assumed to be in decimal degrees (arc_degrees).\n\nggplot() +\n  geom_sf(data = buffers) +\n  geom_sf(data = gps)\n\n\n\n\nThis giant circle is certainly not what we would expect! What’s going on here? Earlier in this post we mentioned that the WGS84 crs is a geographic coordinate system that simply uses the latitude and longitude coordinates to identify locations and the units are in degrees, rather than meters or kilometers. This circle thus has a radius of 10,000 degrees and since the Earth only spans 360 degrees it is fully covered by this circle. As we mentioned, the WGS84 crs is not ideal for measuring distances. R alerted us of this problem with two warnings: st_buffer does not correctly buffer longitude/latitude data and dist is assumed to be in decimal degrees (arc_degrees). This is why it’s so important to pay attention to the crs of your data.\nTo properly construct a buffer circle around these GPS points, we need to transform the data to a different projection that uses meters or kilometers. And, because it’s essential that all of our data are in the same crs, we need to transform or reproject everything. For vector data, we can do this using sf::st_transform() and for raster data we’ll do this with raster::projectRaster(). For the transformation, we’re using a crs that is projected to meters and is appropriate to the local geography of Burkina Faso. You can read about it on the epsg.io site. After reprojecting, we’ll calculate the buffer again and plot it to make sure this looks right.\n\n\n# transform the GPS data\ngps_tr <- gps %>% st_transform(crs = 32630)\ngps_tr\n\n\nSimple feature collection with 83 features and 5 fields\ngeometry type:  POINT\ndimension:      XY\nbbox:           xmin: 260943.3 ymin: 1114669 xmax: 1025472 ymax: 1653511\nprojected CRS:  WGS 84 / UTM zone 30N\n# A tibble: 83 x 6\n   PMACC PMAYEAR REGION                EAID DATUM           geometry\n * <chr>   <dbl> <chr>                <dbl> <chr>        <POINT [m]>\n 1 BF       2017 5. centre-nord        7610 WGS84 (837531.4 1567675)\n 2 BF       2017 1. boucle-du-mouhoun  7820 WGS84 (491871.7 1488848)\n 3 BF       2017 3. centre             7271 WGS84   (982414 1349907)\n 4 BF       2017 3. centre             7799 WGS84   (739431 1352652)\n 5 BF       2017 8. est                7243 WGS84 (545866.2 1219668)\n 6 BF       2017 6. centre-ouest       7026 WGS84 (352638.7 1209502)\n 7 BF       2017 3. centre             7859 WGS84 (833822.1 1377527)\n 8 BF       2017 3. centre             7725 WGS84 (980025.8 1406727)\n 9 BF       2017 6. centre-ouest       7390 WGS84 (439876.7 1190609)\n10 BF       2017 11. plateau-central   7104 WGS84 (835483.2 1469280)\n# … with 73 more rows\n\n# reproject the raster data\npop_density_tr <- projectRaster(\n  pop_density, \n  crs = \"+proj=utm +zone=30 +datum=WGS84 +units=m +no_defs\"\n)\npop_density_tr\n\n\nclass      : RasterLayer \ndimensions : 699, 970, 678030  (nrow, ncol, ncell)\nresolution : 907, 922  (x, y)\nextent     : 218942.9, 1098733, 1035714, 1680192  (xmin, xmax, ymin, ymax)\ncrs        : +proj=utm +zone=30 +datum=WGS84 +units=m +no_defs \nsource     : memory\nnames      : bfa_pd_2017_1km \nvalues     : 0.9709167, 8775.492  (min, max)\n\n\nNote: the projectRaster function takes crs as a character string, rather than the EPSG code 32630. We’re using the PROJ.4 code shown in the “Export” menu on the epsg.io site.\n\n\n# calculate 10 km (10,000 meter) buffer circles\nbuffers_tr <- st_buffer(gps_tr, dist = 10000) # because the units are in meters\n\n# plot\nggplot() +\n  geom_sf(data = buffers_tr) +\n  geom_sf(data = gps_tr, color = \"red\")\n\n\n\n\nLooking at the meta-data for both the gps_tr and raster_tr objects, we can see they have the same new projected crs: UTM zone 30N. The raster_tr meta-data also includes information on the units (+units=m) confirming that distances are measured in meters. Turning to the plot, we can see the GPS coordinates marked in red and each has a circle around it.\nNow that we have correctly estimated 10 km buffer circles, we can calculate the average population density within each buffer using the raster::extract() command and specifying fun = mean. This produces an 83 x 1 vector of results, which means we have one population density value for each enumeration area. Printing the first 5 results shows there is some substantial variation in population density.\n\n\nbuffer_density <- raster::extract(\n  pop_density_tr, \n  buffers_tr, \n  fun = mean, \n  na.rm = TRUE,\n  cellnumbers = TRUE\n)\ndim(buffer_density)\n\n\n[1] 83  1\n\nhead(buffer_density)\n\n\n          [,1]\n[1,]  35.58080\n[2,]  21.36878\n[3,]  17.56161\n[4,] 113.36298\n[5,]  31.73017\n[6,]  57.09591\n\nNote, that we don’t actually need to create the buffers first to extract the mean values of the raster. We can do it all in one step, shown below. Just make sure to use the gps_tr object instead of the buffer_tr object! But, we’ll use those buffers again with the road data.\n\n\nbuffer_density_alt <- raster::extract(\n  pop_density_tr, gps_tr, \n  buffer = 10000,\n  fun = mean, \n  na.rm = TRUE\n)\nhead(buffer_density_alt)\n\n\n[1]  35.58080  21.36878  17.56161 113.21781  31.73017  57.09591\n\nFinally, so we can merge everything together by EAID, let’s add the population density calculation directly to the gps_tr data. Note that the raster::extract() command preserves the order of the inputs, so we know the first row of the density calculation corresponds to the first row of the gps_tr data.\n\n\ngps_tr$pop_density <- raster::extract(\n  pop_density_tr, gps_tr, \n  buffer = 10000,\n  fun = mean, na.rm = TRUE\n)\n\n\n\nRoad Networks: Working with vector data\nBefore we do anything with the road data, let’s make sure to reproject it to match the rest of our data.\n\n\nroads_tr <- roads %>%\n  st_transform(crs = 32630)\n\n\n\nBecause enumeration areas with better access to roads may make it easier for women to reach local service delivery providers. We are going to calculate the total length of roads within each buffer as a proxy for this accessibility. Because each of these buffers was constructed with the same 10 km radius, they have the same area, which means the sum of road length can also be thought of as a road density measure.\nFirst, we need to identify which portions of the road fall into each buffer. We’ll use sf::st_intersection(), which returns a new sf object that contains observations from the first argument that touch (geographically) the second argument.\n\nNote that there is also an sf::intersects() command. This is different than the one we’re using because it returns a logical matrix that indicates whether each geometry pair intersects. See more on these types of operations in the sf vignette.\n\n\nint <- st_intersection(roads_tr, buffers_tr)\nint\n\n\nSimple feature collection with 238 features and 10 fields\ngeometry type:  LINESTRING\ndimension:      XY\nbbox:           xmin: 251238.7 ymin: 1104708 xmax: 1033002 ymax: 1658158\nprojected CRS:  WGS 84 / UTM zone 30N\nFirst 10 features:\n        MED_DESCRI      RTT_DESCRI F_CODE_DES ISO   ISOCOUNTRY PMACC\n240 Without Median Secondary Route       Road BFA BURKINA FASO    BF\n241 Without Median Secondary Route       Road BFA BURKINA FASO    BF\n268 Without Median Secondary Route       Road BFA BURKINA FASO    BF\n711 Without Median Secondary Route       Road BFA BURKINA FASO    BF\n640    With Median   Primary Route       Road BFA BURKINA FASO    BF\n649    With Median   Primary Route       Road BFA BURKINA FASO    BF\n728 Without Median Secondary Route       Road BFA BURKINA FASO    BF\n958 Without Median Secondary Route       Road BFA BURKINA FASO    BF\n959 Without Median Secondary Route       Road BFA BURKINA FASO    BF\n964 Without Median Secondary Route       Road BFA BURKINA FASO    BF\n    PMAYEAR               REGION EAID DATUM\n240    2017 1. boucle-du-mouhoun 7820 WGS84\n241    2017 1. boucle-du-mouhoun 7820 WGS84\n268    2017 1. boucle-du-mouhoun 7820 WGS84\n711    2017            3. centre 7271 WGS84\n640    2017            3. centre 7799 WGS84\n649    2017            3. centre 7799 WGS84\n728    2017            3. centre 7799 WGS84\n958    2017               8. est 7243 WGS84\n959    2017               8. est 7243 WGS84\n964    2017               8. est 7243 WGS84\n                          geometry\n240 LINESTRING (501051.3 149280...\n241 LINESTRING (481961.6 149016...\n268 LINESTRING (489661.7 148171...\n711 LINESTRING (981157 1359825,...\n640 LINESTRING (732417.5 135977...\n649 LINESTRING (746990.9 135527...\n728 LINESTRING (746990.9 135527...\n958 LINESTRING (553191.7 122647...\n959 LINESTRING (554462.3 122043...\n964 LINESTRING (535888.5 122030...\n\nThe returned object (int) is a data.frame with 238 observations (far fewer than the original 1149 in the roads_tr data). Note that it also contains all the variables from both roads_tr and buffers_tr, so this operates a bit like an inner_join, which means it only includes observations that are in both datasets. We can see the implications of this by making a quick map. The full road network is shown in gray, the buffer circles are in black and the roads that fall into the circles are highlighted in red. Based on this map, it looks like there are a few buffer circles that don’t contain any roads. We want to be sure we account for this.\n\n\n# plot intersection with buffers and road networks \nggplot() +\n  geom_sf(data = buffers_tr) +\n  geom_sf(data = roads_tr, color = \"grey\") +\n  geom_sf(data = int, color = \"red\")\n\n\n\n\nWe can merge in the full list of EAIDs to make sure we don’t miss this one (or any others) using sf:st_join(), which works like dplyr::left_join(). It’s important that when we do the join, the first argument is int, so that it will retain the LINESTRING geometry from this dataset, which we need to calculate the road length. Then, we’ll calculate the length of the road networks contained in each buffer. We can do this with sf::st_length(). Because many of the buffer circles contain multiple roads, we first need calculate the length of each road then we need to aggregate to get the length of all roads in a given enumeration area. We’ll convert from meters to km for greater readability. It’s important to note that any EAs with buffers that don’t contain any roads will not be in the int dataset, so we’ll do a dplyr::full_join() with gps_tr to make sure we get them all.\nBecause int and gps_tr are both sf objects, it’s not possible to do a standard join – you can only use sf::join() when you have two sf objects. That’s why we convert both to data.frames for the dplyr::full_join() and then back into an sf object. Finally, we’ll convert int back into an sf object, retaining the POINT geometry from gps_tr, and replace all NA road lengths as 0.\n\n\n# join, calculate length, & summarize\nint <- int %>%\n  mutate(road_length = st_length(geometry)) %>%\n  group_by(EAID) %>%\n  summarise(road_length = sum(road_length, na.rm = T)) %>%\n  mutate(road_length = set_units(road_length, \"km\")) %>%\n  as.data.frame() %>%\n  full_join(as.data.frame(gps_tr), by = \"EAID\") %>%\n  st_sf(sf_column_name = 'geometry.y') %>%\n  dplyr::select(-geometry.x) %>%\n  mutate(road_length = ifelse(is.na(road_length), 0, road_length))\n\nint\n\n\nSimple feature collection with 83 features and 7 fields\ngeometry type:  POINT\ndimension:      XY\nbbox:           xmin: 260943.3 ymin: 1114669 xmax: 1025472 ymax: 1653511\nprojected CRS:  WGS 84 / UTM zone 30N\nFirst 10 features:\n   EAID road_length PMACC PMAYEAR               REGION DATUM\n1  7003    22.41682    BF    2017       5. centre-nord WGS84\n2  7006    13.35579    BF    2017       5. centre-nord WGS84\n3  7009    20.45756    BF    2017               8. est WGS84\n4  7016    20.31970    BF    2017 1. boucle-du-mouhoun WGS84\n5  7026    18.99583    BF    2017      6. centre-ouest WGS84\n6  7042    14.52567    BF    2017               8. est WGS84\n7  7048    24.29931    BF    2017        4. centre-est WGS84\n8  7056    15.21114    BF    2017     9. hauts-bassins WGS84\n9  7082    44.15771    BF    2017          2. cascades WGS84\n10 7092    26.30945    BF    2017        7. centre-sud WGS84\n   pop_density               geometry.y\n1     29.55058 POINT (422741.8 1383385)\n2     29.98035 POINT (371721.6 1276582)\n3     37.77861 POINT (348264.9 1114669)\n4    154.07399 POINT (346019.4 1218739)\n5     57.09591 POINT (352638.7 1209502)\n6     63.08637 POINT (752580.5 1219236)\n7     74.19692 POINT (479619.4 1234717)\n8     35.07390 POINT (359915.1 1392593)\n9   2731.76393 POINT (669089.2 1375002)\n10   152.23504 POINT (559070.9 1346179)\n\nThe added benefit of the full_join() with gps_tr is that it brings in the pop_density variable we created earlier. So now everything is in one dataset!\nThis can now be merged into other PMA data, such as the individual level dataset bf_merged we worked with in the other posts in this module, and the variables can be used for analysis!\nAs always, let us know if you have any questions and if you’re doing anything exciting with the PMA spatial data!\nSpecial thanks to Tracy Kugler, Nicholas Nagle, and Jonathan Schroeder for excellent help with this post.\n\nLinard, C., Gilbert, M., Snow, R. W., Noor, A. M., & Tatem, A. J. (2012). Population distribution, settlement patterns and accessibility across Africa in 2010. PloS one, 7(2), e31743.↩︎\nNEON: https://www.neonscience.org/resources/learning-hub/tutorials/raster-res-extent-pixels-r↩︎\nWikipedia↩︎\nhttps://www.earthdatascience.org/courses/earth-analytics/spatial-data-r/intro-to-coordinate-reference-systems/↩︎\n",
    "preview": "posts/2021-02-04-merging-external-spatial-data/images/road_map.png",
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {},
    "preview_width": 936,
    "preview_height": 574
  },
  {
    "path": "posts/2021-01-29-mapping-sdp-variables/",
    "title": "Mapping Service Delivery Point Data",
    "description": "Map spatial variation in the service delivery environment across enumeration areas.",
    "author": [
      {
        "name": "Nina Brooks",
        "url": "http://www.ninarbrooks.com/"
      }
    ],
    "date": "2021-01-30",
    "categories": [
      "Individuals in Context",
      "Service Delivery Points",
      "Data Manipulation",
      "Mapping",
      "sf"
    ],
    "contents": "\n\nContents\nData\nSetup\nMerge and Map\nBasic Maps\nMerge GPS and SDP Data\nMap SDP data\n\nPutting it All Together\n\n\n\n\nIn our last post, we showed how PMA Service Delivery Point (SDP) data can be aggregated to the enumeration area they serve (captured by EASERVED) and linked to individual-level data from a PMA Household and Female survey. In this post, we’ll continue thinking about the spatial distribution of SDP summary data. We’ll first show how to merge our example data to a GPS dataset obtained from pmadata.org, and we’ll then use the new dataset to visualize a few of our variables on a map of Burkina Faso.\nData\nBuilding on the steps we’ve covered in the last two posts in this series, we’ll be working with an example dataset we’re calling bf_merged that contains records from female respondents to the 2017 and 2018 Burkina Faso Household and Female surveys merged with five variables we’ve created from the 2017 and 2018 SDP surveys. These five variables describe services provided within the enumeration area where each woman resides:\nNUM_METHODS_PROV - number of methods provided by at least one SDP\nNUM_METHODS_INSTOCK - number of methods in-stock with at least one SDP\nNUM_METHODS_OUT3MO - number of methods out of stock any time in the last 3 months with at least one SDP\nMEAN_OUTDAY - the mean length of a stockout for any family planning method (measured in days)\nN_SDP - number of SDPs\nThe remaining four variables in bf_merged were taken directly from a data extract containing only female respondents:\nPERSONID - unique identifer for each woman\nEAID - unique identifier for each woman’s enumeration area\nURBAN - whether each woman lives in an urban enumeration area\nFPCURRUSE - whether each woman is currently using any family planning method\nWe’ll also be working with toy PMA GPS datasets for Burkina Faso. PMA GPS data include one GPS coordinate per enumeration area. The Burkina Faso Round 5 and 6 surveys sampled the same enumeration areas, which means we can link the GPS data to both rounds. To use real PMA GPS data you must request access directly from our partners at pmadata.org. For the purpose of use in this post, we’ve created a “toy” GPS dataset: the toy data contains randomly sampled locations within Burkina Faso that have no actual relationship to the EAs in the PMA data.\nThe last dataset we’ll use in this post are the administrative boundaries for Burkina Faso. Shapefiles with administrative boundaries are widely available for download, but we’ll use the ones made available from IPUMS PMA.\nSetup\nMake sure you have all of the following packages installed. Once installed, load the packages we’ll be using today:\n\n\nlibrary(ipumsr)\nlibrary(sf) # primary spatial package\nlibrary(viridis) # for color palettes\nlibrary(tabulator) # for pipe-friendly tabs & cross-tabs\nlibrary(tidyverse)\n\n\n\n\nCheck out our posts on R Packages and Loading IPUMS PMA data into R.\nIf you followed along with our last post, glimpse(bf_merged) should list the first few records for all of the variables we have so far:\n\n\n\n\n\nglimpse(bf_merged)\n\n\nRows: 6,944\nColumns: 10\n$ EAID                <dbl+lbl> 7003, 7003, 7003, 7003, 7003, 7003,…\n$ SAMPLE              <int+lbl> 85405, 85405, 85405, 85405, 85405, …\n$ N_SDP               <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, …\n$ NUM_METHODS_PROV    <int> 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,…\n$ NUM_METHODS_INSTOCK <int> 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, …\n$ NUM_METHODS_OUT3MO  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ MEAN_OUTDAY         <dbl> NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN,…\n$ PERSONID            <chr> \"0700300000019732017504\", \"070030000001…\n$ URBAN               <int+lbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FPCURRUSE           <int+lbl> 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,…\n\nRemember that we merged the EA-level data into the individual-level data, but the GPS datasets provide coordinates for the enumeration area. So the first thing we’ll do is aggregate bf_merged to the EA-level, and assign the aggregated data to a new object called bf_ea.\n\n\nbf_ea <- bf_merged %>%\n  dplyr::select(-PERSONID) %>%\n  group_by(EAID, SAMPLE) %>%\n  summarise_all(mean, na.rm = T) %>%\n  filter(!is.na(N_SDP)) \n\n\n\n\nIn this example, we’ll exclude any EAs where no facilities in our SDP sample provide services with filter(!is.na(N_SDP))\nNow, let’s read in the GPS data from the data folder and see what the it contains.\n\n\ngps <- read_csv(\"bf_gps_fake.csv\")\ngps\n\n\n# A tibble: 83 x 7\n   PMACC PMAYEAR REGION               EA_ID DATUM GPSLAT GPSLONG\n   <chr>   <dbl> <chr>                <dbl> <chr>  <dbl>   <dbl>\n 1 BF       2017 5. centre-nord        7610 WGS84   14.2  0.126 \n 2 BF       2017 1. boucle-du-mouhoun  7820 WGS84   13.5 -3.08  \n 3 BF       2017 3. centre             7271 WGS84   12.2  1.43  \n 4 BF       2017 3. centre             7799 WGS84   12.2 -0.799 \n 5 BF       2017 8. est                7243 WGS84   11.0 -2.58  \n 6 BF       2017 6. centre-ouest       7026 WGS84   10.9 -4.35  \n 7 BF       2017 3. centre             7859 WGS84   12.4  0.0703\n 8 BF       2017 3. centre             7725 WGS84   12.7  1.42  \n 9 BF       2017 6. centre-ouest       7390 WGS84   10.8 -3.55  \n10 BF       2017 11. plateau-central   7104 WGS84   13.3  0.0957\n# … with 73 more rows\n\n\nIf you requested access to the actual GPS datasets, make sure to replace the bf_gps_fake.csv with the filename of the real data!\n\n\n\nThe gps data has 7 variables:\nPMACC: the country code\nPMAYEAR: the 4-digit year of data collection\nREGION: sub-national administrative division name\nEA_ID: the enumeration area ID (and how we’ll merge this data into other PMA datasets)\nGPSLAT: the displaced EA’s centroid latitude coordinate in decimal degrees\nGPSLONG: the displaced EA’s centroid longitude coordinate in decimal degrees\nDATUM: the coordinate reference system and geographic datum. This variable is always “WGS84” for the World Geodetic System 1984.\n\nNote that while the PMAYEAR variable is 2017 for all EAs, because the same EAs were sampled in the 2017 (Round 5) and 2018 (Round 6) surveys, we can link these coordinates to both samples.\nNote that the GPSLAT and GPSLONG are displaced coordinates of the EA centroid. This is because PMA randomly displaces the geographic coordinates to preserve the privacy of survey respondents. Coordinates are displaced randomly by both angle and distance. Urban EAs are displaced from their true location up to 2 km. Rural EAs are displaced from their true location up to 5 km. Additionally, a random sample of 1% of rural EAs are displaced up to 10km. The PMA GPS data come with documentation that explains the displacement in more detail. The primary spatial package we’ll use is simple features or sf. We’ll use sf::st_as_sf() to convert the GPS data to a spatial data object (known as a simple feature collection).\n\n\ngps <- gps %>%\n    rename(EAID = EA_ID) %>% # rename to be consistent with other PMA data\n    st_as_sf(\n      coords = c(\"GPSLONG\", \"GPSLAT\"), \n      crs = 4326) # 4326 is the coordinate reference system (CRS) identifier for WGS84\ngps\n\n\nSimple feature collection with 83 features and 5 fields\ngeometry type:  POINT\ndimension:      XY\nbbox:           xmin: -5.185229 ymin: 10.08082 xmax: 1.829187 ymax: 14.93619\ngeographic CRS: WGS 84\n# A tibble: 83 x 6\n   PMACC PMAYEAR REGION               EAID DATUM              geometry\n * <chr>   <dbl> <chr>               <dbl> <chr>           <POINT [°]>\n 1 BF       2017 5. centre-nord       7610 WGS84  (0.1263576 14.15999)\n 2 BF       2017 1. boucle-du-mouho…  7820 WGS84   (-3.075099 13.4676)\n 3 BF       2017 3. centre            7271 WGS84   (1.430382 12.17557)\n 4 BF       2017 3. centre            7799 WGS84 (-0.7991777 12.22721)\n 5 BF       2017 8. est               7243 WGS84  (-2.580105 11.03307)\n 6 BF       2017 6. centre-ouest      7026 WGS84  (-4.348525 10.93844)\n 7 BF       2017 3. centre            7859 WGS84 (0.07032293 12.44352)\n 8 BF       2017 3. centre            7725 WGS84   (1.417154 12.68821)\n 9 BF       2017 6. centre-ouest      7390 WGS84  (-3.549929 10.77006)\n10 BF       2017 11. plateau-central  7104 WGS84 (0.09573113 13.27184)\n# … with 73 more rows\n\n\n\n\nNow that gps is a simple features object, we’ve lost the GPSLAT and GPSLONG variables and gained a variable called geometry, which contains the spatial information for this data.\n\n\n\nThe last thing we need is the Burkina Faso shapefile, which are available from IPUMS PMA. You’ll need to download the shapefile (geobf.zip) from the IPUMS site and save it in your working directory to use it. We can use sf::st_read() to read the shapefile into R as an sf object. Note that here the geometry variable is a POLYGON, whereas in the gps data it is a POINT.\n\nNote that what we call a shapefile is actually a collection of many files. More on this in a future post! But for now, just know that you’ll need all the files that come in the zipped download and can refer to the collectively with “geobf.shp”.\n\n\nbf_shp <- st_read(\"geobf/geobf.shp\") \n\n\n\nMerge and Map\nNow that we have all our data, we’ll show you how to map variables… but before we do that, let’s do some basic, exploratory mapping.\nBasic Maps\nggplot2 has support for sf objects, which makes it really easy to map things using the ggplot2 system. ggplot2::geom_sf() will automatically identify what kind of spatial data you’re plotting and handle it appropriately. For example, let’s plot the gps data (which are points) and the administrative region (which are polygons).\nggplot2 is included when you load library(tidyverse)\n\n\n# Plot EA centroids\nggplot() +\n  geom_sf(data = gps)\n\n\n\n# Plot regions of Burkina Faso\nggplot() +\n  geom_sf(data = bf_shp)\n\n\n\n\nThe building-block approach of ggplot2 (“Grammar of Graphics”) also makes it really easy to layer different spatial features on the same map.\n\n\n# Plot regions of Burkina Faso & EA centroids on the same map\nggplot() +\n  geom_sf(data = bf_shp) +\n  geom_sf(data = gps)\n\n\n\n\nMerge GPS and SDP Data\nTo map the EA-level variables constructed in the last post, we need to merge the bf_ea data and the gps data by EAID. First, let’s rename the EASEARVED variable to match the GPS data and then use a dplyr::right_join to merge in the SDP data. We need to use a right_join() because the sf object must be listed first in our join command to retain the sf class, but we want to ensure that all rows from bf_ea are preserved.\n\nRemember, the SDP data contains information from both 2017 and 2018, while the GPS data has a single observation per EA.\n\n\nbf_ea <- right_join(gps, bf_ea, by = \"EAID\")\n\n\n\nMap SDP data\nRemember, the bf_ea data contains information from 2017 & 2018 for the same EA, which can clog up the map depending on how we use this information. To start out, let’s use only the 2017 data and add information about the number of service delivery providers that serve a given EA (N_SDP). By passing N_SDP to the size aesthetic, we can more easily visualize how EAs vary in their access to service delivery providers.\n\n\nbf_ea2017 <- bf_ea %>%\n  filter(SAMPLE == 85405) # this sample corresponds to the 2017 wave\n\nggplot() +\n  geom_sf(data = bf_shp) +\n  geom_sf(data = bf_ea2017, \n          aes(size = N_SDP),\n          alpha = 0.4) \n\n\n\n\nFrom the map, it looks like there may be a few locations where there EAs are both close together and served by many SDPs, which are likely in urban areas. For example, the capital of Burkina Faso, Ouagadougou, is in the center of the map where there are a number of EAs on top of each other. But, it’s a little hard to see the variation in size when there are so many values for N_SDP and so many EAs on top of each other. Let’s do two things to make this more readable. First, we’ll create smaller categories of the N_SDP variable, and second, we’ll map the URBAN variable to the color aesthetic.\n\n\nbf_ea2017 <- bf_ea2017 %>%\n  mutate(\n    N_SDP_CAT = case_when(\n      N_SDP <= 2 ~ 1,\n      N_SDP >2 & N_SDP <= 4 ~ 2,\n      N_SDP >4 ~ 3),\n    N_SDP_CAT = factor(N_SDP_CAT,\n                       levels = c(1, 2, 3),\n                       labels = c(\"Low\", \"Mid\", \"High\"),\n                       ordered = T), # needs to be an ORDERED factor to map to the size aesthetic\n    MEAN_OUTDAY = ifelse(is.na(MEAN_OUTDAY), 0, MEAN_OUTDAY),\n    URBAN = factor(URBAN, \n                   levels = c(0,1),\n                   labels = c(\"Rural\", \"Urban\"))\n  )\n\n\n# let's take a look at the distribution of this new categorical variable\nbf_ea2017 %>% \n  tab(URBAN, N_SDP_CAT)\n\n\nSimple feature collection with 5 features and 5 fields\ngeometry type:  MULTIPOINT\ndimension:      XY\nbbox:           xmin: -5.18865 ymin: 9.883331 xmax: 1.634087 ymax: 14.39679\ngeographic CRS: WGS 84\n# A tibble: 5 x 6\n  URBAN N_SDP_CAT     N                        geometry  prop cum_prop\n  <fct> <ord>     <int>                <MULTIPOINT [°]> <dbl>    <dbl>\n1 Rural Mid          29 ((-5.18865 11.54962), (-4.3401…  0.35     0.35\n2 Urban Mid          23 ((-5.178223 10.66001), (-4.781…  0.28     0.63\n3 Urban Low          15 ((-4.307564 11.18051), (-4.299…  0.18     0.81\n4 Rural Low          13 ((-4.969563 10.45619), (-4.804…  0.16     0.96\n5 Urban High          3 ((-4.262726 11.14746), (-1.528…  0.04     1   \n\nggplot() +\n  geom_sf(data = bf_shp) +\n  geom_sf(data = bf_ea2017, \n          aes(size = N_SDP_CAT,\n              color = URBAN),\n          alpha = 0.4) +\n  scale_color_viridis_d() \n\n\n\n\nFrom this map we can see that urban areas are generally served by more SDPs – in fact, no rural EAs fall into the “High” category – although the difference is perhaps not as stark as one might have expected. But, what is the service environment like? Do urban areas have more stockouts than rural areas? Do SDPs in urban areas offer a greater selection of family planning methods? Did the service environment change between 2017 and 2018? Mapping can shed a lot of light on these questions.\nLet’s look at the NUM_METHODS_PROV variable created in the last post. This variable captures the number of family planning methods provided by at least one SDP that serves a given EA.\n\n\nbf_ea2017 %>%\n  tab(NUM_METHODS_PROV) %>%\n  arrange(NUM_METHODS_PROV)\n\n\nSimple feature collection with 5 features and 4 fields\ngeometry type:  MULTIPOINT\ndimension:      XY\nbbox:           xmin: -5.18865 ymin: 9.883331 xmax: 1.634087 ymax: 14.39679\ngeographic CRS: WGS 84\n# A tibble: 5 x 5\n  NUM_METHODS_PROV     N                       geometry  prop cum_prop\n             <dbl> <int>               <MULTIPOINT [°]> <dbl>    <dbl>\n1                8     2 ((-4.299839 11.18039), (-2.96…  0.02     1   \n2                9    13 ((-4.340111 11.8743), (-4.281…  0.16     0.92\n3               10    34 ((-5.18865 11.54962), (-4.969…  0.41     0.41\n4               11    29 ((-5.178223 10.66001), (-3.84…  0.35     0.76\n5               12     5 ((-2.757122 11.53829), (-2.26…  0.06     0.98\n\nSince there is not a large range of number of FP methods provided, let’s dichotomize this so we can map it to the shape aesthetic.\n\n\nbf_ea2017 <- bf_ea2017 %>%\n  mutate(\n    NUM_METHODS_CAT = case_when(\n      NUM_METHODS_PROV <= 9 ~ 1,\n      NUM_METHODS_PROV >9  ~ 2),\n    NUM_METHODS_CAT = factor(NUM_METHODS_CAT,\n                       levels = c(1, 2),\n                       labels = c(\"Low (<=9)\", \"High (>9)\"),\n                       ordered = T)\n  )\n\n\nggplot() +\n  geom_sf(data = bf_shp) +\n  geom_sf(data = bf_ea2017, \n          aes(size = NUM_METHODS_CAT,\n              shape = URBAN,\n              color = NUM_METHODS_OUT3MO),\n          alpha = 0.4) +\n  scale_color_viridis_c() \n\n\n\n\nPutting it All Together\nNow we have a map that shows spatial variation in availability of different methods of family planning and prevalence of stock-outs, as well as demonstrates how these characteristic differ across urban vs. rural EAs. It’s super quick to make a basic map like this, but let’s clean up a few things to make it look nicer.\n\n\nggplot() +\n  geom_sf(data = bf_shp, fill = \"#f2f2f5\") +\n  geom_sf(data = bf_ea2017, \n          aes(size = NUM_METHODS_CAT,\n              shape = URBAN,\n              color = NUM_METHODS_OUT3MO),\n          alpha = 0.4) +\n  scale_color_viridis_c(direction = -1) + # reversing the direction makes the high #s stand out more\n  labs(title = \"Spatial Variation in Family Planning Service Environment\",\n       subtitle = \"Burkina Faso 2017\",\n       caption = \"Source: IPUMS PMA\",\n       shape = \"\",\n       size = \"Methods\\nProvided\",\n       color = \"Out of Stock\\n(Past 3 Months)\",\n       x = NULL,\n       y = NULL) +\n  theme_minimal() +\n  theme(\n    axis.line = element_blank(),\n    axis.text.x = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks = element_blank(),\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank())\n\n\n\n\n\n\n\nThis map suggests there is spatial correlation to the stockouts – with 2 regions responsible for the majority of EAs with stockouts. It also looks like these EAs tend to have more methods provided by the SDPs that serve them. Finally, let’s use both years of data and see if there is any temporal variation. To do this, we’ll use the original bf_ea dataset (instead of sdp2017) and re-create the same NUM_METHODS_CAT factor variable that dichotomizes the NUM_METHODS_PROV variable. Then, we’ll use facet_wrap() to make a multi-panel plot, with one panel per year.\n\n\nbf_ea <- bf_ea %>%\n  mutate(\n    NUM_METHODS_CAT = case_when(\n      NUM_METHODS_PROV <= 9 ~ 1,\n      NUM_METHODS_PROV >9  ~ 2),\n    NUM_METHODS_CAT = factor(NUM_METHODS_CAT,\n                       levels = c(1, 2),\n                       labels = c(\"Low (<=9)\", \"High (>9)\"),\n                       ordered = T),\n    YEAR = case_when(\n      SAMPLE == 85405 ~ 2017,\n      SAMPLE == 85408 ~ 2018\n    ),\n    URBAN = factor(URBAN, \n                   levels = c(0,1),\n                   labels = c(\"Urban\", \"Rural\"))\n  )\n\nggplot() +\n  geom_sf(data = bf_shp, fill = \"#f2f2f5\") +\n  geom_sf(data = bf_ea, \n          aes(size = NUM_METHODS_CAT,\n              shape = URBAN,\n              color = NUM_METHODS_OUT3MO),\n          alpha = 0.4) +\n  facet_wrap(~ YEAR) +\n  # reversing the direction makes the high #s stand out more\n  scale_color_viridis_c(direction = -1) + \n  guides(color = guide_colorbar(barheight = .75,\n                                barwidth = 4.5,\n                                label.position = \"top\",\n                                label.hjust = 0)) + \n  labs(title = \"Spatial Variation in Family Planning Service Environment\",\n       subtitle = \"Burkina Faso 2017-2018\",\n       caption = \"Source: IPUMS PMA\",\n       shape = \"\",\n       size = \"Methods\\nProvided\",\n       color = \"# Methods\\nOut of Stock\\n(Past 3 Months)\",\n       x = NULL,\n       y = NULL) +\n  theme_minimal() +\n  theme(\n    axis.line = element_blank(),\n    axis.text.x = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks = element_blank(),\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    legend.title = element_text(size = 8),\n    legend.position = \"bottom\") \n\n\n\n\nWith the 2018 data included, it looks like the service environment may have improved between 2017 and 2018 with fewer stockouts. However, it also looks the EAs that faced more stockouts in 2017 are not always the same as those facing stockouts in 2018. But, there is still a spatial pattern to the stockouts in 2018. It also looks like some EAs had fewer family planning methods available from SDPs in 2018 than in 2017, specifically in the western part of the country.\nFuture posts may explore other supply-side factors that could influence the SDPs (and look at how these change over time) or examine demand-side factors by merging in the individual-level data.\nAs always, let us know what kinds of questions about fertility and family planning you’re answering – especially if you’re doing anything spatial!\n\n\n\n",
    "preview": "posts/2021-01-29-mapping-sdp-variables/images/bf_fp_map.png",
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {},
    "preview_width": 2100,
    "preview_height": 1350
  },
  {
    "path": "posts/2021-01-28-summarize-by-easerved/",
    "title": "Merging Service Delivery Point Data to Household & Female Records",
    "description": "Create aggregate measures for women living the areas served by SDPs",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-01-29",
    "categories": [
      "Individuals in Context",
      "Data Manipulation",
      "Service Delivery Points",
      "pivot_longer",
      "join"
    ],
    "contents": "\n\nContents\nReviewing SDP Sample Design\nSetup: Create and Load a Data Extract\nEAID and EASERVED\nPivot Longer: EASERVED in Rows\nSummarise by EASERVED and SAMPLE\nMerging to Household and Female Data\n\n\n\n\nWelcome to the third post in a series all about using PMA Service Delivery Point (SDP) data to better understand Individuals in Context. In our last post, we discussed a few of the variable groups related to contraceptive availability, and we showed how to use functions like dplyr::across to recode and summarize these variable groups in preparation for merging with Household and Female data.\nBefore we dive in, let’s quickly revisit the geographic sampling units - or enumeration areas - we’ll be using to link SDPs with their counterparts in the Household and Female data.\nReviewing SDP Sample Design\nRemember: the SDP sample design selects facilities meant to reflect the health service environment experienced by individuals included in Household and Female samples. If you were designing survey with this goal in mind, how would you select facilities?\nWell, you might target a sample of facilities located within the same geographic sampling units PMA used to define Household and Female samples from the same country in the same year. Presumably, the health services available to a woman living in enumeration area X would be captured pretty well if we surveyed a list of facilities also located in enumeration area X.\nBut what happens if a lot of women living in enumeration area X travel to enumeration area Y to receive family planning services? In that case, you’d want to know as much as possible about the service catchment areas for facilities in that country. Then, you could select facilities based on whether they provide services to enumeration area X, rather than relying simply to those that are located there.\nIn fact, PMA partners with government health agencies to obtain information about the service catchment area for all of the public-sector health facilities in each participating country. As a result, public SDPs are sampled if one of the enumeration areas used in a corresponding Household and Female sample appears in their service catchment area.\nBecause service catchment data are only available for public facilities, PMA uses a different method to select private-sector facilities. A private facility will be selected for a SDP sample only if it is located inside the boundaries of an enumeration area included in a corresponding Household and Female sample.\nSetup: Create and Load a Data Extract\nLet’s take a look at an example SDP dataset to see how all of this information gets reported. We’ll use the same data we highlighted in our last post, which includes facilities sampled from Burkina Faso in 2017 and 2018. First, load the following packages into R:\n\n\nlibrary(tidyverse)\nlibrary(ipumsr)\n\n\n\n\nCheck out our posts on R Packages and Loading IPUMS PMA data into R.\nAgain in this post, we’ll be working with all of the available contraceptive services and stock variables ending with the suffixes PROV, OBS, OUT3MO, and OUTDAY. We’ll also add the variable group EASERVED, which - as we’ll see - stores information about the service catchment area for facilities where that information was available. Finally, we’ll add a few more variables that we’ll explore a bit later: AUTHORITY, FACILITYTYPE, and FACILITYTYPEGEN.\nWe’ll first load the data using ipumsr::read_ipums_micro:\n\n\nsdp <- ipumsr::read_ipums_micro(\n  ddi = \"data/pma_00008.xml\",\n  data = \"data/pma_00008.dat.gz\") \n\n\n\n\nRemember: change these file paths to match your own data extract!\nThen, following the steps outlined in our last post, we’ll apply a couple of recoding functions from ipumsr.\n\n\nsdp <- sdp %>% \n  select(-EASERVED) %>% # error from extract system\n  mutate(\n    across(ends_with(\"OBS\"), ~lbl_relabel(\n      .x,\n      lbl(1, \"in stock\") ~ .val %in% 1:2,\n      lbl(0, \"out of stock\") ~ .val == 3\n    )),\n    across(everything(), ~lbl_na_if(\n      .x,\n      ~.lbl %in% c(\n        \"Not interviewed (SDP questionnaire)\",\n        \"Don't know\",\n        \"No response or missing\",\n        \"NIU (not in universe)\"\n      )\n    ))\n  )\n\n\n\nEAID and EASERVED\nFor the moment, let’s just take a look at the basic structure of our data, selecting only the variables FACILITYID, SAMPLE, AUTHORITY, CONSENTSQ, and EAID. For this preview, we’ll also arrange the data in ascending order of FACILITYID and SAMPLE:\nFACILITYID, SAMPLE, CONSENTSQ, and EAID are automatically included in every SDP data extract.\n\n\nsdp %>% \n  select(FACILITYID, SAMPLE, AUTHORITY, CONSENTSQ, EAID) %>% \n  arrange(FACILITYID, SAMPLE)\n\n\n# A tibble: 234 x 5\n   FACILITYID                      SAMPLE    AUTHORITY CONSENTSQ  EAID\n    <int+lbl>                   <int+lbl>    <int+lbl> <int+lbl> <dbl>\n 1       7006 85405 [Burkina Faso 2017 R… 1 [Governme…   1 [Yes]  7390\n 2       7006 85408 [Burkina Faso 2018 R… 1 [Governme…   1 [Yes]  7390\n 3       7027 85405 [Burkina Faso 2017 R… 1 [Governme…   1 [Yes]  7332\n 4       7027 85408 [Burkina Faso 2018 R… 1 [Governme…   1 [Yes]  7332\n 5       7029 85405 [Burkina Faso 2017 R… 4 [Private]    1 [Yes]  7111\n 6       7029 85408 [Burkina Faso 2018 R… 4 [Private]    0 [No]   7111\n 7       7036 85408 [Burkina Faso 2018 R… 1 [Governme…   1 [Yes]  7412\n 8       7046 85408 [Burkina Faso 2018 R… 4 [Private]    1 [Yes]  7798\n 9       7048 85405 [Burkina Faso 2017 R… 1 [Governme…   1 [Yes]  7009\n10       7051 85408 [Burkina Faso 2018 R… 1 [Governme…   1 [Yes]  7798\n# … with 224 more rows\n\nEach row in our data represents one facility from one sample. Notice that some - but not all - facilities appear once in sample 85405 (from 2017), and again in sample 85408 (from 2018).\nThe variable AUTHORITY shows the managing authority for each facility. Following the discussion above, we’ll expect to find information about the service catchment area for each facility where the managing authority is 1 - Government.\nAlso notice CONSENTSQ, which indicates whether a respondent at each facility consented to be interviewed. When you first obtain a data extract, you should expect most variables to be marked Not interviewed (SDP questionnaire) for facilities where CONSENTSQ shows 0 - No. However, we’ve already taken the extra step of marking all non-response values NA: we should now expect to see NA substituted for Not interviewed (SDP questionnaire).\nLastly, take particular note of the variable EAID: in SDP data, EAID shows the identification code associated with the enumeration area where a facility is located.\nWe’ll find information about the service catchment area for each facility in a different set of variables, each starting with with prefix EASERVED:\n\n\nsdp %>% \n  select(starts_with(\"EASERVED\")) \n\n\n# A tibble: 234 x 18\n   EASERVED1 EASERVED2 EASERVED3 EASERVED4 EASERVED5 EASERVED6\n   <int+lbl> <int+lbl> <int+lbl> <int+lbl> <int+lbl> <int+lbl>\n 1      7380      7323      7491      7605      7142      7279\n 2      7879      7516      7111      7554      7934      7791\n 3      7483        NA        NA        NA        NA        NA\n 4      7185        NA        NA        NA        NA        NA\n 5      7725      7859      7472      7175        NA        NA\n 6      7082        NA        NA        NA        NA        NA\n 7      7650        NA        NA        NA        NA        NA\n 8      7955        NA        NA        NA        NA        NA\n 9      7323        NA        NA        NA        NA        NA\n10      7774        NA        NA        NA        NA        NA\n# … with 224 more rows, and 12 more variables: EASERVED7 <int+lbl>,\n#   EASERVED8 <int+lbl>, EASERVED9 <int+lbl>, EASERVED10 <int+lbl>,\n#   EASERVED11 <int+lbl>, …\n\nYou’ll notice that our extract contains 18 EASERVED variables. Why 18? If you created your own data extract, you’ll remember that you only selected one variable called EASERVED: once you’ve selected samples, the IPUMS extract system automatically determines the correct number of EASERVED variables for your dataset based on the facility with the largest service catchment list.\n\nSome samples include facilities serving as many as 42 enumeration areas, requiring 42 EASERVED variables!\nAs we’ve discussed, PMA only receives service catchment information about public-sector facilities. In their case, each EASERVED variable contains an ID code for one of the enumeration areas in its service catchment list, or else it’s NA. We’ll look at these public-sector facilities first:\n\n\nsdp %>% count(AUTHORITY)\n\n\n# A tibble: 3 x 2\n        AUTHORITY     n\n*       <int+lbl> <int>\n1 1 [Government]    202\n2 3 [Faith-based]     3\n3 4 [Private]        29\n\nThe vast majority of SDPs in our sample are public-sector facilities. They comprise 202 of the 234 facilities in our sample.\n\n\nsdp %>% \n  filter(AUTHORITY == 1) %>% \n  select(starts_with(\"EASERVED\")) \n\n\n# A tibble: 202 x 18\n   EASERVED1 EASERVED2 EASERVED3 EASERVED4 EASERVED5 EASERVED6\n   <int+lbl> <int+lbl> <int+lbl> <int+lbl> <int+lbl> <int+lbl>\n 1      7380      7323      7491      7605      7142      7279\n 2      7879      7516      7111      7554      7934      7791\n 3      7483        NA        NA        NA        NA        NA\n 4      7185        NA        NA        NA        NA        NA\n 5      7725      7859      7472      7175        NA        NA\n 6      7082        NA        NA        NA        NA        NA\n 7      7650        NA        NA        NA        NA        NA\n 8      7955        NA        NA        NA        NA        NA\n 9      7323        NA        NA        NA        NA        NA\n10      7774        NA        NA        NA        NA        NA\n# … with 192 more rows, and 12 more variables: EASERVED7 <int+lbl>,\n#   EASERVED8 <int+lbl>, EASERVED9 <int+lbl>, EASERVED10 <int+lbl>,\n#   EASERVED11 <int+lbl>, …\n\nUsing two of the dplyr functions discussed in our last post - summarize and across - we’ll get a better sense of the catchment areas for our public-sector SDPs. Let’s see how many missing values exist for each of these EASERVED variables:\ndplyr is included when you load library(tidyverse)\n\n\nsdp %>% \n  filter(AUTHORITY == 1) %>% \n  summarise(across(starts_with(\"EASERVED\"), ~sum(is.na(.x))))\n\n\n# A tibble: 1 x 18\n  EASERVED1 EASERVED2 EASERVED3 EASERVED4 EASERVED5 EASERVED6\n      <int>     <int>     <int>     <int>     <int>     <int>\n1         0       156       173       181       190       192\n# … with 12 more variables: EASERVED7 <int>, EASERVED8 <int>,\n#   EASERVED9 <int>, EASERVED10 <int>, EASERVED11 <int>, …\n\nWe see that every public facility serves at least one enumeration area (there are no missing values for EASERVED1). However, there are 156 missing values for EASERVED2, which tells us that 156 public facilities only serve one enumeration area. Likewise: 173 facilities serve 2 enumeration areas or fewer, 181 serve 3 or fewer, and so forth.\nWhat about the 32 non-public facilities?\n\n\nsdp %>% \n  filter(AUTHORITY != 1) %>% \n  summarise(across(starts_with(\"EASERVED\"), ~sum(is.na(.x))))\n\n\n# A tibble: 1 x 18\n  EASERVED1 EASERVED2 EASERVED3 EASERVED4 EASERVED5 EASERVED6\n      <int>     <int>     <int>     <int>     <int>     <int>\n1         4        32        32        32        32        32\n# … with 12 more variables: EASERVED7 <int>, EASERVED8 <int>,\n#   EASERVED9 <int>, EASERVED10 <int>, EASERVED11 <int>, …\n\nPMA receives no information about the service catchment areas for these facilities, so - as you might expect - there are 32 missing values for EASERVED2 onward. Note, however, that there are only 4 missing values for EASERVED1: for non-public facilities, EASERVED1 usually contains that same enumeration area code shown in EAID (this is the enumeration area where the facility is, itself, located).\nThe exception to this rule comes from facilities where CONSENTSQ shows that no respondent provided consent to be interviewed. If we’d like, we can copy EAID to EASERVED1 for these facilities using dplyr::case_when:\n\n\nsdp <- sdp %>% \n  mutate(EASERVED1 = case_when(\n    is.na(EASERVED1) ~ EAID,\n    T ~ as.double(EASERVED1)\n  ))\n\n\n\n\nWe coerce EASERVED1 as a double, matching the class provided by EAID.\nNow, every SDP has at least one enumeration area included in the EASERVED group. This will be important in our next step, where we’ll see how to summarize the SDP data by groups of facilities serving the same enumeration area.\nPivot Longer: EASERVED in Rows\nNow that we’re familiar with EASERVED variables, let’s take a look at the kinds of summary statistics we might want to construct from variables related to contraceptive service availability. For example, consider EMRGPROV, which indicates whether a facility provides emergency contraceptives to clients.\nRemember that, right now, each row of our SDP dataset represents responses from one facility per sample. We’ll ultimately want to count the number of facilities providing emergency contraceptives to clients in each enumeration area, so we should use the tidyr function pivot_longer to reshape the data in a way that repeats each facility’s response to EMRGPROV once for every enumeration area that it serves.\ntidyr is included when you load library(tidyverse)\nTake, for example, the first 5 facilities in our dataset: for now, let’s just look at the first two EASERVED variables, along with each facility’s FACILITYID, EAID, and EMRGPROV response:\n\n\nsdp %>% \n  slice(1:5) %>% \n   select(FACILITYID, EASERVED1, EASERVED2, EMRGPROV)\n\n\n# A tibble: 5 x 4\n  FACILITYID EASERVED1 EASERVED2  EMRGPROV\n   <int+lbl>     <dbl> <int+lbl> <int+lbl>\n1       7250      7380      7323   0 [No] \n2       7399      7879      7516   0 [No] \n3       7506      7483        NA   0 [No] \n4       7982      7185        NA   0 [No] \n5       7065      7725      7859   1 [Yes]\n\nAmong these 5 facilities, only facility 7065 provides emergency contraceptives. This facility happens to provide services to 2 enumeration areas: 7725 and 7859. When we use pivot_longer, we’ll reshape the data to emphasize a different conclusion: our example shows two enumeration areas where individuals can access emergency contraceptives. We convey this information by placing each enumeration area from EASERVED1 or EASERVED2 in its own row:\n\n\nsdp %>% \n  slice(1:5) %>% \n  select(FACILITYID, EASERVED1, EASERVED2, EMRGPROV) %>% \n  pivot_longer(\n    cols = starts_with(\"EASERVED\"),\n    values_to = \"EASERVED\",\n    names_to = NULL\n  )\n\n\n# A tibble: 10 x 3\n   FACILITYID  EMRGPROV  EASERVED\n    <int+lbl> <int+lbl> <dbl+lbl>\n 1       7250   0 [No]       7380\n 2       7250   0 [No]       7323\n 3       7399   0 [No]       7879\n 4       7399   0 [No]       7516\n 5       7506   0 [No]       7483\n 6       7506   0 [No]         NA\n 7       7982   0 [No]       7185\n 8       7982   0 [No]         NA\n 9       7065   1 [Yes]      7725\n10       7065   1 [Yes]      7859\n\n\nHere, values_to gives the name of a new column where we store the values. If we wanted, we could use names_to to create another column storing the original variable names (EASERVED1 and EASERVED2) for each value.\nNow, we find that each of the values previously stored in EASERVED1 and EASERVED2 appear in a new column, EASERVED. Each facility occupies two rows: one for each of the enumeration areas that it serves.\nWhat about the rows where EASERVED contains NA? These rows are meaningless: we’re repeating each facility’s response to EMRGPROV twice to represent two enumeration areas, but facilities 7506 and 7982 only serve one enumeration area apiece. We should include the argument values_drop_na = T to drop these rows when we use pivot_longer():\n\n\nsdp %>% \n  slice(1:5) %>% \n  select(FACILITYID, EASERVED1, EASERVED2, EMRGPROV) %>% \n  pivot_longer(\n    cols = starts_with(\"EASERVED\"),\n    values_to = \"EASERVED\",\n    names_to = NULL,\n    values_drop_na = T\n  )\n\n\n# A tibble: 8 x 3\n  FACILITYID  EMRGPROV  EASERVED\n   <int+lbl> <int+lbl> <dbl+lbl>\n1       7250   0 [No]       7380\n2       7250   0 [No]       7323\n3       7399   0 [No]       7879\n4       7399   0 [No]       7516\n5       7506   0 [No]       7483\n6       7982   0 [No]       7185\n7       7065   1 [Yes]      7725\n8       7065   1 [Yes]      7859\n\nNow that we know how to pivot_longer, let’s apply the function to our full dataset:\n\n\nsdp <- sdp %>%\n  pivot_longer(\n    cols = starts_with(\"EASERVED\"),\n    values_to = \"EASERVED\",\n    values_drop_na = T,\n    names_to = NULL\n  ) %>%\n  distinct() # in case any facility listed the same EASERVED twice\n\n\n\nDropping each row where EASERVED is missing, we’re left with 372 rows where information about each SDP gets repeated once for every enumeration area that it serves. (Remember: our original dataset contained only 234 rows because SDPs occupied just one row apiece).\n\n\nsdp %>% select(FACILITYID, EASERVED, everything())\n\n\n# A tibble: 372 x 58\n   FACILITYID EASERVED      SAMPLE COUNTRY  YEAR ROUND  EAID CONSENTSQ\n    <int+lbl> <dbl+lb>   <int+lbl> <int+l> <int> <dbl> <dbl> <int+lbl>\n 1       7250     7380 85405 [Bur… 1 [Bur…  2017     5  7142   1 [Yes]\n 2       7250     7323 85405 [Bur… 1 [Bur…  2017     5  7142   1 [Yes]\n 3       7250     7491 85405 [Bur… 1 [Bur…  2017     5  7142   1 [Yes]\n 4       7250     7605 85405 [Bur… 1 [Bur…  2017     5  7142   1 [Yes]\n 5       7250     7142 85405 [Bur… 1 [Bur…  2017     5  7142   1 [Yes]\n 6       7250     7279 85405 [Bur… 1 [Bur…  2017     5  7142   1 [Yes]\n 7       7250     7370 85405 [Bur… 1 [Bur…  2017     5  7142   1 [Yes]\n 8       7250     7725 85405 [Bur… 1 [Bur…  2017     5  7142   1 [Yes]\n 9       7250     7811 85405 [Bur… 1 [Bur…  2017     5  7142   1 [Yes]\n10       7250     7859 85405 [Bur… 1 [Bur…  2017     5  7142   1 [Yes]\n# … with 362 more rows, and 50 more variables: STRATA <int+lbl>,\n#   FACILITYTYPE <int+lbl>, FACILITYTYPEGEN <int+lbl>,\n#   AUTHORITY <int+lbl>, CONPROV <int+lbl>, …\n\nSummarise by EASERVED and SAMPLE\nNow that we’ve reshaped our data, we’ll be able to create some simple summary statistics about each of the enumeration areas served by the facilities in our sample. First, let’s group_by(EASERVED, SAMPLE) and count() the number of facilities providing services to each enumeration area in each of our samples:\n\n\nsdp %>% \n  group_by(EASERVED, SAMPLE) %>% \n  summarize(\n    .groups = \"keep\", \n    N_SDP = n()\n  )\n\n\n# A tibble: 149 x 3\n# Groups:   EASERVED, SAMPLE [149]\n    EASERVED                            SAMPLE N_SDP\n   <dbl+lbl>                         <int+lbl> <int>\n 1      7003 85405 [Burkina Faso 2017 Round 5]     3\n 2      7003 85408 [Burkina Faso 2018 Round 6]     2\n 3      7006 85405 [Burkina Faso 2017 Round 5]     2\n 4      7006 85408 [Burkina Faso 2018 Round 6]     1\n 5      7009 85405 [Burkina Faso 2017 Round 5]     3\n 6      7009 85408 [Burkina Faso 2018 Round 6]     2\n 7      7016 85405 [Burkina Faso 2017 Round 5]     3\n 8      7016 85408 [Burkina Faso 2018 Round 6]     2\n 9      7026 85405 [Burkina Faso 2017 Round 5]     3\n10      7026 85408 [Burkina Faso 2018 Round 6]     3\n# … with 139 more rows\n\nContinuing with the variable EMRGPROV, we can now also count the number of sampled facilities providing emergency contraception to each EASERVED:\n\n\nsdp %>% \n  group_by(EASERVED, SAMPLE) %>% \n  summarize(\n    .groups = \"keep\",\n    N_EMRGPROV = sum(EMRGPROV)\n  )\n\n\n# A tibble: 149 x 3\n# Groups:   EASERVED, SAMPLE [149]\n    EASERVED                            SAMPLE N_EMRGPROV\n   <dbl+lbl>                         <int+lbl>      <int>\n 1      7003 85405 [Burkina Faso 2017 Round 5]          0\n 2      7003 85408 [Burkina Faso 2018 Round 6]          0\n 3      7006 85405 [Burkina Faso 2017 Round 5]          0\n 4      7006 85408 [Burkina Faso 2018 Round 6]          0\n 5      7009 85405 [Burkina Faso 2017 Round 5]          2\n 6      7009 85408 [Burkina Faso 2018 Round 6]          1\n 7      7016 85405 [Burkina Faso 2017 Round 5]          0\n 8      7016 85408 [Burkina Faso 2018 Round 6]          0\n 9      7026 85405 [Burkina Faso 2017 Round 5]          0\n10      7026 85408 [Burkina Faso 2018 Round 6]          0\n# … with 139 more rows\n\nWhat if we want to include a count of the facilities providing each of the different contraceptive methods in our data? Building on a technique showcased in our last post, we could use dplyr::across to iterate over all variables ending with the suffix PROV:\n\n\nsdp %>% \n  group_by(EASERVED, SAMPLE) %>% \n  summarize(\n    .groups = \"keep\",\n    across(ends_with(\"PROV\"), ~sum(.x), .names = \"N_{.col}\")\n  ) \n\n\n# A tibble: 149 x 15\n# Groups:   EASERVED, SAMPLE [149]\n   EASERVED      SAMPLE N_CONPROV N_CYCBPROV N_DEPOPROV N_DIAPROV\n   <dbl+lb>   <int+lbl>     <int>      <int>      <int>     <int>\n 1     7003 85405 [Bur…         3          3          3         0\n 2     7003 85408 [Bur…         2          2          2         0\n 3     7006 85405 [Bur…         2          2          2         0\n 4     7006 85408 [Bur…         1          1          1         0\n 5     7009 85405 [Bur…         3          1          3         0\n 6     7009 85408 [Bur…         2          2          2         0\n 7     7016 85405 [Bur…         3          3          3         0\n 8     7016 85408 [Bur…         2          1          2         0\n 9     7026 85405 [Bur…         3          3          3         0\n10     7026 85408 [Bur…         3          3          3         0\n# … with 139 more rows, and 9 more variables: N_EMRGPROV <int>,\n#   N_FCPROV <int>, N_FSTPROV <int>, N_FJPROV <int>, N_IMPPROV <int>,\n#   …\n\nWe’ll reduce this information even further, creating a variable NUM_METHODS_PROV indicating the number of methods provided by at least one sampled facility:\n\n\nsdp %>% \n  group_by(EASERVED, SAMPLE) %>% \n  summarize(\n    .groups = \"keep\",\n    across(ends_with(\"PROV\"), ~sum(.x), .names = \"N_{.col}\")\n  ) %>% \n  transmute(\n    EASERVED,\n    SAMPLE,\n    NUM_METHODS_PROV = sum(c_across(ends_with(\"PROV\")) > 0, na.rm = T)\n  )\n\n\n# A tibble: 149 x 3\n# Groups:   EASERVED, SAMPLE [149]\n    EASERVED                            SAMPLE NUM_METHODS_PROV\n   <dbl+lbl>                         <int+lbl>            <int>\n 1      7003 85405 [Burkina Faso 2017 Round 5]               10\n 2      7003 85408 [Burkina Faso 2018 Round 6]                8\n 3      7006 85405 [Burkina Faso 2017 Round 5]               10\n 4      7006 85408 [Burkina Faso 2018 Round 6]                8\n 5      7009 85405 [Burkina Faso 2017 Round 5]                9\n 6      7009 85408 [Burkina Faso 2018 Round 6]               10\n 7      7016 85405 [Burkina Faso 2017 Round 5]                9\n 8      7016 85408 [Burkina Faso 2018 Round 6]                8\n 9      7026 85405 [Burkina Faso 2017 Round 5]               10\n10      7026 85408 [Burkina Faso 2018 Round 6]               10\n# … with 139 more rows\n\nIn our last post, we introduced 4 variable groups related to the availability of different contraceptive methods. We’ll now create a summary variable for each one, and then show how to attach our new variables to a Household and Female dataset:\nN_SDP - number of SDPs\nNUM_METHODS_PROV - number of methods provided by at least one SDP\nNUM_METHODS_INSTOCK - number of methods in-stock with at least one SDP\nNUM_METHODS_OUT3MO - number of methods out of stock in the last 3 months with at least one SDP\nMEAN_OUTDAY - the mean length of a stockout for all out of stock methods\n\n\nsdp <- sdp %>% \n  group_by(EASERVED, SAMPLE) %>% \n  summarize(\n    .groups = \"keep\",\n    N_SDP = n(),\n    across(ends_with(\"PROV\"), ~sum(.x, na.rm = T), .names = \"N_{.col}\"),\n    across(ends_with(\"OBS\"), ~sum(.x, na.rm = T), .names = \"N_{.col}\"),\n    across(ends_with(\"OUT3MO\"), ~sum(.x, na.rm = T), .names = \"N_{.col}\"),\n    across(ends_with(\"OUTDAY\"), ~mean(.x, na.rm = T), .names = \"N_{.col}\"),\n  ) %>% \n  transmute(\n    EASERVED,\n    SAMPLE,\n    N_SDP,\n    NUM_METHODS_PROV = sum(c_across(ends_with(\"PROV\")) > 0, na.rm = T),\n    NUM_METHODS_INSTOCK = sum(c_across(ends_with(\"OBS\")) > 0, na.rm = T),\n    NUM_METHODS_OUT3MO = sum(c_across(ends_with(\"OUT3MO\")) > 0, na.rm = T),\n    MEAN_OUTDAY = mean(c_across(ends_with(\"OUTDAY\")), na.rm = T)\n  ) %>% \n  ungroup()\n\n\n\nMerging to Household and Female Data\nConsider the following female respondent dataset collected from Burkina Faso in 2017 and 2018. It contains a variable FPCURRUSE indicating whether the woman is currently using a method of family planning:\n\n\nhhf <- read_ipums_micro(\n  ddi = \"data/pma_00011.xml\",\n  data = \"data/pma_00011.dat.gz\"\n) %>% \n  select(PERSONID, EAID, URBAN, SAMPLE, FPCURRUSE) %>% \n  mutate(\n    across(everything(), ~lbl_na_if(\n      .x,\n      ~.lbl %in% c(\n        \"No response or missing\",\n        \"NIU (not in universe)\"\n      )\n    ))\n  )\n\n\n\n\n\nhhf\n\n\n# A tibble: 6,944 x 5\n   PERSONID           EAID    URBAN                   SAMPLE FPCURRUSE\n   <chr>             <dbl> <int+lb>                <int+lbl> <int+lbl>\n 1 0762000000029022…  7620 1 [Urba… 85405 [Burkina Faso 201…  NA      \n 2 0735800000017142…  7358 0 [Rura… 85405 [Burkina Faso 201…   0 [No] \n 3 0710400000020992…  7104 0 [Rura… 85405 [Burkina Faso 201…   0 [No] \n 4 0704800000014092…  7048 1 [Urba… 85405 [Burkina Faso 201…   0 [No] \n 5 0715600000020782…  7156 0 [Rura… 85405 [Burkina Faso 201…   0 [No] \n 6 0727900000021452…  7279 1 [Urba… 85405 [Burkina Faso 201…   0 [No] \n 7 0743100000024642…  7431 0 [Rura… 85405 [Burkina Faso 201…   1 [Yes]\n 8 0721200000025792…  7212 0 [Rura… 85405 [Burkina Faso 201…   0 [No] \n 9 0704200000014542…  7042 1 [Urba… 85405 [Burkina Faso 201…   0 [No] \n10 0797200000013032…  7972 1 [Urba… 85405 [Burkina Faso 201…   0 [No] \n# … with 6,934 more rows\n\nYou’ll notice that each row represents one female respondent with a unique PERSONID (non-respondents and other household members have been removed beforehand). We’ve also got EAID, which represents the enumeration area where each respondent resides; the variable URBAN indicates whether the enumeration area is primarily “urban” or “rural”.\nThe variable SAMPLE contains the same values seen in our SDP data:\n85405 - Burkina Faso 2017 Round 5\n85408 - Burkina Faso 2018 Round 6\nWhen we merge, we’ll want to match each woman to both a SAMPLE and an EASERVED from the SDP data. We’ll rename EASERVED to match the variable EAID in the HHF data:\n\n\nbf_merged <- sdp %>% \n  rename(EAID = EASERVED) %>% \n  right_join(hhf, by = c(\"EAID\", \"SAMPLE\"))\n\n\n\nNow, each woman’s record contains all of the variables we created above summarizing the SDPs that serve her enumeration area. For example, for all sampled women living in EAID == 7003 in 2017, the value in NUM_METHODS_OUT3MO shows the number of family planning methods that were out of stock with any SDP serving the woman’s enumeration area within three months prior to the survey:\n\n\nbf_merged %>% \n  filter(EAID == 7003, SAMPLE == 85405) %>% \n  select(PERSONID, EAID, SAMPLE, NUM_METHODS_OUT3MO)\n\n\n# A tibble: 55 x 4\n   PERSONID             EAID                  SAMPLE NUM_METHODS_OUT3…\n   <chr>            <dbl+lb>               <int+lbl>             <int>\n 1 070030000001973…     7003 85405 [Burkina Faso 20…                 0\n 2 070030000001973…     7003 85405 [Burkina Faso 20…                 0\n 3 070030000002640…     7003 85405 [Burkina Faso 20…                 0\n 4 070030000001075…     7003 85405 [Burkina Faso 20…                 0\n 5 070030000001609…     7003 85405 [Burkina Faso 20…                 0\n 6 070030000000835…     7003 85405 [Burkina Faso 20…                 0\n 7 070030000001273…     7003 85405 [Burkina Faso 20…                 0\n 8 070030000000527…     7003 85405 [Burkina Faso 20…                 0\n 9 070030000002561…     7003 85405 [Burkina Faso 20…                 0\n10 070030000002391…     7003 85405 [Burkina Faso 20…                 0\n# … with 45 more rows\n\nYou’ll notice that 55 women were surveyed in EAID 7003 in 2017, and each one has the same value (0) for NUM_METHODS_OUT3MO.\nWe’ll dig deeper into the types of research questions that our new combined dataset can answer in our upcoming Data Analysis post. For now, take a look at the apparent relationship between FPCURRUSE and NUM_METHODS_OUT3MO for all of the women with non-missing responses for both variables:\n\n\nbf_merged %>% \n  filter(!is.na(FPCURRUSE) & !is.na(NUM_METHODS_OUT3MO)) %>% \n  group_by(NUM_METHODS_OUT3MO > 0) %>% \n  count(FPCURRUSE) %>% \n  mutate(pct = n/sum(n))\n\n\n# A tibble: 4 x 4\n# Groups:   NUM_METHODS_OUT3MO > 0 [2]\n  `NUM_METHODS_OUT3MO > 0` FPCURRUSE     n   pct\n  <lgl>                    <int+lbl> <int> <dbl>\n1 FALSE                      0 [No]   2721 0.648\n2 FALSE                      1 [Yes]  1475 0.352\n3 TRUE                       0 [No]   1124 0.700\n4 TRUE                       1 [Yes]   482 0.300\n\nNotably, among those respondents living in an enumeration area that experienced zero stockouts within the 3 months prior to the SDP survey, 35% indicated that they were actively using a family planning method. Compare that to the set of respondents living in an area where at least one method was out of stock during the same time period: only 30% were using a family planning method.\nWhile a 5% difference may or may not prove to be statistically significant under further analysis, it’s not entirely surprising that the reliable availability of contraceptive methods from service providers might influence the contraceptive prevalence rate among women in a given area.\nAs always, let us know what kinds of questions about fertility and family planning you’re answering with data merged from service providers!\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-28-across-sdp/",
    "title": "Recode and Summarize Variables from Multiple Response Questions",
    "description": "Use dplyr::across to summarize variables with a similar naming pattern.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-01-28",
    "categories": [
      "Individuals in Context",
      "Data Manipulation",
      "Service Delivery Points",
      "across",
      "ipumsr"
    ],
    "contents": "\n\nContents\nSDP Multiple Response Questions\nSetup: Load an Example Dataset into R\nRecoding Variables with ipumsr\nIntroducing dplyr::across\nSummarize Variable Groups by Facility\nSummarize Variable Groups by EAID\n\n\n\n\nIn our last post, we introduced PMA Service Delivery Point (SDP) data as an important resource for understanding the health services environment experienced by individuals sampled in PMA Household and Female data. For our second post in this Individuals in Context series, we’ll now take deeper dive into one of the important topics in SDP data: the range and availability of contraceptive methods provided at each facility.\nA common feature of the variables in this topic - and in many other topics - is that you’ll find several binary indicators constructed from the same multiple resposne item on the SDP questionnaire. We’ll see that IPUMS PMA uses a common naming convention to help users group these variables together for use in functions like dplyr::across.\nSDP Multiple Response Questions\nEvery SDP respondent receives a question associated with the variable FPOFFERED, which indicates whether to facility usually offers family planning services or products:\nDo you usually offer family planning services / products?\n\n  [] Yes\n  [] No\n  [] No response\nIf yes, they’ll then receive a multiple response-type question asking about the contraceptive methods provided to clients. The range of options provided on the questionnaire may vary across samples, but most look something like this:\nWhich of the following methods are provided to clients at this facility? \n\n  [] Female sterilization\n  [] Male sterilization\n  [] Implant\n  [] IUD\n  [] Injectables - Depo Provera\n  [] Injectables - Sayana Press\n  [] Pill\n  [] Emergency Contraception\n  [] Male Condom\n  [] Female Condom\n  [] Diaphragm\n  [] Foam/Jelly\n  [] Std. Days / Cycle beads\n  [] None of the above\n  [] No response\n\nIf the response to FPOFFERED was not “Yes”, this question will be skipped and marked “NIU (not in universe)”.\nThis is a multiple response question: each method in the list could be answered individually (Yes or No), or the respondent could reply None of the above or provide No response. The IPUMS PMA extract system generates one variable for each of the methods in the list:\nFSTPROV\nMSTPROV\nIMPPROV\nIUDPROV\nDEPOPROV\nSAYPROV\nPILLPROV\nEMRGPROV\nCONPROV\nFCPROV\nDIAPROV\nFJPROV\nCYCBPROV\nThe questionnaire continues for each one of the methods provided at a given facility. Next, it checks for the current availability of each of the provided methods:\nYou mentioned that you typically provide the [METHOD] at this facility,\ncan you show it to me? If no, probe: Is the [METHOD] out of stock today?\n\n  [] In-stock and observed\n  [] In-stock but not observed\n  [] Out of stock\n  [] No Response\nThe variables associated with each response end with the same suffix OBS:\nIMPOBS\nIUDOBS\nDEPOOBS\nSAYOBS\nPILLOBS\nEMRGOBS\nCONOBS\nFCOBS\nDIAOBS\nFJOBS\nCYCBOBS\nSterilization methods were not included in this question.\nNote: if a given method was not provided at a facility, it would be skipped and marked “NIU (not in universe)”.\nYou can always visit a variable’s Universe tab for details.\nIf a facility did have a particular method in-stock, it received a question asking whether supplies were unavailable any time in the previous three months:\nHas the [METHOD] been out of stock at any time in the last 3 months?\n\n  [] Yes \n  [] No \n  [] Don't know\n  [] No response\nThis question becomes a series of variables ending with the suffix OUT3MO:\nIMPOUT3MO\nIUDOUT3MO\nDEPOOUT3MO\nSAYOUT3MO\nPILLOUT3MO\nEMRGOUT3MO\nCONOUT3MO\nFCOUT3MO\nDIAOUT3MO\nFJOUT3MO\nCYCBOUT3MO\nAgain, sterilization methods were not included in this question.\nNote: if a given method was not in-stock at a facility where it’s normally provided, it would be skipped and marked “NIU (not in universe)”.\nOn the other hand, if a facility that normally provides a given method did not have supplies in-stock during the interview, it received a different question about the duration of the current stockout:\nHow many days has the [METHOD] been out of stock?\n\n  Number of days____\nThe resulting variables - each ending with the suffix OUTDAY - take an integer value representing the stockout duration in days (except where the value is a non-response code, see below):\nIMPOUTDAY\nIUDOUTDAY\nDEPOOUTDAY\nSAYOUTDAY\nPILLOUTDAY\nEMRGOUTDAY\nCONOUTDAY\nFCOUTDAY\nDIAOUTDAY\nFJOUTDAY\nCYCBOUTDAY\nAgain, sterilization methods were not included in this question.\nNote: if a given method was in-stock at a facility where it’s normally provided, it would be skipped and marked “NIU (not in universe)”.\nSetup: Load an Example Dataset into R\nAs you can see, we’re left with quite a few variables from just these 4 questions! That’s very useful if you’re interested in the availability of one method, in particular, but what if you want to get a picture of the full range of methods provided at a particular facility?\nFortunately, the repeated use of variable suffixes (PROV, OBS, OUT3MO, and OUTDAY) make these variables highly suitable for column-wise processing with dplyr::across.\nLet’s start with an example data extract containing all of the variables listed above, collected from just two samples:\nBurkina Faso - 2018 R6\nBurkina Faso - 2017 R5\nOnce you’ve downloaded an extract, open RStudio and load the packages tidyverse and ipumsr:\n\n\nlibrary(tidyverse)\nlibrary(ipumsr)\n\n\n\n\nCheck out our posts on R Packages and Loading IPUMS PMA data into R.\nNext, use the file paths for your data extract to load it into R:\n\n\nsdp <- ipumsr::read_ipums_micro(\n  ddi = \"data/pma_00008.xml\",\n  data = \"data/pma_00008.dat.gz\"\n)\n\n\n\n\nRemember: change these file paths to match your own extract!\nUsing dplyr::ends_with, we’ll select only FACILITYID, SAMPLE, EAID, and the variables using one of the four suffixes PROV, OBS, OUT3MO, or OUTDAY.\n\n\nsdp <- sdp %>%  \n  select(\n    FACILITYID,\n    SAMPLE, \n    EAID, \n    ends_with(\"PROV\"),\n    ends_with(\"OBS\"),\n    ends_with(\"OUT3MO\"),\n    ends_with(\"OUTDAY\")\n  )\n\n\n\nThat leaves us with 234 rows - each a facility from one of our two samples - and 49 variables:\n\n\nsdp\n\n\n# A tibble: 234 x 49\n   FACILITYID          SAMPLE  EAID  CONPROV CYCBPROV DEPOPROV DIAPROV\n    <int+lbl>       <int+lbl> <dbl> <int+lb> <int+lb> <int+lb> <int+l>\n 1       7250 85405 [Burkina…  7142  1 [Yes]  1 [Yes]  1 [Yes]  0 [No]\n 2       7399 85405 [Burkina…  7879  1 [Yes]  1 [Yes]  1 [Yes]  0 [No]\n 3       7506 85405 [Burkina…  7483  1 [Yes]  1 [Yes]  1 [Yes]  0 [No]\n 4       7982 85405 [Burkina…  7185  1 [Yes]  1 [Yes]  1 [Yes]  0 [No]\n 5       7065 85405 [Burkina…  7859  1 [Yes]  1 [Yes]  1 [Yes]  0 [No]\n 6       7729 85405 [Burkina…  7082  1 [Yes]  0 [No]   1 [Yes]  0 [No]\n 7       7490 85405 [Burkina…  7650  1 [Yes]  1 [Yes]  1 [Yes]  0 [No]\n 8       7311 85405 [Burkina…  7955  1 [Yes]  1 [Yes]  1 [Yes]  0 [No]\n 9       7524 85405 [Burkina…  7323  1 [Yes]  1 [Yes]  1 [Yes]  0 [No]\n10       7932 85405 [Burkina…  7774  1 [Yes]  1 [Yes]  1 [Yes]  0 [No]\n# … with 224 more rows, and 42 more variables: EMRGPROV <int+lbl>,\n#   FCPROV <int+lbl>, FSTPROV <int+lbl>, FJPROV <int+lbl>,\n#   IMPPROV <int+lbl>, IUDPROV <int+lbl>, MSTPROV <int+lbl>,\n#   PILLPROV <int+lbl>, SAYPROV <int+lbl>, CONOBS <int+lbl>,\n#   CYCBOBS <int+lbl>, DEPOOBS <int+lbl>, DIAOBS <int+lbl>,\n#   EMRGOBS <int+lbl>, FCOBS <int+lbl>, FJOBS <int+lbl>,\n#   IMPOBS <int+lbl>, IUDOBS <int+lbl>, PILLOBS <int+lbl>,\n#   SAYOBS <int+lbl>, CONOUT3MO <int+lbl>, CYCBOUT3MO <int+lbl>,\n#   DEPOOUT3MO <int+lbl>, DIAOUT3MO <int+lbl>, EMRGOUT3MO <int+lbl>,\n#   FCOUT3MO <int+lbl>, FJOUT3MO <int+lbl>, IMPOUT3MO <int+lbl>,\n#   IUDOUT3MO <int+lbl>, PILLOUT3MO <int+lbl>, SAYOUT3MO <int+lbl>,\n#   CONOUTDAY <int+lbl>, CYCBOUTDAY <int+lbl>, DEPOOUTDAY <int+lbl>,\n#   DIAOUTDAY <int+lbl>, EMRGOUTDAY <int+lbl>, FCOUTDAY <int+lbl>,\n#   FJOUTDAY <int+lbl>, IMPOUTDAY <int+lbl>, IUDOUTDAY <int+lbl>,\n#   PILLOUTDAY <int+lbl>, SAYOUTDAY <int+lbl>\n\nRecoding Variables with ipumsr\nA key feature to remember about IPUMS PMA extracts is that variables often have value labels, which are text labels assigned to the different values taken by a variable. When we load the extract into R with an ipumsr function, these variables are imported as labelled objects rather than the more common factor class of objects.\nMore information on the difference between factors and IPUMS labelled variables.\nAs a result, IPUMS data users need to take some unusual steps when recoding a variable or handling NA values. Happily, the ipumsr package provide a few functions (starting with the prefix lbl_) that make this process very easy.\nLet’s take a look at the variable CONOBS:\n\n\nsdp %>% count(CONOBS)\n\n\n# A tibble: 5 x 2\n                                    CONOBS     n\n                                 <int+lbl> <int>\n1  1 [In-stock and observed]                 204\n2  2 [In-stock but not observed]               3\n3  3 [Out of stock]                            5\n4 94 [Not interviewed (SDP questionnaire)]     4\n5 99 [NIU (not in universe)]                  18\n\nNotice that we have two values representing SDPs with male condoms “in-stock”: SDPs where the interviewer personally observed the condoms get 1, while those where condoms where reported in-stock - but not actually observed by the interviewer - get 2.\nDepending on your research question, the interviewer’s personal observation of each method may or may not be important. You might decide that you’d prefer to recode this variable into a simple binary measure that could be easily plugged into a regression model as a dummy variable later on. To do that, you could use the ipumsr function lbl_relabel:\n\n\nsdp %>% \n  mutate(CONOBS = lbl_relabel(\n      CONOBS,\n      lbl(1, \"In-stock\") ~ .val %in% 1:2,\n      lbl(0, \"Out of stock\") ~ .val == 3\n    )) %>% \n  count(CONOBS)\n\n\n# A tibble: 4 x 2\n                                    CONOBS     n\n                                 <dbl+lbl> <int>\n1  0 [Out of stock]                            5\n2  1 [In-stock]                              207\n3 94 [Not interviewed (SDP questionnaire)]     4\n4 99 [NIU (not in universe)]                  18\n\n\n\n\n\n© 2017 (MPL 2.0)\nThat collapses the values 1 and 2 together, and it moves the value 3 (“Out of stock”) to 0. However, we’ve still got a the values 94 and 99, which are each a different type of non-response. The easiest strategy here would be to recode any value larger than 90 as NA, and we could do that with another ipumsr function, lbl_na_if:\n\n\nsdp %>% \n  mutate(\n    CONOBS = lbl_relabel(\n      CONOBS,\n      lbl(1, \"in-stock\") ~ .val %in% 1:2,\n      lbl(0, \"out of stock\") ~ .val == 3\n    ),\n    CONOBS = lbl_na_if(\n      CONOBS,\n      ~.val > 90\n    )\n  ) %>% \n  count(CONOBS)\n\n\n# A tibble: 3 x 2\n             CONOBS     n\n          <dbl+lbl> <int>\n1  0 [out of stock]     5\n2  1 [in-stock]       207\n3 NA                   22\n\nThis works great for our example variable, CONOBS. Unfortunately, though, we can’t always rely on the rule ~.val > 90 to handle missing responses. For variables like CONOUTDAY, a value above 90 could be a valid response: what if a facility experienced a stockout lasting 94 days? For this reason, the non-response values for CONOUTDAY are padded with additional digits:\n\n\nsdp %>% count(CONOUTDAY)\n\n\n# A tibble: 7 x 2\n                                   CONOUTDAY     n\n                                   <int+lbl> <int>\n1    1                                           1\n2    3                                           1\n3   10                                           1\n4   15                                           1\n5   60                                           1\n6 9994 [Not interviewed (SDP questionnaire)]     4\n7 9999 [NIU (not in universe)]                 225\n\nWe could write a different lbl_na_if function for our OUTDAY variables, but ipumsr provides a much nicer workaround: we can specify non-response labels rather than values, as long as we make sure to use all of the different non-response labels appearing throughout our dataset:\n\n\nsdp %>% \n  mutate(\n    CONOBS = lbl_relabel(\n      CONOBS,\n      lbl(1, \"in-stock\") ~ .val %in% 1:2,\n      lbl(0, \"out of stock\") ~ .val == 3\n    ),\n    CONOBS = lbl_na_if(\n      CONOBS,\n      ~.lbl %in% c(\n        \"Not interviewed (SDP questionnaire)\",\n        \"Don't know\",\n        \"No response or missing\",\n        \"NIU (not in universe)\"\n      )\n    )\n  ) %>% \n  count(CONOBS)\n\n\n# A tibble: 3 x 2\n             CONOBS     n\n          <dbl+lbl> <int>\n1  0 [out of stock]     5\n2  1 [in-stock]       207\n3 NA                   22\n\nNow, we’ll be able to recode all of our variables with the same pair of functions! To do that, we’ll first need to take a look at the column-wise workflow made available by dplyr::across.\nIntroducing dplyr::across\nWhile there are several ways to apply a function across a set of variables in R, the simplest method comes from a new addition to the dplyr package that’s loaded when you run library(tidyverse). The function dplyr::across takes two arguments: a function, and a selection of columns where you want that function to be applied.\ndplyr is included when you load library(tidyverse)\nRemember that we want collapse the values 1 - In-stock and observed and 2 - In-stock but not observed for all of the variables ending with OBS, not just CONOBS. Using across and a selection of variables ending with OBS, we’ll apply the same lbl_relabel function we used on CONOBS above:\n\n\nsdp %>% \n  mutate(\n    across(ends_with(\"OBS\"), ~lbl_relabel(\n      .x,\n      lbl(1, \"in-stock\") ~ .val %in% 1:2,\n      lbl(0, \"out of stock\") ~ .val == 3\n    )) \n  ) %>% \n  count(CONOBS)\n\n\n# A tibble: 4 x 2\n                                    CONOBS     n\n                                 <dbl+lbl> <int>\n1  0 [out of stock]                            5\n2  1 [in-stock]                              207\n3 94 [Not interviewed (SDP questionnaire)]     4\n4 99 [NIU (not in universe)]                  18\n\n\n\n\n\n© 2018 RStudio (CC0 1.0)\nHere, we stick lbl_relabel inside a lambda function with syntax from purrr: the ~ designates a tidy lambda function, which in turn uses .x as a kind of pronoun referencing each of the variables returned by ends_with(\"OBS\"). We’re showing that CONOBS still gets recoded as before, but so do all of the other variables in its group!\nWe’ll use across again with lbl_na_if, but this time we want to produce NA values for all of the variables in our dataset. In place of ends_with(\"OBS\"), we’ll use the selection function everything(). This will take care of all the recoding we want to do, so we’ll also reassign our data with sdp <- sdp:\n\n\nsdp <- sdp %>% \n  mutate(\n    across(ends_with(\"OBS\"), ~lbl_relabel(\n      .x,\n      lbl(1, \"in-stock\") ~ .val %in% 1:2,\n      lbl(0, \"out of stock\") ~ .val == 3\n    )),\n    across(everything(), ~lbl_na_if(\n      .x,\n      ~.lbl %in% c(\n        \"Not interviewed (SDP questionnaire)\",\n        \"Don't know\",\n        \"No response or missing\",\n        \"NIU (not in universe)\"\n      )\n    ))\n  )\n\n\n\nLet’s pick a few variables to check out work:\n\n\nsdp %>% count(CONOBS)\n\n\n# A tibble: 3 x 2\n             CONOBS     n\n          <dbl+lbl> <int>\n1  0 [out of stock]     5\n2  1 [in-stock]       207\n3 NA                   22\n\nsdp %>% count(IMPOBS)\n\n\n# A tibble: 3 x 2\n             IMPOBS     n\n          <dbl+lbl> <int>\n1  0 [out of stock]     3\n2  1 [in-stock]       204\n3 NA                   27\n\nsdp %>% count(CONOUTDAY)\n\n\n# A tibble: 6 x 2\n  CONOUTDAY     n\n  <int+lbl> <int>\n1         1     1\n2         3     1\n3        10     1\n4        15     1\n5        60     1\n6        NA   229\n\nsdp %>% count(IMPOUTDAY)\n\n\n# A tibble: 4 x 2\n  IMPOUTDAY     n\n  <int+lbl> <int>\n1         1     1\n2        14     1\n3        90     1\n4        NA   231\n\nSummarize Variable Groups by Facility\nEverything looks great! Now that we’ve finished reformatting the data, remember that our ultimate goal is to get some sense of the scope of methods available at a particular facility.\nWe’d like to use something like across again here, but this time we’ll only want to apply our function to a selection of columns within the same row (because each row of our dataset represents one facility). To do this, we’ll divide the dataset rowwise, and then use the related function c_across to apply a calculation across columns within each row.\nFor instance, suppose we want to create NUM_METHODS_PROV to show the total number of methods provided at each facility. Let’s look at the PROV variables for the first few facilities:\n\n\nsdp %>% select(ends_with(\"PROV\"))\n\n\n# A tibble: 234 x 13\n    CONPROV  CYCBPROV DEPOPROV DIAPROV EMRGPROV  FCPROV FSTPROV FJPROV\n   <int+lb> <int+lbl> <int+lb> <int+l> <int+lb> <int+l> <int+l> <int+>\n 1  1 [Yes]   1 [Yes]  1 [Yes]  0 [No]  0 [No]  1 [Yes] 1 [Yes] 0 [No]\n 2  1 [Yes]   1 [Yes]  1 [Yes]  0 [No]  0 [No]  1 [Yes] 1 [Yes] 0 [No]\n 3  1 [Yes]   1 [Yes]  1 [Yes]  0 [No]  0 [No]  1 [Yes] 0 [No]  0 [No]\n 4  1 [Yes]   1 [Yes]  1 [Yes]  0 [No]  0 [No]  1 [Yes] 0 [No]  0 [No]\n 5  1 [Yes]   1 [Yes]  1 [Yes]  0 [No]  1 [Yes] 1 [Yes] 1 [Yes] 0 [No]\n 6  1 [Yes]   0 [No]   1 [Yes]  0 [No]  0 [No]  1 [Yes] 1 [Yes] 0 [No]\n 7  1 [Yes]   1 [Yes]  1 [Yes]  0 [No]  0 [No]  1 [Yes] 0 [No]  0 [No]\n 8  1 [Yes]   1 [Yes]  1 [Yes]  0 [No]  0 [No]  1 [Yes] 1 [Yes] 0 [No]\n 9  1 [Yes]   1 [Yes]  1 [Yes]  0 [No]  0 [No]  1 [Yes] 0 [No]  0 [No]\n10  1 [Yes]   1 [Yes]  1 [Yes]  0 [No]  0 [No]  1 [Yes] 0 [No]  0 [No]\n# … with 224 more rows, and 5 more variables: IMPPROV <int+lbl>,\n#   IUDPROV <int+lbl>, MSTPROV <int+lbl>, PILLPROV <int+lbl>,\n#   SAYPROV <int+lbl>\n\nTo calculate NUM_METHODS_PROV, we can just find the sum of values across all of the PROV variables (thanks to our recoding work, the only possible values here are 1 for “yes”, or 0 for “no”). Notice that c_across takes only one argument: a selection function like ends_with(\"PROV\"). That’s because c_across works like the familiar concatenate function c() used to provide a vector of values to a function like sum(c(1,2,3)).\nFirst, use rowwise() to signal that we’ll only calculate the sum across variables in the same row. Then, use c_across() to find the sum() of PROV variables in each row:\n\n\nsdp %>% \n  rowwise() %>% \n  transmute(NUM_METHODS_PROV = sum(c_across(ends_with(\"PROV\")), na.rm = T))\n\n\n# A tibble: 234 x 1\n# Rowwise: \n   NUM_METHODS_PROV\n              <int>\n 1               10\n 2               10\n 3                8\n 4                8\n 5               10\n 6                9\n 7                8\n 8               10\n 9                8\n10                8\n# … with 224 more rows\n\nWe can now create a summary variable for each of the four variable groups. Let’s create:\nNUM_METHODS_PROV - number of methods provided\nNUM_METHODS_INSTOCK - number of methods in-stock\nNUM_METHODS_OUT3MO - number of methods out of stock in the last 3 months\nMEAN_OUTDAY - the mean length of a stockout for all out of stock methods\n\n\nsdp %>% \n  rowwise() %>% \n  transmute(\n    NUM_METHODS_PROV = sum(c_across(ends_with(\"PROV\")), na.rm = T),\n    NUM_METHODS_INSTOCK = sum(c_across(ends_with(\"OBS\")), na.rm = T),\n    NUM_METHODS_OUT3MO = sum(c_across(ends_with(\"OUT3MO\")), na.rm = T),\n    MEAN_OUTDAY = mean(c_across(ends_with(\"OUTDAY\")), na.rm = T)\n  )\n\n\n# A tibble: 234 x 4\n# Rowwise: \n   NUM_METHODS_PROV NUM_METHODS_INSTOCK NUM_METHODS_OUT3MO MEAN_OUTDAY\n              <int>               <dbl>              <int>       <dbl>\n 1               10                   8                  0         NaN\n 2               10                   7                  0           8\n 3                8                   8                  0         NaN\n 4                8                   8                  0         NaN\n 5               10                   9                  0         NaN\n 6                9                   7                  0         NaN\n 7                8                   7                  0         365\n 8               10                   8                  1         NaN\n 9                8                   8                  1         NaN\n10                8                   7                  0          30\n# … with 224 more rows\n\nMEAN_OUTDAY is NaN (not a number) if no methods were out of stock.\nSummarize Variable Groups by EAID\nIn our last post, we mentioned that the best use case for SDP data is to aggregate information collected from facilities working in the same geographic sampling units - or enumeration areas - used to select individuals for PMA Household and Female samples. In our next post, we’ll take a close look at the variable group EASERVED, which lists all of the enumeration area codes where a facility is known to provide health services. We’ll then introduce a strategy using tidyr::pivot_longer to summarize the full scope of services available to women living in a particular enumeration area.\nFor now, let’s simply consider all of the sampled facilities located in a particular enumeration area. That is, rather than calculating the number of methods provided by one facility NUM_METHODS_PROV, let’s create one variable for each method indicating whether the method was provided by at least one facility in a given enumeration area EAID in a given SAMPLE.\nFor instance, look at the number of facilities providing IUDs in enumeration area 7111 for the Burkina Faso sample collected in 2017:\n\n\nsdp %>% \n  filter(EAID == 7111, SAMPLE == 85405) %>% \n  select(EAID, SAMPLE, FACILITYID, PILLPROV)\n\n\n# A tibble: 4 x 4\n   EAID                            SAMPLE FACILITYID  PILLPROV\n  <dbl>                         <int+lbl>  <int+lbl> <int+lbl>\n1  7111 85405 [Burkina Faso 2017 Round 5]       7210   1 [Yes]\n2  7111 85405 [Burkina Faso 2017 Round 5]       7029   0 [No] \n3  7111 85405 [Burkina Faso 2017 Round 5]       7441   1 [Yes]\n4  7111 85405 [Burkina Faso 2017 Round 5]       7403   1 [Yes]\n\nWe want to use a summarize function to create a variable like ANY_PILLPROV, which should simply indicate whether any of these four facilities provide contraceptive pills. Three of them do provide pills, so we want ANY_PILLPROV to be TRUE.\n\n\nsdp %>% \n  filter(EAID == 7111, SAMPLE == 85405) %>% \n  summarize(ANY_PILLPROV = any(PILLPROV == 1))\n\n\n# A tibble: 1 x 1\n  ANY_PILLPROV\n  <lgl>       \n1 TRUE        \n\nNow that we’re familiar with across, we should be able to do the same thing to all PROV variables for this particular group of facilities. Let’s also introduce a naming convention where we glue the prefix ANY_ to the column name referenced by the pronoun .x:\n\n\nsdp %>% \n  filter(EAID == 7111, SAMPLE == 85405) %>% \n  summarize(across(ends_with(\"PROV\"), ~any(.x == 1), .names = \"ANY_{.col}\"))\n\n\n# A tibble: 1 x 13\n  ANY_CONPROV ANY_CYCBPROV ANY_DEPOPROV ANY_DIAPROV ANY_EMRGPROV\n  <lgl>       <lgl>        <lgl>        <lgl>       <lgl>       \n1 TRUE        TRUE         TRUE         FALSE       FALSE       \n# … with 8 more variables: ANY_FCPROV <lgl>, ANY_FSTPROV <lgl>,\n#   ANY_FJPROV <lgl>, ANY_IMPPROV <lgl>, ANY_IUDPROV <lgl>,\n#   ANY_MSTPROV <lgl>, ANY_PILLPROV <lgl>, ANY_SAYPROV <lgl>\n\n\nIt looks like none of the sampled facilities in enumeration area 7111 provided emergency contraception in 2017. This could be very important context for understanding the health services available to women sampled from that area!\nLet’s repeat the same procedure for every enumeration area in each of our samples. Rather than using a filter to select one EAID in one SAMPLE, we’ll use group_by to work with each EAID in each SAMPLE.\n\n\nsdp %>% \n  group_by(EAID, SAMPLE) %>% \n  summarize(\n    .groups = \"keep\",\n    across(ends_with(\"PROV\"), ~any(.x == 1), .names = \"ANY_{.col}\")\n  )\n\n\n# A tibble: 142 x 15\n# Groups:   EAID, SAMPLE [142]\n    EAID      SAMPLE ANY_CONPROV ANY_CYCBPROV ANY_DEPOPROV ANY_DIAPROV\n   <dbl>   <int+lbl> <lgl>       <lgl>        <lgl>        <lgl>      \n 1  7003 85405 [Bur… TRUE        TRUE         TRUE         FALSE      \n 2  7003 85408 [Bur… TRUE        TRUE         TRUE         FALSE      \n 3  7006 85405 [Bur… TRUE        TRUE         TRUE         FALSE      \n 4  7006 85408 [Bur… TRUE        TRUE         TRUE         FALSE      \n 5  7009 85405 [Bur… TRUE        FALSE        TRUE         FALSE      \n 6  7009 85408 [Bur… TRUE        TRUE         TRUE         FALSE      \n 7  7016 85405 [Bur… TRUE        TRUE         TRUE         FALSE      \n 8  7016 85408 [Bur… TRUE        TRUE         TRUE         FALSE      \n 9  7026 85405 [Bur… TRUE        TRUE         TRUE         FALSE      \n10  7042 85405 [Bur… TRUE        TRUE         TRUE         FALSE      \n# … with 132 more rows, and 9 more variables: ANY_EMRGPROV <lgl>,\n#   ANY_FCPROV <lgl>, ANY_FSTPROV <lgl>, ANY_FJPROV <lgl>,\n#   ANY_IMPPROV <lgl>, ANY_IUDPROV <lgl>, ANY_MSTPROV <lgl>,\n#   ANY_PILLPROV <lgl>, ANY_SAYPROV <lgl>\n\nThis is still quite a bit of information! Suppose we want to summarize it even further: let’s calculate NUM_METHODS_PROV again with our summary output. This time, NUM_METHODS_PROV will count the number of methods provided by at least one facility in each group.\n\n\nsdp %>% \n  group_by(EAID, SAMPLE) %>% \n  summarize(\n    .groups = \"keep\",\n    across(ends_with(\"PROV\"), ~any(.x == 1), .names = \"ANY_{.col}\")\n  ) %>% \n  transmute(NUM_METHODS_PROV= sum(c_across(ends_with(\"PROV\")), na.rm = T))\n\n\n# A tibble: 142 x 3\n# Groups:   EAID, SAMPLE [142]\n    EAID                            SAMPLE NUM_METHODS_PROV\n   <dbl>                         <int+lbl>            <int>\n 1  7003 85405 [Burkina Faso 2017 Round 5]                8\n 2  7003 85408 [Burkina Faso 2018 Round 6]                8\n 3  7006 85405 [Burkina Faso 2017 Round 5]                8\n 4  7006 85408 [Burkina Faso 2018 Round 6]                8\n 5  7009 85405 [Burkina Faso 2017 Round 5]                8\n 6  7009 85408 [Burkina Faso 2018 Round 6]               10\n 7  7016 85405 [Burkina Faso 2017 Round 5]                8\n 8  7016 85408 [Burkina Faso 2018 Round 6]                8\n 9  7026 85405 [Burkina Faso 2017 Round 5]                8\n10  7042 85405 [Burkina Faso 2017 Round 5]               10\n# … with 132 more rows\n\nThese summaries are exactly the type of SDP data we’d like to attach to a Household and Female dataset! Watch for our next post, where we’ll show how to create summaries by both EAID and EASERVED, and then match them to records from female respondents sampled from Burkina Faso in 2017 and 2018.\n\n\n\n",
    "preview": "posts/2021-01-28-across-sdp/images/logos.png",
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {},
    "preview_width": 960,
    "preview_height": 540
  },
  {
    "path": "posts/2021-01-26-sdp-data/",
    "title": "Service Delivery Point Data Explained",
    "description": "SDP samples are not nationally representative. Learn how to use them to describe the health service environment experienced by individuals.",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2021-01-26",
    "categories": [
      "Individuals in Context",
      "Data Discovery",
      "Service Delivery Points"
    ],
    "contents": "\n\nContents\nWhat is an SDP?\nSurvey Topics\nSample Design\n\n\n\n\nWhen you visit pma.ipums.org and begin browsing data, you’ll notice that PMA data are available for several different units of analysis.\nYou can see which unit of analysis you’re currently browsing - or switch to a different unit of analysis - in this box:\n\n\n\nClick CHANGE, and you’ll see the different units of analysis that are available:\n\n\n\nThis Data Discovery post kicks off a series of posts all about the data available for the Family Planning - Service Delivery Point unit of analysis. As you’ll see, these data are meant to provide important context for the individuals included in the Family Planning - Person series: while SDP data are not nationally representative, they can help provide a rich portrait of the health service environment experienced by women and households.\nYou’ll find more blog posts about SDP data by following the Individuals in Context series. Look for upcoming posts about:\nWorking with variable groups created from multiple response questions\nMerging SDP summary data with Household and Female data\nMapping SDP Data with GPS Data from our partners at pmadata.org\nMerging SDP Data with spatial datasets from external sources\nAn example of the sort of spatial analysis you can perform with SDP data\nWhat is an SDP?\nA Service Delivery Point (SDP) is any type of facility that provides health services to a community: you’ll find a breakdown of the available facility types for each sample listed in FACILITYTYPE. Because countries may include regionally-specific facility types, we’ve integrated major groupings together in the variable FACILITYTYPEGEN. For example, you may find SDP data available from any of these general facility types:\nHospitals\nHealth Centers\nHealth Clinics\nOther Health Facilities\nPrivate Practices\nDispensaries\nPharmacies / Chemists / Drug Shops\nBoutiques / Shops\nOther\nPMA samples SDPs managed by governments, NGOs, faith-based organizations, private sector organizations, and a range of other institutions. You’ll find the managing authority for each SDP listed in AUTHORITY.\nSurvey Topics\nWhile all SDP surveys cover similar topics, individual questions may be posed somewhat differently - or not at all - for any given sample. That’s where IPUMS PMA comes in: we harmonize differences across samples and document the availability of every variable for each sample.\n\nYou’ll find the full text PDF of the original questionnaire administered to all SDPs in a particular sample here.\nIPUMS PMA also organizes SDP variables by topic. These topics currently include:\nFacility Characteristics\nGeneral Facility Characteristics\nGeography\nAreas Served\nStaffing\nMedical Equipment\nFunding\nManagement\nPerformance Feedback\nQuality of Care\nService Statistics\nMedical Records\nTransportation\n\nFamily Planning Services\nServices Provided\nContraceptive Stock\nReason for Stockout\nClients Served\nStock Supplier\nFees\nFacility Condition\n\nOther Health Services\nAbortion\nPost-abortion Care\nSTDs\nAntenatal Care\nLabor and Delivery\nPostpartum Care\nDelivery Medicines\nCommunity Health Workers\nVaccinations\nHealth Programs\nMedicines in Stock\nOther\n\nThese are listed in the TOPICS menu and are subject to growth & reorganization.\n\n\n\nAdditionally, there are a number of technical variables related to survey administration. For example, every SDP included in the sample frame receives a unique FACILITYID (this ID is preserved across survey rounds if a facility is surveyed more than once). However, some facilities never responded to the questionnaire if, for example, no individual respondent was present, competent, and available to be interviewed (see AVAILABLESQ); if no such person was available - or if such a person declined the interview - the variable CONSENTSQ will indicate that survey consent was never obtained. The variable RESULTSQ indicates whether the questionnaire was fully completed or, if not, it provides the reason.\nFor SDPs where CONSENTSQ is “No”, most variables will take the value “Not interviewed (SDP questionnaire)”.\nNote that the value “NIU (not in universe)” pertains to SDPs that were intentionally skipped because a question was deemed out-of-scope.\nYou may choose whether to include SDPs where RESULTSQ indicates that the questionnaire was not fully completed. Click CREATE DATA EXTRACT from you Data Cart:\n\n\n\nThen click CHANGE next to Sample Members:\n\n\n\nFinally, choose whether to include only “Facility Respondents” (those who fully completed the questionnaire), or “All Cases” instead:\n\n\n\nSample Design\nSo what conclusions can you draw from SDP data? First, it’s important to note that the SDP sample design is not nationally representative, and there are no sampling weights for SDP data.1 In other words, it is not possible to get a sense of the national health services profile in a particular country using SDP data.\nInstead, facilities were selected for the SDP survey using the same geographic enumeration areas used to select households for each Household and Female survey. To see how this works, let’s look at an example dataset collected from Burkina Faso in 2017, beginning with the set of female respondents to the Household questionnaire (other household members and female non-respondents have been excluded):\nRead more about the Household and Female sampling strategy.\n\n\nlibrary(tidyverse)\n\nbf17_hhf <- ipumsr::read_ipums_micro(\n  ddi = \"data/pma_00011.xml\",\n  data = \"data/pma_00011.dat.gz\") %>% \n  filter(YEAR == 2017)\n\n\n\nCheck out our posts on R Packages and Loading IPUMS PMA data into R.\nTo use this code, be sure to change both file paths to match your own extract!\nThe Dataset Notes for this sample describe a two-stage cluster design with urban-rural strata, producing a sample of women from 83 enumeration areas. If we count the number of unique values from EAID in our data, we see that there are 83 unique identification numbers - one for each enumeration area:\n\n\nn_distinct(bf17_hhf$EAID)\n\n\n[1] 83\n\nWe can also see how these enumeration areas are distributed throughout the 13 administrative regions of Burkina Faso. Note that we have more enumeration areas in the Central region (including the capital, Ouagadougou), and we have fewer enumeration areas in regions where the population is lower (Centre-Sud, Plateau-Central, Sud-Ouest, etc.):\n\n\nbf17_hhf %>% \n  group_by(GEOBF) %>% \n  summarize(.groups = \"keep\", n_EAID = n_distinct(EAID)) %>% \n  arrange(n_EAID)\n\n\n# A tibble: 13 x 2\n# Groups:   GEOBF [13]\n                    GEOBF n_EAID\n                <int+lbl>  <int>\n 1  7 [Centre-Sud]             2\n 2 11 [Plateau-Central]        3\n 3 13 [Sud-Ouest]              3\n 4  2 [Cascades]               4\n 5 12 [Sahel]                  4\n 6  5 [Centre-Nord]            5\n 7  4 [Centre-Est]             6\n 8 10 [Nord]                   6\n 9  1 [Boucle du Mouhoun]      7\n10  6 [Centre-Ouest]           7\n11  8 [Est]                    7\n12  9 [Hauts-Bassins]         11\n13  3 [Centre]                18\n\nAlthough the same number of households are randomly selected from within each enumeration area (typically 35), this concentration of enumeration areas within population-dense regions helps to ensure that the Household and Female data are nationally representative.\nLet’s now look at the sample of SDPs collected from Burkina Faso in that same year:\n\n\nbf17_sdp <- ipumsr::read_ipums_micro(\n  ddi = \"data/pma_00008.xml\",\n  data = \"data/pma_00008.dat.gz\") %>% \n  filter(YEAR == 2017)\n\n\n\n\nRemember: to use this code, be sure to change both file paths to match your own extract!\nDataset Notes for the SDP sample explain that the same 83 enumeration areas used in the Household and Female Sample were used to select facilities for the SDP sample. Moreover, we can confirm that all of enumeration areas in the SDP data also appear in the HHF data:\n\n\nall(bf17_sdp$EAID %in% bf17_hhf$EAID)\n\n\n[1] TRUE\n\nBut is the reverse true? Is every enumeration area from the Household and Female Sample represented in the SDP data?\n\n\nall(bf17_hhf$EAID %in% bf17_sdp$EAID)\n\n\n[1] FALSE\n\nPerhaps surprisingly, the answer is no. To learn why, we have to dig a bit deeper into the SDP Dataset Notes. There, we see that a facility located within the physical boundaries of one of the 83 enumeration areas from the Household and Female Survey would have been included in the SDP sample. However, there may be enumeration areas - particularly in remote areas - where no facilities are located.\nFortunately, PMA also includes data about the service catchment area for some facilities.2 You can include this information by selecting the variable series EASERVED. If a given facility serves more than one enumeration area, EASERVED1 will contain the enumeration area ID code for the first enumeration area on its catchment list, EASERVED2 will contain the ID code for the second one, and so forth. If that same facility serves 5 enumeration areas, the variables EASERVED6, EASERVED7, and so forth would be “NIU (not in universe)”.\n\nThe IPUMS PMA extract system automatically determines the right maximum number of EASERVED variables by finding the facility with the largest service catchment list in your extract.\nWhat does this mean? As we’ll show in an upcoming post in this series, it’s possible to create a portrait of the health service environment provided to individuals sampled in the Household and Female surveys. This portrait extends beyond the list of facilities located in an individual’s geographic enumeration area, but users should take care to understand that the scope of facilities providing services to that enumeration area is somewhat limited by sample design.\n\nThe files do contain a weight variable for the sampling units EAWEIGHT, which is a probability weight representing the likelihood of an enumeration area being selected for sampling. The collectors of the original data do not recommend using EAWEIGHT to weight SDP variables.↩︎\nThis information is only available for SDPs where the managing authority listed in AUTHORITY is “government”.↩︎\n",
    "preview": "posts/2021-01-26-sdp-data/images/choose-unit.png",
    "last_modified": "2022-04-13T13:10:45-04:00",
    "input_file": {},
    "preview_width": 909,
    "preview_height": 632
  },
  {
    "path": "posts/2020-12-10-get-ipums-pma-data/",
    "title": "Import IPUMS PMA Data into R",
    "description": "How to download an IPUMS PMA data extract and start using it in R",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2020-11-10",
    "categories": [
      "R Tips",
      "R Packages",
      "Importing Data"
    ],
    "contents": "\n\nContents\nHow to access the data\nUser Guide\nYouTube Tutorials\n\nImporting the data\nFixed-width Data Format (dat)\nThe ipumsr package\n\n\nIPUMS PMA is the harmonized version of the multinational survey Performance Monitoring for Action (formerly known as Performance Monitoring and Accountability 2020 - PMA2020). IPUMS PMA lets researchers easily browse the contents of the survey series and craft customized microdata files they download for analysis.\nHow to access the data\nUser Guide\nVisit the IPUMS PMA data dissemination website to browse the available data, and then follow the posted user guide to get started with an extract of interest.\nNote: all users must register for a free account. See user guide for details.\nYouTube Tutorials\nVisit the IPUMS PMA YouTube page for a video playlist showing how to do things like:\nregister for a free IPUMS account\nselect from the available units of analysis\nbuild a data extract\nselect cases of interest\nuse the available survey weights\nImporting the data\nFixed-width Data Format (dat)\nOnce you have registered and finished selecting PMA samples and variables for your extract, click the “View Cart” button to begin checkout.\nReview the contents of your extract and clik the “Create Data Extract” button as shown:\n\n\n\nOn this final page be sure to change the data format to “.dat (fixed-width text)” if it is not selected by default:\n\n\n\nYou will receive an email when your extract request has been processed. Click the included link to find a download page like this one. You must download both the data file and the DDI codebook:\n\n\n\nThe ipumsr package\nThe R package ipumsr provides the tools you will need to import the data file and DDI codebook into R. You can install the package from CRAN with:\n\nClick here for more information on R packages.\ninstall.packages(\"ipumsr\")\nNote the location where your data file and DDI codebook were saved (in my case, they were saved in my local “Downloads” folder). Substitute your own paths into the function shown below:\n\n\ndat <- ipumsr::read_ipums_micro(\n  ddi = \"~/Downloads/pma_00001.xml\",\n  data_file = \"~/Downloads/pma_00001.dat.gz\"\n)\n\n\n\nYou’re done! The dataset is now accessible as the R object, dat.\n\n\n\n",
    "preview": "posts/2020-12-10-get-ipums-pma-data/images/create-data-extract.png",
    "last_modified": "2022-04-13T13:10:44-04:00",
    "input_file": {},
    "preview_width": 910,
    "preview_height": 790
  },
  {
    "path": "posts/2020-12-10-get-r-and-packages/",
    "title": "Getting Started with R",
    "description": "How to download R for free and install some of the R packages used on this blog",
    "author": [
      {
        "name": "Matt Gunther",
        "url": {}
      }
    ],
    "date": "2020-11-02",
    "categories": [
      "R Tips",
      "R Packages"
    ],
    "contents": "\n\nContents\nWhy analyze PMA data with R?\nGetting started with R\nOur favorite resources\n\nDo I really need statistical software?\nAre there alternatives?\n\nRStudio\nR packages\nEssentials\nipumsr\ntidyverse\nshiny\n\nWatch for updates here\n\n\nWhy analyze PMA data with R?\nLike all IPUMS data projects, IPUMS PMA data is available free of charge to users who agree to our terms of use. That’s because we believe that cost and institutional affiliation should not be barriers to answering pressing concerns around women’s health. (You can register here for a free IPUMS PMA user account.)\nIn fact, users can analyze IPUMS PMA data with any software they like! We’ve chosen to highlight R, in particular, because it is also free and popular with data analysts throughout the world. It’s available for Windows, MacOS, and a wide variety of UNIX platforms and similar systems (including FreeBSD and Linux).\nNon-R users: IPUMS data extracts are available as CSV or fixed-width DAT with syntax files formatted for SPSS, Stata, and SAS.\nGetting started with R\nTo get a copy of R for yourself, visit the Comprehensive R Archive Network (CRAN) and choose the right download link for your operating system.\nIf you’re new to R (or want to refresh your skills), we recommend the excellent, free introductory text R for Data Science. It also introduces tidyverse conventions, which we use throughout this blog.\nOur favorite resources\nR for Data Science, for beginners\nAdvanced R, for a deeper dive\nRSpatial, for analysis with spatial data\nggplot2, for data visualization\nMastering Shiny, for interactive applications\nR Markdown: The Definitive Guide, for producing annotated code, word documents, presentations, web pages, and more\nR-bloggers, for regular news and tutorials\n\n\n\n\n© 2016 The R Foundation (CC-BY-SA 4.0)\nDo I really need statistical software?\nIf you’re new to data analysis, you might wonder exactly what you’re going to find in a toolkit like R.\nPlenty of people come to R after working with more common types of data analysis software, like Microsoft Excel or other spreadsheet programs. If you wanted to, you could absolutely download a CSV file from the IPUMS PMA extract system and open it in Excel. You would find individual respondents in rows and their responses for variables in columns, and you could make use of built-in spreadsheet functions to do things like:\nCalculate and visualize the distribution of a variable\nBuild pivot tables and graphs examining basic relationships between variables\nCreate new variables of your own that combine data from several variables\nHowever, you might also notice that a spreadsheet comes with certain limitations:\nThere is no variable “metadata”, including labels for the variables and each response option. For example, you might see that the responses to a certain variable include the numbers 0, 1, and 99 - what do these values actually mean?\nYou might find yourself repeating the same “point” and “click” procedure over and over. Or, maybe you’ve had to build a library of custom macro functions on your own to help automate those procedures.\nWhile you can perform arithmetic with built-in functions, there is little support for more advanced statistical procedures\nGraphics are limited within a set of pre-built templates\nMerging data from external sources (like spatial data) can be very tricky\nStatistical software is designed specifically to address these and other issues related to data cleaning and analysis. Learning a program like R takes a lot of practice, but doing so will almost certainly make your work much more efficient!\nAre there alternatives?\nYes! Many data analysts use proprietary statistical software like Stata, SAS, or SPSS. These tools are also powerful, and you may even find them easier to use than R.\n\nComing soon, we hope to include Stata code for many of the blog posts currently written in R.\nBeyond price, R has a few additional advantages that make it a particularly useful tool for working with PMA data:\nCommunity support: R users are particularly active on forums like Stack Overflow and R-bloggers. Groups like R-ladies even organize in-person meetups in cities around the world to help promote inclusion within the R community.\nCustomizability: Because R is open-source, you can change just about anything you like! With a little practice, you’ll be able to create functions and graphics that perfectly match your own needs.\nBeyond statistics: You can use R to build a website (like this one), manage and share a code repository on GitHub, scrape and compile a social media database, or automatically generate word documents, slide presentations, and more! There are practically endless ways to use functional programming in R that have nothing to do with statistics at all.\nIf you’re a beginner, learning R can be a daunting task. Keep at it! And never hesitate to ask questions.\nRStudio\nWe strongly recommend running R within RStudio, an integrated development environment (IDE) designed to make your experience with R much easier. Some of the reasons we use it, ourselves:\nIncludes a multi-pane window that puts your R console, source code, output, and help files all in one place\nSyntax highlighting and code completion\nSupport for R Projects, a crucial approach to organizing your work and sharing it with others\nIncludes RMarkdown, an R package that allows you write text-based documents with embedded snippets of code that can be passed directly to your R console\nComing soon: tools like the command palette, an improved package manager, and integrated citation management\nLike R, it is available at no cost for users on Windows, Mac, and Linux\n\nThis blog is, itself, an R Project with an individual R Markdown file for each page on the site. Look for a download button at the top of every post: you can download the original R Markdown file, open it in RStudio, and run all of the included code.\nR packages\nAn R package is a collection of functions created by other R users that you can download and install for yourself. Packages can be distributed in many ways, but all of the packages we highlight on this blog can be downloaded from CRAN (the same resource used to download “base” R). A package like ipumsr can be downloaded from CRAN by typing the following function into the R console:\n\nThis function saves package files in your default “library” location. If you’re using a Linux machine and don’t have root access, you’ll need to set up R to save packages to a location where you’re able to write files.\n\n\ninstall.packages(\"ipumsr\")\n\n\n\nPackages also come with help files detailing the purpose and possible inputs (or “arguments”) of each included function. Other included metadata explains what version of R you’ll need to use the package, and also whether the package borrows functions from any other packages that should also be installed (usually these are called “dependencies”).\nIn order to access the functions and help files for a package, you need to load it after installation with:\n\n\nlibrary(ipumsr)\n\n\n\nOn this blog, we will often show functions together with their package like this:\n\n\nipumsr::read_ipums_micro(\n  ddi = \"~/Downloads/pma_00001.xml\",\n  data_file = \"~/Downloads/pma_00001.dat.gz\"\n)\n\n\n\nThe function read_ipums_micro comes from the package ipumsr. It is not necessary for you to include the package each time you call a function (as long as you’ve already loaded the package with library()); we’re using this notation simply as a reminder (in case you want to consult the original package documentation).\n\nYou can use the package::function() notation if you ever want to access a function from a package without loading everything else in the package.\nEssentials\nHere are the packages you’ll need to install to reproduce the code on this blog:\nipumsr\nThe ipumsr package contains functions that make it easy to load IPUMS PMS data into R (mainly read_ipums_micro).\nIt also contains functions that will return variable metadata (like the variable descriptions you see while browsing for data on pma.ipums.org.\ntidyverse\nThe tidyverse package actually installs a family of related packages, including:\nggplot2, for data visualization\ndplyr, for data manipulation\ntidyr, for data tidying\nreadr, for data import\npurrr, for functional programming\ntibble, for tibbles (a modern re-imagining of data frames)\nstringr, for strings\nforcats, for factors\nThis blog uses tidyverse functions and syntax wherever possible because so-called “tidy” conventions are designed with the expressed purpose of making code and console output more human readable. Sometimes, human readability imposes a performance cost: in our experience, IPUMS PMA datasets are small enough that this is not an issue.\n\nFor larger datasets, we recommend exploring the package data.table.\nshiny\nInteractive graphics shown throughout this blog are built with the shiny package.\nWatch for updates here\nWe may add more package suggestions for future posts!\n\n\n\n",
    "preview": {},
    "last_modified": "2022-04-13T13:10:44-04:00",
    "input_file": {}
  }
]
